{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jvvfb1riBioe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "from torch import nn, optim \n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.utils.data\n",
    "import time\n",
    "import itertools\n",
    "import glob \n",
    "from PIL import Image\n",
    "import csv \n",
    "import cv2\n",
    "import re\n",
    "import torchvision\n",
    "import random\n",
    "from xml.etree import ElementTree\n",
    "from torchvision.ops.boxes import box_iou\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sarthak/DataSets/ILSVRC2015/EfficientDet.Pytorch-Updated\n",
      "/home/sarthak/DataSets/ILSVRC2015\n"
     ]
    }
   ],
   "source": [
    "#Packages commonly needed to install pycocotools, tqdm, and requests.\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "%cd EfficientDet.Pytorch-Updated/\n",
    "import math\n",
    "from models.efficientnet import EfficientNet\n",
    "from models.bifpn import BIFPN\n",
    "from models.retinahead import RetinaHead\n",
    "from models.module import RegressionModel, ClassificationModel, Anchors, ClipBoxes, BBoxTransform\n",
    "from torchvision.ops import nms\n",
    "from models.losses import FocalLoss\n",
    "from models.efficientdet import EfficientDet\n",
    "from models.losses import FocalLoss\n",
    "from datasets import VOCDetection, CocoDataset, get_augumentation, detection_collate, Resizer, Normalizer, Augmenter, collater\n",
    "from utils import EFFICIENTDET, get_state_dict\n",
    "from eval import evaluate, evaluate_coco\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Ranger-Deep-Learning-Optimizer' already exists and is not an empty directory.\n",
      "/home/sarthak/DataSets/ILSVRC2015/Ranger-Deep-Learning-Optimizer\n",
      "Obtaining file:///home/sarthak/DataSets/ILSVRC2015/Ranger-Deep-Learning-Optimizer\n",
      "Requirement already satisfied: torch in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from ranger==0.1.dev0) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch->ranger==0.1.dev0) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch->ranger==0.1.dev0) (3.7.4.3)\n",
      "Installing collected packages: ranger\n",
      "  Attempting uninstall: ranger\n",
      "    Found existing installation: ranger 0.1.dev0\n",
      "    Uninstalling ranger-0.1.dev0:\n",
      "      Successfully uninstalled ranger-0.1.dev0\n",
      "  Running setup.py develop for ranger\n",
      "Successfully installed ranger\n",
      "/home/sarthak/DataSets/ILSVRC2015\n",
      "fatal: destination path 'sam' already exists and is not an empty directory.\n",
      "/home/sarthak/DataSets/ILSVRC2015/sam\n",
      "Imported SAM Successfully from github .py file\n",
      "/home/sarthak/DataSets/ILSVRC2015\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
    "%cd Ranger-Deep-Learning-Optimizer\n",
    "!pip install -e .\n",
    "from ranger import Ranger  \n",
    "%cd ..\n",
    "#https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1\n",
    "!git clone https://github.com/davda54/sam.git\n",
    "%cd sam\n",
    "import sam\n",
    "print(\"Imported SAM Successfully from github .py file\")\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPKm4C39fzGD"
   },
   "source": [
    "## To DO \n",
    "\n",
    "### Configure fast rcnn model for training overnight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Fix the metric creating of Effecient Det Model. \n",
    "\n",
    "* Fix assertion when trying to predict on an image.\n",
    "* Try different learning rates and see what gets constant improvement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Goal:\n",
    "\n",
    "Get acceptable resukts with a rcnn torchvision model\n",
    "Get acceptable results with effecient det\n",
    "\n",
    "### Some Errors I get\n",
    "\n",
    "Value Error in Det dataset\n",
    "Model sometimes gets error while running on data.\n",
    "\n",
    "### Advice\n",
    "\n",
    "Try to start with simplest (Adam basics) and keep on adding stuff to improve mAP\n",
    " How much data 57 k in Det dataset\n",
    " Full validation has 170,00 but use \n",
    " \n",
    " * (2,000 images in valid loader).\n",
    "* 10 - 15 images per folder.\n",
    "\n",
    "Great Proportions is that around 35 - 40% should be the Det Dataset and 60 - 65 % should be the sampled VID Dataset. \n",
    "\n",
    "### Get better results\n",
    "\n",
    "* Reduce dataset to 5000 train images and 500 valid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "collapsed": true,
    "id": "G9vLpqYsehKW",
    "outputId": "5ae89189-d6ba-4cdd-d080-4a77f7c5a410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: PyYAML in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: scipy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (1.19.2)\n",
      "Requirement already satisfied: Shapely in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: six in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: imageio in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (8.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "juEv3bvw0yYp"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXvczm7BMhQw"
   },
   "outputs": [],
   "source": [
    "def get_class_info(get_keys = False, smaller_mb_net = False):\n",
    "    obj_dict = {\n",
    "    \"n02691156\": \"airplane\", \n",
    "    \"n02419796\": \"antelope\", \n",
    "    \"n02131653\": \"bear\", \n",
    "    \"n02834778\": \"bicycle\", \n",
    "    \"n01503061\": \"bird\", \n",
    "    \"n02924116\": \"bus\", \n",
    "    \"n02958343\": \"car\", \n",
    "    \"n02402425\": \"cattle\", \n",
    "    \"n02084071\": \"dog\", \n",
    "    \"n02121808\": \"domestic_cat\", \n",
    "    \"n02503517\": \"elephant\", \n",
    "    \"n02118333\": \"fox\",\n",
    "    \"n02510455\": \"giant_panda\", \n",
    "    \"n02342885\": \"hamster\", \n",
    "    \"n02374451\": \"horse\", \n",
    "    \"n02129165\": \"lion\", \n",
    "    \"n01674464\": \"lizard\", \n",
    "    \"n02484322\": \"monkey\", \n",
    "    \"n03790512\": \"motorcycle\", \n",
    "    \"n02324045\": \"rabbit\",\n",
    "    \"n02509815\": \"red_panda\", \n",
    "    \"n02411705\": \"sheep\", \n",
    "    \"n01726692\": \"snake\", \n",
    "    \"n02355227\": \"squirrel\", \n",
    "    \"n02129604\": \"tiger\", \n",
    "    \"n04468005\": \"train\", \n",
    "    \"n01662784\": \"turtle\", \n",
    "    \"n04530566\": \"watercraft\", \n",
    "    \"n02062744\": \"whale\",\n",
    "    \"n02391049\": \"zebra\"\n",
    "    }\n",
    "    \n",
    "    if get_keys:\n",
    "        return list(obj_dict.keys())\n",
    "    \n",
    "    return obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameDataset():\n",
    "    \n",
    "    def __init__(self, mode, vid_data_root_dir, vid_annotations_root_dir, transforms, seg_len = None, \n",
    "               make_valid_smaller_percent = None, effdet_data = None, rcnn_big = None, det_text_file_paths = None, \n",
    "               data_size = None):\n",
    "                 \n",
    "        \n",
    "    # If valid smaller is true cut the length of valid list to certain length with if statement. \n",
    "        if (mode == \"train\"):\n",
    "            if (seg_len):\n",
    "                ORIG_SEG_LEN = seg_len\n",
    "                #Subset images from every scene there are 3862 data folders.\n",
    "                print(\"There are 1122397 train images in total\")\n",
    "                globbed_image_file_paths = sorted(glob.glob(\"{}/*/*\".format(vid_data_root_dir)))\n",
    "                globbed_annotations_file_paths = sorted(glob.glob(\"{}/*/*\".format(vid_annotations_root_dir)))\n",
    "                \n",
    "                self.image_file_paths, self.annotations_file_paths = list(), list()\n",
    "                \n",
    "                for folder in list(zip(globbed_image_file_paths, globbed_annotations_file_paths)):\n",
    "                    scene_images = sorted(glob.glob(\"{}/*.JPEG\".format(folder[0])))\n",
    "                    scene_annotations = sorted(glob.glob(\"{}/*.xml\".format(folder[1])))\n",
    "                    \n",
    "                    image_annot = list(zip(scene_images, scene_annotations))\n",
    "\n",
    "                    if seg_len % 5 != 0:\n",
    "                        raise ValueError(\"Not allowed value for seg_len must be divisible by 5\")\n",
    "                    if seg_len >= len(image_annot):\n",
    "                        seg_len = 5\n",
    "                    \n",
    "                    if len(image_annot) % seg_len != 0:\n",
    "                        image_annot = image_annot[:-(len(image_annot) % seg_len)]\n",
    "                    \n",
    "                    red_img_annot, start_index = list(), 0 \n",
    "                    \n",
    "                    for window in range(int(len(image_annot) / seg_len)):\n",
    "                        end_index = start_index + seg_len\n",
    "                        red_img_annot.append(image_annot[end_index - 1])\n",
    "                        #red_img_annot.append(random.sample(image_annot[start_index : end_index], 1)[0])\n",
    "                        start_index = end_index\n",
    "                    \n",
    "                   \n",
    "                    scene_images, scene_annotations = zip(*red_img_annot) \n",
    "                    \n",
    "                    self.annotations_file_paths.extend(scene_annotations)\n",
    "                    self.image_file_paths.extend(scene_images)\n",
    "                    \n",
    "                    seg_len = ORIG_SEG_LEN\n",
    "                    \n",
    "            else:\n",
    "                self.image_file_paths = sorted(glob.glob(\"{}/*/*/*.JPEG\".format(vid_data_root_dir))) \n",
    "                self.annotations_file_paths = sorted(glob.glob(\"{}/*/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "            \n",
    "        elif (mode == \"validation\"):\n",
    "            if make_valid_smaller_percent:\n",
    "                #Subset a percent of the valid data\n",
    "                valid_image_list = sorted(glob.glob(\"{}/*/*.JPEG\".format(vid_data_root_dir)))\n",
    "                valid_annotations_list = sorted(glob.glob(\"{}/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "\n",
    "                subset = int(len(valid_image_list) * make_valid_smaller_percent)\n",
    "\n",
    "                #Shuffle both lists at once with same order\n",
    "                mapIndexPosition = list(zip(valid_image_list, valid_annotations_list))\n",
    "                random.shuffle(mapIndexPosition)\n",
    "                valid_image_list, valid_annotations_list = zip(*mapIndexPosition)\n",
    "                valid_image_list, valid_annotations_list = list(valid_image_list), list(valid_annotations_list)\n",
    "\n",
    "                self.image_file_paths = valid_image_list[:subset]\n",
    "                self.annotations_file_paths = valid_annotations_list[:subset]\n",
    "            else:\n",
    "                self.image_file_paths = sorted(glob.glob(\"{}/*/*.JPEG\".format(vid_data_root_dir))) \n",
    "                self.annotations_file_paths = sorted(glob.glob(\"{}/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "        else:\n",
    "            raise ValueError(\"Choose mode between train or validation only\")\n",
    "\n",
    "        self.labels_key = get_class_info(get_keys = True)\n",
    "\n",
    "        self.data_size = data_size\n",
    "        self.transforms = transforms\n",
    "        self.effdet_data = effdet_data\n",
    "        self.rcnn_big = rcnn_big\n",
    "        \n",
    "        if det_text_file_paths:\n",
    "            home_file_path_data = \"/data1/group/mlgroup/train_data/ILSVRC2015/Data/DET/\"\n",
    "            home_file_path_annot = \"/data1/group/mlgroup/train_data/ILSVRC2015/Annotations/DET/\"\n",
    "            \n",
    "            assert len(self.image_file_paths) == len(self.annotations_file_paths)\n",
    "            print(\"\\n\")\n",
    "            print(\"BEFORE DET: Amount of image files in Dataset {}\".format(len(self.image_file_paths)))\n",
    "            print(\"BEFORE DET: Amount of annotation files in Dataset {} \\n\".format(len(self.annotations_file_paths)))\n",
    "            det_txt = open(det_text_file_paths, \"r\").readlines()\n",
    "            np.random.shuffle(det_txt)\n",
    "            \n",
    "            #I am gonna sample about 10k images or around 20% of Det Dataset\n",
    "            det_txt = det_txt[:int(len(det_txt) * 0.25)]\n",
    "            print(\"Amount of images in Det Set (Approx.) {}\".format(len(det_txt)))\n",
    "            \n",
    "            for line in det_txt:\n",
    "                self.image_file_paths.append((home_file_path_data + line.split(\" \")[0] + \".JPEG\"))\n",
    "                self.annotations_file_paths.append((home_file_path_annot + line.split(\" \")[0] + \".xml\"))\n",
    "        \n",
    "        #Final sort to keep annotations and image file paths in same config\n",
    "        self.image_file_paths, self.annotations_file_paths = sorted(self.image_file_paths), sorted(self.annotations_file_paths)\n",
    "        \n",
    "        assert len(self.image_file_paths) == len(self.annotations_file_paths)\n",
    "        print(\"Amount of image files in Dataset {}\".format(len(self.image_file_paths)))\n",
    "        print(\"Amount of annotation files in Dataset {}\".format(len(self.annotations_file_paths)))\n",
    "        \n",
    "        \n",
    "        if self.effdet_data:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with Effecient Det Structure ... \\n\")\n",
    "        elif self.rcnn_big:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with bigger rcnn with ROI Structure ... \\n\")\n",
    "        else:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with mobilenet Faster R CNN Structure ... \\n\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path, xml_path = self.image_file_paths[idx], self.annotations_file_paths[idx]\n",
    "        img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        # img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        marking = False\n",
    "        xml_doc = ElementTree.parse(xml_path)\n",
    "\n",
    "        bounding_boxes_nodes = xml_doc.findall(\"object/bndbox\")\n",
    "        labels_nodes = xml_doc.findall(\"object/name\")\n",
    "\n",
    "        bbox, labels = [], []\n",
    "\n",
    "        for node in bounding_boxes_nodes:\n",
    "            xmax = node.find(\"xmax\").text\n",
    "            xmin = node.find(\"xmin\").text\n",
    "            ymax = node.find(\"ymax\").text\n",
    "            ymin = node.find(\"ymin\").text\n",
    "            bbox.append([int(xmin), int(ymin), int(xmax), int(ymax)])  \n",
    "            \n",
    "\n",
    "        for node in labels_nodes:\n",
    "            if node.text in self.labels_key:\n",
    "                label = self.labels_key.index(node.text)    \n",
    "            else:\n",
    "                label = \"DNE\"\n",
    "                marking = True\n",
    "            labels.append(label)\n",
    "        \n",
    "        if (marking):\n",
    "            removed_indices = list()\n",
    "            \n",
    "            for ii in range(len(labels)):\n",
    "                if (labels[ii] == \"DNE\"):\n",
    "                    removed_indices.append(ii)\n",
    "            labels = [i for j, i in enumerate(labels) if j not in removed_indices]\n",
    "            bbox = [i for j, i in enumerate(bbox) if j not in removed_indices]\n",
    "                \n",
    "        if not(self.effdet_data or self.rcnn_big):\n",
    "            #Need to add one to labels\n",
    "            labels = [label + 1 for label in labels]\n",
    "        \n",
    "        bbox = torch.as_tensor(bbox, dtype = torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype = torch.int64)\n",
    "\n",
    "        # labels = tf.cast(labels, dtype = tf.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        \n",
    "        try:\n",
    "            if self.transforms:  \n",
    "                sample = {\n",
    "                    'image': img,\n",
    "                    'bboxes': bbox,\n",
    "                    'labels': labels\n",
    "                      }\n",
    "\n",
    "                sample = self.transforms(**sample)\n",
    "                img = sample['image']\n",
    "                try:\n",
    "                    bbox = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                except:\n",
    "                    bbox = torch.zeros((0, 4), dtype=torch.float32)\n",
    "                    \n",
    "        except:\n",
    "            print(\"Caught error. Now trying to instill transforms using Pytorch transforms\")\n",
    "            \n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            emergency_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "            \n",
    "            \n",
    "            img = emergency_transforms(img)\n",
    "                \n",
    "                \n",
    "          # img = tf.cast(sample['image'], dtype = tf.float32) / 255.0\n",
    "          # bbox = tf.convert_to_tensor(torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0), dtype = tf.float32)\n",
    "\n",
    "        if self.effdet_data:\n",
    "            return {\"image\": img, \"bboxes\": bbox, \"category_id\": labels}\n",
    "        \n",
    "        target = dict()\n",
    "        target[\"boxes\"] = bbox\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        return img, target  \n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.data_size:\n",
    "            return self.data_size\n",
    "        return len(self.image_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change image size and try and except in dataclass before transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(mode):\n",
    "    if (mode == \"train\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(512, 512), \n",
    "                          A.OneOf([\n",
    "                          A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                         val_shift_limit=0.2, p=0.9),\n",
    "                          A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                               contrast_limit=0.2, p=0.9)],p=0.9),\n",
    "                          A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.5),\n",
    "                          A.HorizontalFlip(),\n",
    "                          A.VerticalFlip(), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"test\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(512, 512), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"effdet_train\"):\n",
    "        return A.Compose([\n",
    "                          A.OneOf([\n",
    "                          A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                         val_shift_limit=0.2, p=0.9),\n",
    "                          A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                               contrast_limit=0.2, p=0.9)],p=0.9),\n",
    "                          A.Cutout(num_holes=8, max_h_size=4, max_w_size=4, p=0.5),\n",
    "                          A.HorizontalFlip(),\n",
    "                          A.VerticalFlip(), \n",
    "                          A.Resize(height = 512, width=512), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"effdet_test\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(height = 512, width = 512), \n",
    "                          ToTensorV2()])\n",
    "    else:\n",
    "        raise ValueError(\"mode is wrong value can either be train or test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IwHLAJZQjrt6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1122397 train images in total\n",
      "\n",
      "\n",
      "BEFORE DET: Amount of image files in Dataset 19743\n",
      "BEFORE DET: Amount of annotation files in Dataset 19743 \n",
      "\n",
      "Amount of images in Det Set (Approx.) 13409\n",
      "Amount of image files in Dataset 33152\n",
      "Amount of annotation files in Dataset 33152\n",
      "\n",
      "\n",
      "Loading with mobilenet Faster R CNN Structure ... \n",
      "\n",
      "Amount of image files in Dataset 2201\n",
      "Amount of annotation files in Dataset 2201\n",
      "\n",
      "\n",
      "Loading with mobilenet Faster R CNN Structure ... \n",
      "\n",
      " \n",
      " ... Seperate from Data Loader \n",
      "\n",
      "Length of train_dataset 33152\n",
      "Length of valid_dataset 2201\n"
     ]
    }
   ],
   "source": [
    "# 1122397 Files in train set total\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "#The amount of scenes to load in one go. # 2 and 2 are the best values\n",
    "train_batch_size = 4\n",
    "valid_batch_size = 4\n",
    "det_text_file = \"/data1/group/mlgroup/train_data/ILSVRC2015/DET_train_30classes.txt\"\n",
    "\n",
    "\n",
    "train_dataset = VideoFrameDataset(\"train\", os.path.join(\"Data/VID\", \"train\"), os.path.join(\"Annotations/VID\", \"train\"), get_transforms(mode = \"train\"), \n",
    "                                  seg_len = 80, det_text_file_paths = det_text_file, data_size = None)\n",
    "valid_dataset = VideoFrameDataset(\"validation\", os.path.join(\"Data/VID\", \"val\"), os.path.join(\"Annotations/VID\", \"val\"), get_transforms(mode = \"test\"),\n",
    "                                  make_valid_smaller_percent = 0.0125, data_size = None)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True, collate_fn= collate_fn)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = valid_batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "\n",
    "print(\" \\n ... Seperate from Data Loader \\n\")\n",
    "print(\"Length of train_dataset {}\".format(len(train_dataset)))\n",
    "print(\"Length of valid_dataset {}\".format(len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3iCwxnxIcRsr"
   },
   "outputs": [],
   "source": [
    "COLORS = [(0, 0, 0), (0, 255, 0), (0, 0 , 255), (255, 255, 0), (255, 0, 0)]\n",
    "\n",
    "def draw_boxes(boxes, labels, image, infer = False, put_text = True):\n",
    "    classes = get_class_info()\n",
    "    keys = list(classes.keys())\n",
    "\n",
    "    # read the image with OpenCV\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    if infer:\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = COLORS[1]\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 5\n",
    "        )\n",
    "        if put_text:\n",
    "          cv2.putText(image, classes[keys[labels[i] - 1]], (int(box[0]), int(box[1]-5)),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 2, color, 3, \n",
    "                      lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBIf0ODU0Aod"
   },
   "source": [
    "### Create a draw function to visualize some data (Will give index error if batch size < 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "YMd58kVzZd2L",
    "outputId": "3c70eca3-8a99-4b35-8df9-99b0b895efc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6c2b8dd2ea90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    image = draw_boxes(labels[idx][\"boxes\"], labels[idx][\"labels\"], images[idx], put_text = True)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5ytYP752Zd7S"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(target_box,predictions_box,scores, device):\n",
    "\n",
    "    #Get most confident boxes first and least confident last\n",
    "    predictions_box = predictions_box[scores.argsort().flip(-1)]\n",
    "    iou_mat = box_iou(target_box,predictions_box)\n",
    "    #return a one by one matrix that is form (target_box, prediction_box) or (1, 1)\n",
    "    target_boxes_count, prediction_boxes_count = iou_mat.shape\n",
    "    \n",
    "    mAP_Matrix = torch.zeros_like(iou_mat)\n",
    "    # if not matrix coordinates that relate to nothing.\n",
    "    if not iou_mat[:,0].eq(0.).all():\n",
    "      index_of_biggest_iou = iou_mat[:,0].argsort()[-1]\n",
    "      mAP_Matrix[index_of_biggest_iou,0] = 1\n",
    "\n",
    "    for pr_idx in range(1,prediction_boxes_count):\n",
    "        not_assigned = torch.logical_not(mAP_Matrix[:,:pr_idx].sum(1)).long()\n",
    "        targets = not_assigned * iou_mat[:,pr_idx]\n",
    "\n",
    "        if targets.eq(0).all():\n",
    "            continue\n",
    "\n",
    "        pivot = targets.argsort()[-1]\n",
    "        mAP_Matrix[pivot,pr_idx] = 1\n",
    "\n",
    "    # mAP calculation\n",
    "    tp = mAP_Matrix.sum()\n",
    "    fp = mAP_Matrix.sum(0).eq(0).sum()\n",
    "    fn = mAP_Matrix.sum(1).eq(0).sum()\n",
    "\n",
    "    mAP = tp / (tp+fp)\n",
    "\n",
    "    return mAP\n",
    "\n",
    "def run_metrics_for_batch(output, targets, mAP, missed_images, device):\n",
    "  for pos_in_batch, image_pred in enumerate(output):\n",
    "    assert (len(image_pred[\"boxes\"]) == len(image_pred[\"labels\"]) == len(image_pred[\"scores\"]))\n",
    "    if len(image_pred[\"boxes\"]) != 0:\n",
    "      mAP += calculate_metrics(targets[pos_in_batch][\"boxes\"], output[pos_in_batch][\"boxes\"], output[pos_in_batch][\"scores\"], device)\n",
    "    else:\n",
    "      missed_images += 1\n",
    "  \n",
    "  return mAP, missed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IN1fBHzJZd92"
   },
   "outputs": [],
   "source": [
    "def train(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch,\n",
    "          lo_valid_dataset = len(valid_dataset), lo_train_dataset = len(train_dataset), saving_directory = None,\n",
    "          unique_char_for_saving = None):\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print_every = len(train_dataset) / train_batch_size // print_times_per_epoch\n",
    "    print(\"Print Every: {}\".format(print_every))\n",
    "\n",
    "    #Check which parameters can calculate gradients. \n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "    base_optimizer = optim.Adam\n",
    "#     base_optimizer = optim.Adadelta\n",
    "#     base_optimizer = Ranger\n",
    "    optimizer = sam.SAM(net.parameters(), base_optimizer, lr = lr, weight_decay = weight_decay)\n",
    "#     optimizer = optim.Adam(params, lr = lr, weight_decay = weight_decay)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
    "    \n",
    "    #Lambda\n",
    "#     lambda1 = lambda epoch: 0.65 ** epoch\n",
    "#     scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "    #\n",
    "\n",
    "\n",
    "    #Might be some problems with the Data Parallel code\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#         net = Some Distrubuted Parallel Function\n",
    "    net.to(device)\n",
    "    \n",
    "    print(\"Device: {}\".format(device))\n",
    "    print(\"Optimizer: {}\".format(optimizer))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_time = time.time()\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = train_mAP = steps = train_missed_images = 0\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            \n",
    "            marking = False\n",
    "            \n",
    "            net.train()\n",
    "            steps += 1\n",
    "\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "            \n",
    "            if len(images) != len(targets):\n",
    "                print(\"Images and targets not same size for Valid\")\n",
    "                continue\n",
    "            \n",
    "            for ii in range(len(images)):\n",
    "                if len(targets[ii][\"boxes\"]) != len(targets[ii][\"labels\"]):\n",
    "                    print(\"Boxes and Labels are not same size\")\n",
    "                    marking = True\n",
    "                if (images[ii].size(-1) == 0) or (targets[ii][\"boxes\"].size(-1) == 0):\n",
    "                    print(\"Passed in empty image or target\")\n",
    "                    marking = True\n",
    "            \n",
    "            if marking:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_dict = net(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            if bool(losses == 0):\n",
    "                print('loss equal zero(0)')\n",
    "                continue\n",
    "\n",
    "            net.eval()\n",
    "            try:\n",
    "                train_mAP, train_missed_images = run_metrics_for_batch(net(images), targets, train_mAP, train_missed_images, device)\n",
    "            except:\n",
    "                print(images[0].size(), targets)\n",
    "                print(\"Caught an exception in an image could not predict metric for it\")\n",
    "            net.train()\n",
    "\n",
    "            losses.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(net.parameters(), 100)\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "            \n",
    "#             optimizer.step()\n",
    "\n",
    "            optimizer.first_step(zero_grad = True)\n",
    "\n",
    "            loss_dict = net(images, targets)\n",
    "#             torch.nn.utils.clip_grad_norm_(net.parameters(), 100)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            losses.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "            optimizer.second_step(zero_grad = True)\n",
    "\n",
    "            train_loss +=  losses.item()\n",
    "            scheduler.step()\n",
    "\n",
    "            if (steps % print_every) == 0:  \n",
    "                with torch.no_grad():\n",
    "                \n",
    "                    valid_mAP = valid_loss = valid_missed_images = 0\n",
    "\n",
    "                    for images, targets in valid_loader:\n",
    "                        \n",
    "                        valid_marking = False\n",
    "                        \n",
    "                        net.eval()\n",
    "                        if device == torch.device(\"cuda\"):\n",
    "                            images = [image.to(device) for image in images]\n",
    "                            targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "                        \n",
    "                        if len(images) != len(targets):\n",
    "                            print(\"Images and targets not same size for Valid\")\n",
    "                            continue\n",
    "                        \n",
    "                        for ii in range(len(images)):\n",
    "                            if len(targets[ii][\"boxes\"]) != len(targets[ii][\"labels\"]):\n",
    "                                print(\"Boxes and Labels are not same size\")\n",
    "                                valid_marking = True\n",
    "                            if (images[ii].size(-1) == 0) or (targets[ii][\"boxes\"].size(-1) == 0):\n",
    "                                print(\"Passed in empty image or target\")\n",
    "                                valid_marking = True\n",
    "                        \n",
    "                        if valid_marking:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            output = net(images)\n",
    "                            valid_mAP, valid_missed_images = run_metrics_for_batch(output, targets, valid_mAP, valid_missed_images, device)\n",
    "                        except:\n",
    "                            print(targets, images[0].size())\n",
    "                            print(\"Caught exception with running metrics for one valid image (skipped)\")\n",
    "\n",
    "                        net.train()\n",
    "                        valid_loss_dict = net(images, targets)\n",
    "                        valid_losses = sum(loss for loss in valid_loss_dict.values())\n",
    "                        valid_loss += valid_losses.item()\n",
    "\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        learning_rate_extract = param_group[\"lr\"]\n",
    "                    print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Valid_loss: {:0.2f} | Valid mAP: {:0.2f}% | Valid Missed Images {} / {}\".format(\n",
    "                        epoch + 1, epochs, steps, learning_rate_extract, train_loss, valid_loss,  \n",
    "                        (valid_mAP / float(lo_valid_dataset)) * 100., valid_missed_images, lo_valid_dataset))\n",
    "                    \n",
    "#                     if (valid_mAP / float(lo_valid_dataset)) Save batches with high accuracy on valid set. \n",
    "\n",
    "                assert (steps % print_every) == 0\n",
    "                train_loss = 0\n",
    "                \n",
    "        print(\"\\n Epoch {} | Epoch Time {:0.2f} | Final Train mAP: {:0.2f}% | Final Train Missed Images {} / {} \\n\".format(\n",
    "            epoch + 1, (time.time() - epoch_time),(train_mAP / float(lo_train_dataset)) * 100., train_missed_images, lo_train_dataset\n",
    "        ))\n",
    "        if saving_directory:\n",
    "            if os.path.isdir(saving_directory):\n",
    "                print(\"Saving Model path to directory {} ... \".format(saving_directory))\n",
    "                saving_path = os.path.join(saving_directory, \"Epoch\" + str(epoch + 1) + str(unique_char_for_saving) + \".pth\")\n",
    "                saving_content = {\"model_state_dict\": net.state_dict(), \n",
    "                                  \"optimizer_state_dict\": optimizer.state_dict(), \n",
    "                                  \"epoch\": epoch + 1, \n",
    "                                  \"model_type\": \"FasterRCNNResnet50FPN\"}\n",
    "                torch.save(saving_content, saving_path)\n",
    "                print(\"Succesfully saved model data to file path. \\n\")\n",
    "            else:\n",
    "                print(\"Directory Provided does not exist, hence will skip saving the model\")\n",
    "    \n",
    "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))\n",
    "    \n",
    "        # Example File path: /saved_models/epoch10small.pth \n",
    "        \n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mish helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU to Mish conversion for models \n",
    "#Option to switch any activation function for another.\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Mish activation loaded...\")\n",
    "\n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = x *( torch.tanh(F.softplus(x)))\n",
    "\n",
    "        return x\n",
    "    \n",
    "def convert_it(model, new, replaced_act):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, replaced_act):\n",
    "            setattr(model, child_name, new)\n",
    "        else:\n",
    "            convert_it(child, new, replaced_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuNTqGHFaAyU"
   },
   "source": [
    "## Faster R CNN with mobile net backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "z-R_qJ3haFf-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mish activation loaded...\n"
     ]
    }
   ],
   "source": [
    "mob_net = torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn(pretrained = True)\n",
    "# mob_net = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
    "mob_net.roi_heads.box_predictor.cls_score.out_features = len(get_class_info())\n",
    "mob_net.roi_heads.box_predictor.bbox_pred.out_features = len(get_class_info()) * 4\n",
    "convert_it(mob_net, Mish(), nn.ReLU6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33152, 2201)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too High Learning Rate can cause Exploding Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If this gets 50% in any of the training sequence then I will run saving through batches.\n",
    "\n",
    "* Learning Rate = higher learning rate. Model between batches with high learning rate gets great accuracy before going into exploding gradient.\n",
    "\n",
    "Trying: \n",
    "Increasing weight decay so that as R Adam in ranger increases its steps, the learning rate is still low.\n",
    "Lowering Learning rate to the 3e-4 which 0.0003. \n",
    "\n",
    "Depends: on accuracy of model, if it explodes gradients, does it show gradual improvment\n",
    "\n",
    "Will try:\n",
    "\n",
    "* Changing Ranger to Adam W to get more weight decay control.\n",
    "\n",
    "\n",
    "Hope: To have this run 3 epochs with no exploding gradient error with gradual improvment. \n",
    "Note early improvements will be less because of rAdam in ranger I think. The model moves a little in the beginning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn Image into 224 by 224 image.\n",
    "# Change Learning Rate scheduler to Lamda, Multiplicative, or Step. \n",
    "# Increase batchsize to as much cuda lets me\n",
    "\n",
    "# Try to overfit model on 1000 image dataset. \n",
    "\n",
    "# Save every batch and save a good batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 165.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.0005\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    weight_decay: 1e-05\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Batch Number: 165 | LR: 0.00050 | Train_loss: 75.71 | Valid_loss: 248.19 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 330 | LR: 0.00050 | Train_loss: 57.85 | Valid_loss: 217.73 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 495 | LR: 0.00050 | Train_loss: 61.70 | Valid_loss: 245.21 | Valid mAP: 28.16% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 660 | LR: 0.00050 | Train_loss: 56.46 | Valid_loss: 214.56 | Valid mAP: 1.94% | Valid Missed Images 2114 / 2201\n",
      "Epoch 1/3 | Batch Number: 825 | LR: 0.00050 | Train_loss: 57.50 | Valid_loss: 207.94 | Valid mAP: 35.05% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 990 | LR: 0.00050 | Train_loss: 59.76 | Valid_loss: 204.32 | Valid mAP: 37.64% | Valid Missed Images 1199 / 2201\n",
      "Epoch 1/3 | Batch Number: 1155 | LR: 0.00050 | Train_loss: 58.61 | Valid_loss: 220.43 | Valid mAP: 57.52% | Valid Missed Images 150 / 2201\n",
      "Epoch 1/3 | Batch Number: 1320 | LR: 0.00050 | Train_loss: 62.63 | Valid_loss: 204.94 | Valid mAP: 32.53% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 1485 | LR: 0.00050 | Train_loss: 57.16 | Valid_loss: 211.00 | Valid mAP: 31.37% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 1650 | LR: 0.00049 | Train_loss: 56.63 | Valid_loss: 218.58 | Valid mAP: 57.63% | Valid Missed Images 91 / 2201\n",
      "Epoch 1/3 | Batch Number: 1815 | LR: 0.00049 | Train_loss: 58.42 | Valid_loss: 215.42 | Valid mAP: 51.21% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 1980 | LR: 0.00049 | Train_loss: 56.42 | Valid_loss: 211.17 | Valid mAP: 35.14% | Valid Missed Images 79 / 2201\n",
      "Epoch 1/3 | Batch Number: 2145 | LR: 0.00049 | Train_loss: 57.75 | Valid_loss: 209.00 | Valid mAP: 16.38% | Valid Missed Images 1822 / 2201\n",
      "Epoch 1/3 | Batch Number: 2310 | LR: 0.00049 | Train_loss: 60.73 | Valid_loss: 218.37 | Valid mAP: 26.16% | Valid Missed Images 1232 / 2201\n",
      "Epoch 1/3 | Batch Number: 2475 | LR: 0.00049 | Train_loss: 60.51 | Valid_loss: 213.02 | Valid mAP: 44.70% | Valid Missed Images 414 / 2201\n",
      "Epoch 1/3 | Batch Number: 2640 | LR: 0.00049 | Train_loss: 59.34 | Valid_loss: 203.28 | Valid mAP: 26.11% | Valid Missed Images 11 / 2201\n",
      "Epoch 1/3 | Batch Number: 2805 | LR: 0.00048 | Train_loss: 57.76 | Valid_loss: 202.21 | Valid mAP: 43.51% | Valid Missed Images 325 / 2201\n",
      "Epoch 1/3 | Batch Number: 2970 | LR: 0.00048 | Train_loss: 53.68 | Valid_loss: 208.31 | Valid mAP: 37.02% | Valid Missed Images 63 / 2201\n"
     ]
    }
   ],
   "source": [
    "# USing adam instead of Ranger\n",
    "#Gradient Clipping is lower.\n",
    "# Batch size is a little higher\n",
    "\n",
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 50,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 12.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    rho: 0.05\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 12 | LR: 0.00100 | Train_loss: 9.58 | Valid_loss: 32.90 | Valid mAP: 24.40% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 24 | LR: 0.00099 | Train_loss: 5.66 | Valid_loss: 113.07 | Valid mAP: 9.73% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 36 | LR: 0.00098 | Train_loss: 3.72 | Valid_loss: 23.30 | Valid mAP: 3.24% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 48 | LR: 0.00096 | Train_loss: 2.99 | Valid_loss: 24.82 | Valid mAP: 3.50% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 60 | LR: 0.00094 | Train_loss: 3.07 | Valid_loss: 22.83 | Valid mAP: 10.23% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 72 | LR: 0.00091 | Train_loss: 3.13 | Valid_loss: 25.87 | Valid mAP: 12.96% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 84 | LR: 0.00088 | Train_loss: 2.84 | Valid_loss: 25.49 | Valid mAP: 12.30% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 96 | LR: 0.00085 | Train_loss: 2.94 | Valid_loss: 28.24 | Valid mAP: 12.09% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 108 | LR: 0.00081 | Train_loss: 2.86 | Valid_loss: 33.07 | Valid mAP: 11.86% | Valid Missed Images 0 / 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-c76343e8e02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmob_net_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmob_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-e9663b1929cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m#             torch.nn.utils.clip_grad_norm_(net.parameters(), 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.001, weight_decay = 1e-5, print_times_per_epoch = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 12.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.0005\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 12 | LR: 0.00050 | Train_loss: 10.27 | Valid_loss: 38.68 | Valid mAP: 2.48% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 24 | LR: 0.00049 | Train_loss: 4.24 | Valid_loss: 32.71 | Valid mAP: 10.36% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 36 | LR: 0.00049 | Train_loss: 3.91 | Valid_loss: 31.68 | Valid mAP: 12.59% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 48 | LR: 0.00048 | Train_loss: 3.40 | Valid_loss: 26.12 | Valid mAP: 8.30% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 60 | LR: 0.00047 | Train_loss: 3.32 | Valid_loss: 25.67 | Valid mAP: 10.26% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 72 | LR: 0.00046 | Train_loss: 3.10 | Valid_loss: 37.69 | Valid mAP: 7.79% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 84 | LR: 0.00044 | Train_loss: 3.27 | Valid_loss: 48.53 | Valid mAP: 16.70% | Valid Missed Images 0 / 200\n",
      "Epoch 1/3 | Batch Number: 96 | LR: 0.00042 | Train_loss: 2.80 | Valid_loss: 43.27 | Valid mAP: 14.99% | Valid Missed Images 0 / 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-c18feaf76e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 10,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-e9663b1929cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                         \u001b[0mvalid_loss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                         \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 10,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 7.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    rho: 0.05\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 7 | LR: 0.00100 | Train_loss: 31.35 | Valid_loss: 1.63 | Valid mAP: 0.00% | Valid Missed Images 10 / 10\n",
      "Epoch 1/3 | Batch Number: 14 | LR: 0.00100 | Train_loss: 5.78 | Valid_loss: 3.38 | Valid mAP: 1.40% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 21 | LR: 0.00099 | Train_loss: 4.23 | Valid_loss: 7.40 | Valid mAP: 2.26% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 28 | LR: 0.00099 | Train_loss: 8.00 | Valid_loss: 2.87 | Valid mAP: 13.06% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 35 | LR: 0.00099 | Train_loss: 2.95 | Valid_loss: 3.06 | Valid mAP: 12.05% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 42 | LR: 0.00098 | Train_loss: 1.88 | Valid_loss: 1.79 | Valid mAP: 1.66% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 49 | LR: 0.00097 | Train_loss: 1.98 | Valid_loss: 2.31 | Valid mAP: 12.62% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 56 | LR: 0.00096 | Train_loss: 2.22 | Valid_loss: 3.21 | Valid mAP: 2.16% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 63 | LR: 0.00095 | Train_loss: 1.87 | Valid_loss: 1.53 | Valid mAP: 14.19% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 70 | LR: 0.00094 | Train_loss: 1.86 | Valid_loss: 1.98 | Valid mAP: 6.92% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 77 | LR: 0.00093 | Train_loss: 1.94 | Valid_loss: 2.29 | Valid mAP: 14.37% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 84 | LR: 0.00092 | Train_loss: 2.05 | Valid_loss: 1.96 | Valid mAP: 1.40% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 91 | LR: 0.00090 | Train_loss: 2.17 | Valid_loss: 1.16 | Valid mAP: 10.72% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 98 | LR: 0.00089 | Train_loss: 1.58 | Valid_loss: 1.67 | Valid mAP: 5.12% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 105 | LR: 0.00087 | Train_loss: 1.50 | Valid_loss: 1.18 | Valid mAP: 5.17% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 112 | LR: 0.00085 | Train_loss: 2.52 | Valid_loss: 0.95 | Valid mAP: 1.67% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 119 | LR: 0.00084 | Train_loss: 2.12 | Valid_loss: 1.81 | Valid mAP: 5.47% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 126 | LR: 0.00082 | Train_loss: 2.19 | Valid_loss: 1.22 | Valid mAP: 1.06% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 133 | LR: 0.00080 | Train_loss: 1.99 | Valid_loss: 1.42 | Valid mAP: 5.24% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 140 | LR: 0.00078 | Train_loss: 1.80 | Valid_loss: 1.08 | Valid mAP: 5.37% | Valid Missed Images 0 / 10\n",
      "Epoch 1/3 | Batch Number: 147 | LR: 0.00076 | Train_loss: 1.84 | Valid_loss: 1.02 | Valid mAP: 1.79% | Valid Missed Images 0 / 10\n",
      "\n",
      " Epoch 1 | Epoch Time 377.43 | Final Train mAP: 6.78% | Final Train Missed Images 16 / 300 \n",
      "\n",
      "Epoch 2/3 | Batch Number: 7 | LR: 0.00073 | Train_loss: 1.79 | Valid_loss: 1.14 | Valid mAP: 4.62% | Valid Missed Images 0 / 10\n",
      "Epoch 2/3 | Batch Number: 14 | LR: 0.00071 | Train_loss: 1.33 | Valid_loss: 1.07 | Valid mAP: 5.34% | Valid Missed Images 0 / 10\n",
      "Epoch 2/3 | Batch Number: 21 | LR: 0.00068 | Train_loss: 1.60 | Valid_loss: 1.44 | Valid mAP: 5.17% | Valid Missed Images 0 / 10\n",
      "Epoch 2/3 | Batch Number: 28 | LR: 0.00066 | Train_loss: 1.28 | Valid_loss: 2.16 | Valid mAP: 5.16% | Valid Missed Images 0 / 10\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 41.9840, 138.3784, 276.4800, 422.8228]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([101], device='cuda:0')}, {'boxes': tensor([[  1.7067,   0.0000, 494.9333, 510.0606]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([51], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "[{'boxes': tensor([[264.0000, 100.9778, 369.6000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([8], device='cuda:0')}, {'boxes': tensor([[248.8000, 120.8889, 331.6000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-aef1f995b6c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmob_net_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmob_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-120-b64eb2dc48d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                         \u001b[0mvalid_loss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                         \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.001, weight_decay = 1e-6, print_times_per_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 207.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    eps: 1e-06\n",
      "    initial_lr: 0.0005\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 207 | LR: 0.00050 | Train_loss: 160.20 | Valid_loss: 693.95 | Valid mAP: 16.82% | Valid Missed Images 18 / 2201\n",
      "Epoch 1/3 | Batch Number: 414 | LR: 0.00050 | Train_loss: 131.96 | Valid_loss: 627.66 | Valid mAP: 16.44% | Valid Missed Images 17 / 2201\n",
      "Epoch 1/3 | Batch Number: 621 | LR: 0.00050 | Train_loss: 118.08 | Valid_loss: 590.28 | Valid mAP: 17.59% | Valid Missed Images 15 / 2201\n",
      "Epoch 1/3 | Batch Number: 828 | LR: 0.00050 | Train_loss: 112.80 | Valid_loss: 570.00 | Valid mAP: 19.73% | Valid Missed Images 23 / 2201\n",
      "Epoch 1/3 | Batch Number: 1035 | LR: 0.00050 | Train_loss: 102.27 | Valid_loss: 555.80 | Valid mAP: 22.28% | Valid Missed Images 33 / 2201\n",
      "Epoch 1/3 | Batch Number: 1242 | LR: 0.00050 | Train_loss: 112.45 | Valid_loss: 544.99 | Valid mAP: 22.92% | Valid Missed Images 43 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 294.9120, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3953], device='cuda:0')}, {'boxes': tensor([[ 27.2000, 271.5152,  40.0000, 340.0404],\n",
      "        [ 79.2000, 294.7879,  98.4000, 316.7677],\n",
      "        [132.8000, 287.0303, 152.0000, 312.8889],\n",
      "        [341.6000, 157.7374, 372.8000, 201.6970],\n",
      "        [374.4000, 155.1515, 394.4000, 193.9394]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([11298], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e21002da6c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-6, print_times_per_epoch = 80,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-4f49dc7dc4f9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;31m#             torch.nn.utils.clip_grad_norm_(net.parameters(), 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-6, print_times_per_epoch = 80,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 331.0\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    initial_lr: 0.0003\n",
      "    k: 6\n",
      "    lr: 0.0003\n",
      "    rho: 0.05\n",
      "    step_counter: 0\n",
      "    weight_decay: 0.01\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 331 | LR: 0.00030 | Train_loss: 149.19 | Valid_loss: 437.68 | Valid mAP: 22.60% | Valid Missed Images 21 / 2201\n",
      "Epoch 1/3 | Batch Number: 662 | LR: 0.00030 | Train_loss: 126.98 | Valid_loss: 419.03 | Valid mAP: 27.62% | Valid Missed Images 113 / 2201\n",
      "Epoch 1/3 | Batch Number: 993 | LR: 0.00030 | Train_loss: 119.23 | Valid_loss: 401.78 | Valid mAP: 17.60% | Valid Missed Images 121 / 2201\n",
      "Epoch 1/3 | Batch Number: 1324 | LR: 0.00030 | Train_loss: 121.73 | Valid_loss: 396.27 | Valid mAP: 14.32% | Valid Missed Images 43 / 2201\n",
      "Epoch 1/3 | Batch Number: 1655 | LR: 0.00030 | Train_loss: 125.46 | Valid_loss: 407.55 | Valid mAP: 13.14% | Valid Missed Images 9 / 2201\n",
      "Epoch 1/3 | Batch Number: 1986 | LR: 0.00030 | Train_loss: 114.96 | Valid_loss: 401.33 | Valid mAP: 16.02% | Valid Missed Images 38 / 2201\n",
      "Epoch 1/3 | Batch Number: 2317 | LR: 0.00030 | Train_loss: 115.09 | Valid_loss: 391.27 | Valid mAP: 15.55% | Valid Missed Images 116 / 2201\n",
      "Epoch 1/3 | Batch Number: 2648 | LR: 0.00030 | Train_loss: 120.09 | Valid_loss: 397.78 | Valid mAP: 13.24% | Valid Missed Images 34 / 2201\n",
      "Epoch 1/3 | Batch Number: 2979 | LR: 0.00030 | Train_loss: 118.02 | Valid_loss: 420.46 | Valid mAP: 13.34% | Valid Missed Images 38 / 2201\n",
      "Epoch 1/3 | Batch Number: 3310 | LR: 0.00030 | Train_loss: 119.33 | Valid_loss: 426.25 | Valid mAP: 21.03% | Valid Missed Images 145 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.0160, 297.9840, 401.4080, 507.9040]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3832], device='cuda:0')}, {'boxes': tensor([[184.0000,  43.3778, 425.6000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([15118], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 15.3600, 181.5893, 428.0320, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([9724], device='cuda:0')}, {'boxes': tensor([[138.6667,  31.2889, 512.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([26444], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.4000, 132.9778, 102.8000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([16741], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 258.8445, 172.0000, 374.0444],\n",
      "        [120.0000, 263.1111, 147.2000, 366.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([20302], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[342.4000, 240.3556, 423.2000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([31973], device='cuda:0')}, {'boxes': tensor([[ 76.8000,   2.8445, 243.2000, 251.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([31131], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "[{'boxes': tensor([[ 65.0667, 307.2000, 194.1333, 435.2000],\n",
      "        [379.7333, 292.9778, 445.8667, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([711], device='cuda:0')}, {'boxes': tensor([[151.2000, 204.8000, 224.4000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1465], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[215.2296, 203.3778, 347.9704, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([187], device='cuda:0')}, {'boxes': tensor([[144.0000,  54.0444, 220.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2150], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000, 231.1111, 465.2000, 425.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1212], device='cuda:0')}, {'boxes': tensor([[184.5333,   9.9556, 375.4667, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([593], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 15.6000,  80.3556, 228.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([1404], device='cuda:0')}, {'boxes': tensor([[212.8000, 223.2889, 306.4000, 328.5333],\n",
      "        [ 17.6000, 151.4667, 205.2000, 338.4889],\n",
      "        [177.2000, 222.5778, 275.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([517], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.0000,  54.0444, 288.0000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1502], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  59.7333, 412.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1697], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.8000,  61.8667, 473.2000, 425.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([219], device='cuda:0')}, {'boxes': tensor([[132.2667, 240.3556, 169.6000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1708], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.4242, 265.6970, 231.4343, 467.3940]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2023], device='cuda:0')}, {'boxes': tensor([[ 66.9358, 170.6667, 374.0183, 359.4667],\n",
      "        [154.4220, 321.0667, 510.2385, 508.8000],\n",
      "        [  0.5872, 300.8000,  62.2385, 442.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7, 19], device='cuda:0'), 'image_id': tensor([483], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[229.6000, 319.2889, 428.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1915], device='cuda:0')}, {'boxes': tensor([[254.9333, 153.6000, 510.9333, 334.2222],\n",
      "        [105.6000,  61.1556, 435.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([48], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.4000, 187.0222, 322.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1966], device='cuda:0')}, {'boxes': tensor([[  0.0000, 157.8667, 227.2000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([198], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.0000, 103.1111, 350.4000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1532], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([736], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 368.2623, 192.8000, 442.7541],\n",
      "        [216.8000, 385.0492, 368.8000, 498.3607],\n",
      "        [365.6000, 350.4262, 400.8000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5], device='cuda:0'), 'image_id': tensor([964], device='cuda:0')}, {'boxes': tensor([[ 64.4000,  64.0000, 447.2000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([840], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.8000, 194.1333, 510.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1103], device='cuda:0')}, {'boxes': tensor([[116.4000,   0.0000, 164.0000,  66.8444],\n",
      "        [193.6000, 107.3778, 370.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([390], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[138.8000,  46.2222, 306.8000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2046], device='cuda:0')}, {'boxes': tensor([[100.8000, 179.2000, 368.0000, 467.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1303], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.2000, 136.5333, 288.0000, 332.8000],\n",
      "        [240.0000,  44.0889, 390.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1228], device='cuda:0')}, {'boxes': tensor([[122.3111,  85.3333, 511.0518, 395.3778],\n",
      "        [178.2518, 310.0444, 274.0148, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([178], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 177.7778, 295.6000, 364.8000],\n",
      "        [166.4000, 265.9556, 249.6000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([521], device='cuda:0')}, {'boxes': tensor([[155.2340,  41.2444, 332.2553, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1087], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[329.7152,  10.6667, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1975], device='cuda:0')}, {'boxes': tensor([[  0.0000, 240.3556, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([251], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.0000, 179.2000, 374.0000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2158], device='cuda:0')}, {'boxes': tensor([[236.0000, 199.8222, 313.6000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([0], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 40.5333,  15.6444, 302.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1076], device='cuda:0')}, {'boxes': tensor([[324.6972, 179.2000, 480.2936, 306.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([470], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.4000, 189.1555, 275.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2060], device='cuda:0')}, {'boxes': tensor([[ 68.0000, 170.6667, 295.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([865], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.8667,  15.6444, 300.8000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1075], device='cuda:0')}, {'boxes': tensor([[192.4000, 140.0889, 362.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([82], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[273.6000, 200.5333, 295.6000, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2053], device='cuda:0')}, {'boxes': tensor([[223.2000, 145.0667, 369.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([83], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.3333,  51.2000, 413.8667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1694], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 115.2000, 365.8667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1473], device='cuda:0')}, {'boxes': tensor([[117.6000, 193.4222, 149.6000, 257.4222],\n",
      "        [ 73.6000, 260.2667, 100.8000, 337.0667],\n",
      "        [156.8000,  78.2222, 171.2000, 112.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([624], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.8000,   0.0000, 182.4000, 128.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1187], device='cuda:0')}, {'boxes': tensor([[187.7333, 100.9778, 309.3333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1470], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872,   1.0667, 497.3211, 503.4667],\n",
      "        [219.5963, 256.0000, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([454], device='cuda:0')}, {'boxes': tensor([[140.0000,   7.1111, 236.0000, 182.0444],\n",
      "        [225.6000,  17.0667, 311.2000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[345.6000,   0.0000, 510.4000, 509.1555],\n",
      "        [179.2000,  79.6444, 496.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1236], device='cuda:0')}, {'boxes': tensor([[172.8000, 159.2889, 342.0000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([745], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.8000, 137.2444, 397.6000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([422], device='cuda:0')}, {'boxes': tensor([[251.7333,   0.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1729], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.0000,  47.6444, 458.0000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([379], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 104.5333, 511.2000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([374], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000,  85.3333, 329.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([835], device='cuda:0')}, {'boxes': tensor([[140.8000,   0.0000, 510.4000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1809], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6330, 184.5333, 304.7339, 322.1333],\n",
      "        [  2.3486, 320.0000, 509.0642, 508.8000],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 150.8991, 440.5333],\n",
      "        [135.0459, 291.2000, 182.0183, 336.0000],\n",
      "        [137.3945, 276.2667, 187.8899, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [320.0000, 273.0667, 354.0551, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([456], device='cuda:0')}, {'boxes': tensor([[  2.1333, 146.4889,  58.6667, 227.5556],\n",
      "        [346.6667, 179.2000, 480.0000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([677], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 163.0815, 237.8667, 297.7185]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1144], device='cuda:0')}, {'boxes': tensor([[ 56.8000, 113.7778, 455.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1200], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.8667, 231.8222, 167.4667, 295.8222],\n",
      "        [136.5333, 193.4222, 192.0000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([683], device='cuda:0')}, {'boxes': tensor([[209.6000, 296.5333, 248.8000, 403.2000],\n",
      "        [250.0000, 205.5111, 269.2000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([832], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 20.4000,   9.9556, 509.2000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1581], device='cuda:0')}, {'boxes': tensor([[ 44.0000, 207.6444,  82.4000, 300.0889],\n",
      "        [ 91.2000, 216.1778, 141.6000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([944], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.6620,   0.0000, 510.1972, 507.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1481], device='cuda:0')}, {'boxes': tensor([[ 26.6667,   0.0000, 285.8667, 405.8074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[255.2000, 125.8667, 275.2000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([874], device='cuda:0')}, {'boxes': tensor([[299.2000, 384.0000, 315.2000, 411.0222],\n",
      "        [222.8000, 212.6222, 239.6000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1874], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 176.3556, 268.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([928], device='cuda:0')}, {'boxes': tensor([[120.8000, 145.0667, 254.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2035], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[247.2000, 257.4222, 387.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([1048], device='cuda:0')}, {'boxes': tensor([[360.0000, 209.0667, 444.0000, 504.8889],\n",
      "        [164.0000, 240.3556, 268.0000, 509.1555],\n",
      "        [  0.0000, 237.5111,  88.8000, 507.7333],\n",
      "        [324.8000, 164.9778, 343.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([773], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.2000, 264.5333, 347.2000, 334.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1922], device='cuda:0')}, {'boxes': tensor([[227.2000, 122.3111, 341.3333, 133.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2107], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.0000, 218.3111, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1211], device='cuda:0')}, {'boxes': tensor([[145.6000, 295.8222, 236.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2009], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.8000, 163.5556, 312.8000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([743], device='cuda:0')}, {'boxes': tensor([[186.8000,  22.7556, 322.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1050], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000, 190.5778, 219.2000, 367.6444],\n",
      "        [277.2000, 172.8000, 425.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1113], device='cuda:0')}, {'boxes': tensor([[272.8000, 123.7333, 339.2000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([115], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([285], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2085], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[255.2000, 128.0000, 414.0000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1792], device='cuda:0')}, {'boxes': tensor([[  0.5872,   9.6000, 509.6514, 507.7333],\n",
      "        [294.1651, 309.3333, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([453], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.8667,  49.7778, 395.7333, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1689], device='cuda:0')}, {'boxes': tensor([[141.2000, 244.6222, 315.6000, 477.8667],\n",
      "        [ 35.6000, 221.1555, 348.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([558], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 199.1111, 160.0000, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1940], device='cuda:0')}, {'boxes': tensor([[252.8000, 125.8667, 350.8000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([8], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000, 284.4445, 160.0000, 388.2667],\n",
      "        [223.2000, 284.4445, 249.6000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([768], device='cuda:0')}, {'boxes': tensor([[136.0000, 206.9333, 183.6000, 235.3778],\n",
      "        [418.0000, 206.2222, 453.2000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([527], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[125.6000,  97.4222, 285.6000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1852], device='cuda:0')}, {'boxes': tensor([[139.7333, 186.3111, 330.6667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([202], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 167.8222, 276.0000, 321.4222],\n",
      "        [231.2000,  78.2222, 358.4000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1226], device='cuda:0')}, {'boxes': tensor([[204.0000, 105.9556, 220.4000, 147.9111],\n",
      "        [136.8000, 115.9111, 156.0000, 157.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([621], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1272], device='cuda:0')}, {'boxes': tensor([[1.2680e+02, 2.1049e+02, 2.5400e+02, 3.5129e+02],\n",
      "        [4.0000e-01, 1.5502e+02, 1.1800e+02, 2.8302e+02],\n",
      "        [2.2560e+02, 1.1591e+02, 3.0800e+02, 2.4604e+02],\n",
      "        [1.1160e+02, 2.6169e+02, 2.5520e+02, 4.4871e+02],\n",
      "        [3.5680e+02, 2.6169e+02, 4.9640e+02, 4.4231e+02],\n",
      "        [4.2760e+02, 2.1120e+02, 5.1080e+02, 3.1644e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8, 8, 8, 8], device='cuda:0'), 'image_id': tensor([638], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.8000,  14.2222, 324.0000, 496.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([264], device='cuda:0')}, {'boxes': tensor([[290.1333, 234.6667, 350.9333, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1937], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 120.8889, 241.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1948], device='cuda:0')}, {'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([284], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.6000, 182.7556, 320.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1965], device='cuda:0')}, {'boxes': tensor([[197.6000, 123.7333, 270.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1333], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1355], device='cuda:0')}, {'boxes': tensor([[ 16.0000, 257.4222, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([246], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 86.4000, 198.4000, 132.8000, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1274], device='cuda:0')}, {'boxes': tensor([[278.8000, 236.8000, 338.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([530], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.2000, 142.2222, 364.0000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1932], device='cuda:0')}, {'boxes': tensor([[ 33.2000,  79.6444, 297.2000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([548], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.2000, 198.4000, 255.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2064], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1896], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.3333, 233.2444, 241.0667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2130], device='cuda:0')}, {'boxes': tensor([[283.6000, 215.4667, 509.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2196], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 290.1333, 231.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2006], device='cuda:0')}, {'boxes': tensor([[170.6667, 240.3556, 222.9333, 260.2667],\n",
      "        [309.3333, 236.0889, 422.4000, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2109], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[242.4000, 127.2889, 344.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2187], device='cuda:0')}, {'boxes': tensor([[136.4000,  94.5778, 302.0000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1854], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.7677, 246.3030, 159.0303, 434.4243]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2021], device='cuda:0')}, {'boxes': tensor([[204.0000,   0.0000, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([386], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 31.2000, 136.5333,  76.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1134], device='cuda:0')}, {'boxes': tensor([[154.4000, 133.6889, 236.8000, 359.8222],\n",
      "        [218.4000,  44.0889, 404.8000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1232], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.3333,  79.6444, 386.1333, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([723], device='cuda:0')}, {'boxes': tensor([[160.4000, 268.8000, 332.4000, 491.3778],\n",
      "        [ 51.6000, 235.3778, 364.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([556], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.8000, 164.9778, 263.6000, 349.8667],\n",
      "        [134.0000, 248.8889, 217.2000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([519], device='cuda:0')}, {'boxes': tensor([[ 58.7156,  80.0000, 466.2018, 410.6667],\n",
      "        [ 20.5505, 257.0667, 231.3394, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([475], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000,  92.4444, 272.8000, 261.6889],\n",
      "        [249.6000,  76.8000, 361.6000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1742], device='cuda:0')}, {'boxes': tensor([[243.2000,  60.4444, 346.8000, 384.0000],\n",
      "        [319.2000, 143.6444, 362.4000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1537], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 295.8222, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([706], device='cuda:0')}, {'boxes': tensor([[  0.0000, 199.1111, 145.0667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1733], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.2000, 291.6721, 137.6000, 312.6557],\n",
      "        [272.0000, 286.4262, 291.2000, 310.5574],\n",
      "        [185.6000, 210.8852, 250.4000, 375.6066],\n",
      "        [365.6000, 313.7049, 503.2000, 443.8033],\n",
      "        [337.6000, 329.4426, 410.4000, 422.8197]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([965], device='cuda:0')}, {'boxes': tensor([[  0.0000,  61.8667, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1178], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.6000, 241.0667, 246.0000, 393.9556],\n",
      "        [336.0000, 180.6222, 474.8000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([642], device='cuda:0')}, {'boxes': tensor([[  0.0000, 256.0000, 147.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([946], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 257.4222, 422.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1817], device='cuda:0')}, {'boxes': tensor([[403.2000, 242.4889, 510.4000, 506.3111],\n",
      "        [132.8000,  81.7778, 487.6000, 419.5555],\n",
      "        [ 56.0000,  56.8889, 133.6000, 146.4889],\n",
      "        [ 22.0000,  80.3556,  57.6000, 132.2667],\n",
      "        [229.6000,  46.2222, 385.2000, 123.7333],\n",
      "        [  0.0000,  68.9778,  28.8000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1801], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000, 151.4667, 297.6000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1845], device='cuda:0')}, {'boxes': tensor([[305.0667, 228.9778, 362.6667, 284.4445],\n",
      "        [ 25.6000, 153.6000,  83.2000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([257], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 179.2000, 257.2000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2037], device='cuda:0')}, {'boxes': tensor([[  7.6000,  84.6222, 271.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1433], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.1662e+02, 3.4000e+02, 4.9351e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([297], device='cuda:0')}, {'boxes': tensor([[204.8000, 115.9111, 219.2000, 159.2889],\n",
      "        [131.2000, 135.8222, 148.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([622], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 145.0667, 441.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([332], device='cuda:0')}, {'boxes': tensor([[289.6000, 259.5555, 511.2000, 480.0000],\n",
      "        [238.8000, 218.3111, 378.0000, 307.9111],\n",
      "        [ 80.8000, 239.6444, 235.2000, 357.6889],\n",
      "        [  5.6000, 211.9111,  58.0000, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1469], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.4000,   0.7111, 448.0000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([160], device='cuda:0')}, {'boxes': tensor([[192.4000, 119.4667, 505.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([227], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 224.7111, 353.0667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2101], device='cuda:0')}, {'boxes': tensor([[296.4632, 166.4000, 485.9593, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1972], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000, 204.8000, 290.1333, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([259], device='cuda:0')}, {'boxes': tensor([[  0.0000, 211.2000,   8.8000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1462], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.6000, 148.6222, 280.8000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1887], device='cuda:0')}, {'boxes': tensor([[206.8000,  55.4667, 350.0000, 366.9333],\n",
      "        [235.6000, 273.0667, 246.0000, 304.3556],\n",
      "        [243.2000, 268.0889, 251.6000, 304.3556],\n",
      "        [411.6000, 255.2889, 446.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1011], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.7333, 143.6444,  87.4667, 223.2889],\n",
      "        [338.1333, 169.2444, 474.6667, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([680], device='cuda:0')}, {'boxes': tensor([[298.6667, 224.7111, 360.5333, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1936], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000, 220.4444, 349.6000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2188], device='cuda:0')}, {'boxes': tensor([[212.0000, 199.8222, 316.8000, 289.4222],\n",
      "        [ 60.4000, 226.1333, 197.6000, 337.0667],\n",
      "        [202.0000, 252.4444, 338.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1577], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 239.6444, 234.4000, 344.8889],\n",
      "        [ 80.0000, 149.3333, 267.6000, 354.1333],\n",
      "        [ 66.8000, 236.0889, 134.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([518], device='cuda:0')}, {'boxes': tensor([[  0.0000, 191.2889,  78.8000, 295.8222],\n",
      "        [126.8000, 199.8222, 140.4000, 217.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[158.0000,   3.5556, 502.8000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([308], device='cuda:0')}, {'boxes': tensor([[112.8000, 221.8667, 267.2000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([41], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.6000,  62.5778, 224.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1070], device='cuda:0')}, {'boxes': tensor([[150.4000,  64.0000, 449.2000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([848], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 223.2889, 252.8000, 296.5333],\n",
      "        [298.4000, 255.2889, 354.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([884], device='cuda:0')}, {'boxes': tensor([[223.6000, 224.7111, 347.2000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[158.4000,  48.3556, 296.4000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1184], device='cuda:0')}, {'boxes': tensor([[218.8000, 258.8445, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1221], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 157.1555, 400.4000, 297.2444],\n",
      "        [ 95.6000, 142.2222, 289.2000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([903], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.1333, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([798], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.6000,  89.6000, 405.2000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([28], device='cuda:0')}, {'boxes': tensor([[ 21.3333, 315.7333, 188.8000, 393.9556],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([692], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.0000, 189.1555, 230.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([417], device='cuda:0')}, {'boxes': tensor([[143.6000, 100.9778, 246.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1857], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.0000,  59.0222, 288.4000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([849], device='cuda:0')}, {'boxes': tensor([[220.4000, 227.5556, 251.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1239], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000, 159.2889, 311.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1994], device='cuda:0')}, {'boxes': tensor([[218.4000, 214.7556, 428.8000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1677], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 224.7111, 249.6000, 356.2667],\n",
      "        [267.2000, 166.4000, 297.2000, 228.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1648], device='cuda:0')}, {'boxes': tensor([[228.4000, 180.6222, 333.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[173.2000, 130.1333, 272.0000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1345], device='cuda:0')}, {'boxes': tensor([[162.0000, 171.3778, 291.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1786], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[159.2000, 218.3111, 236.8000, 312.8889],\n",
      "        [283.6000, 226.1333, 344.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1518], device='cuda:0')}, {'boxes': tensor([[172.8000, 113.7778, 400.4000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1353], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.8000, 100.9778, 253.6000, 475.0222],\n",
      "        [268.8000, 139.3778, 412.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1428], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.1947e+02, 2.5560e+02, 4.9067e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([302], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 386.8445, 171.2000, 510.5778],\n",
      "        [371.2000, 317.1555, 394.4000, 509.1555],\n",
      "        [484.8000, 371.2000, 511.2000, 510.5778],\n",
      "        [189.6000, 402.4889, 318.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([783], device='cuda:0')}, {'boxes': tensor([[284.8000, 271.6444, 434.4000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1917], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.8000, 110.9333, 420.0000, 427.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1795], device='cuda:0')}, {'boxes': tensor([[290.1333, 216.1778, 342.4000, 268.8000],\n",
      "        [  6.4000, 142.2222,  61.8667, 199.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([255], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 110.9333, 422.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([208], device='cuda:0')}, {'boxes': tensor([[236.8000, 213.3333, 302.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1337], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[341.7248, 234.6667, 510.2385, 437.3333],\n",
      "        [  7.6330, 270.9333, 236.0367, 425.6000],\n",
      "        [ 17.0275, 130.1333, 473.8349, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([482], device='cuda:0')}, {'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [151.4667,  82.4889, 340.2667, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([600], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.0000, 174.2222, 472.0000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1288], device='cuda:0')}, {'boxes': tensor([[134.4000, 106.6667, 194.4000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1138], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 117.3333, 297.2000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1856], device='cuda:0')}, {'boxes': tensor([[240.7339, 172.8000, 496.1468, 314.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([472], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([23], device='cuda:0')}, {'boxes': tensor([[112.0000, 258.8445, 510.9333, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([252], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 96.4000,   3.5556, 503.2000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([317], device='cuda:0')}, {'boxes': tensor([[258.0000, 244.6222, 408.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([27], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 89.6000, 172.8000, 507.2000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1280], device='cuda:0')}, {'boxes': tensor([[ 29.8667,  32.7111, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1941], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 104.5333, 354.8000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2145], device='cuda:0')}, {'boxes': tensor([[166.4000, 200.5333, 301.2000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1551], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.4000,   7.1111, 504.4000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([311], device='cuda:0')}, {'boxes': tensor([[ 59.7333, 317.1555, 194.1333, 438.0444],\n",
      "        [372.2667, 298.6667, 432.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([703], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000,   8.5333, 458.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2149], device='cuda:0')}, {'boxes': tensor([[ 58.8000, 100.9778, 378.0000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1798], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.4000,  97.4222, 310.8000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([25], device='cuda:0')}, {'boxes': tensor([[138.8000, 194.8445, 368.0000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1601], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.2000, 133.6889, 510.0000, 406.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([589], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1865], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.0000, 275.9111, 344.0000, 373.3333],\n",
      "        [229.2000, 289.4222, 270.8000, 386.1333],\n",
      "        [128.0000, 339.2000, 171.2000, 443.7333],\n",
      "        [133.6000, 232.5333, 176.4000, 330.6667],\n",
      "        [297.6000, 160.7111, 338.8000, 253.1555],\n",
      "        [270.4000,  71.1111, 316.0000, 167.1111],\n",
      "        [206.0000,  88.1778, 249.6000, 184.8889],\n",
      "        [149.6000, 124.4444, 192.0000, 220.4444],\n",
      "        [229.2000, 192.7111, 272.0000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([109], device='cuda:0')}, {'boxes': tensor([[330.8169,   0.0000, 511.0986, 417.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1482], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 244.6222, 162.4000, 510.5778],\n",
      "        [ 73.6000,  76.8000, 124.4000, 150.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([504], device='cuda:0')}, {'boxes': tensor([[ 98.4000, 133.6889, 271.2000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2043], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 285.8667, 399.6000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1205], device='cuda:0')}, {'boxes': tensor([[288.0000, 214.7556, 312.8000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2052], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.8000,   0.0000, 415.2000, 467.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([347], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1617], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 277.3333, 240.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2004], device='cuda:0')}, {'boxes': tensor([[190.0000,  27.0222, 322.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1052], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.4000, 167.8222, 262.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([929], device='cuda:0')}, {'boxes': tensor([[148.4000, 125.1556, 318.4000, 395.3778],\n",
      "        [ 21.6000, 147.2000, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([552], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 207.6444, 289.2000, 310.7556],\n",
      "        [254.8000, 210.4889, 335.6000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1519], device='cuda:0')}, {'boxes': tensor([[243.2000, 136.5333, 509.6000, 502.0444],\n",
      "        [  0.0000,   0.0000, 265.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1621], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  41.2444, 240.0000, 504.1778],\n",
      "        [195.2000, 128.7111, 374.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([908], device='cuda:0')}, {'boxes': tensor([[230.8000, 195.5556, 310.4000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([804], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000,  88.1778, 242.4000, 273.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2062], device='cuda:0')}, {'boxes': tensor([[  0.0000, 204.8000, 174.9333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1370], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.4000, 228.9778, 282.4000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([947], device='cuda:0')}, {'boxes': tensor([[226.1333,  52.6222, 430.9333, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1151], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 199.8222, 336.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([162], device='cuda:0')}, {'boxes': tensor([[125.6000, 119.4667, 168.0000, 172.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([792], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.9333,  58.3111, 394.6667, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1696], device='cuda:0')}, {'boxes': tensor([[231.2000, 263.1111, 275.2000, 463.6444],\n",
      "        [328.8000, 264.5333, 395.2000, 509.1555],\n",
      "        [156.8000, 256.0000, 196.0000, 415.2889],\n",
      "        [284.0000, 250.3111, 312.0000, 371.2000],\n",
      "        [ 13.6000, 312.8889, 130.4000, 507.7333],\n",
      "        [483.2000, 334.2222, 511.2000, 507.7333],\n",
      "        [469.6000, 297.2444, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  1.1743, 320.0000, 159.7064, 501.3333],\n",
      "        [  0.5872, 321.0667,  71.6330, 410.6667],\n",
      "        [  5.8716, 338.1333, 223.1193, 504.5333],\n",
      "        [117.4312, 372.2667, 365.7982, 508.8000],\n",
      "        [409.2477, 418.1333, 507.3028, 504.5333],\n",
      "        [432.7339, 332.8000, 510.2385, 432.0000],\n",
      "        [121.5413, 149.3333, 392.8073, 449.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([443], device='cuda:0')}, {'boxes': tensor([[282.0000, 147.9111, 384.0000, 295.8222],\n",
      "        [ 96.0000, 141.5111, 287.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([902], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 24.0000, 217.6000, 508.8000, 506.3111],\n",
      "        [  0.0000,   0.0000, 274.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1644], device='cuda:0')}, {'boxes': tensor([[ 83.2000, 200.5333, 363.2000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1267], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 236.6061, 129.2929, 378.1818]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2018], device='cuda:0')}, {'boxes': tensor([[152.0000,  36.2667, 278.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1057], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6741,  91.0222, 448.4741, 378.3111],\n",
      "        [178.2518, 307.2000, 270.2222, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([184], device='cuda:0')}, {'boxes': tensor([[182.0000, 145.0667, 321.2000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([396], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 125.1556, 508.4000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([998], device='cuda:0')}, {'boxes': tensor([[320.4000, 193.4222, 460.0000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([653], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,  59.0222, 511.2000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1651], device='cuda:0')}, {'boxes': tensor([[130.8000,  66.8444, 447.2000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([108], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000, 149.3333, 480.0000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1672], device='cuda:0')}, {'boxes': tensor([[207.2000,   0.0000, 511.2000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1310], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[317.8667, 210.4889, 385.0667, 338.4889],\n",
      "        [284.8000, 179.2000, 370.1333, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([262], device='cuda:0')}, {'boxes': tensor([[ 49.2000, 103.1111, 281.2000, 495.6444],\n",
      "        [204.0000, 217.6000, 300.0000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([916], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.4000,  55.4667, 336.8000, 507.7333],\n",
      "        [  0.0000,   0.0000, 176.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1664], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 277.6000, 509.1555],\n",
      "        [281.6000,   0.0000, 511.2000, 237.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1430], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000,  34.1333, 312.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1775], device='cuda:0')}, {'boxes': tensor([[198.4000,  79.6444, 398.4000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([492], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000,  59.0222, 331.2000, 357.6889],\n",
      "        [438.4000, 244.6222, 474.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1009], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1637], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 177.7778, 385.8963, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([755], device='cuda:0')}, {'boxes': tensor([[ 62.4000,   0.0000, 511.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1633], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[141.6000, 226.9091, 254.4000, 322.9091],\n",
      "        [449.6000, 232.7273, 507.2000, 331.6364],\n",
      "        [352.0000, 285.0909, 388.0000, 315.6364],\n",
      "        [251.2000, 282.1818, 285.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([1420], device='cuda:0')}, {'boxes': tensor([[ 74.8000,  91.0222, 349.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 125.1556,  91.2000, 320.0000],\n",
      "        [ 76.8000,  96.7111, 225.6000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1761], device='cuda:0')}, {'boxes': tensor([[202.8000, 183.4667, 348.8000, 268.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1930], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.1333, 105.2444, 331.7333, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1935], device='cuda:0')}, {'boxes': tensor([[194.1333, 193.4222, 356.2667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1716], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[154.0000, 157.8667, 290.0000, 278.7556],\n",
      "        [ 26.8000, 184.1778,  66.8000, 218.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1464], device='cuda:0')}, {'boxes': tensor([[147.2000, 132.2667, 295.2000, 324.2667],\n",
      "        [113.6000, 196.2667, 213.6000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1234], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.8000, 137.2444, 397.2000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([423], device='cuda:0')}, {'boxes': tensor([[  0.0000, 147.9111,  59.7333, 227.5556],\n",
      "        [343.4667, 180.6222, 480.0000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([676], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2089e+02, 2.8840e+02, 5.0916e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1436], device='cuda:0')}, {'boxes': tensor([[187.2000,   9.9556, 435.2000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1669], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 324.2667, 130.1333, 412.4445],\n",
      "        [473.6000, 254.5778, 509.8667, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([690], device='cuda:0')}, {'boxes': tensor([[193.6000,  68.2667, 301.6000, 415.2889],\n",
      "        [166.4000, 324.2667, 230.4000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([509], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000,   0.0000, 384.4000, 231.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([32], device='cuda:0')}, {'boxes': tensor([[130.0000, 177.7778, 429.2000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([281], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 46.9333,   0.0000, 274.1333, 509.1555],\n",
      "        [366.9333,   0.0000, 509.8667, 167.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([597], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 206.9333, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2074], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 120.1778, 509.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([996], device='cuda:0')}, {'boxes': tensor([[  0.0000, 256.0000, 162.0000, 507.7333],\n",
      "        [ 75.2000,  68.2667, 144.8000, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([503], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 206.2222, 301.2000, 488.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2183], device='cuda:0')}, {'boxes': tensor([[ 66.1333, 305.7778, 192.0000, 430.9333],\n",
      "        [373.3333, 283.0222, 443.7333, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([709], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  76.8000, 236.8000, 312.8889],\n",
      "        [224.0000,   0.0000, 508.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1081], device='cuda:0')}, {'boxes': tensor([[225.6000, 113.7778, 402.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([377], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 156.4444, 210.0000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1402], device='cuda:0')}, {'boxes': tensor([[205.8667, 209.0667, 355.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  21.3333, 364.8000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1030], device='cuda:0')}, {'boxes': tensor([[ 50.1333, 253.1555, 184.5333, 392.5333],\n",
      "        [421.3333, 201.9556, 491.7333, 257.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([695], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[246.4000,  64.0000, 422.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([896], device='cuda:0')}, {'boxes': tensor([[284.8000, 253.8667, 332.0000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([194], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.5963, 181.3333, 318.8257, 321.0667],\n",
      "        [ 11.1560, 317.8667, 510.2385, 506.6667],\n",
      "        [300.6238, 298.6667, 509.6514, 454.4000],\n",
      "        [  0.0000, 189.8667, 162.0550, 448.0000],\n",
      "        [146.2018, 291.2000, 191.4128, 334.9333],\n",
      "        [148.5505, 277.3333, 197.2844, 321.0667],\n",
      "        [187.3027, 263.4667, 211.9633, 308.2667],\n",
      "        [352.2936, 274.1333, 413.3578, 304.0000],\n",
      "        [329.3945, 274.1333, 364.0367, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([455], device='cuda:0')}, {'boxes': tensor([[130.0000, 244.6222, 264.4000, 448.7111],\n",
      "        [303.2000, 257.4222, 366.4000, 386.1333],\n",
      "        [  6.8000, 320.7111,  39.6000, 388.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([1523], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.4000,   0.0000, 509.6000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2081], device='cuda:0')}, {'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [165.6000, 160.0000, 205.2000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.4000, 244.6222, 301.2000, 480.0000],\n",
      "        [ 19.6000, 218.3111, 333.6000, 431.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([559], device='cuda:0')}, {'boxes': tensor([[157.8667,   0.0000, 394.6667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2087], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.4507,   0.0000, 508.3944, 308.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1483], device='cuda:0')}, {'boxes': tensor([[ 81.0667,   0.0000, 277.3333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1255], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.8000, 187.7333, 326.8000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1349], device='cuda:0')}, {'boxes': tensor([[  3.6000,  78.9333, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1210], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  99.5556, 163.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([211], device='cuda:0')}, {'boxes': tensor([[ 53.3333, 263.1111, 183.4667, 382.5778],\n",
      "        [361.6000, 250.3111, 429.8667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([701], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.6000, 103.8222, 240.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1850], device='cuda:0')}, {'boxes': tensor([[ 87.6000, 225.4222, 190.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  3.2000,  38.4000, 280.0000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1045], device='cuda:0')}, {'boxes': tensor([[241.0667, 118.0444, 492.8000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([663], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000,   0.0000, 442.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1612], device='cuda:0')}, {'boxes': tensor([[218.8000, 175.6444, 308.4000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([810], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.4000, 185.6000, 319.2000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2184], device='cuda:0')}, {'boxes': tensor([[246.4000, 206.9333, 387.2000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([647], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2152], device='cuda:0')}, {'boxes': tensor([[180.8000, 149.3333, 224.0000, 368.3556],\n",
      "        [233.6000,  42.6667, 424.0000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1233], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 109.5111, 318.4000, 200.5333],\n",
      "        [ 90.0000, 170.6667, 234.4000, 261.6889],\n",
      "        [ 61.6000, 265.2444, 170.4000, 330.6667],\n",
      "        [ 60.8000, 342.0444, 100.8000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([148], device='cuda:0')}, {'boxes': tensor([[121.6000, 179.2000, 371.2000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1302], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.2667, 197.6889, 509.8667, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([244], device='cuda:0')}, {'boxes': tensor([[ 56.5333,  59.7333, 510.9333, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1024], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.4000, 177.0667, 160.0000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1463], device='cuda:0')}, {'boxes': tensor([[ 65.0667, 312.8889, 197.3333, 433.7778],\n",
      "        [376.5333, 291.5555, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([708], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  73.9556, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2153], device='cuda:0')}, {'boxes': tensor([[ 94.8000, 100.2667, 352.4000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([101], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 223.2889, 172.0000, 507.7333],\n",
      "        [266.4000, 151.4667, 336.0000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([501], device='cuda:0')}, {'boxes': tensor([[193.2000, 118.7556, 499.2000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([229], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 106.6667, 511.2000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([734], device='cuda:0')}, {'boxes': tensor([[163.2000,  81.0667, 337.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([65], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[137.9817,  85.3333, 345.8349, 439.4667],\n",
      "        [  4.6972, 246.4000, 114.4954, 435.2000],\n",
      "        [422.1651, 222.9333, 453.2844, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([485], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 280.1778, 193.2000, 352.7111],\n",
      "        [214.0000, 271.6444, 300.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1823], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[297.6000, 403.9111, 322.0000, 435.9111],\n",
      "        [230.4000, 246.7556, 251.2000, 298.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1879], device='cuda:0')}, {'boxes': tensor([[ 91.2000, 136.5333, 308.0000, 388.2667],\n",
      "        [160.0000, 182.0444, 428.8000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([60], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 33.2000, 244.6222,  84.4000, 263.8222],\n",
      "        [148.0000, 233.2444, 191.6000, 261.6889],\n",
      "        [228.8000, 243.9111, 269.2000, 263.8222],\n",
      "        [368.0000, 244.6222, 420.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29, 29], device='cuda:0'), 'image_id': tensor([524], device='cuda:0')}, {'boxes': tensor([[143.6000, 218.3111, 262.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1968], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000, 152.8889, 211.2000, 221.8667],\n",
      "        [381.6000, 253.8667, 428.8000, 335.6444],\n",
      "        [248.0000, 196.9778, 296.4000, 263.8222],\n",
      "        [202.4000, 140.0889, 233.2000, 261.6889],\n",
      "        [ 44.8000, 119.4667, 112.0000, 187.7333],\n",
      "        [137.2000, 145.0667, 174.0000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2024], device='cuda:0')}, {'boxes': tensor([[119.2000,  54.0444, 336.0000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([825], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 278.7556, 315.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1020], device='cuda:0')}, {'boxes': tensor([[154.0000, 103.1111, 238.4000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1360], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 93.8667,  35.5556, 338.1333, 507.7333],\n",
      "        [408.5333, 136.5333, 510.9333, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([606], device='cuda:0')}, {'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 425.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([700], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[113.6000, 175.6444, 285.6000, 439.4667],\n",
      "        [  7.2000, 159.2889, 318.8000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([560], device='cuda:0')}, {'boxes': tensor([[316.8000, 116.3636, 491.2000, 322.9091],\n",
      "        [144.8000, 181.8182, 236.8000, 318.5454]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1318], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.8148, 237.5111, 250.3111, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([165], device='cuda:0')}, {'boxes': tensor([[ 67.2000, 199.1111, 329.6000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1106], device='cuda:0')}, {'boxes': tensor([[222.0000, 228.2667, 251.6000, 300.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1238], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.7333, 184.8889, 332.8000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([201], device='cuda:0')}, {'boxes': tensor([[  0.0000, 110.9333, 304.8000, 504.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1183], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 77.8667, 253.1555, 510.9333, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([243], device='cuda:0')}, {'boxes': tensor([[326.4000, 264.5333, 406.4000, 285.8667],\n",
      "        [151.4667, 268.8000, 230.4000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2116], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000, 214.7556, 340.8000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1170], device='cuda:0')}, {'boxes': tensor([[ 13.6000,   0.0000, 299.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([407], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 280.1778, 149.2000, 415.2889],\n",
      "        [122.4000, 137.9556, 146.8000, 177.7778],\n",
      "        [325.6000, 185.6000, 377.6000, 278.7556],\n",
      "        [ 76.4000, 128.7111, 112.8000, 167.8222],\n",
      "        [286.4000, 135.1111, 310.0000, 216.8889],\n",
      "        [174.4000, 210.4889, 257.2000, 292.9778],\n",
      "        [332.0000, 167.8222, 415.2000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2027], device='cuda:0')}, {'boxes': tensor([[235.2000, 210.4889, 358.8000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2193], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  45.5111, 250.6667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1074], device='cuda:0')}, {'boxes': tensor([[320.0000, 248.8889, 507.2000, 509.1555],\n",
      "        [ 86.4000,   0.0000, 236.8000, 280.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1613], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.2000, 214.7556, 366.8000, 497.7778],\n",
      "        [ 82.4000, 219.0222, 381.6000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([549], device='cuda:0')}, {'boxes': tensor([[103.6000, 117.3333, 511.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([731], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  36.9778, 228.2667, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1476], device='cuda:0')}, {'boxes': tensor([[ 67.2000,   0.0000, 313.6000, 457.9556],\n",
      "        [394.6667,  73.9556, 509.8667, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([609], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[494.8732, 148.8000, 510.1972, 334.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1486], device='cuda:0')}, {'boxes': tensor([[148.4000, 196.9778, 278.0000, 401.7778],\n",
      "        [255.6000, 209.7778, 438.4000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([569], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000, 152.1778, 430.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1679], device='cuda:0')}, {'boxes': tensor([[248.8000,  91.0222, 435.2000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1675], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.4000,  83.2000, 226.8000, 125.8667],\n",
      "        [185.6000, 158.5778, 217.6000, 200.5333],\n",
      "        [179.6000, 243.9111, 213.6000, 287.2889],\n",
      "        [180.0000, 329.2444, 212.0000, 371.2000],\n",
      "        [178.4000, 400.3556, 210.4000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([146], device='cuda:0')}, {'boxes': tensor([[144.0000, 375.4667, 249.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2016], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.4000, 122.3111, 329.6000, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([398], device='cuda:0')}, {'boxes': tensor([[104.5333,   1.4222, 149.3333,  68.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2093], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.8074,  28.4444, 309.0963, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1824], device='cuda:0')}, {'boxes': tensor([[ 74.4000,   0.0000, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000,  19.9111, 508.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([385], device='cuda:0')}, {'boxes': tensor([[117.2000, 160.0000, 302.8000, 358.4000],\n",
      "        [174.0000, 259.5555, 256.4000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([522], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 34.8000,   3.5556, 290.4000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([267], device='cuda:0')}, {'boxes': tensor([[121.5413, 201.6000, 243.6697, 326.4000],\n",
      "        [  4.6972, 317.8667, 510.2385, 505.6000],\n",
      "        [292.9908, 300.8000, 509.6514, 456.5333],\n",
      "        [140.3303, 292.2667, 186.7156, 334.9333],\n",
      "        [140.9174, 277.3333, 191.4128, 320.0000],\n",
      "        [348.1835, 277.3333, 409.2477, 307.2000],\n",
      "        [323.5229, 278.4000, 357.5780, 313.6000],\n",
      "        [298.8624, 276.2667, 335.8532, 318.9333],\n",
      "        [274.2018, 265.6000, 325.8716, 324.2667],\n",
      "        [253.6514, 269.8667, 279.4862, 321.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([459], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000,  12.8000, 428.8000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([665], device='cuda:0')}, {'boxes': tensor([[ 34.0000,  73.9556, 258.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1431], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 160.0000, 358.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2154], device='cuda:0')}, {'boxes': tensor([[ 33.2000,  85.3333, 238.4000, 482.8445],\n",
      "        [224.4000, 140.0889, 358.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([913], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.9333, 221.8667, 509.8667, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([233], device='cuda:0')}, {'boxes': tensor([[  0.0000, 189.8667, 293.2000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1375], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 367.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1386], device='cuda:0')}, {'boxes': tensor([[198.8000,  98.8444, 398.8000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1351], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000, 364.8000, 293.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1888], device='cuda:0')}, {'boxes': tensor([[168.8000, 233.9556, 262.0000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1796], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 53.3333,  46.9333, 377.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1687], device='cuda:0')}, {'boxes': tensor([[  0.5872, 332.8000, 256.5872, 504.5333],\n",
      "        [138.5688,  19.2000, 389.2844, 480.0000],\n",
      "        [395.1560, 217.6000, 509.6514, 282.6667],\n",
      "        [385.1743, 272.0000, 484.9908, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6, 7, 7], device='cuda:0'), 'image_id': tensor([468], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000, 122.3111, 510.4000, 484.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2164], device='cuda:0')}, {'boxes': tensor([[190.4000, 159.2889, 280.8000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([932], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1466], device='cuda:0')}, {'boxes': tensor([[211.2000, 159.2889, 313.6000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1999], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.0000,   9.9556, 499.6000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([286], device='cuda:0')}, {'boxes': tensor([[170.2752,  93.8667, 355.2294, 422.4000],\n",
      "        [ 44.6239, 241.0667, 155.5963, 423.4667],\n",
      "        [411.5963, 222.9333, 443.8899, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([486], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 10.0000,  83.2000, 263.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1434], device='cuda:0')}, {'boxes': tensor([[281.6000, 338.4889, 510.4000, 507.7333],\n",
      "        [  0.0000,   0.0000, 308.0000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1615], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.3333, 146.4889, 377.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1718], device='cuda:0')}, {'boxes': tensor([[  0.0000, 285.8667, 264.5333, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2121], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  77.5111, 348.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([11], device='cuda:0')}, {'boxes': tensor([[ 38.4000, 164.9778, 163.2000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([199], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000, 221.3770, 201.6000, 386.0984],\n",
      "        [348.8000, 287.4754, 480.8000, 454.2951],\n",
      "        [304.8000, 347.2787, 357.6000, 430.1639],\n",
      "        [314.4000,   0.0000, 372.0000,  64.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([966], device='cuda:0')}, {'boxes': tensor([[160.0000, 229.6889, 316.8000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.2000,   1.4222, 510.8000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([309], device='cuda:0')}, {'boxes': tensor([[307.2000, 314.3111, 328.0000, 342.0444],\n",
      "        [308.8000, 272.3556, 330.4000, 305.0667],\n",
      "        [310.4000, 236.8000, 331.6000, 265.2444],\n",
      "        [311.2000, 200.5333, 332.4000, 230.4000],\n",
      "        [309.6000, 167.8222, 330.8000, 199.1111],\n",
      "        [282.0000, 158.5778, 303.2000, 190.5778],\n",
      "        [256.0000, 157.1555, 276.4000, 187.7333],\n",
      "        [232.8000, 145.0667, 254.0000, 176.3556],\n",
      "        [204.8000, 138.6667, 225.6000, 170.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 99.2000, 104.5333, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1284], device='cuda:0')}, {'boxes': tensor([[249.6000, 275.9111, 298.8000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 277.3333, 230.4000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2000], device='cuda:0')}, {'boxes': tensor([[ 83.6000, 192.0000, 225.2000, 366.2222],\n",
      "        [281.6000, 174.9333, 423.6000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1095], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.8889, 183.4667, 511.0518, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([174], device='cuda:0')}, {'boxes': tensor([[187.6000, 177.7778, 351.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([494], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[121.6000,  85.3333, 293.3333, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1073], device='cuda:0')}, {'boxes': tensor([[124.8000, 152.1778, 273.0667, 439.4667],\n",
      "        [253.8667,   0.0000, 508.8000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1086], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.0000,   0.0000, 300.0000, 470.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([546], device='cuda:0')}, {'boxes': tensor([[  0.0000, 203.3778, 221.8667, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1368], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000, 156.4444, 288.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1332], device='cuda:0')}, {'boxes': tensor([[171.7333,   0.0000, 509.8667, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([684], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000,  39.8222, 339.6000, 364.8000],\n",
      "        [130.0000, 261.6889, 139.2000, 292.9778],\n",
      "        [123.6000, 257.4222, 132.0000, 293.6889],\n",
      "        [334.0000, 244.6222, 369.2000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1015], device='cuda:0')}, {'boxes': tensor([[121.6000,  85.3333, 293.6000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1853], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.0000, 228.2667, 333.2000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1153], device='cuda:0')}, {'boxes': tensor([[278.0000, 106.6667, 284.4000, 118.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1444], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 219.7333, 284.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([661], device='cuda:0')}, {'boxes': tensor([[ 78.4000,  73.9556, 240.8000, 234.6667],\n",
      "        [243.2000,  54.0444, 364.0000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1738], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.2000, 238.2222, 153.6000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([209], device='cuda:0')}, {'boxes': tensor([[217.6000, 209.0667, 419.2000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1676], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000,  79.6444, 374.4000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([828], device='cuda:0')}, {'boxes': tensor([[ 76.8000, 199.1111, 118.0000, 356.2667],\n",
      "        [356.0000, 201.9556, 401.6000, 261.6889],\n",
      "        [ 55.2000, 105.9556, 134.8000, 156.4444],\n",
      "        [268.4000, 144.3556, 308.0000, 206.2222],\n",
      "        [118.0000, 201.9556, 221.2000, 293.6889],\n",
      "        [163.6000, 132.2667, 187.2000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2028], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.0000, 113.7778, 380.4000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([879], device='cuda:0')}, {'boxes': tensor([[189.6000,   0.0000, 510.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1808], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 58.7156,  76.8000, 466.2018, 407.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([476], device='cuda:0')}, {'boxes': tensor([[ 23.4667, 260.2667, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([245], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[231.6000, 271.6444, 309.2000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([491], device='cuda:0')}, {'boxes': tensor([[167.2000, 142.2222, 340.4000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([634], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 43.2000,  76.8000, 453.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1121], device='cuda:0')}, {'boxes': tensor([[186.0000, 157.8667, 290.0000, 252.4444],\n",
      "        [ 38.8000, 196.2667, 168.8000, 300.0889],\n",
      "        [182.4000, 238.2222, 308.0000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1574], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[320.8000, 170.6667, 391.2000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2148], device='cuda:0')}, {'boxes': tensor([[186.8000, 161.4222, 301.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 96.0000, 153.6000, 276.2667, 312.8889],\n",
      "        [503.4667, 206.2222, 509.8667, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([673], device='cuda:0')}, {'boxes': tensor([[ 39.4667,  56.8889, 299.7333, 194.8445],\n",
      "        [317.8667, 176.3556, 395.7333, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([667], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 75.2000,  11.3778, 228.0000, 227.5556],\n",
      "        [242.4000,   9.9556, 369.6000, 216.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1747], device='cuda:0')}, {'boxes': tensor([[140.0000,   0.0000, 186.0000,  83.2000],\n",
      "        [196.4000, 150.0444, 364.8000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([389], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.5333, 240.3556, 215.4667, 261.6889],\n",
      "        [296.5333, 231.8222, 410.6667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2110], device='cuda:0')}, {'boxes': tensor([[122.8000, 228.9778, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1154], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 194.8445,  91.7333, 509.1555],\n",
      "        [147.2000,  83.9111, 334.9333, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([601], device='cuda:0')}, {'boxes': tensor([[  0.0000, 184.1778,  38.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1904], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 182.0444, 319.2000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1777], device='cuda:0')}, {'boxes': tensor([[120.8000, 128.0000, 507.2000, 496.3556],\n",
      "        [165.6000,   0.0000, 316.8000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1611], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.8000,  88.1778, 331.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1459], device='cuda:0')}, {'boxes': tensor([[  0.0000, 214.7556, 296.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1392], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 135.1111, 281.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([813], device='cuda:0')}, {'boxes': tensor([[227.8165, 161.0667, 298.2752, 278.4000],\n",
      "        [  0.5872, 274.1333, 126.8257, 509.8667],\n",
      "        [222.5321, 199.4667, 235.4495, 234.6667],\n",
      "        [186.7156, 218.6667, 225.4679, 276.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([426], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 117.3333, 270.8000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1849], device='cuda:0')}, {'boxes': tensor([[226.0000, 170.6667, 326.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2178], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.8000, 200.5333, 368.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1265], device='cuda:0')}, {'boxes': tensor([[267.2000, 187.7333, 286.4000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([936], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[422.8000, 177.0667, 471.2000, 210.4889],\n",
      "        [323.2000, 169.9556, 416.0000, 211.9111],\n",
      "        [254.8000, 186.3111, 328.8000, 219.0222],\n",
      "        [ 17.6000, 225.4222,  92.0000, 280.1778],\n",
      "        [164.0000, 222.5778, 191.6000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29, 29], device='cuda:0'), 'image_id': tensor([537], device='cuda:0')}, {'boxes': tensor([[ 56.8000,   5.6889, 338.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([132], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000,  32.7111, 333.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([391], device='cuda:0')}, {'boxes': tensor([[286.9333, 102.4000, 371.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1586], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.4000, 226.1333, 250.0000, 356.2667],\n",
      "        [268.8000, 157.8667, 297.2000, 219.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1647], device='cuda:0')}, {'boxes': tensor([[  6.4000,  44.0889, 510.8000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([573], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[310.0000, 214.7556, 368.0000, 297.9556],\n",
      "        [ 62.4000, 123.7333, 352.0000, 478.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([900], device='cuda:0')}, {'boxes': tensor([[225.2000, 214.7556, 348.8000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2192], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000,  32.7111, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1313], device='cuda:0')}, {'boxes': tensor([[135.2000, 162.1333, 314.4000, 354.1333],\n",
      "        [354.0000, 266.6667, 392.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1553], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8000, 201.9556, 332.8000, 472.1778],\n",
      "        [  0.0000,  66.8444,  52.0000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1767], device='cuda:0')}, {'boxes': tensor([[224.8000, 216.1778, 348.4000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.4000, 133.6889, 510.9333, 369.7778],\n",
      "        [  1.0667,   0.0000, 465.0667, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([50], device='cuda:0')}, {'boxes': tensor([[  0.0000,  98.1333, 307.2000, 507.7333],\n",
      "        [300.8000, 325.6889, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1630], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.0000, 191.2889, 470.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1292], device='cuda:0')}, {'boxes': tensor([[149.7248, 193.0667, 395.7431, 363.7333],\n",
      "        [125.0642, 228.2667, 159.7064, 266.6667],\n",
      "        [ 65.1743, 234.6667, 112.7339, 277.3333],\n",
      "        [109.7982, 277.3333, 139.7431, 321.0667],\n",
      "        [389.8716, 252.8000, 464.4404, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7,  7, 19,  7], device='cuda:0'), 'image_id': tensor([439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.2000, 142.9333, 479.2000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([373], device='cuda:0')}, {'boxes': tensor([[278.4000, 187.0222, 375.2000, 447.2889],\n",
      "        [147.2000, 310.7556, 226.8000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([867], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([12], device='cuda:0')}, {'boxes': tensor([[167.2000, 258.1333, 250.4000, 364.0889],\n",
      "        [ 19.2000, 186.3111, 206.8000, 368.3556],\n",
      "        [136.4000, 254.5778, 231.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([515], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.2000, 200.5333, 270.4000, 234.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([938], device='cuda:0')}, {'boxes': tensor([[162.0000, 163.5556, 376.0000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2172], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.2000, 172.0889, 284.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1359], device='cuda:0')}, {'boxes': tensor([[ 89.6000,  72.5333, 413.8667, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1693], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[231.6000, 108.8000, 384.8000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1791], device='cuda:0')}, {'boxes': tensor([[376.9541, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 263.4667,  69.8716, 412.8000],\n",
      "        [238.3853, 200.5333, 381.6514, 485.3333],\n",
      "        [258.3486, 306.1333, 413.9449, 507.7333],\n",
      "        [111.5596, 244.2667, 216.0734, 361.6000],\n",
      "        [380.4771, 274.1333, 458.5688, 345.6000],\n",
      "        [ 46.9725, 265.6000, 140.9174, 403.2000],\n",
      "        [  0.0000, 210.1333,  78.6789, 275.2000],\n",
      "        [125.0642, 245.3333, 233.1009, 352.0000],\n",
      "        [236.0367, 125.8667, 510.2385, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([446], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 136.5333, 231.2000, 321.4222],\n",
      "        [221.2000,  86.7556, 374.0000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([565], device='cuda:0')}, {'boxes': tensor([[366.0000, 348.4445, 396.0000, 443.7333],\n",
      "        [  0.0000, 285.1555,  95.2000, 507.7333],\n",
      "        [ 64.0000, 302.9333, 181.2000, 471.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7, 7], device='cuda:0'), 'image_id': tensor([1988], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 233.2444, 510.9333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([242], device='cuda:0')}, {'boxes': tensor([[206.0000, 216.8889, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1222], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.2000, 196.9778, 381.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1605], device='cuda:0')}, {'boxes': tensor([[115.2000, 192.0000, 243.2000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([401], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000, 125.8667, 300.0000, 437.3333],\n",
      "        [280.8000, 201.9556, 324.8000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([906], device='cuda:0')}, {'boxes': tensor([[  0.0000, 204.0889, 173.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([500], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 95.2000, 104.5333, 294.8000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([266], device='cuda:0')}, {'boxes': tensor([[ 85.2000,  96.7111, 492.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1196], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 145.0667, 268.8000, 487.8222],\n",
      "        [288.8000, 113.7778, 426.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1427], device='cuda:0')}, {'boxes': tensor([[118.0000, 226.1333, 442.8000, 510.5778],\n",
      "        [  0.0000, 229.6889, 135.6000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.8000, 156.4444, 111.6000, 201.9556],\n",
      "        [337.6000, 206.2222, 350.4000, 221.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([2080], device='cuda:0')}, {'boxes': tensor([[106.0000, 193.4222, 275.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2061], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.0000,   0.0000, 208.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1509], device='cuda:0')}, {'boxes': tensor([[217.2000,  66.8444, 371.2000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1545], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.6667, 106.6667, 290.1333, 243.2000],\n",
      "        [317.8667, 221.8667, 394.6667, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([669], device='cuda:0')}, {'boxes': tensor([[  0.0000, 386.8445, 175.2000, 510.5778],\n",
      "        [371.2000, 331.3778, 395.2000, 509.1555],\n",
      "        [468.0000, 352.7111, 511.2000, 509.1555],\n",
      "        [224.0000, 392.5333, 341.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([784], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.9333,  68.2667, 284.8000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([724], device='cuda:0')}, {'boxes': tensor([[230.8000, 190.5778, 511.2000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([574], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 34.4000,  22.7556, 472.0000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([220], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 206.2222, 258.1333, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([686], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.8667, 125.1556, 317.8667, 184.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1589], device='cuda:0')}, {'boxes': tensor([[178.0000, 119.4667, 328.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1377], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 366.0000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1385], device='cuda:0')}, {'boxes': tensor([[ 58.1818, 176.4848, 186.1818, 364.6060]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2020], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.2667, 130.8445, 248.5333, 197.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1592], device='cuda:0')}, {'boxes': tensor([[  0.0000, 190.5778,  21.3333, 248.8889],\n",
      "        [377.6000, 167.8222, 510.9333, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([688], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.6000, 230.4000, 509.6000, 499.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([586], device='cuda:0')}, {'boxes': tensor([[143.6000,  18.4889, 219.6000, 137.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1176], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[207.6000, 203.3778, 257.2000, 278.0444],\n",
      "        [142.8000, 238.9333, 177.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([851], device='cuda:0')}, {'boxes': tensor([[128.0000, 196.9778, 378.0000, 397.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1593], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 153.6000, 373.6000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([747], device='cuda:0')}, {'boxes': tensor([[177.3211, 241.0667, 221.3578, 327.4667],\n",
      "        [134.4587, 229.3333, 194.9358, 343.4667],\n",
      "        [423.9266, 266.6667, 509.6514, 411.7333],\n",
      "        [207.8532,  49.0667, 392.2202, 414.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([451], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000,  11.3778, 262.4000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([511], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2092], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000,   7.1111, 502.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([306], device='cuda:0')}, {'boxes': tensor([[134.0000, 193.4222, 374.4000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1602], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.4000,  99.5556, 418.0000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([493], device='cuda:0')}, {'boxes': tensor([[299.2676, 179.2000, 511.1988, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1973], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.2000, 142.2222, 461.2000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([337], device='cuda:0')}, {'boxes': tensor([[120.8000, 280.1778, 235.2000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2003], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.4000,   0.0000, 510.4000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2100], device='cuda:0')}, {'boxes': tensor([[165.6000, 201.9556, 383.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1595], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[147.2000, 308.6222, 230.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2011], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([44], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 33.6000,   9.2444, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1116], device='cuda:0')}, {'boxes': tensor([[181.2000, 216.1778, 457.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([577], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([226], device='cuda:0')}, {'boxes': tensor([[140.0000, 196.2667, 216.0000, 477.8667],\n",
      "        [264.8000, 170.6667, 308.0000, 335.6444],\n",
      "        [478.4000, 213.3333, 509.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([780], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 67.2000,  27.0222, 361.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([595], device='cuda:0')}, {'boxes': tensor([[112.0000, 152.1778, 265.2000, 342.7556],\n",
      "        [219.6000, 175.6444, 398.0000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([568], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.2000, 108.8000, 393.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1352], device='cuda:0')}, {'boxes': tensor([[140.0000, 142.2222, 294.8000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2050], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.4000, 103.8222, 440.0000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1682], device='cuda:0')}, {'boxes': tensor([[118.4000, 209.7778, 327.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1168], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.3333, 234.6667, 155.7333, 300.0889],\n",
      "        [133.3333, 194.8445, 185.6000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([682], device='cuda:0')}, {'boxes': tensor([[326.8000, 196.9778, 482.4000, 424.5333],\n",
      "        [130.8000, 104.5333, 310.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[234.8000, 202.6667, 250.0000, 225.4222],\n",
      "        [280.8000, 224.0000, 305.6000, 256.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([845], device='cuda:0')}, {'boxes': tensor([[306.4000, 386.8445, 328.4000, 418.1333],\n",
      "        [234.0000, 228.2667, 254.8000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000,  49.3115, 284.0000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([958], device='cuda:0')}, {'boxes': tensor([[239.6000,  83.2000, 510.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2167], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 160.0000, 219.2000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1403], device='cuda:0')}, {'boxes': tensor([[274.4000, 285.8667, 510.4000, 506.3111],\n",
      "        [  0.0000,   0.0000, 217.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1614], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[354.8000, 114.4889, 410.0000, 150.0444],\n",
      "        [316.4000, 109.5111, 372.4000, 146.4889],\n",
      "        [244.4000, 122.3111, 314.0000, 152.8889],\n",
      "        [113.6000, 167.8222, 192.4000, 210.4889],\n",
      "        [256.0000, 185.6000, 292.8000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29, 29], device='cuda:0'), 'image_id': tensor([535], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([320], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 164.2667, 509.6000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([572], device='cuda:0')}, {'boxes': tensor([[143.6000, 190.5778, 368.4000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,  44.0889, 322.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1547], device='cuda:0')}, {'boxes': tensor([[115.6000, 329.9556, 148.8000, 418.8445],\n",
      "        [144.4000, 329.2444, 193.2000, 450.8445],\n",
      "        [163.2000, 103.8222, 179.6000, 139.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([627], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[227.5556,  72.5333, 511.0518, 365.5111],\n",
      "        [292.9778, 305.7778, 385.8963, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([183], device='cuda:0')}, {'boxes': tensor([[ 58.4000,   0.0000, 412.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([66], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.6000,   0.0000, 409.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([619], device='cuda:0')}, {'boxes': tensor([[ 89.2000, 221.8667, 190.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([857], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.8000, 117.3333, 219.6000, 174.2222],\n",
      "        [334.8000,  88.1778, 380.4000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1867], device='cuda:0')}, {'boxes': tensor([[201.6000, 162.8445, 363.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([880], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 2.7307e+02, 1.8240e+02, 4.1956e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([381], device='cuda:0')}, {'boxes': tensor([[229.6000, 277.3333, 268.0000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([942], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.4000, 187.7333, 430.8000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([539], device='cuda:0')}, {'boxes': tensor([[334.4000, 289.5738, 435.2000, 393.4426],\n",
      "        [ 88.8000, 220.3279, 258.4000, 436.4590]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([969], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000,  92.4444, 436.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1683], device='cuda:0')}, {'boxes': tensor([[228.8000,  78.2222, 280.0000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([886], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[263.2000, 112.3556, 402.4000, 302.9333],\n",
      "        [ 76.0000,  98.1333, 233.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1754], device='cuda:0')}, {'boxes': tensor([[147.2000, 302.9333, 236.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2010], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.4000, 185.6000, 256.8000, 252.4444],\n",
      "        [241.6000, 263.1111, 263.2000, 298.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([1656], device='cuda:0')}, {'boxes': tensor([[  3.2000,  76.0889, 329.6000, 498.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([270], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 70.8000, 192.0000, 211.2000, 369.0667],\n",
      "        [300.4000, 174.2222, 444.0000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1110], device='cuda:0')}, {'boxes': tensor([[ 14.8000,   0.0000, 299.6000, 329.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[348.8000, 473.6000, 389.6000, 510.5778],\n",
      "        [187.6000, 258.1333, 203.6000, 293.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1871], device='cuda:0')}, {'boxes': tensor([[  0.0000,  89.6000, 264.5333, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([203], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.4519, 106.6667, 508.2074, 399.6444],\n",
      "        [181.0963, 322.8445, 275.9111, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([177], device='cuda:0')}, {'boxes': tensor([[143.6000,  25.6000, 204.4000, 145.7778],\n",
      "        [258.0000, 219.7333, 406.0000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([388], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[345.6000, 354.1333, 364.0000, 428.0889],\n",
      "        [288.0000, 393.9556, 305.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([772], device='cuda:0')}, {'boxes': tensor([[  0.0000, 124.4444, 302.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1003], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 67.2000, 224.7111, 509.8667, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([240], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1866], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.4000, 200.5333, 250.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1245], device='cuda:0')}, {'boxes': tensor([[179.2000,  39.8222, 300.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1056], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[272.0000,  95.2889, 418.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1673], device='cuda:0')}, {'boxes': tensor([[398.0917, 228.2667, 509.6514, 321.0667],\n",
      "        [391.0459, 284.8000, 510.2385, 396.8000],\n",
      "        [ 48.7339, 249.6000, 185.5413, 443.7333],\n",
      "        [423.9266, 309.3333, 510.2385, 466.1333],\n",
      "        [409.2477, 298.6667, 510.2385, 425.6000],\n",
      "        [ 37.5780, 320.0000, 132.6973, 340.2667],\n",
      "        [ 28.7706, 332.8000, 128.5872, 363.7333],\n",
      "        [ 11.7431, 362.6667, 142.0917, 404.2667],\n",
      "        [  0.5872, 400.0000, 162.6422, 505.6000],\n",
      "        [197.8716,  87.4667, 367.5596, 451.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([461], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 263.1111, 258.1333, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2142], device='cuda:0')}, {'boxes': tensor([[202.6667, 182.0444, 249.6000, 241.7778],\n",
      "        [235.7333, 174.9333, 297.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([366], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 171.3778, 302.4000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([114], device='cuda:0')}, {'boxes': tensor([[228.0000,  96.5246, 385.6000, 497.3115]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([957], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1514], device='cuda:0')}, {'boxes': tensor([[ 97.6000, 149.3333, 286.4000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1558], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000,  37.6889, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([639], device='cuda:0')}, {'boxes': tensor([[  4.2667, 253.1555, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([247], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[107.2000, 109.5111, 511.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([732], device='cuda:0')}, {'boxes': tensor([[127.2000, 209.7778, 338.0000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1348], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 70.1630,   0.0000, 510.1037, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1830], device='cuda:0')}, {'boxes': tensor([[190.4000, 192.0000, 348.8000, 364.0889],\n",
      "        [485.6000, 182.7556, 509.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1108], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[113.6000, 211.9111, 264.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([40], device='cuda:0')}, {'boxes': tensor([[211.2000,  91.7333, 278.0000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([263], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.4000, 277.3333, 163.2000, 376.8889],\n",
      "        [199.2000, 278.7556, 212.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([771], device='cuda:0')}, {'boxes': tensor([[270.0000, 223.2889, 356.8000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[202.8000, 135.1111, 443.2000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([327], device='cuda:0')}, {'boxes': tensor([[ 98.0000, 113.7778, 443.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([644], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.8000, 317.8667, 270.0000, 345.6000],\n",
      "        [238.4000, 281.6000, 258.8000, 312.1778],\n",
      "        [236.0000, 244.6222, 256.4000, 276.6222],\n",
      "        [220.8000, 174.2222, 243.6000, 204.8000],\n",
      "        [200.8000, 168.5333, 223.6000, 199.8222],\n",
      "        [177.6000, 163.5556, 201.2000, 193.4222],\n",
      "        [154.8000, 160.0000, 177.6000, 192.0000],\n",
      "        [133.2000, 162.1333, 156.0000, 193.4222],\n",
      "        [228.8000, 206.2222, 251.6000, 236.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([113], device='cuda:0')}, {'boxes': tensor([[103.6000,  70.4000, 233.2000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1907], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.6000,  86.0444, 374.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([131], device='cuda:0')}, {'boxes': tensor([[ 17.6000, 263.8222, 511.2000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.4000, 137.9556, 435.2000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1680], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1516], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 189.1555, 204.8000, 337.0667],\n",
      "        [201.6000, 179.2000, 350.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([637], device='cuda:0')}, {'boxes': tensor([[253.6000, 207.6444, 280.8000, 241.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([940], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.0000,  49.0667, 511.2000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([749], device='cuda:0')}, {'boxes': tensor([[172.8000,  39.8222, 328.5333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1474], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.4000, 216.8889, 329.2000, 301.5111],\n",
      "        [ 80.0000, 237.5111, 206.0000, 347.0222],\n",
      "        [214.4000, 256.0000, 347.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1578], device='cuda:0')}, {'boxes': tensor([[256.0000,  62.5778, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([392], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 157.8667,  53.0963, 220.4444],\n",
      "        [ 45.5111, 160.7111,  82.4889, 199.1111],\n",
      "        [192.4741, 169.2444, 257.8963, 226.1333],\n",
      "        [414.3407, 160.7111, 493.0370, 223.2889],\n",
      "        [252.2074, 149.3333, 320.4741, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 3], device='cuda:0'), 'image_id': tensor([1140], device='cuda:0')}, {'boxes': tensor([[  6.4000, 315.7333, 173.8667, 393.9556],\n",
      "        [388.2667, 256.0000, 509.8667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([691], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.0000,  45.5111, 293.6000, 411.0222],\n",
      "        [112.8000, 297.2444, 136.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([507], device='cuda:0')}, {'boxes': tensor([[199.2000,  79.6444, 351.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1782], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[114.4000, 196.9778, 234.0000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([402], device='cuda:0')}, {'boxes': tensor([[ 82.4000, 192.0000, 231.6000, 374.0444],\n",
      "        [276.8000, 172.8000, 424.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1094], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 74.4000, 125.8667, 348.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([649], device='cuda:0')}, {'boxes': tensor([[  0.0000, 177.7778, 382.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1219], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 105.2444, 509.8667, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1067], device='cuda:0')}, {'boxes': tensor([[  0.0000, 162.8445, 147.2000, 338.4889],\n",
      "        [132.8000, 157.1555, 323.7333, 373.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([56], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  2.4000,  67.5556, 306.4000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([269], device='cuda:0')}, {'boxes': tensor([[480.0000, 273.0667, 509.6000, 366.9333],\n",
      "        [185.6000,  68.2667, 298.4000, 409.6000],\n",
      "        [158.4000, 331.3778, 214.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2,  2, 20], device='cuda:0'), 'image_id': tensor([508], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[319.2000, 226.8445, 397.2000, 356.9778],\n",
      "        [ 77.6000, 171.3778, 232.8000, 306.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1556], device='cuda:0')}, {'boxes': tensor([[386.0000, 381.8667, 451.2000, 455.8222],\n",
      "        [353.2000, 220.4444, 447.2000, 312.1778],\n",
      "        [253.2000, 114.4889, 352.4000, 209.7778],\n",
      "        [272.8000, 278.0444, 369.2000, 368.3556],\n",
      "        [300.0000, 413.1555, 396.8000, 492.0889],\n",
      "        [160.4000, 179.9111, 259.6000, 265.9556],\n",
      "        [182.8000, 304.3556, 278.4000, 381.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([86], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [147.2000,  93.8667, 334.9333, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([603], device='cuda:0')}, {'boxes': tensor([[211.2000, 182.7556, 297.6000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1962], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 172.8000, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1224], device='cuda:0')}, {'boxes': tensor([[223.2000, 227.5556, 346.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2189], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.2000, 224.7111, 288.4000, 330.6667],\n",
      "        [112.0000, 194.1333, 193.2000, 296.5333],\n",
      "        [225.2000, 234.6667, 302.0000, 322.1333],\n",
      "        [137.6000, 209.7778, 218.0000, 297.9556],\n",
      "        [158.4000, 205.5111, 227.2000, 290.1333],\n",
      "        [250.8000, 237.5111, 321.2000, 328.5333],\n",
      "        [319.2000, 258.8445, 398.0000, 358.4000],\n",
      "        [338.4000, 283.0222, 418.0000, 387.5555],\n",
      "        [239.6000, 237.5111, 317.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([121], device='cuda:0')}, {'boxes': tensor([[179.6000, 280.8889, 252.8000, 378.3111],\n",
      "        [ 14.0000, 202.6667, 197.6000, 384.0000],\n",
      "        [139.6000, 278.7556, 226.4000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([513], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.6973,  87.4667, 474.4220, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([474], device='cuda:0')}, {'boxes': tensor([[  0.0000, 120.8889, 310.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1181], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[319.6000, 267.3778, 340.4000, 316.4445],\n",
      "        [295.6000, 201.9556, 318.4000, 257.4222],\n",
      "        [276.8000, 150.0444, 299.2000, 195.5556],\n",
      "        [271.6000, 103.1111, 293.2000, 149.3333],\n",
      "        [269.2000,  59.0222, 289.6000, 103.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([98], device='cuda:0')}, {'boxes': tensor([[117.2000,   0.0000, 336.0000, 428.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1078], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.0000,  41.2444, 356.0000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([63], device='cuda:0')}, {'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1397], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.8667,  83.9111, 332.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1934], device='cuda:0')}, {'boxes': tensor([[377.6000, 139.3778, 402.4000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 51.5220,  27.0222, 396.0755, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1029], device='cuda:0')}, {'boxes': tensor([[254.8000, 269.5111, 276.0000, 320.7111],\n",
      "        [260.0000, 222.5778, 280.4000, 276.6222],\n",
      "        [266.8000, 171.3778, 287.6000, 223.2889],\n",
      "        [240.0000, 139.3778, 259.2000, 189.8667],\n",
      "        [213.2000, 115.2000, 233.2000, 168.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([142], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000, 314.3111, 197.3333, 429.5111],\n",
      "        [377.6000, 300.0889, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([704], device='cuda:0')}, {'boxes': tensor([[169.6000, 271.6444, 251.2000, 337.0667],\n",
      "        [120.8000, 275.9111, 207.2000, 342.0444],\n",
      "        [272.0000, 233.9556, 356.8000, 301.5111],\n",
      "        [226.8000, 184.8889, 320.0000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([136], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 216.8889, 264.4000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2059], device='cuda:0')}, {'boxes': tensor([[195.2000, 167.8222, 456.5333, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([230], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 173.5111,  77.8667, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1714], device='cuda:0')}, {'boxes': tensor([[110.0000, 205.5111, 170.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1508], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 275.9111, 165.6000, 381.1555],\n",
      "        [188.0000, 275.9111, 206.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([770], device='cuda:0')}, {'boxes': tensor([[270.9333, 209.0667, 464.0000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.2000, 189.1555, 336.0000, 234.6667],\n",
      "        [288.8000, 219.0222, 322.0000, 261.6889],\n",
      "        [241.6000, 211.2000, 272.4000, 260.9778],\n",
      "        [213.6000, 256.0000, 248.8000, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([151], device='cuda:0')}, {'boxes': tensor([[147.9111, 109.5111, 511.0518, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.6000, 201.9556, 293.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([95], device='cuda:0')}, {'boxes': tensor([[  8.5333, 182.0444, 299.7333, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([195], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[287.2000, 205.5111, 432.4000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1911], device='cuda:0')}, {'boxes': tensor([[208.8000, 124.4444, 510.0000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([995], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[177.2000, 202.6667, 330.0000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1600], device='cuda:0')}, {'boxes': tensor([[218.6667, 227.5556, 370.1333, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2105], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[317.6000, 234.6667, 366.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1870], device='cuda:0')}, {'boxes': tensor([[  4.4000, 229.6889, 466.0000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1213], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.8000, 120.8889, 221.6000, 364.0889],\n",
      "        [172.8000,  56.8889, 505.6000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([980], device='cuda:0')}, {'boxes': tensor([[  0.0000,  75.3778, 260.8000, 506.3111],\n",
      "        [317.6000, 342.0444, 378.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1645], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.2667, 317.1555, 200.5333, 435.2000],\n",
      "        [379.7333, 300.0889, 442.6667, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([713], device='cuda:0')}, {'boxes': tensor([[ 15.6000,   0.0000, 262.8000, 450.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([545], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000,  70.4000, 314.0000, 400.3556],\n",
      "        [290.8000, 157.8667, 324.8000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1536], device='cuda:0')}, {'boxes': tensor([[214.0000, 114.4889, 508.8000, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([988], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 86.4000,   9.2444, 447.2000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([291], device='cuda:0')}, {'boxes': tensor([[154.0000, 123.7333, 327.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1478], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[297.2000, 332.0889, 324.0000, 380.4445],\n",
      "        [231.6000, 288.0000, 260.0000, 339.9111],\n",
      "        [260.8000, 315.7333, 288.4000, 366.2222],\n",
      "        [238.0000, 214.7556, 268.8000, 268.8000],\n",
      "        [306.4000, 273.7778, 333.2000, 327.1111],\n",
      "        [316.8000, 214.7556, 345.6000, 266.6667],\n",
      "        [278.0000, 179.2000, 306.4000, 229.6889],\n",
      "        [245.2000, 157.8667, 272.8000, 208.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([139], device='cuda:0')}, {'boxes': tensor([[183.2000,   0.0000, 510.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1807], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.7333, 203.3778, 358.4000, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2103], device='cuda:0')}, {'boxes': tensor([[368.0000, 281.6000, 509.8667, 395.3778],\n",
      "        [  0.0000, 250.3111, 226.1333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000,   0.0000, 350.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1479], device='cuda:0')}, {'boxes': tensor([[214.4000, 160.7111, 281.6000, 241.7778],\n",
      "        [281.6000, 162.1333, 356.2667, 238.9333],\n",
      "        [254.9333,  59.7333, 276.2667,  76.8000],\n",
      "        [307.2000,  72.5333, 328.5333,  93.8667],\n",
      "        [424.5333,  75.3778, 446.9333,  93.8667],\n",
      "        [126.9333,  73.9556, 148.2667,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([358], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.0000, 193.4222, 375.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1603], device='cuda:0')}, {'boxes': tensor([[ 64.0000, 195.3185, 246.4000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1148], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[247.6000, 132.9778, 348.8000, 257.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([404], device='cuda:0')}, {'boxes': tensor([[104.0000,  55.4667, 320.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1668], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.0000, 189.8667, 263.6000, 295.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([164], device='cuda:0')}, {'boxes': tensor([[270.8000, 275.2000, 346.0000, 317.8667],\n",
      "        [160.4000, 302.9333, 237.6000, 348.4445],\n",
      "        [271.2000, 227.5556, 350.4000, 273.0667],\n",
      "        [144.0000, 216.8889, 227.2000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([134], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[259.2000, 216.1778, 326.8000, 286.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([130], device='cuda:0')}, {'boxes': tensor([[100.4000, 244.6222, 313.6000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[255.2000,  58.3111, 468.0000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1670], device='cuda:0')}, {'boxes': tensor([[ 83.2000,   0.0000, 298.4000, 228.9778],\n",
      "        [276.0000,   0.0000, 466.4000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1631], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.2000, 295.8222, 429.2000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([655], device='cuda:0')}, {'boxes': tensor([[260.0000, 271.6444, 297.6000, 371.2000],\n",
      "        [166.0000, 172.8000, 187.2000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([831], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.4000,  93.1556, 396.0000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1350], device='cuda:0')}, {'boxes': tensor([[132.0000, 189.8667, 162.8000, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1261], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.2000,   0.0000, 312.0000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1079], device='cuda:0')}, {'boxes': tensor([[198.4000, 218.3111, 232.4000, 263.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([856], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 141.5111, 352.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([658], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000,  18.4000, 104.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1650], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 160.0000, 205.6000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1401], device='cuda:0')}, {'boxes': tensor([[144.8000, 113.0667, 240.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1851], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6000,  21.3333, 418.8000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([353], device='cuda:0')}, {'boxes': tensor([[224.0000, 156.4444, 314.4000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1993], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[242.7259,   0.0000, 475.0222, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1829], device='cuda:0')}, {'boxes': tensor([[ 62.4000, 109.5111, 363.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([157], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.8000, 119.4667, 340.4000, 377.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([923], device='cuda:0')}, {'boxes': tensor([[281.6000, 294.4000, 509.8667, 430.9333],\n",
      "        [  0.0000, 267.3778, 130.1333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2118], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.7333, 261.6889, 295.4667, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2133], device='cuda:0')}, {'boxes': tensor([[162.8000, 276.6222, 435.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([656], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000, 146.4889, 314.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([830], device='cuda:0')}, {'boxes': tensor([[113.6000, 162.9091, 287.2000, 279.2727]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1417], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[327.3114,   8.5333, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1974], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1607], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 10.6667, 145.0667,  70.4000, 220.4444],\n",
      "        [360.5333, 179.2000, 491.7333, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([675], device='cuda:0')}, {'boxes': tensor([[128.4000,  86.7556, 288.4000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2049], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.8000, 142.9333, 268.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2042], device='cuda:0')}, {'boxes': tensor([[170.6667, 166.4000, 324.2667, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([719], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.8000, 142.9333, 438.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([329], device='cuda:0')}, {'boxes': tensor([[202.6667,   0.0000, 360.5333, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2072], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([13], device='cuda:0')}, {'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 229.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1396], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000, 115.9111, 510.4000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2163], device='cuda:0')}, {'boxes': tensor([[108.0367, 116.2667, 294.7523, 300.8000],\n",
      "        [385.1743, 241.0667, 509.0642, 350.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([484], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000,  55.4667, 457.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1806], device='cuda:0')}, {'boxes': tensor([[151.4667, 159.2889, 222.9333, 219.0222],\n",
      "        [216.5333, 169.2444, 300.8000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[138.4296, 182.0444, 232.2963, 284.4445],\n",
      "        [195.3185, 267.3778, 326.1630, 506.3111],\n",
      "        [380.2074, 186.3111, 422.8741, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 3, 7], device='cuda:0'), 'image_id': tensor([1142], device='cuda:0')}, {'boxes': tensor([[224.8000, 147.9111, 314.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1992], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 159.2889, 307.2000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1998], device='cuda:0')}, {'boxes': tensor([[ 12.8000,  96.7111, 280.5333, 231.8222],\n",
      "        [304.0000, 219.0222, 381.8667, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([668], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.2000, 247.4667, 320.4000, 477.8667],\n",
      "        [ 40.4000, 221.1555, 352.8000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([557], device='cuda:0')}, {'boxes': tensor([[  2.8000, 152.1778, 466.8000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1208], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[277.3333, 250.3111, 394.6667, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2108], device='cuda:0')}, {'boxes': tensor([[ 76.0000, 328.5333, 166.0000, 404.6222],\n",
      "        [ 62.4000, 241.0667, 128.0000, 316.4445],\n",
      "        [131.6000, 253.8667, 218.0000, 328.5333],\n",
      "        [ 97.2000, 185.6000, 184.0000, 258.8445],\n",
      "        [146.4000, 135.1111, 230.0000, 203.3778],\n",
      "        [226.4000, 179.2000, 307.6000, 249.6000],\n",
      "        [250.4000, 246.0444, 333.2000, 320.7111],\n",
      "        [304.4000, 238.9333, 391.2000, 309.3333],\n",
      "        [179.2000, 211.9111, 263.6000, 286.5778],\n",
      "        [348.4000, 324.2667, 434.4000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([123], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 228.2667, 470.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1104], device='cuda:0')}, {'boxes': tensor([[327.0459, 218.6667, 423.3394, 330.6667],\n",
      "        [178.4954, 291.2000, 243.6697, 339.2000],\n",
      "        [258.9358, 284.8000, 298.2752, 337.0667],\n",
      "        [294.1651, 281.6000, 332.9174, 329.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([469], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[448.8000,   0.0000, 480.8000,  47.2131]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([975], device='cuda:0')}, {'boxes': tensor([[  0.0000, 258.8445,  76.0000, 405.3333],\n",
      "        [128.0000, 247.4667, 184.0000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([949], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.3333, 119.4667, 407.4667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([205], device='cuda:0')}, {'boxes': tensor([[  5.6000, 250.3111, 384.0000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([654], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.0000, 250.3111, 300.8000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([487], device='cuda:0')}, {'boxes': tensor([[148.0000,   7.1111, 505.2000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([316], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.3111, 130.8445, 509.1555, 420.9778],\n",
      "        [206.6963, 348.4445, 298.6667, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([175], device='cuda:0')}, {'boxes': tensor([[286.0000, 238.2222, 421.6000, 386.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([1049], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 155.0222, 342.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([924], device='cuda:0')}, {'boxes': tensor([[247.2000, 283.0222, 262.4000, 320.7111],\n",
      "        [216.8000, 252.4444, 234.4000, 292.9778],\n",
      "        [232.4000, 271.6444, 248.8000, 312.1778],\n",
      "        [212.4000, 208.3556, 228.8000, 248.8889],\n",
      "        [243.2000, 247.4667, 260.8000, 288.0000],\n",
      "        [240.0000, 210.4889, 256.4000, 250.3111],\n",
      "        [224.0000, 189.1555, 238.8000, 228.2667],\n",
      "        [208.0000, 174.2222, 224.4000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([137], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[175.2000, 241.0667, 258.4000, 347.0222],\n",
      "        [  4.8000, 164.2667, 194.0000, 346.3111],\n",
      "        [150.8000, 240.3556, 243.2000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([516], device='cuda:0')}, {'boxes': tensor([[  9.6000, 290.1333, 294.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1042], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 174.9333, 217.6000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1365], device='cuda:0')}, {'boxes': tensor([[197.8716, 184.5333, 303.5596, 322.1333],\n",
      "        [  1.7615, 321.0667, 509.0642, 509.8667],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 149.7248, 440.5333],\n",
      "        [134.4587, 291.2000, 181.4312, 334.9333],\n",
      "        [136.2202, 276.2667, 187.3027, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [319.4128, 272.0000, 353.4679, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([457], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.3333, 136.5333, 428.8000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([232], device='cuda:0')}, {'boxes': tensor([[ 61.6000, 236.8000, 263.2000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([864], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000, 150.0444, 264.4000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([92], device='cuda:0')}, {'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [170.4000, 158.5778, 202.0000, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1399], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 20.4000,  12.8000, 506.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1579], device='cuda:0')}, {'boxes': tensor([[115.6000, 143.6444, 250.8000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2036], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 164.9778, 425.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1717], device='cuda:0')}, {'boxes': tensor([[191.5259, 149.3333, 511.0518, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([173], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.6000, 132.2667, 220.4000, 317.1555],\n",
      "        [195.2000,  76.8000, 370.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([566], device='cuda:0')}, {'boxes': tensor([[198.4000, 318.5454, 230.4000, 359.2727]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1426], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.1927, 103.4667, 452.6972, 409.6000],\n",
      "        [ 25.2477, 246.4000, 170.2752, 420.2667],\n",
      "        [ 75.7431,  86.4000, 131.5229, 138.6667],\n",
      "        [124.4771,  96.0000, 190.2385, 151.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([432], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 376.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1624], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.0000, 243.9111, 295.6000, 369.0667],\n",
      "        [  0.0000, 226.1333,  66.0000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7], device='cuda:0'), 'image_id': tensor([1990], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([685], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.2000, 241.0667, 510.0000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([587], device='cuda:0')}, {'boxes': tensor([[188.8000, 202.6667, 325.2000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1598], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 33.0667, 162.8445, 196.2667, 342.0444],\n",
      "        [177.6000, 161.4222, 374.9333, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([55], device='cuda:0')}, {'boxes': tensor([[200.0000, 299.6364, 371.2000, 500.3636],\n",
      "        [152.8000, 336.0000, 233.6000, 485.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1322], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1864], device='cuda:0')}, {'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 426.6667, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([699], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 164.9778, 369.0667, 293.9259]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1145], device='cuda:0')}, {'boxes': tensor([[101.6000, 136.5333, 282.4000, 331.3778],\n",
      "        [101.6000, 214.7556, 204.8000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1235], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1511], device='cuda:0')}, {'boxes': tensor([[265.2000, 389.6889, 291.2000, 465.0667],\n",
      "        [242.0000, 294.4000, 266.8000, 369.0667],\n",
      "        [223.2000, 206.9333, 250.4000, 281.6000],\n",
      "        [261.2000, 134.4000, 285.2000, 207.6444],\n",
      "        [297.6000,  79.6444, 323.2000, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([99], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 108.0889, 278.4000, 190.5778],\n",
      "        [174.8000,  76.8000, 262.4000, 155.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([872], device='cuda:0')}, {'boxes': tensor([[270.4000,  87.2727, 394.4000, 231.2727],\n",
      "        [222.4000, 122.1818, 292.0000, 224.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1316], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000,  83.2000, 452.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1833], device='cuda:0')}, {'boxes': tensor([[128.0000, 344.1778, 220.0000, 509.1555],\n",
      "        [354.4000, 339.9111, 463.2000, 510.5778],\n",
      "        [ 45.6000, 327.1111, 125.6000, 506.3111],\n",
      "        [282.4000, 314.3111, 333.6000, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([786], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.7333,  76.8000, 509.8667, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([664], device='cuda:0')}, {'boxes': tensor([[105.2000,  36.2667, 245.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1860], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.0000, 162.1333, 262.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([930], device='cuda:0')}, {'boxes': tensor([[  0.4000, 135.1111, 359.6000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([728], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 55.2000, 118.7556, 281.2000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([223], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1252], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 258.8445, 109.8667, 509.1555],\n",
      "        [164.2667,  99.5556, 349.8667, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([598], device='cuda:0')}, {'boxes': tensor([[152.0000, 104.5333, 372.4000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([78], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 53.3333,   0.0000, 509.8667, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1493], device='cuda:0')}, {'boxes': tensor([[197.6000, 263.8222, 467.6000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([16], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 177.7778, 382.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1218], device='cuda:0')}, {'boxes': tensor([[129.3617, 105.2444, 239.6596, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1089], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 147.9111, 462.9333, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1942], device='cuda:0')}, {'boxes': tensor([[198.4000, 260.2667, 345.6000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1938], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 193.4222, 324.2667, 305.3037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1147], device='cuda:0')}, {'boxes': tensor([[147.2000, 135.1111, 206.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1193], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.4000,   4.2667, 501.6000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([307], device='cuda:0')}, {'boxes': tensor([[150.0000,  89.6000, 261.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([91], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 142.2222, 341.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([635], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([735], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000, 119.4667, 414.4000, 509.8667],\n",
      "        [ 76.8000, 123.7333, 310.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1412], device='cuda:0')}, {'boxes': tensor([[132.8000, 167.1111, 388.0000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([279], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[262.4000, 284.4445, 304.0000, 341.3333],\n",
      "        [183.2000, 224.7111, 224.4000, 285.1555],\n",
      "        [220.8000, 260.2667, 260.8000, 319.2889],\n",
      "        [196.0000, 140.0889, 238.8000, 200.5333],\n",
      "        [280.0000, 219.7333, 321.2000, 276.6222],\n",
      "        [299.2000, 148.6222, 340.4000, 208.3556],\n",
      "        [252.8000, 107.3778, 292.8000, 166.4000],\n",
      "        [213.2000,  70.4000, 252.8000, 130.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([140], device='cuda:0')}, {'boxes': tensor([[171.6000,  12.0889, 410.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([265], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.5333, 221.8667, 338.1333, 278.7556],\n",
      "        [  0.0000, 149.3333,  58.6667, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([256], device='cuda:0')}, {'boxes': tensor([[267.2000, 115.2000, 352.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1132], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.0000,   3.5556, 497.2000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([289], device='cuda:0')}, {'boxes': tensor([[187.7333, 176.3556, 326.1630, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([760], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 230.4000, 274.4000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1634], device='cuda:0')}, {'boxes': tensor([[120.8000,  22.7556, 394.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([346], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000,  80.3556, 292.8000, 219.7333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1189], device='cuda:0')}, {'boxes': tensor([[136.0000,  58.3111, 371.6000, 434.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1859], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  9.2000,  47.6444, 510.8000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([378], device='cuda:0')}, {'boxes': tensor([[121.6000, 110.9333, 381.8667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([715], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[484.4000, 194.1333, 511.2000, 226.1333],\n",
      "        [401.6000, 188.4444, 483.6000, 228.9778],\n",
      "        [332.0000, 200.5333, 403.2000, 235.3778],\n",
      "        [146.4000, 260.2667, 229.6000, 300.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29], device='cuda:0'), 'image_id': tensor([536], device='cuda:0')}, {'boxes': tensor([[ 89.6000, 181.3333, 510.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1279], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.2000,  80.3556, 295.6000, 221.8667],\n",
      "        [140.0000, 113.7778, 178.4000, 192.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1188], device='cuda:0')}, {'boxes': tensor([[182.0000, 137.9556, 457.6000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([339], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.6000, 205.5111, 510.4000, 480.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([585], device='cuda:0')}, {'boxes': tensor([[208.8000, 104.5333, 334.8000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1842], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[233.6000, 184.8889, 339.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2180], device='cuda:0')}, {'boxes': tensor([[187.6000, 145.0667, 292.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1841], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 14.8000,   0.0000, 272.0000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([411], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 318.4000, 510.5778],\n",
      "        [302.4000, 228.9778, 466.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1632], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 11.2000,   0.0000, 251.6000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([412], device='cuda:0')}, {'boxes': tensor([[  0.0000, 204.8000, 130.1333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2091], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 251.7333, 179.2000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1035], device='cuda:0')}, {'boxes': tensor([[ 94.4000, 187.0222, 252.4000, 364.8000],\n",
      "        [282.4000, 182.7556, 425.6000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1097], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000,  78.2222, 448.8000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1681], device='cuda:0')}, {'boxes': tensor([[ 26.6667, 157.1555,  72.5333, 307.9111],\n",
      "        [101.3333, 194.8445, 219.7333, 312.8889],\n",
      "        [233.6000, 214.0444, 342.4000, 315.7333],\n",
      "        [408.5333, 209.0667, 461.3333, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([59], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 179.2000, 270.0000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1339], device='cuda:0')}, {'boxes': tensor([[208.0000,  57.6000, 508.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.3099, 196.8000, 376.7887, 336.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1061], device='cuda:0')}, {'boxes': tensor([[206.8000, 178.4889, 259.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([855], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[209.6000, 115.9111, 353.2000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([118], device='cuda:0')}, {'boxes': tensor([[196.0000, 322.1333, 363.2000, 510.5778],\n",
      "        [ 67.2000, 330.6667, 374.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 365.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1772], device='cuda:0')}, {'boxes': tensor([[104.4000, 192.0000, 195.2000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([369], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 70.4000, 136.5333, 347.6000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([742], device='cuda:0')}, {'boxes': tensor([[  6.0000, 113.0667, 466.4000, 425.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1209], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  24.1778, 317.2000, 491.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([272], device='cuda:0')}, {'boxes': tensor([[216.8000, 136.5333, 392.4000, 312.8889],\n",
      "        [ 64.4000, 143.6444, 219.6000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([869], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[113.6000, 204.8000, 288.8000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([926], device='cuda:0')}, {'boxes': tensor([[ 96.0000,  49.7778, 323.2000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([721], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.2667, 302.9333, 245.3333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2122], device='cuda:0')}, {'boxes': tensor([[195.2000, 153.6000, 338.0000, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1954], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[202.6667, 271.6444, 224.0000, 285.8667],\n",
      "        [402.1333, 265.9556, 430.9333, 280.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2113], device='cuda:0')}, {'boxes': tensor([[ 68.8000, 160.7111, 300.0000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([542], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[282.8000, 161.4222, 393.6000, 299.3778],\n",
      "        [ 94.0000, 142.2222, 290.4000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([904], device='cuda:0')}, {'boxes': tensor([[  7.4667, 179.2000, 306.1333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([196], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 216.8889, 287.2000, 280.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1928], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2131], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  3.2000,  12.8000, 311.6000, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([294], device='cuda:0')}, {'boxes': tensor([[275.2000, 125.1556, 385.0667, 194.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1588], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.0881,   0.0000, 322.8176, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1027], device='cuda:0')}, {'boxes': tensor([[203.2000,  47.6444, 371.6000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([827], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.4000, 210.4889, 288.8000, 419.5555],\n",
      "        [  0.0000,   0.0000, 368.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1663], device='cuda:0')}, {'boxes': tensor([[181.2000, 276.6222, 443.6000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([578], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[394.5688, 224.0000, 509.6514, 316.8000],\n",
      "        [388.1101, 281.6000, 510.2385, 393.6000],\n",
      "        [ 45.7982, 246.4000, 182.0183, 440.5333],\n",
      "        [420.9908, 306.1333, 510.2385, 461.8667],\n",
      "        [406.3119, 294.4000, 510.2385, 421.3333],\n",
      "        [ 34.0550, 316.8000, 129.1743, 337.0667],\n",
      "        [ 25.8349, 329.6000, 125.0642, 360.5333],\n",
      "        [ 10.5688, 359.4667, 137.9817, 401.0667],\n",
      "        [  0.5872, 396.8000, 159.7064, 504.5333],\n",
      "        [195.5229,  83.2000, 366.3853, 449.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([462], device='cuda:0')}, {'boxes': tensor([[158.4000,  96.7111, 200.4000, 138.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.9333, 129.4222, 509.8667, 365.5111],\n",
      "        [  4.2667,   0.0000, 472.5333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([51], device='cuda:0')}, {'boxes': tensor([[277.2000, 184.1778, 378.0000, 374.0444],\n",
      "        [263.2000, 201.9556, 420.8000, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([418], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 283.0222, 289.2000, 349.8667],\n",
      "        [238.8000, 271.6444, 315.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1822], device='cuda:0')}, {'boxes': tensor([[291.2000, 285.3770, 328.0000, 344.1311]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([976], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 192.0000, 265.2000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1357], device='cuda:0')}, {'boxes': tensor([[ 31.2000, 128.0000,  83.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1135], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.4667, 157.8667, 221.8667, 219.0222],\n",
      "        [214.4000, 169.2444, 296.5333, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([362], device='cuda:0')}, {'boxes': tensor([[272.1185,   0.0000, 485.4518, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1828], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[352.4000, 199.1111, 425.2000, 323.5555],\n",
      "        [  1.6000, 160.7111,  54.4000, 231.1111],\n",
      "        [ 57.6000, 122.3111, 126.4000, 236.8000],\n",
      "        [152.0000, 142.9333, 195.6000, 266.6667],\n",
      "        [ 92.8000, 110.9333, 116.8000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2031], device='cuda:0')}, {'boxes': tensor([[295.6000,  88.1778, 416.4000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1534], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.9333, 109.5111, 245.3333, 228.9778],\n",
      "        [326.4000, 152.1778, 385.0667, 227.5556],\n",
      "        [290.1333,  52.6222, 309.3333,  71.1111],\n",
      "        [343.4667,  65.4222, 362.6667,  83.9111],\n",
      "        [457.6000,  65.4222, 480.0000,  83.9111],\n",
      "        [155.7333,  68.2667, 177.0667,  92.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([360], device='cuda:0')}, {'boxes': tensor([[180.8000, 135.1111, 321.6000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([395], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 135.2727, 460.8000, 347.6364],\n",
      "        [176.0000, 205.0909, 297.6000, 343.2727]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1317], device='cuda:0')}, {'boxes': tensor([[225.0667,  35.5556, 421.3333, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1152], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.6000, 224.7111, 268.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([39], device='cuda:0')}, {'boxes': tensor([[282.8000, 179.9111, 459.2000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1287], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 260.2667, 268.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([948], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([803], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.0667,  49.7778, 410.6667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1695], device='cuda:0')}, {'boxes': tensor([[164.0000, 103.1111, 202.8000, 140.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1173], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2089], device='cuda:0')}, {'boxes': tensor([[ 88.5333,  82.4889, 259.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1071], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.8000, 214.7556, 192.8000, 493.5111],\n",
      "        [263.2000, 184.8889, 309.6000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([778], device='cuda:0')}, {'boxes': tensor([[220.8000, 164.2667, 342.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1448], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000,   0.0000, 302.0000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([814], device='cuda:0')}, {'boxes': tensor([[224.0000, 208.3556, 348.4000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([77], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 219.0222, 252.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1240], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  17.0667, 487.4667, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  9.6000, 198.4000, 454.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1271], device='cuda:0')}, {'boxes': tensor([[ 69.3333,  28.4444, 329.6000, 167.8222],\n",
      "        [326.4000, 155.0222, 409.6000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([666], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000, 154.3111, 454.0000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([372], device='cuda:0')}, {'boxes': tensor([[ 94.8000,   0.0000, 288.4000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([413], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[126.4000, 198.4000, 315.6000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1953], device='cuda:0')}, {'boxes': tensor([[255.6000, 113.7778, 420.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1794], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[147.2000,  96.7111, 305.6000, 501.3333],\n",
      "        [255.2000,  16.3556, 416.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1123], device='cuda:0')}, {'boxes': tensor([[  0.0000,  17.7778, 304.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1180], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.2000,  98.6229, 197.6000, 442.7541]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([961], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.3938e+02, 2.5560e+02, 4.9067e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([301], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[126.4000, 259.1476, 306.4000, 382.9508]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([973], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  88.1778, 243.2000, 253.1555],\n",
      "        [243.2000,  69.6889, 366.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1740], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.8000, 132.9778, 352.4000, 350.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([659], device='cuda:0')}, {'boxes': tensor([[124.4000, 125.8667, 310.0000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1855], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.2000, 214.7556, 295.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([88], device='cuda:0')}, {'boxes': tensor([[180.4000,  56.8889, 329.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.5872, 121.6000, 376.3670, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([427], device='cuda:0')}, {'boxes': tensor([[180.2667,   0.0000, 377.6000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([594], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.4225,  88.0000, 396.6197, 427.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1063], device='cuda:0')}, {'boxes': tensor([[193.6000, 153.6000, 372.0000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([746], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 195.5556, 317.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([80], device='cuda:0')}, {'boxes': tensor([[206.8000, 210.4889, 430.0000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2156], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 133.6889, 461.2000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([341], device='cuda:0')}, {'boxes': tensor([[  9.6000, 278.0444, 352.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([47], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.8000,  88.1778, 505.6000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([324], device='cuda:0')}, {'boxes': tensor([[210.4000, 132.2667, 312.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([81], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000,  51.2000, 310.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1047], device='cuda:0')}, {'boxes': tensor([[265.9155,   0.0000, 511.0986, 288.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1489], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.8000,  96.0000, 372.8000, 509.1555],\n",
      "        [322.0000, 104.5333, 432.8000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([912], device='cuda:0')}, {'boxes': tensor([[220.8000, 143.6444, 279.2000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1342], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[175.6000,   0.0000, 323.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1309], device='cuda:0')}, {'boxes': tensor([[ 27.7333, 169.2444, 410.6667, 457.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1712], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000,  47.6444, 511.2000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([751], device='cuda:0')}, {'boxes': tensor([[ 84.8000, 119.4667, 510.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1283], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.6000, 130.8445, 193.6000, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2151], device='cuda:0')}, {'boxes': tensor([[ 94.4000, 180.6222, 507.2000, 364.0889],\n",
      "        [ 28.8000, 125.1556, 147.2000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1639], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 229.6889, 316.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([46], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1764], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000,  61.8667, 362.8000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([842], device='cuda:0')}, {'boxes': tensor([[  9.6000, 178.4889, 176.0000, 358.4000],\n",
      "        [158.9333, 178.4889, 350.4000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([57], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.0000, 103.1111, 154.0000, 201.9556],\n",
      "        [284.8000, 135.1111, 326.4000, 214.7556],\n",
      "        [333.2000, 171.3778, 383.2000, 255.2889],\n",
      "        [ 58.8000, 112.3556,  94.4000, 223.2889],\n",
      "        [234.4000, 142.2222, 284.8000, 199.1111],\n",
      "        [305.2000, 142.9333, 346.8000, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2030], device='cuda:0')}, {'boxes': tensor([[166.4000, 185.6000, 316.8000, 509.8667],\n",
      "        [310.4000, 204.8000, 476.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1414], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 218.3111, 286.0000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1927], device='cuda:0')}, {'boxes': tensor([[124.8000,  34.1333, 362.4000, 429.5111],\n",
      "        [  0.0000,  18.4889,  80.0000, 160.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1774], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.0000,  39.1111, 348.8000, 374.7556],\n",
      "        [ 89.6000, 265.9556,  98.0000, 298.6667],\n",
      "        [ 79.6000, 263.8222,  88.4000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1016], device='cuda:0')}, {'boxes': tensor([[288.0000, 255.2889, 326.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([193], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 192.0000, 511.2000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([575], device='cuda:0')}, {'boxes': tensor([[  0.5872, 421.3333, 402.2018, 506.6667],\n",
      "        [452.1101, 370.1333, 510.2385, 491.7333],\n",
      "        [299.4496, 299.7333, 437.4312, 433.0667],\n",
      "        [344.6606, 336.0000, 493.2110, 504.5333],\n",
      "        [191.4128, 359.4667, 216.6606, 424.5333],\n",
      "        [214.3119, 356.2667, 260.6972, 432.0000],\n",
      "        [176.7339, 279.4667, 313.5413, 429.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([440], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[125.2000, 213.3333, 338.0000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1169], device='cuda:0')}, {'boxes': tensor([[116.4000, 236.8000, 188.4000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1507], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[315.7333, 164.9778, 378.6667, 250.3111],\n",
      "        [254.9333, 150.7556, 338.1333, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([357], device='cuda:0')}, {'boxes': tensor([[ 59.4747, 257.9394, 196.5253, 473.2121]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2022], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 123.0222, 332.8000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1378], device='cuda:0')}, {'boxes': tensor([[128.0000,  41.2444, 401.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([351], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.7248, 129.0667, 419.2294, 437.3333],\n",
      "        [408.6606,  89.6000, 438.0183, 192.0000],\n",
      "        [ 35.2294, 106.6667,  94.5321, 172.8000],\n",
      "        [ 85.7248, 118.4000, 156.1835, 173.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([435], device='cuda:0')}, {'boxes': tensor([[ 56.5333,  45.5111, 299.7333, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1506], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000, 193.4222, 349.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([126], device='cuda:0')}, {'boxes': tensor([[ 61.0642, 109.8667, 369.9083, 410.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([428], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.8000, 205.5111, 222.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([403], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 438.4000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1835], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,   5.6889, 509.6000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([310], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.5929e+02, 3.2760e+02, 4.9849e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([304], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.3289e+01, 2.5680e+02, 4.9422e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([300], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 448.8000, 440.8889],\n",
      "        [238.4000, 103.8222, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1643], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.6000, 155.0222, 467.6000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([333], device='cuda:0')}, {'boxes': tensor([[126.4000, 205.5111, 308.4000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1952], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 220.4444, 332.4000, 509.1555],\n",
      "        [320.8000, 351.2889, 412.8000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1249], device='cuda:0')}, {'boxes': tensor([[203.7333, 170.6667, 274.1333, 243.2000],\n",
      "        [267.7333, 180.6222, 337.0667, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([354], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000,  52.6222, 381.6000, 146.4889],\n",
      "        [132.0000, 112.3556, 283.6000, 205.5111],\n",
      "        [ 62.4000, 174.2222, 203.2000, 268.8000],\n",
      "        [ 61.6000, 276.6222, 121.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([149], device='cuda:0')}, {'boxes': tensor([[119.2000, 114.4889, 220.4000, 247.4667],\n",
      "        [272.8000, 159.2889, 314.0000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([850], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000, 128.0000, 359.6000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([650], device='cuda:0')}, {'boxes': tensor([[269.2000,  86.7556, 365.2000, 226.1333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000,  86.7556, 489.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1195], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 5.5467e+01, 4.5800e+02, 4.4160e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([276], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.4000,   3.5556, 503.2000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([318], device='cuda:0')}, {'boxes': tensor([[ 55.2000, 130.1333, 458.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1201], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 199.8222, 201.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1654], device='cuda:0')}, {'boxes': tensor([[196.0000,  66.8444, 317.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([878], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.0000, 182.0444, 286.4000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1548], device='cuda:0')}, {'boxes': tensor([[172.0000, 198.4000, 342.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000,   0.0000, 508.8000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1811], device='cuda:0')}, {'boxes': tensor([[176.0000, 104.5333, 191.2000, 155.0222],\n",
      "        [238.0000, 244.6222, 251.6000, 268.8000],\n",
      "        [244.4000, 405.3333, 314.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24], device='cuda:0'), 'image_id': tensor([1880], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333, 260.2667, 317.8667, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1939], device='cuda:0')}, {'boxes': tensor([[196.4000, 217.6000, 236.4000, 357.6889],\n",
      "        [432.8000, 132.9778, 484.0000, 199.1111],\n",
      "        [310.8000, 128.0000, 358.8000, 197.6889],\n",
      "        [304.0000, 128.7111, 343.6000, 175.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1950], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.8000,  64.0000, 281.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1901], device='cuda:0')}, {'boxes': tensor([[159.2000, 164.2667, 289.6000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1783], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.6000,  32.7111, 375.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([807], device='cuda:0')}, {'boxes': tensor([[ 32.4000,   3.5556, 289.6000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([268], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.0000,  79.6444, 201.6000, 261.6889],\n",
      "        [152.0000,  34.1333, 285.6000, 233.2444],\n",
      "        [444.8000, 123.7333, 511.2000, 226.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1746], device='cuda:0')}, {'boxes': tensor([[268.8000, 187.0222, 360.0000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1520], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.0000, 244.6222, 276.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([950], device='cuda:0')}, {'boxes': tensor([[187.6000, 216.8889, 345.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([921], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.4000, 181.3333, 249.6000, 251.7333],\n",
      "        [245.2000, 263.8222, 260.8000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([1657], device='cuda:0')}, {'boxes': tensor([[ 73.2000,  32.0000, 501.6000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([288], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.8000, 109.5111, 238.0000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([212], device='cuda:0')}, {'boxes': tensor([[  1.1743, 467.2000, 383.4128, 508.8000],\n",
      "        [446.2385, 417.0667, 509.0642, 508.8000],\n",
      "        [292.9908, 349.8667, 432.7339, 487.4667],\n",
      "        [342.8991, 394.6667, 483.2294, 507.7333],\n",
      "        [184.3670, 404.2667, 214.3119, 471.4667],\n",
      "        [224.8807, 265.6000, 361.1009, 470.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([442], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.0667, 261.6889, 499.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([238], device='cuda:0')}, {'boxes': tensor([[213.6000, 250.3111, 292.4000, 307.2000],\n",
      "        [112.0000, 263.8222, 194.8000, 318.5778],\n",
      "        [260.8000, 192.0000, 344.0000, 256.0000],\n",
      "        [150.4000, 159.2889, 240.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([135], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.8000,  12.0889, 510.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([571], device='cuda:0')}, {'boxes': tensor([[ 99.6000, 238.2222, 310.0000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1162], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 28.8000, 175.6444, 201.6000, 381.1555],\n",
      "        [388.8000, 179.2000, 460.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1522], device='cuda:0')}, {'boxes': tensor([[206.0000,  65.4222, 322.0000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([837], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.2148, 190.5778, 334.6963, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([757], device='cuda:0')}, {'boxes': tensor([[260.8000, 110.9333, 440.8000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1986], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.0667, 250.3111, 510.9333, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([248], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1492], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.0000, 188.4444, 361.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2160], device='cuda:0')}, {'boxes': tensor([[  0.0000, 198.4000, 175.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([499], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.2000, 196.2667, 380.4000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1604], device='cuda:0')}, {'boxes': tensor([[166.4000, 185.6000, 288.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1967], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.0000, 170.6667, 363.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2174], device='cuda:0')}, {'boxes': tensor([[216.8000, 126.5778, 347.6000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([660], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.8000, 110.9333, 305.6000, 453.6889],\n",
      "        [  0.0000,  89.6000,  64.0000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1770], device='cuda:0')}, {'boxes': tensor([[189.6000, 200.5333, 414.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2157], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.4000, 352.7111, 243.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1133], device='cuda:0')}, {'boxes': tensor([[181.0963,  86.7556, 508.2074, 395.3778],\n",
      "        [241.7778, 318.5778, 340.3852, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 135.1111, 334.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1762], device='cuda:0')}, {'boxes': tensor([[200.4000, 194.1333, 236.8000, 226.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2063], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.0667, 194.8445, 509.8667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([241], device='cuda:0')}, {'boxes': tensor([[302.0000, 172.8000, 354.4000, 260.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1446], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667,   2.8444, 369.0667, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([590], device='cuda:0')}, {'boxes': tensor([[152.0000,  56.8889, 204.8000, 123.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667, 179.2000, 229.3333, 244.6222],\n",
      "        [224.0000, 176.3556, 289.0667, 244.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([365], device='cuda:0')}, {'boxes': tensor([[169.2000, 107.3778, 262.4000, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1898], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 198.4000, 393.6000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([918], device='cuda:0')}, {'boxes': tensor([[104.0000,  96.7111, 456.0000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1812], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[291.6557, 149.3333, 493.5712, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1971], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 460.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2099], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 97.6000, 125.1556, 382.4000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1814], device='cuda:0')}, {'boxes': tensor([[168.8000, 250.3111, 198.4000, 381.1555],\n",
      "        [251.2000, 251.7333, 273.6000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([763], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 182.0444,  26.6667, 264.5333],\n",
      "        [356.2667, 137.9556, 509.8667, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([689], device='cuda:0')}, {'boxes': tensor([[155.2000, 149.3333, 277.6000, 285.8667],\n",
      "        [  1.6000, 142.2222,  44.0000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1382], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[262.8000, 193.4222, 325.6000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([94], device='cuda:0')}, {'boxes': tensor([[  0.0000, 318.9333, 118.0183, 446.9333],\n",
      "        [  0.5872, 337.0667, 181.4312, 504.5333],\n",
      "        [ 78.0917, 376.5333, 325.8716, 509.8667],\n",
      "        [365.2110, 417.0667, 506.7156, 503.4667],\n",
      "        [108.0367, 103.4667, 476.7706, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([444], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[380.8000, 203.3778, 446.4000, 263.8222],\n",
      "        [351.2000, 160.0000, 400.8000, 237.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([868], device='cuda:0')}, {'boxes': tensor([[148.8000,   0.0000, 274.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([415], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.8000,   8.5333, 292.8000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1046], device='cuda:0')}, {'boxes': tensor([[241.9083, 202.6667, 470.8991, 405.3333],\n",
      "        [  0.0000, 238.9333, 129.7615, 408.5333],\n",
      "        [ 44.0367, 105.6000, 506.7156, 374.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([481], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 193.4222, 223.2000, 232.5333],\n",
      "        [276.4000, 208.3556, 319.2000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([847], device='cuda:0')}, {'boxes': tensor([[111.2000, 299.7333, 184.0000, 382.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([794], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 231.1111, 345.2000, 509.8667],\n",
      "        [339.6000, 354.8445, 417.2000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1250], device='cuda:0')}, {'boxes': tensor([[172.0000, 122.3111, 185.6000, 170.6667],\n",
      "        [224.4000, 247.4667, 248.8000, 270.2222],\n",
      "        [232.4000, 388.9778, 292.8000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24], device='cuda:0'), 'image_id': tensor([1881], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.1333, 174.9333, 342.4000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1064], device='cuda:0')}, {'boxes': tensor([[212.4000,  80.3556, 253.6000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([853], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[239.2000, 132.2667, 349.6000, 211.2000],\n",
      "        [225.2000, 179.9111, 330.8000, 260.2667],\n",
      "        [220.0000, 236.8000, 325.6000, 315.0222],\n",
      "        [207.2000, 270.2222, 312.0000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([147], device='cuda:0')}, {'boxes': tensor([[  0.0000, 187.7333,  76.8000, 318.5778],\n",
      "        [358.4000, 224.7111, 441.6000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([672], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[137.6000, 248.8889, 324.2667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2140], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.2231e+02, 4.2720e+02, 3.1929e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([730], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.8000, 189.1555, 279.2000, 315.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([894], device='cuda:0')}, {'boxes': tensor([[171.2000, 161.4222, 423.6000, 440.8889],\n",
      "        [ 60.4000, 258.8445, 152.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([866], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 344.5333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1257], device='cuda:0')}, {'boxes': tensor([[ 21.2000,  18.4889, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1580], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.0000, 138.6667, 378.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1100], device='cuda:0')}, {'boxes': tensor([[229.3333, 182.0444, 307.2000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([261], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[244.4000, 190.5778, 318.4000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1929], device='cuda:0')}, {'boxes': tensor([[139.2000, 241.0667, 238.0000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1344], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000,  64.0000, 470.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([218], device='cuda:0')}, {'boxes': tensor([[158.8000, 280.1778, 230.0000, 386.8445],\n",
      "        [  0.4000, 204.8000, 176.4000, 385.4222],\n",
      "        [147.2000, 284.4445, 240.4000, 393.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([512], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 43.2000, 100.9778, 177.6000, 295.8222],\n",
      "        [184.0000,  93.8667, 325.6000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1753], device='cuda:0')}, {'boxes': tensor([[152.0000, 125.8667, 510.4000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1039], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[202.4000, 174.5455, 371.2000, 373.8182],\n",
      "        [140.8000, 218.1818, 238.4000, 366.5454]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1323], device='cuda:0')}, {'boxes': tensor([[185.6000, 140.0889, 377.6000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1101], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.8000, 216.8889, 336.4000, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1171], device='cuda:0')}, {'boxes': tensor([[220.4000, 187.0222, 290.8000, 371.2000],\n",
      "        [295.6000, 105.9556, 336.0000, 170.6667],\n",
      "        [388.8000, 107.3778, 425.6000, 160.0000],\n",
      "        [228.4000, 106.6667, 264.0000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1951], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.7333, 130.8445, 300.8000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1150], device='cuda:0')}, {'boxes': tensor([[ 48.7339, 344.5333, 510.2385, 508.8000],\n",
      "        [100.4037,  16.0000, 496.7339, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([463], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[298.4000, 203.3778, 340.0000, 277.3333],\n",
      "        [ 41.6000, 102.4000, 304.8000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([899], device='cuda:0')}, {'boxes': tensor([[  4.0000, 211.9111, 312.8000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([296], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000,  39.8222, 262.4000, 216.1778],\n",
      "        [247.2000,  45.5111, 338.4000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1745], device='cuda:0')}, {'boxes': tensor([[180.4000, 185.6000, 258.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1338], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  8.4000,  18.4889, 311.2000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1799], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  68.9778, 453.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.0000, 145.7778, 469.2000, 480.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1451], device='cuda:0')}, {'boxes': tensor([[158.0000, 159.2889, 295.2000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1784], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 112.3556, 287.2000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1334], device='cuda:0')}, {'boxes': tensor([[260.4000, 123.0222, 277.6000, 165.6889],\n",
      "        [244.8000, 176.3556, 262.0000, 216.8889],\n",
      "        [230.4000, 244.6222, 249.6000, 285.1555],\n",
      "        [215.6000, 316.4445, 233.6000, 354.1333],\n",
      "        [204.8000, 379.7333, 222.4000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([143], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  59.0222, 396.8000, 155.0222],\n",
      "        [144.4000, 117.3333, 295.2000, 213.3333],\n",
      "        [ 70.4000, 179.2000, 213.6000, 276.6222],\n",
      "        [ 61.6000, 279.4667, 130.0000, 326.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([150], device='cuda:0')}, {'boxes': tensor([[331.2000, 206.2222, 415.2000, 373.3333],\n",
      "        [109.2000, 190.5778, 239.6000, 395.3778],\n",
      "        [238.0000, 234.6667, 265.6000, 304.3556],\n",
      "        [266.4000, 236.0889, 281.6000, 289.4222],\n",
      "        [290.8000, 241.0667, 332.0000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([1908], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000,  11.3778, 468.2667, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1723], device='cuda:0')}, {'boxes': tensor([[108.4000, 108.0889, 273.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2047], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000,  41.2444, 354.0000, 359.8222],\n",
      "        [208.8000, 262.4000, 220.4000, 297.9556],\n",
      "        [397.2000, 244.6222, 430.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1014], device='cuda:0')}, {'boxes': tensor([[175.6000, 278.0444, 258.8000, 375.4667],\n",
      "        [ 22.4000, 200.5333, 210.0000, 381.8667],\n",
      "        [140.8000, 269.5111, 238.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([514], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 43.7333, 201.9556, 253.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1043], device='cuda:0')}, {'boxes': tensor([[175.6000, 189.8667, 280.4000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([893], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.8000, 203.3778, 249.6000, 337.0667],\n",
      "        [124.4000, 150.0444, 192.0000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([1243], device='cuda:0')}, {'boxes': tensor([[ 55.1927,  73.6000, 462.6789, 405.3333],\n",
      "        [459.1560, 264.5333, 480.2936, 334.9333],\n",
      "        [  0.5872, 326.4000, 297.6881, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6, 19,  7], device='cuda:0'), 'image_id': tensor([478], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 111.6444, 297.2000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([726], device='cuda:0')}, {'boxes': tensor([[140.0000, 177.7778, 314.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1964], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[282.0000, 179.9111, 383.6000, 292.9778],\n",
      "        [100.0000, 135.8222, 292.8000, 462.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([901], device='cuda:0')}, {'boxes': tensor([[ 62.4000, 228.2667, 265.6000, 505.6000],\n",
      "        [266.4000, 283.7333, 333.6000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([905], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 91.0222,  62.5778, 468.3852, 369.7778],\n",
      "        [159.2889, 292.9778, 247.4667, 366.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([181], device='cuda:0')}, {'boxes': tensor([[  0.0000, 189.1555,  45.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1905], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 136.5333, 299.2000, 341.3333],\n",
      "        [244.8000,  44.0889, 404.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1230], device='cuda:0')}, {'boxes': tensor([[ 66.1333, 305.7778, 193.0667, 433.7778],\n",
      "        [379.7333, 291.5555, 446.9333, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([710], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000, 144.0000, 463.2000, 349.0909],\n",
      "        [159.2000, 208.0000, 254.4000, 341.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1319], device='cuda:0')}, {'boxes': tensor([[ 44.4000,  12.8000, 510.4000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([799], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  2.0000,  35.5556, 339.6000, 492.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([271], device='cuda:0')}, {'boxes': tensor([[104.5333,   0.0000, 274.1333, 413.3926]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1256], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[231.2000, 151.4667, 300.0000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1961], device='cuda:0')}, {'boxes': tensor([[116.4000, 349.8667, 350.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([15], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[137.6000,  34.8444, 346.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1480], device='cuda:0')}, {'boxes': tensor([[130.6205,  88.8889, 475.7165, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2095], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 116.6222, 310.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1182], device='cuda:0')}, {'boxes': tensor([[ 55.4667,  85.3333, 249.6000, 294.4000],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1083], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 216.1778, 389.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2169], device='cuda:0')}, {'boxes': tensor([[ 12.8000, 157.8667,  72.5333, 226.1333],\n",
      "        [375.4667, 192.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([674], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[113.0667,  79.6444, 412.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1691], device='cuda:0')}, {'boxes': tensor([[ 20.1258,   1.4222, 301.0818, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1026], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2135], device='cuda:0')}, {'boxes': tensor([[135.6000, 152.8889, 356.0000, 471.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2155], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[177.3211, 244.2667, 221.3578, 327.4667],\n",
      "        [133.2844, 231.4667, 192.0000, 345.6000],\n",
      "        [415.7064, 268.8000, 509.6514, 410.6667],\n",
      "        [209.0275,  49.0667, 393.9817, 421.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([452], device='cuda:0')}, {'boxes': tensor([[  2.4000, 135.8222, 256.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([213], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[156.8000,  78.2222, 391.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1820], device='cuda:0')}, {'boxes': tensor([[340.8000,  75.3778, 510.4000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1455], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  28.4444, 315.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1051], device='cuda:0')}, {'boxes': tensor([[ 54.0000, 128.0000, 331.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([910], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.4000,   0.0000, 482.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1832], device='cuda:0')}, {'boxes': tensor([[240.0000, 172.8000, 339.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.2000, 164.2667, 252.4000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1329], device='cuda:0')}, {'boxes': tensor([[ 48.8000, 179.2000, 388.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1388], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1060], device='cuda:0')}, {'boxes': tensor([[281.6000, 196.2667, 359.4667, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.2000,  56.8889, 453.6000, 258.8445],\n",
      "        [166.4000,  68.2667, 300.8000, 263.1111],\n",
      "        [102.4000, 119.4667, 247.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1758], device='cuda:0')}, {'boxes': tensor([[236.8000,  75.3778, 418.0000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([823], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.6000, 182.7556, 445.2000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([156], device='cuda:0')}, {'boxes': tensor([[122.8000, 157.8667, 310.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.0000, 132.2667, 386.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([375], device='cuda:0')}, {'boxes': tensor([[  0.0000, 196.2667, 293.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1391], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.4000, 169.2444, 276.8000, 384.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2038], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 213.3333, 486.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1038], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[159.2000, 201.9556, 347.6000, 478.5778],\n",
      "        [ 60.8000, 204.8000, 361.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([550], device='cuda:0')}, {'boxes': tensor([[ 81.6000, 189.1555, 239.6000, 372.6222],\n",
      "        [276.4000, 171.3778, 424.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1092], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.2000, 368.3556, 243.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2013], device='cuda:0')}, {'boxes': tensor([[ 45.8667, 273.0667, 510.9333, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([249], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000, 120.8889, 444.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1452], device='cuda:0')}, {'boxes': tensor([[ 26.0000,   0.0000, 256.0000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1861], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 79.6000, 206.2222, 157.6000, 267.3778],\n",
      "        [  3.6000, 244.6222,  97.2000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1467], device='cuda:0')}, {'boxes': tensor([[196.0000, 118.7556, 266.4000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([811], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  64.0000, 409.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1032], device='cuda:0')}, {'boxes': tensor([[  0.0000, 206.2222, 168.5333, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1362], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.4000, 157.8667, 383.2000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([748], device='cuda:0')}, {'boxes': tensor([[  4.7407, 164.9778,  75.8519, 224.7111],\n",
      "        [ 64.4741, 164.9778,  95.7630, 207.6444],\n",
      "        [201.0074, 177.7778, 255.0518, 224.7111],\n",
      "        [400.1185, 173.5111, 476.9185, 224.7111],\n",
      "        [246.5185, 173.5111, 311.9407, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 3], device='cuda:0'), 'image_id': tensor([1139], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.6000, 311.2727, 376.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1421], device='cuda:0')}, {'boxes': tensor([[ 89.6000, 153.6000, 505.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1281], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000,  30.3407, 247.4667, 510.1037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1258], device='cuda:0')}, {'boxes': tensor([[ 50.1333, 253.1555, 182.4000, 395.3778],\n",
      "        [420.2667, 196.2667, 490.6667, 257.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([694], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 122.3111, 289.6000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1946], device='cuda:0')}, {'boxes': tensor([[273.2000,  71.8222, 386.8000, 387.5555],\n",
      "        [345.6000, 118.7556, 432.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1544], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,   1.4222, 324.2667, 457.9556],\n",
      "        [412.8000, 108.0889, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([605], device='cuda:0')}, {'boxes': tensor([[ 23.6000,  11.3778, 508.8000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1582], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  23.4667, 509.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([802], device='cuda:0')}, {'boxes': tensor([[ 51.2000,  76.8000, 422.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1031], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000,  91.7333, 415.2000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1983], device='cuda:0')}, {'boxes': tensor([[265.6000, 179.2000, 350.4000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([852], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,  73.9556, 449.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1122], device='cuda:0')}, {'boxes': tensor([[ 32.0000, 203.3778, 187.6000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1653], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000,   0.0000, 363.7333, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([591], device='cuda:0')}, {'boxes': tensor([[ 24.5333,   8.5333, 275.2000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1068], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  21.3333, 225.6000, 506.3111],\n",
      "        [173.6000, 114.4889, 346.8000, 352.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([907], device='cuda:0')}, {'boxes': tensor([[  0.0000, 172.8000, 292.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1216], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000,  76.8000, 218.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([370], device='cuda:0')}, {'boxes': tensor([[255.2000, 186.1818, 400.8000, 320.0000],\n",
      "        [203.2000, 221.0909, 276.8000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.4000,  93.1556, 396.8000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([752], device='cuda:0')}, {'boxes': tensor([[268.4000, 137.2444, 398.0000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([421], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[135.6000,  88.1778, 290.8000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1902], device='cuda:0')}, {'boxes': tensor([[ 43.6000, 217.6000, 191.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1655], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.8000, 200.5333, 342.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([97], device='cuda:0')}, {'boxes': tensor([[ 94.9333, 354.1333, 197.3333, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1802], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000,  94.5778, 282.0000, 472.1778],\n",
      "        [255.2000, 156.4444, 316.8000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1529], device='cuda:0')}, {'boxes': tensor([[182.0000, 133.6889, 461.2000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([340], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[292.0000, 238.9333, 430.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1499], device='cuda:0')}, {'boxes': tensor([[ 84.5283,   0.0000, 324.4277, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1028], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.0000,  44.0889, 450.8000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([821], device='cuda:0')}, {'boxes': tensor([[219.2000, 192.0000, 396.8000, 395.6364],\n",
      "        [141.6000, 244.3636, 229.6000, 385.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.2000, 304.3556, 235.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2007], device='cuda:0')}, {'boxes': tensor([[177.2000, 194.1333, 251.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1246], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 511.2000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([796], device='cuda:0')}, {'boxes': tensor([[252.8000, 138.6667, 348.8000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([6], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.2000, 174.9333, 368.0000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1263], device='cuda:0')}, {'boxes': tensor([[100.8000, 223.2889, 308.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1167], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.4000, 237.5111, 194.8000, 309.3333],\n",
      "        [201.2000, 147.9111, 308.4000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([125], device='cuda:0')}, {'boxes': tensor([[220.8000, 160.0000, 276.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([887], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[154.8000,  32.7111, 357.6000, 477.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([349], device='cuda:0')}, {'boxes': tensor([[ 46.0000, 108.0889, 165.6000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1259], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.1867e+01, 4.5800e+02, 4.4729e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([277], device='cuda:0')}, {'boxes': tensor([[185.6000, 115.2000, 421.3333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([207], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.0000, 161.4222, 365.2000, 309.3333],\n",
      "        [283.6000, 156.4444, 388.0000, 273.0667],\n",
      "        [ 77.2000, 172.0889, 120.0000, 199.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([889], device='cuda:0')}, {'boxes': tensor([[129.2000,   0.0000, 400.4000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([820], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.1333, 237.5111, 387.2000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1706], device='cuda:0')}, {'boxes': tensor([[409.6000, 102.8197, 508.0000, 314.7541]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([971], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[158.0000, 199.1111, 321.6000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([163], device='cuda:0')}, {'boxes': tensor([[182.0183, 186.6667, 293.5780, 322.1333],\n",
      "        [  0.0000, 314.6667, 510.2385, 503.4667],\n",
      "        [289.4679, 293.3333, 509.6514, 449.0667],\n",
      "        [132.6973, 289.0667, 177.9083, 331.7333],\n",
      "        [133.8716, 273.0667, 185.5413, 325.3333],\n",
      "        [341.1376, 270.9333, 402.2018, 299.7333],\n",
      "        [316.4771, 269.8667, 350.5321, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([458], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   2.1333, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([797], device='cuda:0')}, {'boxes': tensor([[168.4000, 177.7778, 333.2000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.2000, 143.6444, 278.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1840], device='cuda:0')}, {'boxes': tensor([[ 81.0667, 261.6889, 499.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([237], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000, 176.3556, 508.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1223], device='cuda:0')}, {'boxes': tensor([[ 62.5778,  21.3333, 485.4518, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1826], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[131.6000,   7.1111, 502.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([305], device='cuda:0')}, {'boxes': tensor([[ 64.0000, 182.0444, 228.2667, 237.0370]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1149], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.6000, 401.7778, 324.0000, 433.7778],\n",
      "        [232.4000, 243.9111, 253.2000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1878], device='cuda:0')}, {'boxes': tensor([[110.9333, 154.3111, 217.6000, 281.6000],\n",
      "        [242.1333, 168.5333, 316.2667, 251.0222],\n",
      "        [192.0000, 263.1111, 262.9333, 392.5333],\n",
      "        [219.7333, 211.9111, 312.0000, 335.6444],\n",
      "        [418.1333, 150.7556, 484.2667, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([53], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 263.1111, 301.6000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1002], device='cuda:0')}, {'boxes': tensor([[144.0000,  50.4889, 359.6000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([350], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000,  75.3778, 376.0000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1456], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1513], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 154.3111,  64.0000, 252.4444],\n",
      "        [167.6000, 156.4444, 196.8000, 219.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1394], device='cuda:0')}, {'boxes': tensor([[148.8000, 126.5778, 262.8000, 325.6889],\n",
      "        [258.0000, 103.1111, 420.0000, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([562], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2083], device='cuda:0')}, {'boxes': tensor([[117.2000, 164.2667, 250.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2034], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000, 213.3333, 199.2000, 500.6222],\n",
      "        [252.8000, 193.4222, 295.2000, 358.4000],\n",
      "        [454.4000, 203.3778, 509.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([781], device='cuda:0')}, {'boxes': tensor([[194.8000, 135.1111, 473.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([336], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 294.4000, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([707], device='cuda:0')}, {'boxes': tensor([[162.0000, 238.9333, 473.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1646], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([761], device='cuda:0')}, {'boxes': tensor([[128.0000,  65.4222, 212.4000, 460.0889],\n",
      "        [236.8000, 128.7111, 357.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1186], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 199.1111, 381.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2168], device='cuda:0')}, {'boxes': tensor([[148.8000, 224.0000, 510.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1040], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.6000, 171.3778, 310.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([809], device='cuda:0')}, {'boxes': tensor([[ 14.8000, 164.2667, 189.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.4000,   0.0000, 262.4000, 265.2444],\n",
      "        [268.8000,  49.0667, 378.8000, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([18], device='cuda:0')}, {'boxes': tensor([[136.4000, 135.1111, 256.4000, 232.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([128], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.2000,  59.0222, 410.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([824], device='cuda:0')}, {'boxes': tensor([[128.8000,  59.7333, 357.6000, 406.7556],\n",
      "        [  0.0000,   1.4222,  76.8000, 128.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1768], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 236.8000,  48.7339, 352.0000],\n",
      "        [430.3853, 235.7333, 472.0734, 284.8000],\n",
      "        [472.0734, 213.3333, 510.2385, 268.8000],\n",
      "        [297.6881, 176.0000, 437.4312, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([480], device='cuda:0')}, {'boxes': tensor([[221.7465,   0.0000, 479.5493, 291.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1490], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 25.6000, 103.8222, 244.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([384], device='cuda:0')}, {'boxes': tensor([[194.1333, 115.2000, 430.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([206], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.0667, 202.6667, 169.6000, 283.0222],\n",
      "        [192.0000, 219.0222, 254.9333, 287.2889],\n",
      "        [263.4667, 224.7111, 312.5333, 291.5555],\n",
      "        [365.3333, 231.1111, 390.9333, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([58], device='cuda:0')}, {'boxes': tensor([[161.6000, 146.4889, 235.2000, 362.6667],\n",
      "        [227.2000,  48.3556, 410.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1231], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 236.0889, 275.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1732], device='cuda:0')}, {'boxes': tensor([[216.0000,  75.3778, 328.4000, 395.3778],\n",
      "        [307.6000, 151.4667, 359.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1540], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.6000, 219.7333, 359.2000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([93], device='cuda:0')}, {'boxes': tensor([[206.8000, 113.7778, 327.6000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([399], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.6000, 238.9333, 436.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1497], device='cuda:0')}, {'boxes': tensor([[184.0000, 136.5333, 297.6000, 339.9111],\n",
      "        [243.2000,  45.5111, 403.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1229], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 386.8445, 294.8000, 462.9333],\n",
      "        [244.4000, 291.5555, 269.6000, 366.9333],\n",
      "        [224.8000, 204.0889, 252.8000, 278.7556],\n",
      "        [263.6000, 131.5556, 289.2000, 204.8000],\n",
      "        [300.8000,  73.9556, 327.6000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([100], device='cuda:0')}, {'boxes': tensor([[109.6000, 204.8000, 337.6000, 477.8667],\n",
      "        [  0.0000,  68.2667,  52.8000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1766], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 247.4667, 158.4000, 492.0889],\n",
      "        [355.2000, 233.2444, 409.6000, 465.0667],\n",
      "        [304.8000, 217.6000, 328.0000, 308.6222],\n",
      "        [467.2000, 260.2667, 510.4000, 398.2222],\n",
      "        [173.6000, 227.5556, 205.6000, 341.3333],\n",
      "        [199.2000, 237.5111, 268.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([776], device='cuda:0')}, {'boxes': tensor([[377.5413, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 264.5333,  70.4587, 413.8667],\n",
      "        [238.9725, 201.6000, 382.2385, 486.4000],\n",
      "        [258.9358, 306.1333, 413.9449, 507.7333],\n",
      "        [112.1468, 244.2667, 216.0734, 362.6667],\n",
      "        [381.0642, 274.1333, 459.1560, 345.6000],\n",
      "        [ 47.5596, 265.6000, 141.5046, 403.2000],\n",
      "        [  0.0000, 210.1333,  79.2661, 276.2667],\n",
      "        [125.6514, 245.3333, 231.9266, 352.0000],\n",
      "        [233.1009, 125.8667, 510.2385, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([447], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.4000, 257.4222, 192.0000, 418.1333],\n",
      "        [277.6000, 261.6889, 318.4000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([766], device='cuda:0')}, {'boxes': tensor([[200.4000, 184.1778, 293.6000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1331], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[203.7333, 201.9556, 411.7333, 506.3111],\n",
      "        [210.1333,  93.8667, 442.6667, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1734], device='cuda:0')}, {'boxes': tensor([[358.8000, 421.6889, 375.2000, 452.2667],\n",
      "        [177.6000, 213.3333, 192.4000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1872], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[285.7465,   0.0000, 510.1972, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1484], device='cuda:0')}, {'boxes': tensor([[222.4000,  12.8000, 500.0000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([287], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 320.0000, 150.8000, 408.1778],\n",
      "        [152.8000, 359.1111, 197.2000, 457.2444],\n",
      "        [165.6000,  98.8444, 181.6000, 135.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([626], device='cuda:0')}, {'boxes': tensor([[ 57.6000, 263.1111, 187.7333, 384.0000],\n",
      "        [371.2000, 244.6222, 430.9333, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([702], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.4000,  86.0444, 323.6000, 364.0889],\n",
      "        [402.4000, 279.4667, 414.0000, 311.4667],\n",
      "        [427.2000, 275.9111, 436.8000, 312.8889],\n",
      "        [496.0000, 265.2444, 511.2000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1008], device='cuda:0')}, {'boxes': tensor([[188.8000, 285.1555, 269.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1884], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 14.4000, 155.0222, 234.4000, 285.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([214], device='cuda:0')}, {'boxes': tensor([[267.2000, 144.3556, 398.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([420], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000,  96.7111, 367.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([406], device='cuda:0')}, {'boxes': tensor([[200.8000, 138.6667, 441.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([328], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 58.1284, 249.6000, 209.0275, 357.3333],\n",
      "        [457.9817, 222.9333, 484.4037, 269.8667],\n",
      "        [354.0551, 171.7333, 460.9174, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([479], device='cuda:0')}, {'boxes': tensor([[249.6000, 192.0000, 274.4000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([935], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[343.4862, 327.4667, 510.2385, 505.6000],\n",
      "        [  0.0000, 270.9333,  34.6422, 429.8667],\n",
      "        [203.7431, 213.3333, 348.7706, 498.1333],\n",
      "        [224.2936, 318.9333, 378.7156, 508.8000],\n",
      "        [ 75.7431, 263.4667, 185.5413, 374.4000],\n",
      "        [342.3119, 283.7333, 419.2294, 362.6667],\n",
      "        [  6.4587, 279.4667, 105.6881, 419.2000],\n",
      "        [  0.0000, 226.1333,  41.1009, 289.0667],\n",
      "        [ 91.0092, 259.2000, 213.1376, 362.6667],\n",
      "        [404.5504, 171.7333, 492.6238, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([445], device='cuda:0')}, {'boxes': tensor([[299.4496, 126.9333, 442.1284, 364.8000],\n",
      "        [ 47.5596, 105.6000, 105.1009, 153.6000],\n",
      "        [ 98.0550, 118.4000, 162.6422, 170.6667],\n",
      "        [159.7064, 124.8000, 236.0367, 179.2000],\n",
      "        [  5.2844, 272.0000, 143.8532, 486.4000],\n",
      "        [ 63.4128, 122.6667, 142.6789, 185.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([438], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 330.6667, 277.2000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1885], device='cuda:0')}, {'boxes': tensor([[ 75.2000,  45.5111, 235.2000, 228.9778],\n",
      "        [216.0000,  32.7111, 369.6000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1752], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.0000, 194.1333, 456.0000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1278], device='cuda:0')}, {'boxes': tensor([[252.8000, 155.0222, 510.9333, 393.9556],\n",
      "        [  4.2667,   2.8444, 453.3333, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([52], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.2667, 193.4222, 410.6667, 290.1333],\n",
      "        [254.9333, 192.0000, 358.4000, 285.8667],\n",
      "        [148.2667, 157.8667, 204.8000, 236.0889],\n",
      "        [433.0667, 221.8667, 510.9333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([355], device='cuda:0')}, {'boxes': tensor([[248.0000, 273.7778, 320.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([490], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[311.2000,  39.1111, 408.8000, 125.8667],\n",
      "        [230.4000, 105.9556, 342.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27], device='cuda:0'), 'image_id': tensor([1347], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 511.2000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2084], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.2000, 145.7778, 378.0000, 224.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([127], device='cuda:0')}, {'boxes': tensor([[156.8000, 310.0444, 330.6667, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.0000, 182.0444, 270.4000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1358], device='cuda:0')}, {'boxes': tensor([[289.2000, 200.5333, 433.2000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1912], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 219.7333, 328.0000, 509.1555],\n",
      "        [318.4000, 349.8667, 413.2000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1248], device='cuda:0')}, {'boxes': tensor([[259.2000, 193.4222, 358.8000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2181], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 15.6000,   0.0000, 302.0000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([408], device='cuda:0')}, {'boxes': tensor([[193.0667, 187.7333, 341.3333, 257.4222],\n",
      "        [ 25.6000, 204.8000, 272.0000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([681], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.0000,  49.0667, 287.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1897], device='cuda:0')}, {'boxes': tensor([[172.8000,  59.7333, 328.0000, 396.8000],\n",
      "        [248.0000, 150.7556, 358.4000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1237], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[370.4789,   0.0000, 510.1972, 304.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1488], device='cuda:0')}, {'boxes': tensor([[ 24.8000,  11.3778, 508.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.8000, 270.2222, 354.1333, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2115], device='cuda:0')}, {'boxes': tensor([[113.6000,  86.7556, 377.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([67], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.4000, 234.6667, 317.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1156], device='cuda:0')}, {'boxes': tensor([[  0.0000, 120.1778, 234.0000, 198.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1947], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 211.9111, 486.8000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([367], device='cuda:0')}, {'boxes': tensor([[169.2000, 251.0222, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1921], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[154.0000, 102.4000, 461.2000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2195], device='cuda:0')}, {'boxes': tensor([[168.5333, 174.9333, 308.2667, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2129], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.2000,  98.1333, 364.4000, 278.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([10], device='cuda:0')}, {'boxes': tensor([[261.3333,  91.0222, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1731], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 163.5556, 396.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1296], device='cuda:0')}, {'boxes': tensor([[183.2000, 140.8000, 462.4000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([338], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 41.6000,  45.5111, 459.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1117], device='cuda:0')}, {'boxes': tensor([[ 57.6000,  64.0000, 380.8000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1688], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.2000, 296.5333, 320.0000, 506.3111],\n",
      "        [360.4000, 322.1333, 407.2000, 450.8445],\n",
      "        [  0.0000, 381.1555,  33.2000, 440.8889],\n",
      "        [ 33.2000, 384.0000,  70.4000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([1524], device='cuda:0')}, {'boxes': tensor([[172.5630,  96.7111, 508.2074, 403.9111],\n",
      "        [240.8296, 339.9111, 332.8000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([182], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000, 100.9778, 509.1555, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([172], device='cuda:0')}, {'boxes': tensor([[192.0000, 201.9556, 328.0000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1597], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.2000, 140.0889, 288.4000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1909], device='cuda:0')}, {'boxes': tensor([[ 44.8000,  44.0889, 282.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([547], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.2000,  93.1556, 381.2000, 510.5778],\n",
      "        [320.4000, 101.6889, 412.0000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([911], device='cuda:0')}, {'boxes': tensor([[274.0000,  78.9333, 474.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 31.2000, 172.8000, 426.8000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1389], device='cuda:0')}, {'boxes': tensor([[252.8000, 128.0000, 350.8000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([7], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 182.7556, 348.8000, 276.6222],\n",
      "        [161.2000, 161.4222, 238.0000, 260.2667],\n",
      "        [259.2000, 198.4000, 336.0000, 285.1555],\n",
      "        [152.8000, 187.0222, 237.2000, 281.6000],\n",
      "        [152.0000, 206.9333, 227.2000, 297.9556],\n",
      "        [232.4000, 247.4667, 314.8000, 337.0667],\n",
      "        [315.6000, 271.6444, 394.4000, 361.2444],\n",
      "        [418.0000, 371.2000, 446.4000, 438.0444],\n",
      "        [310.4000, 320.7111, 383.2000, 396.8000],\n",
      "        [244.4000, 223.2889, 326.4000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([120], device='cuda:0')}, {'boxes': tensor([[134.4000, 386.8445, 253.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2017], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[242.3787, 161.4222, 494.7731, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1969], device='cuda:0')}, {'boxes': tensor([[ 77.6000, 189.1555, 222.4000, 367.6444],\n",
      "        [280.8000, 176.3556, 425.2000, 350.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1112], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.7630,   0.0000, 462.6963, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1831], device='cuda:0')}, {'boxes': tensor([[ 64.0000,  81.7778, 310.4000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([871], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[388.2667, 281.6000, 509.8667, 391.1111],\n",
      "        [  0.0000, 250.3111, 246.4000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2120], device='cuda:0')}, {'boxes': tensor([[257.2000, 276.6222, 326.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1883], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 164.9778, 276.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1956], device='cuda:0')}, {'boxes': tensor([[226.0426,  69.6889, 336.3404, 173.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1088], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333, 135.1111, 509.1555, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([171], device='cuda:0')}, {'boxes': tensor([[116.8000, 284.4445, 229.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 16.0000,   0.0000, 279.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([410], device='cuda:0')}, {'boxes': tensor([[174.8000, 125.8667, 301.2000, 444.4445],\n",
      "        [280.0000, 187.0222, 388.8000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1541], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.8000,   0.0000, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1659], device='cuda:0')}, {'boxes': tensor([[103.2000, 201.9556, 281.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([927], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 295.8222, 510.9333, 473.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([250], device='cuda:0')}, {'boxes': tensor([[179.6000, 153.6000, 307.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1844], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 102.4000, 255.2000, 289.4222],\n",
      "        [239.6000, 211.9111, 398.8000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1406], device='cuda:0')}, {'boxes': tensor([[108.8000, 179.2000, 499.2000, 375.4667],\n",
      "        [ 25.6000, 123.7333, 139.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1640], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[203.2000, 184.1778, 250.8000, 226.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([854], device='cuda:0')}, {'boxes': tensor([[ 23.2000,  74.6667, 453.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1115], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 75.7333,  56.8889, 411.7333, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1698], device='cuda:0')}, {'boxes': tensor([[170.4000,  96.7111, 284.4000, 477.8667],\n",
      "        [215.2000, 163.5556, 305.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1528], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 113.7778, 395.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1298], device='cuda:0')}, {'boxes': tensor([[  0.0000,  83.2000,  45.2000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1906], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[356.8000, 159.2889, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2147], device='cuda:0')}, {'boxes': tensor([[164.0000, 142.2222, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1652], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.4000,   0.0000, 510.0000, 475.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1311], device='cuda:0')}, {'boxes': tensor([[204.0000,  71.1111, 416.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1684], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 247.4667, 179.2000, 375.4667],\n",
      "        [405.3333, 228.9778, 434.1333, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([696], device='cuda:0')}, {'boxes': tensor([[304.4000, 185.6000, 369.6000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1290], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  1.1743, 261.3333, 117.4312, 411.7333],\n",
      "        [281.2477, 197.3333, 426.8624, 483.2000],\n",
      "        [302.3853, 305.0667, 456.8073, 506.6667],\n",
      "        [424.5138, 266.6667, 501.4312, 338.1333],\n",
      "        [ 91.0092, 265.6000, 183.1927, 405.3333],\n",
      "        [ 17.0275, 210.1333, 125.0642, 272.0000],\n",
      "        [  0.0000, 280.5333,  67.5229, 426.6667],\n",
      "        [192.5872, 101.3333, 493.7982, 402.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([449], device='cuda:0')}, {'boxes': tensor([[  0.0000,  14.2222, 233.6000, 167.8222],\n",
      "        [260.2667, 132.2667, 337.0667, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([671], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  39.1111, 345.6000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([826], device='cuda:0')}, {'boxes': tensor([[158.4000, 152.1778, 289.6000, 356.2667],\n",
      "        [266.4000, 170.6667, 450.4000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([570], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  6.4000,  89.6000, 233.6000, 289.4222],\n",
      "        [295.6000, 226.1333, 388.0000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1405], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 198.4000, 136.0000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1275], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000, 223.2889, 253.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([22], device='cuda:0')}, {'boxes': tensor([[134.0000,  45.5111, 304.8000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2045], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.0000, 128.7111, 454.8000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([278], device='cuda:0')}, {'boxes': tensor([[110.4630,  88.8889, 471.2819, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2096], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.6000, 302.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2082], device='cuda:0')}, {'boxes': tensor([[  0.0000,  98.1333, 425.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1295], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000, 125.1556, 309.3333, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1590], device='cuda:0')}, {'boxes': tensor([[ 34.8000, 166.4000, 282.4000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1384], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1023], device='cuda:0')}, {'boxes': tensor([[223.2000, 109.5111, 510.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.2667,  83.9111, 433.0667, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1692], device='cuda:0')}, {'boxes': tensor([[264.8000, 272.7869, 388.0000, 375.6066]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([978], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[161.2000, 171.3778, 291.2000, 451.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1785], device='cuda:0')}, {'boxes': tensor([[213.3333, 209.0667, 416.0000, 506.3111],\n",
      "        [209.0667, 118.0444, 443.7333, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1735], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.3333, 275.9111, 315.7333, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2137], device='cuda:0')}, {'boxes': tensor([[ 81.6000, 198.4000, 361.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1268], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.8000, 135.1111, 396.0000, 332.8000],\n",
      "        [ 83.2000, 135.1111, 234.4000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1755], device='cuda:0')}, {'boxes': tensor([[162.8000, 135.1111, 354.8000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([405], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.2000, 160.0000, 291.2000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1336], device='cuda:0')}, {'boxes': tensor([[ 80.0000,  62.5778, 371.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1862], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.0000, 230.4000, 260.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1958], device='cuda:0')}, {'boxes': tensor([[169.2000, 105.9556, 263.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1899], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000,   0.0000, 363.2000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1262], device='cuda:0')}, {'boxes': tensor([[  2.1333, 273.0667, 365.8667, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2138], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 25.6000, 315.7333, 188.8000, 392.5333],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([693], device='cuda:0')}, {'boxes': tensor([[258.4000, 238.9333, 290.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([951], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.4000, 132.2667, 346.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1787], device='cuda:0')}, {'boxes': tensor([[127.2000,  84.6222, 413.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.2000, 179.9111, 303.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([76], device='cuda:0')}, {'boxes': tensor([[114.4000, 241.3115, 380.0000, 391.3443]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([968], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.4000,  91.7333, 492.8000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1194], device='cuda:0')}, {'boxes': tensor([[150.4000,   0.0000, 254.4000, 170.6667],\n",
      "        [243.2000,  12.8000, 324.8000, 199.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1743], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000,   0.0000, 509.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1312], device='cuda:0')}, {'boxes': tensor([[214.0000,  96.7111, 368.0000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1984], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.0000, 211.9111, 508.8000, 507.7333],\n",
      "        [  0.0000, 113.7778, 325.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1619], device='cuda:0')}, {'boxes': tensor([[ 62.9333,  41.2444, 296.5333, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1504], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000, 238.9333, 283.2000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([38], device='cuda:0')}, {'boxes': tensor([[408.0000,  93.3771, 492.0000, 220.3279]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([972], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.8000,   0.0000, 266.4000, 159.2889],\n",
      "        [253.6000,   0.0000, 396.8000, 159.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1748], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([953], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 227.5556, 390.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2127], device='cuda:0')}, {'boxes': tensor([[ 62.4000,   0.7111, 401.6000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([158], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 142.2222, 468.0000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([334], device='cuda:0')}, {'boxes': tensor([[120.0000,   0.0000, 252.8000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1177], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 432.3556, 181.6000, 509.1555],\n",
      "        [377.6000, 348.4445, 401.6000, 506.3111],\n",
      "        [476.0000, 403.9111, 510.4000, 509.1555],\n",
      "        [200.8000, 440.8889, 324.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([782], device='cuda:0')}, {'boxes': tensor([[327.6000, 185.6000, 462.0000, 233.9556],\n",
      "        [189.6000, 241.7778, 290.4000, 290.8445],\n",
      "        [ 76.8000, 256.0000, 172.0000, 291.5555],\n",
      "        [  0.0000, 283.0222,  50.4000, 297.9556],\n",
      "        [ 70.8000, 230.4000, 188.8000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29, 29, 29, 29], device='cuda:0'), 'image_id': tensor([529], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.2000,  46.2222, 376.8000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([806], device='cuda:0')}, {'boxes': tensor([[227.2000, 156.4444, 308.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1997], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.4000, 273.7778, 281.6000, 340.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([983], device='cuda:0')}, {'boxes': tensor([[  0.8000, 113.7778, 261.6000, 328.5333],\n",
      "        [170.4000, 227.5556, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1641], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 155.0222, 329.6000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([862], device='cuda:0')}, {'boxes': tensor([[191.2000,  79.6444, 300.0000, 341.3333],\n",
      "        [108.8000,   0.0000, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([979], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[270.8000,  88.1778, 365.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1192], device='cuda:0')}, {'boxes': tensor([[210.4000,  70.4000, 331.2000, 400.3556],\n",
      "        [222.4000, 161.4222, 329.6000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1535], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.8000, 107.3778, 265.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1900], device='cuda:0')}, {'boxes': tensor([[218.4000,   0.0000, 354.4000, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([614], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 11.2000,  37.6889,  84.4000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1903], device='cuda:0')}, {'boxes': tensor([[240.8000, 187.7333, 344.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2182], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[114.0000,  46.2222, 474.0000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([352], device='cuda:0')}, {'boxes': tensor([[176.0000,  45.5111, 469.6000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2199], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000,   0.0000, 355.2000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2073], device='cuda:0')}, {'boxes': tensor([[386.0000, 154.3111, 510.8000, 233.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([534], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.0000, 371.2000, 321.2000, 405.3333],\n",
      "        [214.4000, 203.3778, 228.8000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1873], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 390.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1834], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 126.5778, 509.6000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([322], device='cuda:0')}, {'boxes': tensor([[379.6000, 275.2000, 450.8000, 349.8667],\n",
      "        [260.0000, 156.4444, 356.8000, 258.8445],\n",
      "        [179.2000, 110.9333, 274.4000, 216.8889],\n",
      "        [296.4000, 227.5556, 393.2000, 325.6889],\n",
      "        [428.0000, 364.8000, 450.8000, 398.9333],\n",
      "        [219.6000, 174.2222, 315.6000, 275.2000],\n",
      "        [351.2000, 228.2667, 445.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([87], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 192.7111, 255.6000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1376], device='cuda:0')}, {'boxes': tensor([[236.0000, 261.6889, 280.0000, 459.3778],\n",
      "        [333.6000, 260.2667, 400.0000, 509.1555],\n",
      "        [156.8000, 253.1555, 194.4000, 413.8667],\n",
      "        [287.2000, 248.8889, 315.2000, 369.7778],\n",
      "        [ 15.2000, 311.4667, 128.8000, 506.3111],\n",
      "        [487.2000, 332.8000, 511.2000, 506.3111],\n",
      "        [468.8000, 292.9778, 500.0000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([789], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[111.6596, 130.8445, 253.2766, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1091], device='cuda:0')}, {'boxes': tensor([[ 12.8000, 146.4889,  69.3333, 223.2889],\n",
      "        [339.2000, 173.5111, 482.1333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([679], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.8000,  80.3556, 320.4000, 450.8445],\n",
      "        [236.8000, 146.4889, 320.4000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1531], device='cuda:0')}, {'boxes': tensor([[ 26.0000, 159.2889,  64.0000, 252.4444],\n",
      "        [166.0000, 156.4444, 200.8000, 231.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1398], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2090], device='cuda:0')}, {'boxes': tensor([[108.8000, 157.8667, 433.6000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1304], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.4000, 286.5778, 279.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([981], device='cuda:0')}, {'boxes': tensor([[300.8000, 405.3333, 428.0000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.8000,  54.0444, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1025], device='cuda:0')}, {'boxes': tensor([[352.0000, 180.6222, 397.6000, 290.8445],\n",
      "        [278.0000, 182.7556, 382.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1521], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 95.7630,  79.6444, 476.9185, 403.9111],\n",
      "        [164.9778, 318.5778, 255.0518, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([180], device='cuda:0')}, {'boxes': tensor([[219.0222, 231.8222, 269.2741, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([167], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 288.0000, 202.4000, 509.1555],\n",
      "        [249.6000, 312.1778, 378.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([19], device='cuda:0')}, {'boxes': tensor([[192.4000, 199.8222, 325.6000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1955], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 196.2667, 364.8000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1266], device='cuda:0')}, {'boxes': tensor([[196.0000, 220.4444, 225.2000, 286.5778],\n",
      "        [304.8000, 228.2667, 342.8000, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([834], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[291.2000, 236.0889, 390.4000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1705], device='cuda:0')}, {'boxes': tensor([[208.8000, 226.8445, 288.4000, 282.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1926], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.2000, 164.9778, 290.8000, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1910], device='cuda:0')}, {'boxes': tensor([[448.0000, 190.5778, 511.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([531], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000, 157.8667, 308.8000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1996], device='cuda:0')}, {'boxes': tensor([[170.4000,  68.2667, 436.4000, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([73], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 201.9556, 373.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1596], device='cuda:0')}, {'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([283], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.8000,  99.5556, 244.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1510], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 435.2000, 301.5111],\n",
      "        [340.8000, 284.4445, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1622], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 201.9556, 213.3333, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1364], device='cuda:0')}, {'boxes': tensor([[146.4000,  61.8667, 346.0000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([342], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[233.2000, 171.3778, 310.4000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1863], device='cuda:0')}, {'boxes': tensor([[174.8000,   0.0000, 316.8000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1308], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.6000, 162.8445, 212.8000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([861], device='cuda:0')}, {'boxes': tensor([[169.6000,  78.2222, 342.0000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([897], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 295.1111, 456.8000, 489.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1916], device='cuda:0')}, {'boxes': tensor([[  0.0000, 147.2000, 278.8000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1215], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 248.8889, 156.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([43], device='cuda:0')}, {'boxes': tensor([[223.2000, 146.4889, 288.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1335], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([985], device='cuda:0')}, {'boxes': tensor([[  5.6000, 229.6889, 462.8000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1206], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.8000, 243.2000, 273.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([737], device='cuda:0')}, {'boxes': tensor([[188.4000, 199.8222, 296.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.4000, 116.2667, 176.0000, 163.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([793], device='cuda:0')}, {'boxes': tensor([[  0.4000,  44.0889, 258.4000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([210], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 208.3556, 250.8000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1242], device='cuda:0')}, {'boxes': tensor([[305.2000, 202.6667, 472.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1293], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.2000,   0.0000, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1771], device='cuda:0')}, {'boxes': tensor([[171.2000, 105.9556, 374.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1354], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 110.1639, 175.2000, 401.8361]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([962], device='cuda:0')}, {'boxes': tensor([[290.8000, 211.9111, 321.2000, 300.8000],\n",
      "        [  0.0000, 177.7778,  69.6000, 346.3111],\n",
      "        [ 42.4000, 194.1333, 109.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7, 7], device='cuda:0'), 'image_id': tensor([1987], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 41.6000, 256.0000, 308.8000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1818], device='cuda:0')}, {'boxes': tensor([[ 28.1835,   0.0000, 510.2385, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([464], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000,  62.5778, 292.0000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([836], device='cuda:0')}, {'boxes': tensor([[ 78.4000,  29.8667, 341.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([61], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.0000,  49.0667, 336.8000, 496.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1477], device='cuda:0')}, {'boxes': tensor([[120.5333, 294.4000, 509.8667, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([234], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000,  81.0667, 350.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([64], device='cuda:0')}, {'boxes': tensor([[182.0000, 188.4444, 448.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([588], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 123.7333, 297.6000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1945], device='cuda:0')}, {'boxes': tensor([[185.6000, 193.4222, 254.0000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1892], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 230.4000, 279.4667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2094], device='cuda:0')}, {'boxes': tensor([[  0.8000,  96.7111, 284.0000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1435], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[159.2000, 127.2889, 383.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1099], device='cuda:0')}, {'boxes': tensor([[  0.8000,  61.1556, 263.6000, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([371], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.4000, 111.6444, 510.8000, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1001], device='cuda:0')}, {'boxes': tensor([[141.2741,  98.1333, 475.0222, 378.3111],\n",
      "        [201.0074, 314.3111, 300.5630, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([185], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.8000,  85.3333, 368.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([68], device='cuda:0')}, {'boxes': tensor([[  0.0000, 118.7556, 288.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1374], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.2000, 239.6444, 313.2000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1158], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 362.6667, 508.2074],\n",
      "        [  8.5333,  81.5407, 359.4667, 508.2074],\n",
      "        [326.4000,   0.0000, 510.9333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([35], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 354.1333, 174.4593],\n",
      "        [  0.0000,  56.8889, 456.5333, 508.2074],\n",
      "        [371.2000,   0.0000, 510.9333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([37], device='cuda:0')}, {'boxes': tensor([[356.2667, 183.4667, 430.9333, 258.8445],\n",
      "        [240.0000, 267.3778, 277.3333, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1701], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 285.1555, 285.6000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([190], device='cuda:0')}, {'boxes': tensor([[245.6000, 160.7111, 326.0000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8000, 133.6889, 258.0000, 324.2667],\n",
      "        [218.0000, 146.4889, 394.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([567], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1253], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 106.6667, 371.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1297], device='cuda:0')}, {'boxes': tensor([[385.0667, 162.1333, 461.8667, 220.4444],\n",
      "        [253.8667, 223.2889, 292.2667, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1703], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.8000,   9.2444, 450.8000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([292], device='cuda:0')}, {'boxes': tensor([[171.2000, 221.8667, 454.4000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1037], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.8000, 109.5111, 440.8000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1985], device='cuda:0')}, {'boxes': tensor([[ 76.8000,  73.9556, 242.4000, 247.4667],\n",
      "        [243.2000,  46.9333, 357.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1737], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 108.0889, 510.4000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2166], device='cuda:0')}, {'boxes': tensor([[  0.0000, 112.3556, 412.8000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1294], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.8963, 120.8889, 511.0518, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([169], device='cuda:0')}, {'boxes': tensor([[ 14.4000, 411.2787,  35.2000, 436.4590],\n",
      "        [233.6000, 231.8689, 248.8000, 254.9508],\n",
      "        [ 52.8000, 371.4099,  74.4000, 418.6230],\n",
      "        [ 92.8000, 393.4426, 122.4000, 437.5082],\n",
      "        [404.8000, 193.0492, 431.2000, 229.7705]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([974], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000,  82.4889, 346.4000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1781], device='cuda:0')}, {'boxes': tensor([[208.8000,   0.0000, 350.4000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([618], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.8000, 103.1111, 379.6000, 494.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([344], device='cuda:0')}, {'boxes': tensor([[ 98.1333, 210.4889, 343.4667, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2139], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.8000, 211.2000, 270.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2058], device='cuda:0')}, {'boxes': tensor([[194.4000, 175.6444, 301.2000, 270.2222],\n",
      "        [ 41.6000, 201.9556, 178.4000, 310.7556],\n",
      "        [188.8000, 242.4889, 316.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1575], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 210.4889, 164.2667, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1363], device='cuda:0')}, {'boxes': tensor([[453.3333, 288.7111, 510.9333, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1707], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 200.5333, 427.2000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1678], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  85.3333, 242.4000, 247.4667],\n",
      "        [243.2000,  65.4222, 365.6000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1739], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.6000, 155.0222, 277.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2039], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 133.6889, 336.0000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([741], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.0000,  45.5111, 445.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([822], device='cuda:0')}, {'boxes': tensor([[231.4667,  39.8222, 362.6667, 473.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1471], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.8000, 204.8000, 336.0000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1778], device='cuda:0')}, {'boxes': tensor([[104.8000,  96.7111, 376.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1021], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.7333,  69.6889, 331.7333, 352.7111],\n",
      "        [292.2667,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1080], device='cuda:0')}, {'boxes': tensor([[174.8000, 128.7111, 228.0000, 210.4889],\n",
      "        [242.4000, 192.0000, 297.2000, 266.6667],\n",
      "        [226.0000, 190.5778, 277.2000, 270.2222],\n",
      "        [290.0000, 260.2667, 344.0000, 338.4889],\n",
      "        [329.2000, 324.2667, 384.4000, 403.9111],\n",
      "        [142.8000,  73.9556, 196.0000, 147.9111],\n",
      "        [368.8000, 410.3111, 426.4000, 492.8000],\n",
      "        [ 99.2000,  14.9333, 156.8000,  99.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[251.2000,  95.2889, 439.2000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1674], device='cuda:0')}, {'boxes': tensor([[230.8000, 155.0222, 314.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([5], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.0000,  94.5778, 511.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2162], device='cuda:0')}, {'boxes': tensor([[ 64.0000,  98.1333, 470.4000, 504.8889],\n",
      "        [ 76.8000,   0.0000, 243.2000, 115.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1609], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.8000,   0.0000, 381.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([616], device='cuda:0')}, {'boxes': tensor([[208.8000, 275.2000, 384.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([14], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.2000,  58.3111, 280.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1054], device='cuda:0')}, {'boxes': tensor([[237.2000, 117.3333, 388.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1790], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 113.7778, 364.8000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2143], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 187.7333, 227.2000, 366.2222],\n",
      "        [280.0000, 179.2000, 425.6000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1096], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000, 207.6444, 510.9333, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([253], device='cuda:0')}, {'boxes': tensor([[ 98.1333,  49.7778, 320.0000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([722], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[410.8000, 103.1111, 508.4000, 494.9333],\n",
      "        [136.4000,   0.0000, 490.4000, 285.1555],\n",
      "        [ 84.4000,   0.0000, 183.2000,  37.6889],\n",
      "        [421.6000,   2.1333, 508.8000, 125.1556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1800], device='cuda:0')}, {'boxes': tensor([[ 56.5333,  91.0222, 401.0667, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1699], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000, 192.0000, 429.8667, 268.8000],\n",
      "        [240.0000, 275.9111, 277.3333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1702], device='cuda:0')}, {'boxes': tensor([[163.6000, 201.9556, 384.4000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1594], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.0000,  44.0889, 366.8000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([818], device='cuda:0')}, {'boxes': tensor([[135.2000,  32.7111, 396.0000, 384.0000],\n",
      "        [119.2000, 261.6889, 172.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([506], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 159.2889, 352.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2173], device='cuda:0')}, {'boxes': tensor([[  9.6000, 185.6000, 216.0000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1034], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.0000, 256.0000, 324.0000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([489], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([762], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[38.4000, 11.3778, 96.4000, 86.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1837], device='cuda:0')}, {'boxes': tensor([[  0.0000, 210.4889, 156.4000, 507.7333],\n",
      "        [186.4000, 156.4444, 336.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([497], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 108.0889, 302.0000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([727], device='cuda:0')}, {'boxes': tensor([[283.7333, 109.5111, 369.0667, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1587], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[341.2000, 354.8445, 492.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1495], device='cuda:0')}, {'boxes': tensor([[ 63.2000, 227.5556, 176.0000, 507.7333],\n",
      "        [286.4000, 194.8445, 343.2000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([777], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[246.4000, 159.2889, 300.8000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2128], device='cuda:0')}, {'boxes': tensor([[201.2000, 206.9333, 300.0000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000,  85.3333, 251.7333, 315.7333],\n",
      "        [162.1333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1084], device='cuda:0')}, {'boxes': tensor([[192.0000, 395.6364, 210.4000, 420.3636]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1424], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.6000, 164.2667, 284.8000, 351.2889],\n",
      "        [149.6000, 246.0444, 232.8000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([520], device='cuda:0')}, {'boxes': tensor([[ 48.8000, 102.4000, 390.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([643], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.8000, 105.9556, 317.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([863], device='cuda:0')}, {'boxes': tensor([[125.2000, 308.6222, 186.8000, 444.4445],\n",
      "        [164.8000,  99.5556, 182.4000, 141.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([628], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.0000, 281.6000, 280.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([982], device='cuda:0')}, {'boxes': tensor([[  0.0000, 146.4889, 153.6000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1372], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 118.7556, 322.8000, 211.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1944], device='cuda:0')}, {'boxes': tensor([[217.6000,  66.8444, 384.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([615], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.2000,   0.0000, 510.4000, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1810], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([812], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 182.0444, 359.6000, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1931], device='cuda:0')}, {'boxes': tensor([[161.2000, 234.6667, 346.8000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([74], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([955], device='cuda:0')}, {'boxes': tensor([[411.6000, 246.0444, 509.6000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([533], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 230.4000, 206.2222],\n",
      "        [403.2000, 320.0000, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1625], device='cuda:0')}, {'boxes': tensor([[185.2000, 128.0000, 318.0000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 211.9111, 328.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1549], device='cuda:0')}, {'boxes': tensor([[143.3239,  76.8000, 401.1268, 438.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1062], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000, 270.2222, 435.2000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1816], device='cuda:0')}, {'boxes': tensor([[102.4000, 100.9778, 172.8000, 216.1778],\n",
      "        [247.2000,  91.0222, 292.0000, 201.2444],\n",
      "        [337.2000, 181.3333, 371.6000, 258.8445],\n",
      "        [ 62.8000, 110.2222,  94.4000, 224.0000],\n",
      "        [277.2000, 147.9111, 303.6000, 195.5556],\n",
      "        [304.0000, 141.5111, 377.2000, 209.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2029], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[229.6000, 167.8222, 331.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2176], device='cuda:0')}, {'boxes': tensor([[ 80.8000,  82.4889, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1773], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[209.6000, 125.1556, 508.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([999], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([34], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[286.0000, 182.0444, 511.2000, 483.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1285], device='cuda:0')}, {'boxes': tensor([[ 88.8000, 175.6444, 241.6000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([21], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.0000, 245.3333, 467.2000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1105], device='cuda:0')}, {'boxes': tensor([[339.2000, 253.8667, 369.6000, 332.0889],\n",
      "        [101.2000, 204.0889, 267.2000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1557], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 210.4889, 244.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([416], device='cuda:0')}, {'boxes': tensor([[214.0000, 125.1556, 250.0000, 210.4889],\n",
      "        [230.4000, 150.0444, 294.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([885], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.2000, 187.0222, 288.0000, 258.8445],\n",
      "        [228.8000, 193.4222, 256.4000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([846], device='cuda:0')}, {'boxes': tensor([[ 68.0000, 183.4667, 509.6000, 352.7111],\n",
      "        [ 50.4000, 120.8889, 166.4000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1638], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 63.2000, 169.2444, 334.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([870], device='cuda:0')}, {'boxes': tensor([[194.0000, 214.7556, 396.8000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([70], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000,  91.7333, 280.8000, 473.6000],\n",
      "        [215.2000, 157.8667, 305.6000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1527], device='cuda:0')}, {'boxes': tensor([[262.8000, 133.6889, 379.6000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([657], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 86.0000, 192.0000, 236.8000, 371.2000],\n",
      "        [317.2000, 170.6667, 460.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1109], device='cuda:0')}, {'boxes': tensor([[208.0000, 238.9333, 441.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1914], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000, 205.5111, 329.6000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1155], device='cuda:0')}, {'boxes': tensor([[  2.1333,   0.0000, 238.9333, 457.9556],\n",
      "        [320.0000,  66.8444, 509.8667, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([610], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 274.4889, 230.4000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2002], device='cuda:0')}, {'boxes': tensor([[ 97.6000, 347.0222, 197.6000, 509.1555],\n",
      "        [353.6000, 342.7556, 455.2000, 510.5778],\n",
      "        [ 15.2000, 325.6889,  92.8000, 510.5778],\n",
      "        [277.6000, 315.7333, 328.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([785], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.4000,  59.0222, 277.2000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([841], device='cuda:0')}, {'boxes': tensor([[196.8000, 266.6667, 343.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1923], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.6000,  34.8444, 243.2000, 115.9111],\n",
      "        [298.4000, 251.0222, 364.8000, 349.8667],\n",
      "        [373.2000,  91.0222, 404.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24, 24], device='cuda:0'), 'image_id': tensor([1868], device='cuda:0')}, {'boxes': tensor([[257.6000, 151.4667, 443.6000, 245.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([90], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2018e+02, 4.2080e+02, 3.1502e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([729], device='cuda:0')}, {'boxes': tensor([[  0.0000, 280.1778, 176.8000, 510.5778],\n",
      "        [225.2000, 388.9778, 374.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([20], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.4000, 187.7333, 266.4000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1340], device='cuda:0')}, {'boxes': tensor([[  0.0000, 195.5556, 296.4000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1390], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.6000, 200.5333, 369.6000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1269], device='cuda:0')}, {'boxes': tensor([[181.0963, 177.7778, 323.3185, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([759], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[207.6000, 157.8667, 281.6000, 320.7111],\n",
      "        [247.2000, 187.7333, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1571], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  76.8000, 236.8000, 297.2444],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1082], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.8667, 234.6667, 251.2593, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([166], device='cuda:0')}, {'boxes': tensor([[152.0000, 331.3778, 221.6000, 509.1555],\n",
      "        [364.0000, 322.8445, 444.0000, 510.5778],\n",
      "        [ 79.2000, 325.6889, 145.6000, 506.3111],\n",
      "        [277.6000, 304.3556, 321.6000, 473.6000],\n",
      "        [  0.0000, 307.2000,  63.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([787], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 211.2000, 201.2000, 233.9556],\n",
      "        [439.2000, 206.2222, 474.8000, 222.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([526], device='cuda:0')}, {'boxes': tensor([[153.6000,  93.1556, 462.8000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2194], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.8667, 154.3111, 216.5333, 281.6000],\n",
      "        [242.1333, 164.9778, 316.2667, 247.4667],\n",
      "        [189.8667, 263.1111, 261.3333, 392.5333],\n",
      "        [219.7333, 211.9111, 312.0000, 335.6444],\n",
      "        [418.1333, 150.7556, 484.2667, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([54], device='cuda:0')}, {'boxes': tensor([[107.2000, 184.1778, 179.6000, 288.7111],\n",
      "        [314.4000, 182.7556, 415.2000, 289.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1517], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  98.1333, 510.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([582], device='cuda:0')}, {'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 426.6667, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([698], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.4000,  76.0889, 452.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1114], device='cuda:0')}, {'boxes': tensor([[ 75.2000, 120.8889, 302.0000, 349.8667],\n",
      "        [311.2000, 223.2889, 409.6000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1554], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[345.6000, 176.3556, 406.4000, 274.4889],\n",
      "        [209.0667, 244.6222, 243.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1700], device='cuda:0')}, {'boxes': tensor([[138.0000,  71.8222, 417.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 112.3556, 280.0000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1846], device='cuda:0')}, {'boxes': tensor([[340.2667, 187.7333, 410.6667, 284.4445],\n",
      "        [258.1333, 186.3111, 363.7333, 280.1778],\n",
      "        [125.8667, 162.1333, 179.2000, 227.5556],\n",
      "        [396.8000, 223.2889, 490.6667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([356], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000, 204.8000, 283.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([939], device='cuda:0')}, {'boxes': tensor([[224.0000,  91.0222, 480.0000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([662], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000,   9.9556, 252.8000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1839], device='cuda:0')}, {'boxes': tensor([[265.2000, 206.9333, 287.2000, 229.6889],\n",
      "        [262.8000, 238.9333, 283.6000, 263.8222],\n",
      "        [259.2000, 270.2222, 281.6000, 292.9778],\n",
      "        [257.2000, 302.9333, 278.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([153], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 260.2667, 201.6000, 392.5333],\n",
      "        [256.0000, 260.2667, 283.2000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([764], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 214.7556, 299.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 177.7778, 200.5333, 206.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2136], device='cuda:0')}, {'boxes': tensor([[256.4000, 213.3333, 400.8000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1979], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[313.6000, 232.5333, 450.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1494], device='cuda:0')}, {'boxes': tensor([[146.4000, 157.8667, 297.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1963], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.6000, 204.8000, 396.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([651], device='cuda:0')}, {'boxes': tensor([[221.6000, 223.2889, 320.4000, 280.1778],\n",
      "        [388.8000,  91.7333, 410.0000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1890], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.4000, 379.0222, 357.2000, 509.8667],\n",
      "        [ 64.4000, 375.4667, 362.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([554], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  55.4667, 450.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1118], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.8000,  62.5778, 229.6000, 484.9778],\n",
      "        [242.4000, 115.2000, 389.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1429], device='cuda:0')}, {'boxes': tensor([[174.4000, 190.5778, 250.0000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1247], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.2000, 127.2889, 389.6000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([376], device='cuda:0')}, {'boxes': tensor([[  1.2000,   4.9778, 509.6000, 288.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2086], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.0000, 176.3556, 341.2000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([805], device='cuda:0')}, {'boxes': tensor([[176.0000,  46.9333, 351.6000, 404.6222],\n",
      "        [164.8000, 267.3778, 194.4000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1018], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 203.3778,  90.6667, 509.1555],\n",
      "        [145.0667,  93.8667, 336.0000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([602], device='cuda:0')}, {'boxes': tensor([[160.8000, 120.1778, 432.0000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2197], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.0000, 160.0000, 385.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1301], device='cuda:0')}, {'boxes': tensor([[ 86.4000, 211.2000, 369.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1264], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[202.4000, 177.7778, 332.4000, 448.7111],\n",
      "        [ 87.6000,  14.9333, 142.4000,  91.0222],\n",
      "        [ 34.4000,  76.8000,  80.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([648], device='cuda:0')}, {'boxes': tensor([[ 45.6000, 177.7778, 370.8000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1387], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[227.2000, 296.5333, 243.2000, 335.6444],\n",
      "        [187.6000, 265.2444, 204.0000, 305.7778],\n",
      "        [207.6000, 285.8667, 224.0000, 326.4000],\n",
      "        [182.8000, 219.0222, 200.4000, 258.8445],\n",
      "        [224.8000, 258.1333, 241.2000, 297.9556],\n",
      "        [223.6000, 212.6222, 240.0000, 251.7333],\n",
      "        [200.8000, 192.0000, 216.8000, 231.8222],\n",
      "        [181.6000, 173.5111, 197.6000, 215.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([138], device='cuda:0')}, {'boxes': tensor([[ 73.2000,   0.0000, 510.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1658], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 395.6364, 216.8000, 424.7273]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1423], device='cuda:0')}, {'boxes': tensor([[120.9541, 100.2667, 463.2661, 397.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([473], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000,  60.4444, 322.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([876], device='cuda:0')}, {'boxes': tensor([[ 32.0000,  78.9333, 300.8000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1044], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.6000, 206.2222, 352.8000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1779], device='cuda:0')}, {'boxes': tensor([[ 22.4000,  70.4000, 259.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1432], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[362.0000, 214.0444, 510.8000, 330.6667],\n",
      "        [249.2000, 305.0667, 510.4000, 491.3778],\n",
      "        [ 64.4000, 234.6667, 189.6000, 340.6222],\n",
      "        [  0.0000, 213.3333,  33.2000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1468], device='cuda:0')}, {'boxes': tensor([[ 12.8000, 125.1556, 140.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1131], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.7248, 129.0667, 412.7706, 437.3333],\n",
      "        [411.0092,  91.7333, 439.7798, 195.2000],\n",
      "        [ 38.7523, 109.8667,  97.4679, 176.0000],\n",
      "        [ 88.6606, 121.6000, 157.9450, 177.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([436], device='cuda:0')}, {'boxes': tensor([[102.4000, 242.4889, 314.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1157], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.3333,  59.7333, 309.3333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([725], device='cuda:0')}, {'boxes': tensor([[256.0000, 173.5111, 356.0000, 434.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2186], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 274.4889, 231.2000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2001], device='cuda:0')}, {'boxes': tensor([[ 71.4667, 241.7778, 494.9333, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([239], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[292.4570, 130.8445, 499.1800, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1970], device='cuda:0')}, {'boxes': tensor([[136.5333,  46.9333, 419.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([716], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000,  79.6444, 473.6000, 275.9111],\n",
      "        [154.4000,  79.6444, 289.6000, 295.8222],\n",
      "        [ 51.2000, 132.2667, 192.0000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1756], device='cuda:0')}, {'boxes': tensor([[219.6000, 132.2667, 463.2000, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([325], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.8000, 118.0444, 357.6000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([105], device='cuda:0')}, {'boxes': tensor([[103.4667,  78.2222, 413.8667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1690], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000, 246.0444, 357.3333, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2125], device='cuda:0')}, {'boxes': tensor([[162.1333, 209.0667, 291.2000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.0000, 136.5333, 486.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1496], device='cuda:0')}, {'boxes': tensor([[ 93.6000, 122.3111, 394.4000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1813], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 42.6667,  51.2000, 282.6667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1501], device='cuda:0')}, {'boxes': tensor([[207.2000, 146.4889, 338.4000, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1819], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.2000,   0.0000, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([387], device='cuda:0')}, {'boxes': tensor([[141.2000, 137.2444, 300.4000, 350.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2040], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000,   0.0000, 407.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([617], device='cuda:0')}, {'boxes': tensor([[308.8000,  51.2000, 438.4000, 261.6889],\n",
      "        [128.0000,  71.1111, 272.0000, 261.6889],\n",
      "        [ 64.0000, 113.7778, 223.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1757], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 140.0889, 285.6000, 290.1333],\n",
      "        [230.0000, 205.5111, 378.8000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1407], device='cuda:0')}, {'boxes': tensor([[115.2000, 213.3333, 411.7333, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1715], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8000, 268.8000, 141.2000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([523], device='cuda:0')}, {'boxes': tensor([[  3.2000, 152.8889, 466.8000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1207], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[380.8000, 151.4667, 438.4000, 214.7556],\n",
      "        [274.4000, 167.1111, 328.8000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([629], device='cuda:0')}, {'boxes': tensor([[192.0000, 257.4222, 221.8667, 275.9111],\n",
      "        [311.4667, 250.3111, 426.6667, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2112], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.6000, 391.8222, 324.0000, 423.8222],\n",
      "        [231.6000, 236.8000, 252.8000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1877], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 349.8667, 180.1481],\n",
      "        [  0.0000,  53.0963, 389.3333, 510.1037],\n",
      "        [356.2667,   0.0000, 509.8667, 510.1037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([36], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000,  14.2222, 492.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1671], device='cuda:0')}, {'boxes': tensor([[248.4000, 142.9333, 329.6000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([2], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.4000,  78.9333, 331.6000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2048], device='cuda:0')}, {'boxes': tensor([[163.2000, 199.8222, 318.8000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1550], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.5333, 116.6222, 510.9333, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1710], device='cuda:0')}, {'boxes': tensor([[ 51.2000, 117.3333, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1203], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.0667,   0.0000, 454.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1711], device='cuda:0')}, {'boxes': tensor([[149.2000,   0.7111, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([640], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.2000, 192.0000, 187.6000, 367.6444],\n",
      "        [296.4000, 174.2222, 436.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1111], device='cuda:0')}, {'boxes': tensor([[  0.0000, 192.0000, 189.8667, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1369], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[131.2000, 177.7778, 240.0000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2056], device='cuda:0')}, {'boxes': tensor([[144.0000, 290.1333, 172.8000, 409.6000],\n",
      "        [226.4000, 284.4445, 261.6000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([767], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 151.4667, 357.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1978], device='cuda:0')}, {'boxes': tensor([[228.8000, 159.2889, 311.2000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1995], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 77.6000,   0.0000, 232.0000, 159.2889],\n",
      "        [211.2000,   0.0000, 364.0000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1749], device='cuda:0')}, {'boxes': tensor([[ 71.6000,  91.0222, 476.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1199], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.4000, 250.3111, 508.8000, 503.4667],\n",
      "        [ 96.8000,  66.8444, 339.2000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1616], device='cuda:0')}, {'boxes': tensor([[ 69.6000, 145.0667, 284.4000, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1560], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 86.4000,  41.2444, 355.2000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([62], device='cuda:0')}, {'boxes': tensor([[154.8000,  60.4444, 307.6000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([877], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.6000, 166.4000, 411.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31], device='cuda:0')}, {'boxes': tensor([[228.8000, 104.5333, 308.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([85], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 108.0889, 320.0000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1949], device='cuda:0')}, {'boxes': tensor([[236.0000, 228.2667, 331.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1918], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000,   0.0000, 268.8000, 455.1111],\n",
      "        [267.2000, 388.2667, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1627], device='cuda:0')}, {'boxes': tensor([[172.8000, 227.5556, 283.6000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1957], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.4000, 180.6222, 258.8000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([189], device='cuda:0')}, {'boxes': tensor([[148.2667, 103.8222, 393.6000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([714], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[141.6000, 207.6444, 214.4000, 484.9778],\n",
      "        [264.8000, 182.0444, 310.4000, 359.8222],\n",
      "        [492.0000, 240.3556, 508.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([779], device='cuda:0')}, {'boxes': tensor([[ 25.6000, 128.0000, 107.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1136], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  8.5333,   0.0000, 510.9333, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1022], device='cuda:0')}, {'boxes': tensor([[262.0000, 136.5333, 338.8000, 184.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1381], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.2000, 260.2667, 267.2000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1019], device='cuda:0')}, {'boxes': tensor([[184.0000, 151.4667, 262.4000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1341], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.2000,  51.9111, 511.2000, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([750], device='cuda:0')}, {'boxes': tensor([[172.8000, 230.4000, 368.0000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2117], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 456.5333, 378.1284, 509.8667],\n",
      "        [436.8440, 417.0667, 510.2385, 509.8667],\n",
      "        [287.1193, 347.7333, 428.0367, 483.2000],\n",
      "        [334.6789, 389.3333, 473.8349, 508.8000],\n",
      "        [176.7339, 401.0667, 200.8073, 467.2000],\n",
      "        [264.2202, 289.0667, 354.0551, 467.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([441], device='cuda:0')}, {'boxes': tensor([[158.9333, 176.3556, 220.8000, 241.7778],\n",
      "        [209.0667, 174.9333, 275.2000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([364], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.7523,  98.1333, 437.4312, 406.4000],\n",
      "        [429.2110,  73.6000, 460.9174, 167.4667],\n",
      "        [120.3670,  88.5333, 173.2110, 150.4000],\n",
      "        [ 28.1835,  49.0667, 115.6697, 142.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([434], device='cuda:0')}, {'boxes': tensor([[139.7333, 275.9111, 315.7333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2124], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([319], device='cuda:0')}, {'boxes': tensor([[206.0000,  88.1778, 238.8000, 130.8445],\n",
      "        [195.2000, 162.8445, 227.2000, 205.5111],\n",
      "        [188.8000, 244.6222, 220.8000, 288.0000],\n",
      "        [186.8000, 329.9556, 218.0000, 372.6222],\n",
      "        [183.2000, 403.2000, 215.2000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([145], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.1333, 186.3111, 343.4667, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([258], device='cuda:0')}, {'boxes': tensor([[181.2000, 136.5333, 338.4000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([922], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 341.3333, 249.5413, 503.4667],\n",
      "        [128.5872,  23.4667, 386.3486, 487.4667],\n",
      "        [390.4587, 217.6000, 506.1284, 281.6000],\n",
      "        [423.9266, 288.0000, 504.3670, 471.4667],\n",
      "        [382.2385, 270.9333, 479.1193, 457.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([467], device='cuda:0')}, {'boxes': tensor([[177.6000, 179.2000, 209.6000, 274.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([934], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[379.6000, 195.5556, 492.8000, 425.9556],\n",
      "        [226.8000, 165.6889, 320.4000, 293.6889],\n",
      "        [  8.4000, 193.4222,  45.2000, 214.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([890], device='cuda:0')}, {'boxes': tensor([[253.6000, 135.8222, 340.4000, 187.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1380], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.8667, 160.7111, 305.0667, 265.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([260], device='cuda:0')}, {'boxes': tensor([[162.8000, 160.0000, 295.6000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([488], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 126.5778, 509.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1636], device='cuda:0')}, {'boxes': tensor([[297.2000, 131.5556, 407.2000, 259.5555],\n",
      "        [ 43.6000, 125.1556, 126.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([895], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 160.7111, 263.5852, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([188], device='cuda:0')}, {'boxes': tensor([[231.6000, 231.1111, 278.8000, 268.8000],\n",
      "        [294.4000, 210.4889, 310.4000, 238.9333],\n",
      "        [248.0000, 191.2889, 265.2000, 226.1333],\n",
      "        [232.4000, 194.1333, 256.0000, 224.7111],\n",
      "        [483.6000, 354.8445, 500.8000, 387.5555],\n",
      "        [104.4000, 378.3111, 122.8000, 418.8445],\n",
      "        [358.4000,  84.6222, 379.6000, 140.0889],\n",
      "        [109.2000,  94.5778, 118.4000, 118.0444],\n",
      "        [ 86.8000,  93.8667, 101.6000, 114.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2032], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.4000,  14.9333, 483.6000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([290], device='cuda:0')}, {'boxes': tensor([[  0.0000, 122.3111, 250.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1006], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,   0.0000, 261.6000, 509.1555],\n",
      "        [220.8000,   0.0000, 398.8000, 510.5778],\n",
      "        [265.6000, 105.2444, 412.0000, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1661], device='cuda:0')}, {'boxes': tensor([[174.9333, 108.0889, 245.3333, 233.2444],\n",
      "        [326.4000, 156.4444, 387.2000, 231.8222],\n",
      "        [290.1333,  56.8889, 309.3333,  72.5333],\n",
      "        [343.4667,  68.2667, 365.8667,  86.7556],\n",
      "        [458.6667,  66.8444, 482.1333,  88.1778],\n",
      "        [156.8000,  71.1111, 178.1333,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([359], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000,   0.0000, 509.6000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1608], device='cuda:0')}, {'boxes': tensor([[124.4000, 136.5333, 308.0000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([215], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[156.8000,  79.6444, 393.6000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1821], device='cuda:0')}, {'boxes': tensor([[211.2000, 182.0444, 229.6000, 206.9333],\n",
      "        [276.8000, 204.8000, 299.2000, 236.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([844], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.8000, 130.1333, 340.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1299], device='cuda:0')}, {'boxes': tensor([[256.0000, 206.2222, 412.8000, 290.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000,  54.0444, 326.4000, 411.0222],\n",
      "        [272.0000, 274.4889, 307.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([510], device='cuda:0')}, {'boxes': tensor([[182.0000, 167.8222, 388.0000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1976], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[288.0000,  98.1333, 372.2667, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1585], device='cuda:0')}, {'boxes': tensor([[162.8000, 187.0222, 377.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2171], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 41.2000,  96.0000, 253.6000, 480.0000],\n",
      "        [221.2000, 156.4444, 313.2000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([915], device='cuda:0')}, {'boxes': tensor([[  0.0000,  19.2000, 303.2000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000, 194.1333, 388.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1300], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([954], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.6000, 228.2667, 340.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([920], device='cuda:0')}, {'boxes': tensor([[ 72.0000,   0.0000, 314.4000, 426.6667],\n",
      "        [292.8000, 251.7333, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1628], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.6000, 214.7556, 248.0000, 317.8667],\n",
      "        [ 48.8000, 155.7333,  92.8000, 199.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([1241], device='cuda:0')}, {'boxes': tensor([[376.8000, 256.0000, 450.8000, 470.0444],\n",
      "        [218.8000, 155.0222, 343.2000, 323.5555],\n",
      "        [ 58.0000, 172.8000, 123.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27,  5], device='cuda:0'), 'image_id': tensor([1346], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.5333,  86.7556, 296.5333, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1072], device='cuda:0')}, {'boxes': tensor([[136.4000, 169.2444, 265.2000, 377.6000],\n",
      "        [262.4000, 127.2889, 412.4000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([561], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[105.6000,  75.3778, 367.2000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2200], device='cuda:0')}, {'boxes': tensor([[121.6000, 183.4667, 192.0000, 247.4667],\n",
      "        [198.4000, 176.3556, 275.2000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([363], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[144.8000,   0.0000, 356.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([815], device='cuda:0')}, {'boxes': tensor([[234.6667, 219.0222, 298.6667, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2126], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 53.2000, 467.2000, 234.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1163], device='cuda:0')}, {'boxes': tensor([[ 64.0000,  85.3333, 389.3333, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1686], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.4741, 169.2444, 329.0074, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([758], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([45], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.2000,  77.0909, 364.8000, 280.7273],\n",
      "        [139.2000, 101.8182, 259.2000, 257.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1328], device='cuda:0')}, {'boxes': tensor([[333.8667,  29.8667, 510.9333, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1724], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.0000, 194.1333, 302.0000, 392.5333],\n",
      "        [  0.0000,   0.0000, 374.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1662], device='cuda:0')}, {'boxes': tensor([[168.4000, 255.2889, 339.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1525], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.6000, 206.9333, 290.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([75], device='cuda:0')}, {'boxes': tensor([[179.2000, 190.5778, 282.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 107.3778, 511.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([991], device='cuda:0')}, {'boxes': tensor([[257.2000, 226.1333, 404.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([29], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 146.4889, 399.6000, 380.4445],\n",
      "        [133.6000,  49.0667, 186.0000, 147.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([425], device='cuda:0')}, {'boxes': tensor([[174.4000,  29.1556, 276.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1058], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 155.7333, 417.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1033], device='cuda:0')}, {'boxes': tensor([[174.8000, 224.7111, 342.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 164.9778, 254.4000, 330.6667],\n",
      "        [198.4000, 194.1333, 265.2000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1569], device='cuda:0')}, {'boxes': tensor([[181.2000,  47.6444, 302.0000, 238.9333],\n",
      "        [295.6000,  26.3111, 453.6000, 251.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([563], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[264.4000, 273.7778, 470.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([576], device='cuda:0')}, {'boxes': tensor([[257.7615, 152.5333, 335.8532, 294.4000],\n",
      "        [106.8624, 228.2667, 169.6881, 296.5333],\n",
      "        [192.5872, 165.3333, 224.2936, 204.8000],\n",
      "        [388.6972, 190.9333, 476.7706, 260.2667],\n",
      "        [434.4954, 182.4000, 474.4220, 227.2000],\n",
      "        [338.7890, 121.6000, 364.6238, 142.9333],\n",
      "        [270.0917, 110.9333, 300.0367, 136.5333],\n",
      "        [243.0826, 106.6667, 273.0275, 131.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([429], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[232.0000,  81.0667, 370.0000, 326.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1457], device='cuda:0')}, {'boxes': tensor([[123.2593, 109.5111, 510.1037, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([168], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[303.6000, 387.5555, 326.8000, 418.8445],\n",
      "        [231.6000, 233.9556, 254.4000, 282.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1876], device='cuda:0')}, {'boxes': tensor([[ 32.0000,  65.4222, 320.0000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2088], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 159.2889, 455.4667, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1066], device='cuda:0')}, {'boxes': tensor([[134.8000, 187.0222, 360.0000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[266.4000, 237.5111, 362.8000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([129], device='cuda:0')}, {'boxes': tensor([[326.8000, 153.6000, 368.8000, 211.2000],\n",
      "        [312.4000, 219.0222, 354.4000, 282.3111],\n",
      "        [243.2000, 177.0667, 286.4000, 231.1111],\n",
      "        [214.4000, 255.2889, 260.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([152], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 30.9333,  73.9556, 206.9333, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1491], device='cuda:0')}, {'boxes': tensor([[142.0000, 258.8445, 429.2000, 507.7333],\n",
      "        [141.6000, 140.0889, 225.2000, 377.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1789], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 176.3556, 122.4000, 280.1778],\n",
      "        [172.0000, 199.1111, 185.6000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2079], device='cuda:0')}, {'boxes': tensor([[100.0000,   0.0000, 352.8000, 384.0000],\n",
      "        [292.8000, 256.0000, 506.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1629], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[285.6000, 179.2000, 462.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1286], device='cuda:0')}, {'boxes': tensor([[107.7333,  48.3556, 410.6667, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([717], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 167.8222, 256.0000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1366], device='cuda:0')}, {'boxes': tensor([[  0.0000,  71.1111, 278.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 69.3333, 310.0444, 200.5333, 435.2000],\n",
      "        [379.7333, 295.8222, 443.7333, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([712], device='cuda:0')}, {'boxes': tensor([[ 50.0000,   3.5556, 419.6000, 465.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([293], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.4000,  59.7333, 504.8000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([312], device='cuda:0')}, {'boxes': tensor([[ 40.8000, 322.0984, 137.6000, 413.3770],\n",
      "        [160.8000, 305.3115, 259.2000, 400.7869]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([963], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.3333,  31.2889, 326.4000, 494.9333],\n",
      "        [410.6667, 139.3778, 508.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([607], device='cuda:0')}, {'boxes': tensor([[267.2000, 123.0222, 308.8000, 204.0889],\n",
      "        [347.6000, 204.0889, 398.0000, 292.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([881], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 105.9556, 348.8000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2144], device='cuda:0')}, {'boxes': tensor([[ 91.2000, 206.9333, 180.8000, 283.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1276], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  57.6000, 316.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1004], device='cuda:0')}, {'boxes': tensor([[226.0000, 208.3556, 289.2000, 252.4444],\n",
      "        [131.6000, 187.7333, 162.4000, 258.8445],\n",
      "        [463.6000, 228.2667, 511.2000, 294.4000],\n",
      "        [ 66.0000, 174.2222,  79.6000, 195.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2025], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[232.4000, 164.2667, 335.6000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([216], device='cuda:0')}, {'boxes': tensor([[  0.0000, 278.7556, 160.8000, 510.5778],\n",
      "        [113.6000,  56.8889, 205.2000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([502], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 58.7156,  75.7333, 466.2018, 406.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([477], device='cuda:0')}, {'boxes': tensor([[212.3852, 204.8000, 343.2296, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([186], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  9.6000,  49.0667, 345.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1546], device='cuda:0')}, {'boxes': tensor([[261.6000, 118.7556, 282.0000, 157.8667],\n",
      "        [250.8000, 171.3778, 270.8000, 211.9111],\n",
      "        [239.6000, 241.0667, 260.0000, 278.0444],\n",
      "        [226.8000, 309.3333, 248.0000, 347.0222],\n",
      "        [218.8000, 369.7778, 240.0000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([144], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 211.9111, 249.6000, 285.1555],\n",
      "        [ 59.6000, 252.4444, 170.4000, 327.1111],\n",
      "        [199.6000, 237.5111, 275.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1572], device='cuda:0')}, {'boxes': tensor([[188.8000,  91.0222, 355.2000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1356], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000,  19.9111, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([641], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([33], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[138.6667,   0.0000, 493.8667, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1709], device='cuda:0')}, {'boxes': tensor([[  4.2667, 150.7556,  62.9333, 230.4000],\n",
      "        [343.4667, 182.0444, 478.9333, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([678], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 19.2000,   0.0000, 204.8000, 510.5778],\n",
      "        [388.0000, 372.6222, 500.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1626], device='cuda:0')}, {'boxes': tensor([[168.0000,  42.6667, 466.4000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2198], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.3333, 133.6889, 462.9333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([204], device='cuda:0')}, {'boxes': tensor([[161.6000, 157.8667, 319.2000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([613], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[422.4000, 156.4444, 497.0667, 216.1778],\n",
      "        [ 76.8000, 223.2889, 189.8667, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1704], device='cuda:0')}, {'boxes': tensor([[108.8000, 156.4444, 275.2000, 304.3556],\n",
      "        [174.9333, 244.6222, 411.7333, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([2076], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.4000, 121.6000, 508.4000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([994], device='cuda:0')}, {'boxes': tensor([[104.2963, 110.9333, 509.1555, 403.9111],\n",
      "        [184.8889, 327.1111, 280.6519, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([176], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.4000, 226.1333, 264.8000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([941], device='cuda:0')}, {'boxes': tensor([[124.8000,  68.9778, 316.8000, 449.4222],\n",
      "        [236.8000, 146.4889, 317.6000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1530], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.4000,  93.8667, 456.5333, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1472], device='cuda:0')}, {'boxes': tensor([[39.6000,  0.0000, 99.2000, 76.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1836], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 122.3111, 510.9333, 348.4445],\n",
      "        [ 32.0000,   0.0000, 500.2667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([49], device='cuda:0')}, {'boxes': tensor([[ 50.1333, 253.1555, 177.0667, 379.7333],\n",
      "        [388.2667, 230.4000, 435.2000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([697], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.4000,   0.7111, 448.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([159], device='cuda:0')}, {'boxes': tensor([[174.0000,  66.8444, 290.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1053], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.5333, 130.8445, 278.4000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([200], device='cuda:0')}, {'boxes': tensor([[ 49.2000,  69.6889, 343.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([224], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 179.2000, 292.0000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2054], device='cuda:0')}, {'boxes': tensor([[218.8000, 117.3333, 300.0000, 210.4889],\n",
      "        [202.4000, 122.3111, 270.8000, 182.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([873], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[144.1185, 170.6667, 215.2296, 250.3111],\n",
      "        [441.8370, 169.2444, 508.2074, 250.3111],\n",
      "        [186.7852, 220.4444, 286.3407, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 3], device='cuda:0'), 'image_id': tensor([1141], device='cuda:0')}, {'boxes': tensor([[ 79.6000,  81.7778, 484.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1198], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  81.7778, 322.4000, 245.3333],\n",
      "        [245.2000, 288.0000, 370.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([69], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.5360e+02, 3.1360e+02, 4.9280e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([298], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 177.7778, 215.4667, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1367], device='cuda:0')}, {'boxes': tensor([[ 87.2000,  75.3778, 242.4000, 244.6222],\n",
      "        [236.8000,  64.0000, 364.0000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1741], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 221.8667, 230.4000, 288.0000],\n",
      "        [298.4000, 224.7111, 338.4000, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([833], device='cuda:0')}, {'boxes': tensor([[393.3945, 314.6667, 510.2385, 504.5333],\n",
      "        [  0.5872, 265.6000,  86.3119, 423.4667],\n",
      "        [252.4771, 203.7333, 396.3303, 487.4667],\n",
      "        [273.0275, 308.2667, 428.0367, 504.5333],\n",
      "        [126.8257, 251.7333, 207.2661, 361.6000],\n",
      "        [395.7431, 272.0000, 473.8349, 344.5333],\n",
      "        [ 61.6514, 269.8667, 154.4220, 405.3333],\n",
      "        [  0.0000, 214.4000,  95.1193, 281.6000],\n",
      "        [137.9817, 246.4000, 227.2294, 344.5333],\n",
      "        [  0.5872, 315.7333,  34.6422, 430.9333],\n",
      "        [193.7615, 113.0667, 487.9266, 397.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([448], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.2000, 104.5333, 478.8000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([313], device='cuda:0')}, {'boxes': tensor([[ 41.6000,  80.3556, 511.2000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1584], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.4000, 202.6667, 250.4000, 335.6444],\n",
      "        [116.4000, 150.0444, 185.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([1244], device='cuda:0')}, {'boxes': tensor([[  0.0000,  15.6444, 234.6667, 465.0667],\n",
      "        [296.5333,  48.3556, 509.8667, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([611], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.0000, 189.8667, 470.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1291], device='cuda:0')}, {'boxes': tensor([[307.2000,  51.2000, 451.2000, 250.3111],\n",
      "        [164.8000,  62.5778, 300.0000, 261.6889],\n",
      "        [ 97.6000, 109.5111, 250.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1759], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000,  91.0222, 510.4000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([323], device='cuda:0')}, {'boxes': tensor([[183.1927, 102.4000, 452.6972, 408.5333],\n",
      "        [ 54.6055, 242.1333, 186.7156, 406.4000],\n",
      "        [123.3027,  99.2000, 190.2385, 154.6667],\n",
      "        [438.0183,  80.0000, 476.1835, 172.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([433], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.0000,  62.5778, 291.2000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([838], device='cuda:0')}, {'boxes': tensor([[  3.2000, 152.8889, 410.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1204], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 75.2000,  82.4889, 449.6000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1805], device='cuda:0')}, {'boxes': tensor([[  0.0000, 146.4889, 293.3333, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([197], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.0000, 122.3111, 492.0000, 499.2000],\n",
      "        [140.8000,   0.0000, 302.4000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1610], device='cuda:0')}, {'boxes': tensor([[140.8000, 169.9556, 176.8000, 221.8667],\n",
      "        [ 67.2000, 217.6000,  91.6000, 297.2444],\n",
      "        [158.8000,  71.8222, 176.8000, 106.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([623], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.0000, 247.4667, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1220], device='cuda:0')}, {'boxes': tensor([[  0.0000,  89.6000, 277.3333, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1410], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.8000, 167.8222, 375.2000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1977], device='cuda:0')}, {'boxes': tensor([[207.2000,  53.3333, 351.6000, 364.0889],\n",
      "        [233.6000, 270.9333, 243.6000, 302.2222],\n",
      "        [410.8000, 253.8667, 444.8000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1012], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[113.6882,  81.7778, 475.3134, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2097], device='cuda:0')}, {'boxes': tensor([[152.8000, 374.0444, 243.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2014], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 146.4889, 436.4000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([330], device='cuda:0')}, {'boxes': tensor([[ 80.0000, 207.6444, 136.0000, 265.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([945], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.8000, 239.6444, 311.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1159], device='cuda:0')}, {'boxes': tensor([[166.4000, 372.6222, 336.8000, 509.1555],\n",
      "        [ 45.2000, 357.6889, 350.4000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([551], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[282.8000, 187.7333, 469.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1289], device='cuda:0')}, {'boxes': tensor([[  5.6000,  98.1333, 182.0000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1330], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.4667,   0.0000, 402.9630, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1827], device='cuda:0')}, {'boxes': tensor([[228.8000, 123.7333, 333.6000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1379], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[246.8000, 265.2444, 280.8000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([984], device='cuda:0')}, {'boxes': tensor([[186.6667, 177.7778, 451.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([231], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.4000, 245.3333, 309.2000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1160], device='cuda:0')}, {'boxes': tensor([[243.6000, 195.5556, 310.0000, 307.9111],\n",
      "        [313.6000,  24.8889, 344.8000, 130.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1869], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 222.5778, 126.8000, 509.8667],\n",
      "        [164.4000, 151.4667, 240.0000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([495], device='cuda:0')}, {'boxes': tensor([[ 90.8000,   0.0000, 510.4000, 498.4889],\n",
      "        [168.4000,  23.4667, 418.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1665], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[273.6000, 226.1333, 304.8000, 299.3778],\n",
      "        [352.0000, 324.2667, 401.6000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([883], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 510.4000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1635], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2294, 100.2667, 452.6972, 424.5333],\n",
      "        [457.3945,  75.7333, 489.6881, 171.7333],\n",
      "        [  0.5872, 272.0000,  71.6330, 504.5333],\n",
      "        [ 88.6606,  86.4000, 146.7890, 141.8667],\n",
      "        [136.8073,  94.9333, 195.5229, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([431], device='cuda:0')}, {'boxes': tensor([[292.0000, 248.8889, 408.8000, 419.5555],\n",
      "        [  0.0000, 164.9778,  93.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([898], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.7138e+02, 4.1240e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([738], device='cuda:0')}, {'boxes': tensor([[194.8000, 118.7556, 500.8000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([228], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 37.2000,  90.3111, 237.6000, 482.8445],\n",
      "        [222.8000, 142.2222, 324.8000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([914], device='cuda:0')}, {'boxes': tensor([[ 52.4000, 118.7556, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1202], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.9333, 247.4667, 219.7333, 268.8000],\n",
      "        [309.3333, 238.9333, 424.5333, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2111], device='cuda:0')}, {'boxes': tensor([[ 88.0000, 200.5333, 208.0000, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1277], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.8000, 301.5111, 369.6000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1920], device='cuda:0')}, {'boxes': tensor([[172.8000, 258.8445, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1225], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  54.0444, 254.4000,  76.8000],\n",
      "        [235.2000, 208.3556, 248.0000, 228.2667],\n",
      "        [252.4000, 328.5333, 265.2000, 344.8889],\n",
      "        [285.6000, 377.6000, 293.6000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([154], device='cuda:0')}, {'boxes': tensor([[170.8000,  64.0000, 307.2000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([843], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.2000,  28.4444, 449.2000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([817], device='cuda:0')}, {'boxes': tensor([[ 44.8000,  41.2444, 224.0000, 224.7111],\n",
      "        [308.0000,  24.1778, 468.8000, 224.7111],\n",
      "        [486.4000,  71.1111, 511.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1760], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 51.2000, 166.4000, 198.4000, 507.7333],\n",
      "        [171.2000,  64.0000, 307.2000, 509.8667],\n",
      "        [  0.0000,   0.0000, 214.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9, 7], device='cuda:0'), 'image_id': tensor([1413], device='cuda:0')}, {'boxes': tensor([[  0.0000, 209.0667, 184.5333, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 258.8445, 203.2000, 402.4889],\n",
      "        [266.4000, 261.6889, 301.6000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([765], device='cuda:0')}, {'boxes': tensor([[108.9362,   0.0000, 183.8298, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1090], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.0000,  75.3778, 340.4000, 393.9556],\n",
      "        [307.6000, 151.4667, 365.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1539], device='cuda:0')}, {'boxes': tensor([[ 98.1333, 278.7556, 509.8667, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([235], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667,  11.3778, 380.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([592], device='cuda:0')}, {'boxes': tensor([[ 88.0000, 123.7333, 507.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1282], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[247.2000, 139.3778, 340.8000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1991], device='cuda:0')}, {'boxes': tensor([[  2.1333, 170.6667, 281.6000, 509.1555],\n",
      "        [316.8000,  96.7111, 509.8667, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([612], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 67.2000, 201.0074, 199.4667, 305.3037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1143], device='cuda:0')}, {'boxes': tensor([[219.2000,   0.7111, 479.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([273], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[259.2000, 200.5333, 406.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([30], device='cuda:0')}, {'boxes': tensor([[373.1831,   0.0000, 510.1972, 305.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1487], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.8000, 216.1778, 353.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([116], device='cuda:0')}, {'boxes': tensor([[  0.0000,  60.4444, 210.8000, 502.7556],\n",
      "        [168.4000, 194.1333, 390.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([909], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.0000, 104.5333, 509.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([42], device='cuda:0')}, {'boxes': tensor([[ 83.2000,   2.8444, 323.2000, 457.9556],\n",
      "        [413.8667, 108.0889, 507.7333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([604], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000, 271.6444, 185.6000, 309.3333],\n",
      "        [237.2000, 275.2000, 361.2000, 325.6889],\n",
      "        [321.2000, 271.6444, 368.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29], device='cuda:0'), 'image_id': tensor([528], device='cuda:0')}, {'boxes': tensor([[ 99.2000, 102.4000, 344.5333, 238.9333],\n",
      "        [358.4000, 240.3556, 443.7333, 483.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([670], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[209.2000,   0.0000, 510.4000, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1314], device='cuda:0')}, {'boxes': tensor([[ 64.0000,   0.0000, 317.6000, 510.5778],\n",
      "        [232.4000,   0.7111, 402.4000, 509.1555],\n",
      "        [255.2000, 167.8222, 424.4000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1660], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[422.0000, 178.4889, 470.4000, 212.6222],\n",
      "        [321.6000, 172.0889, 412.4000, 213.3333],\n",
      "        [253.2000, 187.7333, 327.2000, 220.4444],\n",
      "        [ 14.8000, 227.5556,  87.2000, 281.6000],\n",
      "        [160.4000, 223.2889, 188.4000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29, 29], device='cuda:0'), 'image_id': tensor([538], device='cuda:0')}, {'boxes': tensor([[179.6000, 229.6889, 414.4000, 406.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([17], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.7333, 367.6444, 212.2667, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1803], device='cuda:0')}, {'boxes': tensor([[182.0000, 226.8445, 257.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2057], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.0000, 177.7778, 292.8000, 306.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1127], device='cuda:0')}, {'boxes': tensor([[109.6000, 144.3556, 320.4000, 465.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([544], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.9852, 228.9778, 283.4963, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([753], device='cuda:0')}, {'boxes': tensor([[102.4000,   0.0000, 255.2000, 285.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1838], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 224.0000, 342.4000, 510.5778],\n",
      "        [339.2000, 351.2889, 414.4000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1251], device='cuda:0')}, {'boxes': tensor([[  0.0000, 152.1778, 165.3333, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1371], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 315.7333, 196.2667, 433.7778],\n",
      "        [377.6000, 301.5111, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([705], device='cuda:0')}, {'boxes': tensor([[238.8000,  61.8667, 340.4000, 386.8445],\n",
      "        [322.0000, 138.6667, 362.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1538], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[257.2000,  96.0000, 392.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1440], device='cuda:0')}, {'boxes': tensor([[122.0000, 289.4222, 150.0000, 489.9556],\n",
      "        [127.6000, 156.4444, 150.4000, 197.6889],\n",
      "        [386.0000, 200.5333, 460.8000, 276.6222],\n",
      "        [ 78.8000, 147.9111,  97.2000, 179.9111],\n",
      "        [296.0000, 172.8000, 344.8000, 243.2000],\n",
      "        [341.2000, 180.6222, 426.4000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2026], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.4000, 211.9111, 243.2000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2033], device='cuda:0')}, {'boxes': tensor([[194.0000,   0.0000, 450.0000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([816], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.1111,  38.4000, 425.7185, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1825], device='cuda:0')}, {'boxes': tensor([[216.5333, 224.7111, 384.0000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2104], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.4000, 159.2889, 444.8000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([155], device='cuda:0')}, {'boxes': tensor([[281.6000, 239.6444, 308.4000, 305.7778],\n",
      "        [373.2000, 337.0667, 400.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([882], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.4000,  54.0444, 320.0000, 420.9778],\n",
      "        [  0.0000,  28.4444,  49.6000, 147.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1769], device='cuda:0')}, {'boxes': tensor([[416.4000, 231.1111, 508.4000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([532], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 120.1778, 258.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([222], device='cuda:0')}, {'boxes': tensor([[176.0000, 139.3778, 188.4000, 172.0889],\n",
      "        [224.4000, 239.6444, 248.4000, 256.0000],\n",
      "        [215.2000, 351.2889, 269.2000, 387.5555],\n",
      "        [426.4000, 338.4889, 454.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24, 24], device='cuda:0'), 'image_id': tensor([1882], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 169.2444, 211.6000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([860], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1649], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 261.6889, 412.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1500], device='cuda:0')}, {'boxes': tensor([[271.6000,  88.1778, 365.2000, 226.1333],\n",
      "        [139.2000, 105.9556, 177.6000, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 308.6222, 279.2000, 364.0889],\n",
      "        [293.6000, 314.3111, 312.8000, 376.8889],\n",
      "        [454.4000, 277.3333, 511.2000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([791], device='cuda:0')}, {'boxes': tensor([[102.4000, 105.2444, 437.3333, 125.1556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2132], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 253.1555, 265.6000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2134], device='cuda:0')}, {'boxes': tensor([[313.6000, 207.6444, 352.0000, 371.2000],\n",
      "        [172.0000, 220.4444, 216.0000, 480.7111],\n",
      "        [384.0000, 204.8000, 428.8000, 422.4000],\n",
      "        [424.0000, 236.0889, 509.6000, 506.3111],\n",
      "        [  0.0000, 297.2444, 126.4000, 509.1555],\n",
      "        [195.2000, 275.9111, 308.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([775], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 179.2000,  32.0000, 273.0667],\n",
      "        [379.7333, 170.6667, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([687], device='cuda:0')}, {'boxes': tensor([[115.2000,  45.5111, 267.2000, 226.1333],\n",
      "        [232.0000,  28.4444, 365.6000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1751], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 342.7556, 249.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2012], device='cuda:0')}, {'boxes': tensor([[164.8000, 219.0222, 375.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[141.8667, 374.0444, 219.7333, 439.4667],\n",
      "        [  1.0667, 433.0667,  27.7333, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1804], device='cuda:0')}, {'boxes': tensor([[242.4954, 171.7333, 495.5596, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([471], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[440.8000, 209.8361, 510.4000, 273.8361]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([967], device='cuda:0')}, {'boxes': tensor([[ 46.9333,   0.0000, 273.0667, 510.5778],\n",
      "        [362.6667,   0.0000, 510.9333, 157.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([596], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.8000, 182.7556, 232.4000, 365.5111],\n",
      "        [276.4000, 172.8000, 424.4000, 352.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1093], device='cuda:0')}, {'boxes': tensor([[125.8667, 196.2667, 270.9333, 459.3778],\n",
      "        [211.2000,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1085], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.2000, 105.9556, 332.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1843], device='cuda:0')}, {'boxes': tensor([[158.4000, 209.0667, 234.0000, 277.3333],\n",
      "        [ 44.8000, 246.7556, 156.4000, 315.0222],\n",
      "        [190.4000, 238.2222, 262.0000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1573], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.9185, 173.5111, 297.7185, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([756], device='cuda:0')}, {'boxes': tensor([[123.6000, 217.6000, 334.8000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1172], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 109.5111, 432.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([540], device='cuda:0')}, {'boxes': tensor([[305.6000, 210.4889, 507.2000, 506.3111],\n",
      "        [  0.0000, 113.7778, 332.0000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1620], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[414.6479,   0.0000, 511.0986, 337.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1485], device='cuda:0')}, {'boxes': tensor([[120.8000,  91.0222, 336.8000, 453.6889],\n",
      "        [  0.0000,  51.2000,  58.4000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1765], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 118.7556, 282.8000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1214], device='cuda:0')}, {'boxes': tensor([[173.6000,  74.6667, 261.2000, 273.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([24], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 481.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([282], device='cuda:0')}, {'boxes': tensor([[230.0000, 168.5333, 332.8000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2177], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000,  25.6000, 509.8667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1713], device='cuda:0')}, {'boxes': tensor([[140.8000, 305.7778, 236.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2008], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.4000, 209.7778, 135.2000, 273.7778],\n",
      "        [ 79.6000, 280.1778, 110.8000, 342.7556],\n",
      "        [154.8000,  78.2222, 171.6000, 110.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([625], device='cuda:0')}, {'boxes': tensor([[145.6000, 376.8889, 249.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2015], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[272.0000, 213.3333, 403.6000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1913], device='cuda:0')}, {'boxes': tensor([[  0.0000, 256.0000, 259.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1036], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.7280e+02, 4.0680e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([739], device='cuda:0')}, {'boxes': tensor([[164.0000, 291.5555, 332.8000, 510.5778],\n",
      "        [ 32.0000, 294.4000, 344.0000, 502.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([553], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000, 200.5333, 334.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1933], device='cuda:0')}, {'boxes': tensor([[104.8000, 209.0667, 188.0000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([859], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[173.2000,  31.2889, 273.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1059], device='cuda:0')}, {'boxes': tensor([[ 45.2000,  53.3333, 338.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000, 200.5333, 210.4000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([937], device='cuda:0')}, {'boxes': tensor([[ 85.6000,  90.2295, 257.6000, 489.9672]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.2000, 159.2889, 276.0000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([931], device='cuda:0')}, {'boxes': tensor([[  0.0000,  41.2444, 510.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([580], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.8000, 132.2667, 462.0000, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([326], device='cuda:0')}, {'boxes': tensor([[210.8000, 107.3778, 510.0000, 450.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([989], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.0000, 135.1111, 256.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1343], device='cuda:0')}, {'boxes': tensor([[ 22.4000,   0.0000, 422.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1728], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "Epoch 1/3 | Batch Number: 3641 | LR: 0.00030 | Train_loss: 32724476281.37 | Valid_loss: 2043855885.89 | Valid mAP: 0.00% | Valid Missed Images 241 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.4000, 158.9333, 278.4000, 426.6667],\n",
      "        [ 44.0000, 162.1333, 124.8000, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6], device='cuda:0'), 'image_id': tensor([18625], device='cuda:0')}, {'boxes': tensor([[ 18.4000,   3.7926, 185.6000, 184.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([15247], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 75.0933,  66.8445, 409.6000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([22441], device='cuda:0')}, {'boxes': tensor([[  1.5193, 269.3120, 507.4421, 428.0320],\n",
      "        [344.8783, 393.2160, 508.9614, 501.7600],\n",
      "        [ 77.4837,  24.5760, 422.3620, 327.6800]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 4], device='cuda:0'), 'image_id': tensor([12894], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 61.4400, 122.0465, 512.0000, 510.5116]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1952], device='cuda:0')}, {'boxes': tensor([[  0.0000,  40.1569, 406.5280, 227.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2060], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[114.8000, 192.7111, 326.4000, 404.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([16144], device='cuda:0')}, {'boxes': tensor([[204.4000, 155.0222, 392.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([15421], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 79.6000, 160.0000, 317.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([16172], device='cuda:0')}, {'boxes': tensor([[274.8000, 160.7111, 334.4000, 303.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([25855], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 44.1379,   2.0480, 465.3399, 490.4960]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3848], device='cuda:0')}, {'boxes': tensor([[109.6000, 137.2444, 167.2000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([18565], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[114.6880, 207.5676, 508.9280, 505.8498]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1401], device='cuda:0')}, {'boxes': tensor([[  3.4133,  25.2394, 510.2933, 510.1972]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10825], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[124.8000, 194.8445, 329.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([25255], device='cuda:0')}, {'boxes': tensor([[327.4667, 230.4000, 489.6000, 297.2444],\n",
      "        [211.2000, 254.5778, 253.8667, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([22828], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  3.2000,  12.8000, 400.0000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([32456], device='cuda:0')}, {'boxes': tensor([[ 80.8960,  55.3513, 443.3920, 401.2973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([12949], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[132.0000,  91.7333, 402.4000, 487.1111],\n",
      "        [ 18.8000,  48.3556, 224.0000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14, 14], device='cuda:0'), 'image_id': tensor([16217], device='cuda:0')}, {'boxes': tensor([[291.2000,   5.6889, 500.2667, 176.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([20192], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 21.5040, 141.4535, 466.9440, 495.0871]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10162], device='cuda:0')}, {'boxes': tensor([[128.8000, 113.0667, 432.0000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([25347], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 97.8824,  95.2889, 506.9804, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([30084], device='cuda:0')}, {'boxes': tensor([[159.6000,  46.2222, 353.6000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14503], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 24.8000,  55.4667, 489.6000, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([19572], device='cuda:0')}, {'boxes': tensor([[220.8000,   2.8445, 329.2000, 412.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([19882], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 95.2000, 261.6889, 252.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([20337], device='cuda:0')}, {'boxes': tensor([[244.0000,  96.0000, 433.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26787], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.3333,  82.4889, 484.2667, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([23762], device='cuda:0')}, {'boxes': tensor([[ 84.0000,  79.4358, 424.0000, 435.4528]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11196], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 83.2000, 322.1333, 512.0000, 407.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([23347], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([20212], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[274.0000,  76.8000, 307.6000, 154.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26568], device='cuda:0')}, {'boxes': tensor([[120.8000, 237.5111, 421.6000, 444.4444],\n",
      "        [ 54.0000,  36.9778, 360.0000, 228.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([22265], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[136.5333, 265.9556, 259.2000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([20122], device='cuda:0')}, {'boxes': tensor([[138.8000, 180.6222, 306.0000, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([14929], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[177.6000,  32.7111, 326.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([29063], device='cuda:0')}, {'boxes': tensor([[144.3840, 195.2673, 399.3600, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([7262], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[228.2667,  25.6000, 413.8667, 428.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([7264], device='cuda:0')}, {'boxes': tensor([[ 54.2720,  17.7493, 479.2320, 486.0587],\n",
      "        [  6.1440, 228.0107,  71.6800, 364.5440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6], device='cuda:0'), 'image_id': tensor([10020], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[210.8000,  29.8667, 464.4000, 231.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14638], device='cuda:0')}, {'boxes': tensor([[145.4080, 178.3544, 374.7840, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([11802], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[146.0000,  14.2222, 316.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([16296], device='cuda:0')}, {'boxes': tensor([[138.2400,  85.3333, 286.7200, 412.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3860], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[268.0755, 126.5778, 375.1447, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([25686], device='cuda:0')}, {'boxes': tensor([[202.0000, 100.2667, 512.0000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([29729], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 64.0000, 137.9556, 235.2000, 295.8222],\n",
      "        [186.8000, 280.8889, 212.4000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20,  5], device='cuda:0'), 'image_id': tensor([29048], device='cuda:0')}, {'boxes': tensor([[ 51.2000,  23.0630, 367.6160, 378.2342]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9197], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 27.6480,   5.1717, 447.4880, 486.1414]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8666], device='cuda:0')}, {'boxes': tensor([[150.0000, 140.8000, 297.6000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18008], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[302.9333,  11.3778, 441.6000, 250.3111],\n",
      "        [122.6667, 216.1778, 412.8000, 473.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([25050], device='cuda:0')}, {'boxes': tensor([[108.8000,  77.5111, 262.4000, 241.7778],\n",
      "        [  0.0000, 164.9778, 425.6000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12,  7], device='cuda:0'), 'image_id': tensor([31944], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 70.4000, 105.2444, 438.4000, 376.8889],\n",
      "        [334.4000, 137.9556, 365.6000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([24897], device='cuda:0')}, {'boxes': tensor([[  0.0000,   4.2667, 499.2000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3353], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 26.6240, 316.2353, 423.9360, 465.4545]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5624], device='cuda:0')}, {'boxes': tensor([[ 61.4400,  34.1333, 364.5440, 436.9067]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([6734], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 12.2880, 111.7640, 444.4160, 447.0560]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([13390], device='cuda:0')}, {'boxes': tensor([[142.4000, 199.1111, 274.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([29348], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 30.7200,  42.3253, 486.4000, 401.4080]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([12194], device='cuda:0')}, {'boxes': tensor([[232.5333, 184.8889, 325.3333, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([29532], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 263.8880, 118.7840, 354.2409],\n",
      "        [  1.0240, 108.9972, 508.9280, 395.8319]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 1], device='cuda:0'), 'image_id': tensor([12802], device='cuda:0')}, {'boxes': tensor([[166.8741, 122.3111, 297.7185, 186.3111],\n",
      "        [  0.0000, 126.5778, 168.7704, 203.3778],\n",
      "        [229.4519, 186.3111, 350.8148, 237.5111],\n",
      "        [ 75.8519,  35.5555, 208.5926, 150.7556],\n",
      "        [191.5259, 186.3111, 246.5185, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 23,  9,  9,  9], device='cuda:0'), 'image_id': tensor([23988], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.6400,  59.7085, 507.5200, 480.6531]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([9020], device='cuda:0')}, {'boxes': tensor([[  1.0240,   3.0296, 331.7760, 348.4024],\n",
      "        [  1.0240, 452.9231,  17.4080, 489.2781],\n",
      "        [ 30.7200, 454.4379,  54.2720, 469.5858],\n",
      "        [137.2160, 287.8107, 339.9680, 492.3077],\n",
      "        [150.5280, 452.9231, 204.8000, 492.3077],\n",
      "        [180.2240, 452.9231, 216.0640, 484.7337],\n",
      "        [346.1120, 277.2071, 500.7360, 451.4083]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19,  7,  7,  7,  7,  7,  7], device='cuda:0'), 'image_id': tensor([11525], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[106.4000,   7.1111, 288.4000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15647], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.1333, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([28160], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 34.6280,   6.3603, 484.7923, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3380], device='cuda:0')}, {'boxes': tensor([[217.6000, 283.7333, 324.4000, 340.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26241], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[240.0000, 260.2667, 342.8000, 386.1333],\n",
      "        [234.4000, 177.7778, 300.4000, 247.4667],\n",
      "        [242.8000, 150.0444, 300.8000, 201.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([22491], device='cuda:0')}, {'boxes': tensor([[297.8667, 164.5037, 357.6000, 301.0370]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([13819], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[192.5120,  12.2880, 416.7680, 139.2640],\n",
      "        [226.3040, 402.7733, 275.4560, 495.6160]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([5639], device='cuda:0')}, {'boxes': tensor([[188.8000,  88.1778, 254.8000, 214.7556],\n",
      "        [214.4000, 265.2444, 286.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([21398], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[115.2000,  13.8667, 472.0000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([19564], device='cuda:0')}, {'boxes': tensor([[ 47.7867,  86.0160, 363.1787, 394.2400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5903], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[131.6000,  38.4000, 511.6000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20825], device='cuda:0')}, {'boxes': tensor([[159.2000, 172.8000, 307.6000, 216.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([30286], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[259.6000, 174.9333, 386.0000, 356.2667],\n",
      "        [296.4000, 165.6889, 347.2000, 247.4667],\n",
      "        [159.6000, 123.7333, 271.6000, 381.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13, 13], device='cuda:0'), 'image_id': tensor([29141], device='cuda:0')}, {'boxes': tensor([[245.3333, 220.4444, 362.6667, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([25165], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 22.5280,  90.7147, 360.4480, 412.0601]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([526], device='cuda:0')}, {'boxes': tensor([[144.0000, 159.2889, 322.1333, 366.9333],\n",
      "        [359.4667, 257.4222, 512.0000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([31063], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[168.8000, 312.1778, 238.8000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([22647], device='cuda:0')}, {'boxes': tensor([[240.0000, 250.3111, 438.0000, 480.7111],\n",
      "        [178.4000, 249.6000, 238.0000, 364.0889],\n",
      "        [147.2000, 249.6000, 191.2000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([16090], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[138.4000, 163.2000, 413.6000, 315.7333],\n",
      "        [  0.8000, 221.8667, 503.2000, 452.2667],\n",
      "        [189.6000, 123.7333, 355.2000, 227.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7], device='cuda:0'), 'image_id': tensor([23120], device='cuda:0')}, {'boxes': tensor([[ 87.0400, 129.7067, 440.3200, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3412], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[104.5333, 105.2444, 396.8000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([19000], device='cuda:0')}, {'boxes': tensor([[ 44.5886,  54.2720, 508.9249, 508.9280]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8121], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 58.0267,  40.9600, 510.2933, 509.4400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3774], device='cuda:0')}, {'boxes': tensor([[  2.0480,   1.5375, 251.9040, 508.9249],\n",
      "        [187.3920, 139.9159, 334.8480, 327.4955]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([11480], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  7.1680,   5.1200, 509.9520, 507.9040]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4540], device='cuda:0')}, {'boxes': tensor([[ 80.8000,  98.8445, 472.0000, 399.6444],\n",
      "        [ 50.4000, 199.8222, 103.6000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([16515], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[233.0667, 256.0000, 299.2000, 280.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([21524], device='cuda:0')}, {'boxes': tensor([[252.8000, 122.3111, 340.8000, 278.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14562], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 118.3904, 147.4560, 305.9700],\n",
      "        [ 72.7040,  24.6006, 419.8400, 479.7117]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([12769], device='cuda:0')}, {'boxes': tensor([[132.2282, 247.8080, 438.1982, 453.6320]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10940], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.3653, 451.5840, 415.0613]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8650], device='cuda:0')}, {'boxes': tensor([[133.8027, 329.7280, 324.9493, 466.9440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6507], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  7.8083,   2.0480, 512.0000, 508.9280]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([6154], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([31796], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[232.8000, 329.2444, 313.2000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26890], device='cuda:0')}, {'boxes': tensor([[227.6000, 314.3111, 282.4000, 499.9111],\n",
      "        [207.6000, 171.3778, 241.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([22252], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[126.8000,  93.1556, 338.0000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([30048], device='cuda:0')}, {'boxes': tensor([[ 48.8000, 206.9333, 335.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([28367], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 52.0214,  68.6080, 446.2888, 484.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4972], device='cuda:0')}, {'boxes': tensor([[130.4000, 163.2000, 476.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([22304], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 27.2000, 117.3333, 364.4000, 510.5778],\n",
      "        [351.6000, 128.7111, 511.6000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([22426], device='cuda:0')}, {'boxes': tensor([[122.8800, 119.9279, 389.1200, 452.0360],\n",
      "        [ 20.4800, 115.3153,  99.3280, 287.5195]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([11634], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[149.3333,  11.3778, 358.4000, 345.1259]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([25118], device='cuda:0')}, {'boxes': tensor([[  0.8000,  90.3111, 306.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27523], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[240.0000, 275.2000, 497.2000, 510.5778],\n",
      "        [  0.8000, 239.6444, 175.2000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15790], device='cuda:0')}, {'boxes': tensor([[154.5482, 194.8445, 302.4593, 301.5111],\n",
      "        [ 29.3926, 149.3333, 162.1333, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 10], device='cuda:0'), 'image_id': tensor([32926], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.5706, 512.0000, 507.2883]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([11001], device='cuda:0')}, {'boxes': tensor([[195.2000, 285.8667, 321.2000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([32137], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 19.4560, 109.2683, 423.9360, 441.7561]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10490], device='cuda:0')}, {'boxes': tensor([[189.2000,   0.7111, 408.8000, 509.8667],\n",
      "        [466.4000, 118.0444, 509.6000, 495.6444],\n",
      "        [238.8000, 206.9333, 298.4000, 492.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([28697], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[280.8000, 173.5111, 393.2000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([27684], device='cuda:0')}, {'boxes': tensor([[ 92.1600,  72.3627, 433.1520, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1966], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[120.8320, 178.8587, 265.2160, 342.6987]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8707], device='cuda:0')}, {'boxes': tensor([[231.6190, 115.7120, 406.3492, 292.8640]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1307], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([11179], device='cuda:0')}, {'boxes': tensor([[237.8667, 263.1111, 363.7333, 366.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([27559], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[278.5280, 264.8747, 380.9280, 367.2747]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([12323], device='cuda:0')}, {'boxes': tensor([[230.0000,   2.8445, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([16003], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.1333,  89.6000, 274.1333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([26721], device='cuda:0')}, {'boxes': tensor([[ 77.8240,  59.7844, 380.9280, 441.4850]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5993], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[165.5467, 195.6978, 392.5333, 380.0178]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4345], device='cuda:0')}, {'boxes': tensor([[103.4240,  31.4027, 326.6560, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([7261], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[240.8000, 151.4667, 314.4000, 220.8000],\n",
      "        [228.0000, 199.4667, 256.8000, 234.6667],\n",
      "        [252.8000, 215.4667, 277.6000, 240.0000],\n",
      "        [327.2000, 219.7333, 391.2000, 253.8667],\n",
      "        [321.6000, 200.5333, 368.0000, 231.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6, 7], device='cuda:0'), 'image_id': tensor([19509], device='cuda:0')}, {'boxes': tensor([[ 85.6000,  55.4667, 354.4000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([19634], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[254.9760, 206.0300, 322.5600, 289.0571],\n",
      "        [306.1760, 209.1051, 353.2800, 265.9940],\n",
      "        [187.3920, 395.1472, 311.2960, 504.3123],\n",
      "        [224.2560, 264.4565, 260.0960, 344.4084],\n",
      "        [273.4080, 329.0330, 353.2800, 492.0120],\n",
      "        [318.4640, 226.0180, 338.9440, 292.1321],\n",
      "        [370.6880, 261.3814, 441.3440, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([12811], device='cuda:0')}, {'boxes': tensor([[  6.1440,  40.3728, 105.4720, 190.8531],\n",
      "        [ 19.4560, 179.8423,  70.6560, 236.7312],\n",
      "        [304.1280,  12.8459, 406.5280, 126.6237]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 4], device='cuda:0'), 'image_id': tensor([11794], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[141.6000, 138.6667, 248.8000, 265.6000],\n",
      "        [310.4000,  82.1333, 455.2000, 180.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([19503], device='cuda:0')}, {'boxes': tensor([[ 88.5933,  97.6842, 306.0494, 496.8421]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([305], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[206.9333, 277.3333, 407.4667, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([29482], device='cuda:0')}, {'boxes': tensor([[232.4480, 244.3947, 386.0480, 415.0613]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4119], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[221.2000, 202.6667, 285.2000, 285.8667],\n",
      "        [295.2000,   1.4222, 512.0000, 265.9556],\n",
      "        [371.6000, 258.8445, 414.4000, 302.2222],\n",
      "        [181.6000, 249.6000, 233.6000, 297.2444],\n",
      "        [121.6000, 270.2222, 154.8000, 295.8222],\n",
      "        [  1.6000, 242.4889,  24.0000, 277.3333],\n",
      "        [ 56.4000, 267.3778,  73.2000, 291.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([26710], device='cuda:0')}, {'boxes': tensor([[ 97.2000, 258.6667, 160.4000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13587], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 97.2800, 146.0907, 419.8400, 479.2320],\n",
      "        [465.9200, 185.6853, 510.9760, 353.6213]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8537], device='cuda:0')}, {'boxes': tensor([[  0.0000,   1.3653, 510.9760, 457.3867]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4723], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 66.5600,   1.3653, 484.3520, 354.9867]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5659], device='cuda:0')}, {'boxes': tensor([[ 32.7680,  72.3627, 465.9200, 374.1013]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4142], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.4800, 227.2585, 232.4480, 346.2350],\n",
      "        [329.7280, 271.3734, 448.5120, 352.9191]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([12359], device='cuda:0')}, {'boxes': tensor([[186.4000, 258.8445, 291.2000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([22611], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 83.2000,  32.7111, 347.2000, 260.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([29206], device='cuda:0')}, {'boxes': tensor([[128.0000, 251.1698, 160.8000, 310.3396],\n",
      "        [144.0000, 117.1321, 305.6000, 288.6038]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([19994], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[103.2000,   2.1333, 328.8000, 477.8667],\n",
      "        [  1.2000,  17.7778,  45.2000, 380.4444],\n",
      "        [214.4000,  11.3778, 273.2000, 292.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([28710], device='cuda:0')}, {'boxes': tensor([[ 98.8000,   0.0000, 512.0000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32001], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[169.6000, 166.4000, 440.5333, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([25046], device='cuda:0')}, {'boxes': tensor([[142.3360,  21.5255, 355.3280, 276.7568]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([7286], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 92.4000,  76.8000, 455.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([19143], device='cuda:0')}, {'boxes': tensor([[348.1600, 184.3200, 466.9440, 423.2533],\n",
      "        [  1.0240, 147.4560, 215.0400, 410.9653],\n",
      "        [  1.0240,   0.0000, 133.1200, 375.4667],\n",
      "        [175.1040,   1.3653, 418.8160, 415.0613]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([8522], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[170.6667,   3.7647, 302.9333, 318.1176]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([30080], device='cuda:0')}, {'boxes': tensor([[ 85.3333, 227.5556, 185.6000, 355.5555],\n",
      "        [362.6667, 254.5778, 416.0000, 359.8222],\n",
      "        [228.2667, 250.3111, 285.8667, 362.6667],\n",
      "        [274.1333, 275.9111, 344.5333, 358.4000],\n",
      "        [273.0667, 234.6667, 324.2667, 260.2667],\n",
      "        [275.2000, 248.8889, 307.2000, 270.2222],\n",
      "        [245.3333, 233.2444, 268.8000, 264.5333],\n",
      "        [221.8667, 238.9333, 246.4000, 267.3778],\n",
      "        [  4.2667, 234.6667,  76.8000, 265.9556],\n",
      "        [389.3333, 214.7556, 450.1333, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([26202], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[193.0667,  59.7333, 408.5333, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([30489], device='cuda:0')}, {'boxes': tensor([[ 64.8000,  59.0222, 222.8000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([25153], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0364,   2.0480, 467.4332, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6425], device='cuda:0')}, {'boxes': tensor([[322.0000, 268.0889, 363.2000, 292.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([30313], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[180.8000, 138.6667, 253.2000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32776], device='cuda:0')}, {'boxes': tensor([[  0.8000, 267.3778, 174.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26114], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[103.5378,  27.0222, 344.7467, 433.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([27678], device='cuda:0')}, {'boxes': tensor([[ 96.8000, 188.4444, 216.0000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([16232], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[195.6000,  73.9556, 274.8000, 202.6667],\n",
      "        [395.6000, 204.0889, 435.2000, 265.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([29508], device='cuda:0')}, {'boxes': tensor([[ 15.3600,   0.0000, 509.9520, 508.9280]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5056], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.9588, 329.9556, 113.1386, 456.5333],\n",
      "        [ 43.1461, 402.4889, 162.9962, 509.1555],\n",
      "        [392.1498, 302.9333, 512.0000, 507.7333],\n",
      "        [207.1011, 113.7778, 309.6929, 325.6889],\n",
      "        [139.9850, 113.7778, 242.5768, 297.2444],\n",
      "        [137.1086, 455.1111, 266.5468, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([20649], device='cuda:0')}, {'boxes': tensor([[184.1096,  63.3905, 427.8356, 208.4572],\n",
      "        [  3.5068, 192.6095, 434.8493, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([8860], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[441.3440, 181.4294, 510.9760, 367.4715],\n",
      "        [280.5760, 290.5946, 401.4080, 505.8499]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([13121], device='cuda:0')}, {'boxes': tensor([[ 82.9440,   1.5375, 370.6880, 450.4985]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4861], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 42.4000, 145.7778, 512.0000, 415.2889],\n",
      "        [285.6000,  87.4667, 411.6000, 300.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([32529], device='cuda:0')}, {'boxes': tensor([[194.0000,  36.9778, 512.0000, 339.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([25077], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[323.6000, 105.9556, 442.4000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([26777], device='cuda:0')}, {'boxes': tensor([[171.2000, 388.9778, 218.8000, 462.2222],\n",
      "        [268.0000, 391.8222, 287.6000, 467.9111],\n",
      "        [312.4000, 388.9778, 358.0000, 467.2000],\n",
      "        [369.6000, 403.2000, 431.2000, 475.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([28801], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 61.2000,  12.8000, 450.4000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21457], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([31772], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,  59.7844, 335.8720, 510.4671]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7733], device='cuda:0')}, {'boxes': tensor([[ 43.0080, 192.5120, 507.9040, 359.0827]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11166], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[290.8160, 190.6547, 486.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1613], device='cuda:0')}, {'boxes': tensor([[  4.0960,  69.2932, 481.2800, 454.2556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11808], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 47.6637,   0.0000, 508.9249, 498.6880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8400], device='cuda:0')}, {'boxes': tensor([[ 61.6000,   0.7111, 304.4000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([21241], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000, 119.4667, 262.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([29458], device='cuda:0')}, {'boxes': tensor([[ 14.3360, 158.3787, 464.8960, 412.3307]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([205], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "Epoch 1/3 | Batch Number: 3972 | LR: 0.00030 | Train_loss: 77097838639.69 | Valid_loss: 7272860.77 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 57.3440, 182.2720, 354.9867, 396.2880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10558], device='cuda:0')}, {'boxes': tensor([[202.8000, 219.7333, 254.0000, 288.0000],\n",
      "        [296.0000, 219.7333, 346.8000, 288.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([16643], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[105.3333,  12.3259, 345.6000, 275.4370]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([13890], device='cuda:0')}, {'boxes': tensor([[ 39.9360,   1.3333, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6343], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[142.3360,   0.0000, 512.0000, 479.6145]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2488], device='cuda:0')}, {'boxes': tensor([[ 52.2763,  32.7680, 456.6486, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10514], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "Epoch 1/3 | Batch Number: 4303 | LR: 0.00029 | Train_loss: 4280759859.05 | Valid_loss: 46110665.20 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 4634 | LR: 0.00029 | Train_loss: 57398571.18 | Valid_loss: 12920216.00 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[153.2000,  34.8445, 224.8000, 285.8667],\n",
      "        [241.2000, 225.4222, 336.0000, 497.0667],\n",
      "        [323.2000, 214.0444, 395.6000, 409.6000],\n",
      "        [203.6000, 406.0444, 230.8000, 512.0000],\n",
      "        [120.8000, 328.5333, 182.4000, 502.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([32016], device='cuda:0')}, {'boxes': tensor([[120.8000, 155.0222, 255.2000, 234.6667],\n",
      "        [294.0000, 179.2000, 444.4000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([22575], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,  99.6693, 510.9760, 506.5387]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10621], device='cuda:0')}, {'boxes': tensor([[ 51.8827, 122.8800, 330.4107, 427.0080]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13232], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[262.4000, 244.6222, 371.2000, 351.2889],\n",
      "        [ 44.0000, 208.3556, 142.0000, 364.0889],\n",
      "        [472.8000, 231.1111, 511.2000, 339.9111],\n",
      "        [124.4000, 196.9778, 209.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([28808], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([25475], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "Epoch 1/3 | Batch Number: 4965 | LR: 0.00029 | Train_loss: 175504891.82 | Valid_loss: 4294330.41 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 5296 | LR: 0.00029 | Train_loss: 19831236.94 | Valid_loss: 3165886.57 | Valid mAP: 0.05% | Valid Missed Images 2199 / 2201\n",
      "Epoch 1/3 | Batch Number: 5627 | LR: 0.00029 | Train_loss: 1711866958.71 | Valid_loss: 15410958.68 | Valid mAP: 0.32% | Valid Missed Images 2191 / 2201\n",
      "Epoch 1/3 | Batch Number: 5958 | LR: 0.00029 | Train_loss: 11139577.37 | Valid_loss: 2844124.71 | Valid mAP: 0.05% | Valid Missed Images 2200 / 2201\n",
      "Epoch 1/3 | Batch Number: 6289 | LR: 0.00029 | Train_loss: 2088479871.10 | Valid_loss: 4360254.96 | Valid mAP: 0.09% | Valid Missed Images 2198 / 2201\n",
      "Epoch 1/3 | Batch Number: 6620 | LR: 0.00029 | Train_loss: 16585416.44 | Valid_loss: 1542908.90 | Valid mAP: 1.39% | Valid Missed Images 2137 / 2201\n",
      "Epoch 1/3 | Batch Number: 6951 | LR: 0.00029 | Train_loss: 10425956.53 | Valid_loss: 812691.70 | Valid mAP: 0.18% | Valid Missed Images 2185 / 2201\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[275.2000, 123.7333, 374.8000, 339.9111],\n",
      "        [207.6000,  51.9111, 268.0000, 115.9111],\n",
      "        [ 69.6000, 150.0444, 198.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26, 26], device='cuda:0'), 'image_id': tensor([25102], device='cuda:0')}, {'boxes': tensor([[134.8000, 110.9333, 193.2000, 225.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18104], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 41.0667, 216.1778, 201.6000, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([27198], device='cuda:0')}, {'boxes': tensor([[134.8000, 226.8445, 208.0000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18153], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[102.0000, 229.6889, 190.8000, 310.0444],\n",
      "        [401.2000, 249.6000, 511.6000, 306.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([24609], device='cuda:0')}, {'boxes': tensor([[ 60.8000, 337.0667, 221.8667, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([20190], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000, 131.5555, 313.6000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([25341], device='cuda:0')}, {'boxes': tensor([[265.6000, 160.7111, 295.2000, 227.5556],\n",
      "        [467.2000, 157.8667, 488.0000, 207.6444],\n",
      "        [ 51.2000, 273.0667, 156.0000, 509.1555],\n",
      "        [436.0000, 147.9111, 478.4000, 193.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 17, 18], device='cuda:0'), 'image_id': tensor([29574], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   4.5851, 510.9760, 430.9970]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([457], device='cuda:0')}, {'boxes': tensor([[278.8000, 218.3111, 512.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([18577], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 51.2000,   7.2113, 486.4000, 504.7887]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8479], device='cuda:0')}, {'boxes': tensor([[ 68.6080,  90.1120, 509.9520, 417.7920]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([12207], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 55.2960, 214.9305, 435.2000, 309.3904]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3074], device='cuda:0')}, {'boxes': tensor([[ 26.6240, 226.0180, 416.7680, 428.9730]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([11279], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[166.9120,  93.7898, 510.9760, 302.8949]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1388], device='cuda:0')}, {'boxes': tensor([[ 94.8000, 270.2222, 511.6000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([18473], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[116.7360,   1.5375, 507.9040, 313.6577],\n",
      "        [ 47.1040, 319.8078, 112.6400, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 23], device='cuda:0'), 'image_id': tensor([1793], device='cuda:0')}, {'boxes': tensor([[145.4080, 113.7778, 379.9040, 372.0841]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1527], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 88.3451,  65.0159, 481.8824, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7504], device='cuda:0')}, {'boxes': tensor([[312.8000, 230.4000, 512.0000, 346.6667],\n",
      "        [422.4000, 115.2000, 497.6000, 185.6000],\n",
      "        [296.8000,  92.8000, 415.2000, 153.6000],\n",
      "        [114.4000, 156.8000, 327.2000, 260.2667],\n",
      "        [ 14.4000, 205.8667, 242.4000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8, 8, 8], device='cuda:0'), 'image_id': tensor([14348], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[233.6000,  44.0889, 298.8000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([31897], device='cuda:0')}, {'boxes': tensor([[247.4667, 163.5555, 337.0667, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31052], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[157.2000,  63.2889, 304.4000, 192.7111],\n",
      "        [  0.0000, 109.5111, 151.6000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12,  7], device='cuda:0'), 'image_id': tensor([31927], device='cuda:0')}, {'boxes': tensor([[158.8000, 203.3778, 375.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([15497], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[154.6667, 182.0444, 510.9333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([25209], device='cuda:0')}, {'boxes': tensor([[307.2000,  51.8827, 498.6880, 148.8213],\n",
      "        [113.6640,  62.8053, 197.6320, 120.1493],\n",
      "        [214.0160,  62.8053, 348.1600, 121.5147],\n",
      "        [  2.0480,  69.6320,  24.5760, 106.4960]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([10990], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[294.8000, 257.4222, 374.8000, 418.1333],\n",
      "        [217.2000, 270.2222, 329.6000, 431.6444],\n",
      "        [220.4000, 260.9778, 275.2000, 389.6889],\n",
      "        [297.6000, 237.5111, 356.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([16228], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  24.8889, 481.6000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([32458], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 51.2000,   0.0000, 512.0000, 344.6519]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21844], device='cuda:0')}, {'boxes': tensor([[208.4000, 352.7111, 246.4000, 397.5111],\n",
      "        [173.6000, 130.8445, 213.6000, 176.3556],\n",
      "        [227.2000, 140.8000, 270.4000, 183.4667],\n",
      "        [291.6000, 152.1778, 330.8000, 197.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([22206], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 21.5040, 195.2427, 512.0000, 393.2160]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1074], device='cuda:0')}, {'boxes': tensor([[319.7333, 112.3556, 352.8000, 164.5037],\n",
      "        [349.3333, 187.2592, 366.9333, 210.0148]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 5], device='cuda:0'), 'image_id': tensor([21629], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[312.8000, 215.4667, 324.8000, 238.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([26848], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([26317], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[267.7333,  96.7111, 357.3333, 167.8222],\n",
      "        [285.8667, 102.4000, 350.9333, 213.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 10], device='cuda:0'), 'image_id': tensor([22629], device='cuda:0')}, {'boxes': tensor([[221.6000, 103.8222, 291.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20888], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[109.6000, 187.7333, 139.6000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([24442], device='cuda:0')}, {'boxes': tensor([[ 58.3680, 188.1446, 486.4000, 428.7229]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9130], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[173.0560,  78.4144, 289.7920, 390.5345]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5485], device='cuda:0')}, {'boxes': tensor([[259.0720,  90.6812, 510.9760, 354.3542]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([11727], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 80.8960, 178.8587, 441.3440, 421.8880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1907], device='cuda:0')}, {'boxes': tensor([[232.3361, 215.0400, 325.5574, 304.1280],\n",
      "        [ 74.5770,  29.6960, 480.4482, 244.7360]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 15], device='cuda:0'), 'image_id': tensor([12704], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 69.6000, 115.2000, 206.4000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([24294], device='cuda:0')}, {'boxes': tensor([[111.6000,   1.4222, 470.4000, 285.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([31136], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 27.6480, 101.4775, 491.5200, 507.3874]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([181], device='cuda:0')}, {'boxes': tensor([[  0.0000,  74.0367, 420.8640, 503.6578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1175], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[230.4000, 190.5778, 468.8000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18797], device='cuda:0')}, {'boxes': tensor([[156.8000, 296.7704, 324.2667, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([13877], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.6000,   0.0000, 118.4000, 489.9556],\n",
      "        [433.2000,  85.3333, 512.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([19375], device='cuda:0')}, {'boxes': tensor([[ 20.8000,  78.2222, 507.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([26453], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.4000, 204.8000, 511.6000, 509.1555],\n",
      "        [206.4000,  85.3333, 215.6000, 114.4889],\n",
      "        [249.6000,  86.7556, 273.2000, 120.8889],\n",
      "        [326.4000,  73.2444, 402.0000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19,  7,  7], device='cuda:0'), 'image_id': tensor([30031], device='cuda:0')}, {'boxes': tensor([[  1.0240,  68.9820, 481.2800, 412.3593]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([12345], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[117.6000, 188.4444, 267.6000, 434.4889],\n",
      "        [ 14.8000, 127.2889,  76.8000, 175.6444],\n",
      "        [134.4000, 114.4889, 158.0000, 167.1111],\n",
      "        [  0.0000, 169.2444,  73.2000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 7, 7, 7], device='cuda:0'), 'image_id': tensor([14478], device='cuda:0')}, {'boxes': tensor([[ 45.0560, 182.9547, 468.9920, 394.5813]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9300], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000,  73.2444, 401.2000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([25998], device='cuda:0')}, {'boxes': tensor([[  0.0000,  71.6084, 510.2345, 469.0350]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2875], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 72.8000,  44.0889, 509.6000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27100], device='cuda:0')}, {'boxes': tensor([[184.0000, 248.8889, 372.4000, 326.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17096], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 49.1520,  31.1436, 492.5440, 470.8905]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([69], device='cuda:0')}, {'boxes': tensor([[ 21.5040,  77.8240, 490.4960, 386.3893]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([12679], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 25.2000, 113.0667, 182.4000, 306.4889],\n",
      "        [223.2000, 128.7111, 509.6000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21, 21], device='cuda:0'), 'image_id': tensor([15896], device='cuda:0')}, {'boxes': tensor([[138.4000,   3.5555, 293.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([24948], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.5329, 329.7280, 458.3473]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([7919], device='cuda:0')}, {'boxes': tensor([[313.6000, 147.9111, 512.0000, 371.2000],\n",
      "        [134.0000,  56.8889, 240.4000, 361.2444],\n",
      "        [ 67.6000, 116.6222,  99.6000, 186.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30], device='cuda:0'), 'image_id': tensor([23363], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 98.3040, 180.2240, 380.9280, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5534], device='cuda:0')}, {'boxes': tensor([[188.8000, 214.5251, 324.0000, 429.0503],\n",
      "        [146.4000,   0.0000, 280.8000, 400.4469]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([25790], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[230.4000, 298.6667, 308.2667, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([18180], device='cuda:0')}, {'boxes': tensor([[ 50.1760,  16.9129, 473.0880, 498.1622]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([13330], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000,   0.0000, 506.8800, 413.0133]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10321], device='cuda:0')}, {'boxes': tensor([[201.7280, 219.6496, 350.2080, 372.7855]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5553], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[132.0960,  39.5947, 331.7760, 371.3707],\n",
      "        [109.5680, 195.2427, 261.1200, 413.6960]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 23], device='cuda:0'), 'image_id': tensor([3047], device='cuda:0')}, {'boxes': tensor([[ 36.8000,   1.4222, 312.0000, 339.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([21005], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[184.8000,  95.2889, 288.2667, 355.0815]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14014], device='cuda:0')}, {'boxes': tensor([[206.8480,  30.4762, 436.2240, 460.1905]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5308], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.0480, 289.4507, 233.4720, 469.6747],\n",
      "        [ 54.2720,  95.5733, 444.4160, 360.4480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8387], device='cuda:0')}, {'boxes': tensor([[  0.0000,  14.7126, 509.0743, 510.0383]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3338], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[105.6000, 149.3333, 427.2000, 339.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([25351], device='cuda:0')}, {'boxes': tensor([[162.8160, 168.6227, 360.4480, 332.6467]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8567], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8828,   1.3230, 405.1862, 408.8062]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7483], device='cuda:0')}, {'boxes': tensor([[ 69.6000,  13.5111, 480.4000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([16626], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[251.2000, 155.0222, 338.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([24426], device='cuda:0')}, {'boxes': tensor([[136.8000,  89.6000, 346.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17518], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[236.0000, 152.1778, 410.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21496], device='cuda:0')}, {'boxes': tensor([[ 11.2640,   1.3653, 476.1600, 365.9093],\n",
      "        [  0.0000,  95.5733, 153.6000, 356.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([9781], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[359.0827, 300.0320, 416.4267, 377.8560]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10918], device='cuda:0')}, {'boxes': tensor([[248.0000,  93.3926, 257.0667, 111.4074],\n",
      "        [447.2000,   5.2148, 512.0000, 363.6148]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15211], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[389.0667, 109.9852, 482.9333, 471.2296]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([21964], device='cuda:0')}, {'boxes': tensor([[155.2000, 221.1555, 219.2000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18013], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[248.8000,   4.9778, 434.0000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([20268], device='cuda:0')}, {'boxes': tensor([[287.2000, 318.5778, 358.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([19448], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 51.2000,  51.2000, 478.4000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([31225], device='cuda:0')}, {'boxes': tensor([[114.6880,  99.8400, 363.5200, 349.4400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([5313], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[295.6000, 121.6000, 499.2000, 510.5778],\n",
      "        [115.6000,  71.1111, 378.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14, 14], device='cuda:0'), 'image_id': tensor([16215], device='cuda:0')}, {'boxes': tensor([[362.4000,  23.4667, 470.4000, 192.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([20280], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[159.8694,  83.9111, 394.9714, 382.5778],\n",
      "        [  4.1796, 125.1555, 225.6980, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([17555], device='cuda:0')}, {'boxes': tensor([[  2.0480,   8.6050, 501.7600, 497.6583]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11205], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[177.0667, 219.0222, 509.8667, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([25681], device='cuda:0')}, {'boxes': tensor([[113.7778,  11.3778, 439.5959, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4215], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[135.8614, 155.0222, 227.7795, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([25964], device='cuda:0')}, {'boxes': tensor([[242.6880,  40.9600, 399.3600, 408.2347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8692], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.3653, 382.9760, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([4009], device='cuda:0')}, {'boxes': tensor([[184.8000, 118.0444, 308.8000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([23323], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[272.0000, 147.9111, 370.4000, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([19761], device='cuda:0')}, {'boxes': tensor([[252.4000, 164.9778, 310.0000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([31882], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[170.6667,  93.8667, 310.4000, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([25321], device='cuda:0')}, {'boxes': tensor([[190.4640, 204.8000, 369.6640, 450.5600]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4905], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[169.6000, 172.8000, 272.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([27244], device='cuda:0')}, {'boxes': tensor([[296.8000,  95.2889, 411.2000, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18718], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[106.4960, 470.4865, 146.4320, 507.3874]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([11696], device='cuda:0')}, {'boxes': tensor([[460.8000, 389.1200, 510.9760, 427.3493],\n",
      "        [321.5360, 412.3307, 510.9760, 510.6347],\n",
      "        [330.7520, 385.0240, 462.8480, 456.0213],\n",
      "        [ 18.4320, 393.2160,  39.9360, 484.6933],\n",
      "        [  2.0480, 408.2347,  29.6960, 469.6747]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([13159], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[361.6000, 136.5333, 384.8000, 213.3333],\n",
      "        [358.4000, 164.9778, 392.0000, 250.3111],\n",
      "        [394.4000, 167.8222, 412.8000, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5], device='cuda:0'), 'image_id': tensor([17711], device='cuda:0')}, {'boxes': tensor([[ 43.2000,   0.0000, 392.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([15852], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[417.6000, 149.3333, 512.0000, 307.2000],\n",
      "        [319.2000, 155.0222, 401.6000, 288.7111],\n",
      "        [141.6000, 159.2889, 244.0000, 298.6667],\n",
      "        [ 48.0000, 156.4445, 112.0000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([18584], device='cuda:0')}, {'boxes': tensor([[204.8000, 233.2444, 256.8000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([20984], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[180.2240,  95.5733, 389.1200, 412.3307]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8851], device='cuda:0')}, {'boxes': tensor([[241.6000, 183.4667, 396.8000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([15811], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[130.4000, 138.6667, 324.4000, 393.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([16164], device='cuda:0')}, {'boxes': tensor([[215.6000,  51.9111, 321.6000, 172.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([19304], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[261.6000, 339.9111, 273.6000, 383.0518],\n",
      "        [292.2667, 317.1555, 305.0667, 367.8815]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([13931], device='cuda:0')}, {'boxes': tensor([[350.5694, 142.4832, 496.3388, 327.2416],\n",
      "        [ 69.8729, 189.4557, 185.5247, 335.0703]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([326], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[192.8000,   5.6889, 375.6000, 381.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([29419], device='cuda:0')}, {'boxes': tensor([[104.4480,  16.9129, 447.4880, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4045], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 63.4880,   1.4382, 512.0000, 509.1236]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8371], device='cuda:0')}, {'boxes': tensor([[296.8000,  86.0444, 398.4000, 488.5333],\n",
      "        [393.2000, 108.0889, 451.6000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([25612], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[111.7460,   2.3704, 455.1111, 507.2593]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10888], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 345.6000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([25986], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[182.0000,  57.6000, 332.0000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26886], device='cuda:0')}, {'boxes': tensor([[264.0000, 233.2444, 325.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([27235], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.5792,  68.4204, 423.7595, 392.0721]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8778], device='cuda:0')}, {'boxes': tensor([[114.0000, 297.9556, 249.2000, 510.5778],\n",
      "        [237.6000, 100.9778, 435.2000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21, 21], device='cuda:0'), 'image_id': tensor([24118], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  4.0960,   1.5375, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8615], device='cuda:0')}, {'boxes': tensor([[134.8000, 140.0889, 337.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([21006], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[246.4000, 197.6889, 302.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([28448], device='cuda:0')}, {'boxes': tensor([[ 10.6667,  10.6667, 384.0000, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8463], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[385.0667, 125.1556, 456.5333, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([18190], device='cuda:0')}, {'boxes': tensor([[183.6000, 145.7778, 205.6000, 206.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21521], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 144.9639, 415.7440, 328.4819]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([9885], device='cuda:0')}, {'boxes': tensor([[  9.2160, 223.4182, 438.2720, 347.5394]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10341], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 16.0000,  58.3111, 409.2000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14507], device='cuda:0')}, {'boxes': tensor([[236.5440, 118.6846, 346.1120, 380.8949]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5135], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[107.7333, 201.9556, 349.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([25195], device='cuda:0')}, {'boxes': tensor([[291.2000, 258.8445, 336.8000, 329.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([15061], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[140.2880,  75.0933, 483.3280, 480.5973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3172], device='cuda:0')}, {'boxes': tensor([[134.4000, 285.8667, 179.2000, 388.2667],\n",
      "        [324.8000, 145.0667, 440.0000, 237.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 12], device='cuda:0'), 'image_id': tensor([27150], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[242.3145, 142.2222, 449.2075, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([29751], device='cuda:0')}, {'boxes': tensor([[220.8914, 210.6951, 361.3257, 400.6482]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10029], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[252.8000,  86.2222, 340.0000, 328.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13553], device='cuda:0')}, {'boxes': tensor([[241.6640,   2.5536, 512.0000, 413.6858],\n",
      "        [  3.0720,   3.8304, 379.9040, 476.2494]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([8265], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "Epoch 1/3 | Batch Number: 7282 | LR: 0.00028 | Train_loss: 53008357531783296.00 | Valid_loss: 540961100637.38 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 7613 | LR: 0.00028 | Train_loss: 4474784430957.93 | Valid_loss: 121131619291.25 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[200.0000,  61.1555, 281.2000, 277.3333],\n",
      "        [302.4000,  93.1555, 369.2000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([22224], device='cuda:0')}, {'boxes': tensor([[262.0000, 140.8000, 454.0000, 426.6667],\n",
      "        [ 24.4000,   3.5555, 180.0000, 113.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21, 21], device='cuda:0'), 'image_id': tensor([24109], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-3eb0990dc925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 3e-4, weight_decay = 1e-2, print_times_per_epoch = 50,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-b1dbdd86237c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 3e-4, weight_decay = 1e-2, print_times_per_epoch = 50,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 207.0\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.0005\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "Epoch 1/3 | Batch Number: 207 | LR: 0.00050 | Train_loss: 89.26 | Valid_loss: 403.77 | Valid mAP: 43.28% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 414 | LR: 0.00050 | Train_loss: 72.38 | Valid_loss: 390.47 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 621 | LR: 0.00050 | Train_loss: 73.82 | Valid_loss: 394.81 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 828 | LR: 0.00050 | Train_loss: 91.56 | Valid_loss: 467.35 | Valid mAP: 14.05% | Valid Missed Images 0 / 2201\n",
      "Epoch 1/3 | Batch Number: 1035 | LR: 0.00050 | Train_loss: 92.95 | Valid_loss: 380.24 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 1242 | LR: 0.00050 | Train_loss: 81.99 | Valid_loss: 372.12 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 1449 | LR: 0.00050 | Train_loss: 67.11 | Valid_loss: 397.84 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 1656 | LR: 0.00050 | Train_loss: 69.16 | Valid_loss: 397.92 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 1863 | LR: 0.00050 | Train_loss: 72.09 | Valid_loss: 394.16 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 2070 | LR: 0.00050 | Train_loss: 67.80 | Valid_loss: 395.17 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 2277 | LR: 0.00050 | Train_loss: 74.83 | Valid_loss: 454.99 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 2484 | LR: 0.00050 | Train_loss: 496.18 | Valid_loss: 1077.05 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 2691 | LR: 0.00050 | Train_loss: 334.78 | Valid_loss: 519.10 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 2898 | LR: 0.00050 | Train_loss: 88.62 | Valid_loss: 454.99 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n",
      "Epoch 1/3 | Batch Number: 3105 | LR: 0.00050 | Train_loss: 88.29 | Valid_loss: 418.65 | Valid mAP: 0.00% | Valid Missed Images 2201 / 2201\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-eccc9c6aeaba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Will use Adamw and higher weight decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-3, print_times_per_epoch = 80,\n\u001b[0;32m----> 3\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV3\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-7fc3c0bd63cc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                         \u001b[0mvalid_loss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                         \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/anchor_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),\n\u001b[0;32m--> 147\u001b[0;31m                     torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0manchors_over_all_feature_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_grid_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Will use Adamw and higher weight decay\n",
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-3, print_times_per_epoch = 80,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 331.0\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    initial_lr: 0.0005\n",
      "    k: 6\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    step_counter: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/3 | Batch Number: 331 | LR: 0.00050 | Train_loss: 155.50 | Valid_loss: 455.95 | Valid mAP: 29.20% | Valid Missed Images 200 / 2201\n",
      "Epoch 1/3 | Batch Number: 662 | LR: 0.00050 | Train_loss: 122.84 | Valid_loss: 435.71 | Valid mAP: 23.32% | Valid Missed Images 131 / 2201\n",
      "Epoch 1/3 | Batch Number: 993 | LR: 0.00050 | Train_loss: 117.10 | Valid_loss: 409.04 | Valid mAP: 19.93% | Valid Missed Images 113 / 2201\n",
      "Epoch 1/3 | Batch Number: 1324 | LR: 0.00050 | Train_loss: 125.09 | Valid_loss: 451.03 | Valid mAP: 31.01% | Valid Missed Images 196 / 2201\n",
      "Epoch 1/3 | Batch Number: 1655 | LR: 0.00050 | Train_loss: 118.27 | Valid_loss: 434.58 | Valid mAP: 21.47% | Valid Missed Images 158 / 2201\n",
      "Epoch 1/3 | Batch Number: 1986 | LR: 0.00050 | Train_loss: 117.27 | Valid_loss: 425.81 | Valid mAP: 22.33% | Valid Missed Images 19 / 2201\n",
      "Epoch 1/3 | Batch Number: 2317 | LR: 0.00050 | Train_loss: 122.80 | Valid_loss: 421.53 | Valid mAP: 10.11% | Valid Missed Images 8 / 2201\n",
      "Epoch 1/3 | Batch Number: 2648 | LR: 0.00050 | Train_loss: 118.73 | Valid_loss: 408.01 | Valid mAP: 18.31% | Valid Missed Images 39 / 2201\n",
      "Epoch 1/3 | Batch Number: 2979 | LR: 0.00050 | Train_loss: 127.61 | Valid_loss: 437.36 | Valid mAP: 51.04% | Valid Missed Images 374 / 2201\n",
      "Epoch 1/3 | Batch Number: 3310 | LR: 0.00049 | Train_loss: 125.76 | Valid_loss: 412.12 | Valid mAP: 67.90% | Valid Missed Images 197 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[111.6125,  60.7256, 449.9931, 429.8419]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4653], device='cuda:0')}, {'boxes': tensor([[ 11.2640, 132.7407, 376.8320, 410.2896]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([598], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[3.7200e+01, 5.1911e+01, 1.7440e+02, 2.6596e+02],\n",
      "        [3.6760e+02, 6.9689e+01, 4.5000e+02, 3.0791e+02],\n",
      "        [2.7400e+02, 4.6933e+01, 4.1240e+02, 2.7307e+02],\n",
      "        [1.9480e+02, 4.1244e+01, 2.5840e+02, 2.7520e+02],\n",
      "        [8.5200e+01, 2.7022e+01, 1.6920e+02, 2.3040e+02],\n",
      "        [4.0000e-01, 4.7644e+01, 5.2000e+01, 2.2898e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([18382], device='cuda:0')}, {'boxes': tensor([[397.6000, 273.0667, 510.8000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17165], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 55.2000, 179.2000, 395.2000, 359.8222],\n",
      "        [412.8000,  44.0889, 510.8000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([23357], device='cuda:0')}, {'boxes': tensor([[218.4000,   1.4222, 328.8000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([24576], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 98.4000,  34.8444, 424.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([29302], device='cuda:0')}, {'boxes': tensor([[  0.8000,   0.0000, 448.0000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([20436], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 235.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([24953], device='cuda:0')}, {'boxes': tensor([[  1.0240, 132.7914, 293.8880, 344.9840]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([13385], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([30702], device='cuda:0')}, {'boxes': tensor([[251.6000, 176.3556, 299.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([31617], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[189.4400, 156.8074, 489.4720, 507.2483]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1517], device='cuda:0')}, {'boxes': tensor([[160.0000, 314.3111, 267.7333, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([24312], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[100.3520,  75.0933, 505.8560, 441.0027]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1182], device='cuda:0')}, {'boxes': tensor([[138.2400,  39.0737, 369.6640, 455.4105]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2809], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[158.7200, 180.9323, 304.6400, 311.8195]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5149], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 8.8889e-01, 4.3160e+02, 5.0667e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13575], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 54.0000,   2.8445, 509.6000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([31965], device='cuda:0')}, {'boxes': tensor([[238.0000, 118.7556, 384.0000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32160], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([17035], device='cuda:0')}, {'boxes': tensor([[201.0667,  72.0593, 296.5333, 186.3111],\n",
      "        [360.8000,  96.7111, 399.7333, 158.3407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([13913], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[330.6667,  92.4445, 434.1333, 265.9556],\n",
      "        [ 39.4667, 122.3111, 248.5333, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([29117], device='cuda:0')}, {'boxes': tensor([[103.2127,  55.4667, 217.8032, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([32628], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[236.8000, 280.1778, 326.8000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([32601], device='cuda:0')}, {'boxes': tensor([[233.2000, 207.6444, 346.0000, 355.5555],\n",
      "        [352.0000, 198.4000, 401.6000, 264.5333],\n",
      "        [418.0000, 177.7778, 448.4000, 226.1333],\n",
      "        [480.4000, 168.5333, 506.8000, 207.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([15439], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.8000,  32.0000, 278.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([28845], device='cuda:0')}, {'boxes': tensor([[358.4000, 281.6000, 376.4000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([28554], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[203.2000, 167.8222, 510.4000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([28273], device='cuda:0')}, {'boxes': tensor([[200.0000, 256.7111, 222.8000, 320.0000],\n",
      "        [249.2000,  98.1333, 294.8000, 241.0667],\n",
      "        [375.2000, 182.0444, 412.0000, 236.8000],\n",
      "        [430.8000,  44.8000, 458.4000, 116.6222],\n",
      "        [398.8000, 268.8000, 417.6000, 322.8445],\n",
      "        [446.8000, 248.1778, 482.4000, 298.6667],\n",
      "        [136.8000, 123.0222, 183.2000, 184.8889],\n",
      "        [ 58.4000, 447.2889,  74.0000, 470.0444],\n",
      "        [145.6000, 396.8000, 166.0000, 427.3778],\n",
      "        [178.0000, 409.6000, 192.0000, 445.1556],\n",
      "        [478.4000, 114.4889, 501.2000, 173.5111],\n",
      "        [ 30.0000,   4.2667,  64.4000,  56.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0'), 'image_id': tensor([25704], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[110.0000,  86.7556, 354.8000, 133.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([28517], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([18132], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[237.2000, 144.3556, 318.0000, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([32689], device='cuda:0')}, {'boxes': tensor([[135.3956, 221.8667, 188.8711, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([25397], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 92.4000,   0.0000, 322.8000, 213.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([28984], device='cuda:0')}, {'boxes': tensor([[101.3760, 287.9113, 257.0240, 428.3213]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10522], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[310.4000, 377.6000, 374.4000, 433.0667],\n",
      "        [378.0000, 354.8445, 500.8000, 481.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([26137], device='cuda:0')}, {'boxes': tensor([[279.2000, 264.8276, 300.8000, 288.3678],\n",
      "        [232.0000, 256.0000, 283.2000, 291.3103],\n",
      "        [ 54.4000, 267.7701, 110.4000, 306.0230]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7], device='cuda:0'), 'image_id': tensor([27805], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[148.0000,   0.0000, 512.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([24818], device='cuda:0')}, {'boxes': tensor([[306.4000, 180.6222, 345.6000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18158], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.8000, 221.8667,  99.2000, 362.6667],\n",
      "        [248.8000, 234.6667, 298.4000, 328.5333],\n",
      "        [336.0000, 216.1778, 398.4000, 348.4445],\n",
      "        [239.2000, 196.2667, 284.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([29220], device='cuda:0')}, {'boxes': tensor([[  0.0000, 197.6889, 508.2074, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27767], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[288.0000,  62.5778, 428.0000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18736], device='cuda:0')}, {'boxes': tensor([[137.6000, 163.5556, 512.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27052], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 98.8000,  50.4889, 416.0000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([16481], device='cuda:0')}, {'boxes': tensor([[229.6000, 198.6370, 320.5333, 292.5037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14041], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 88.4000,  76.0889, 402.8000, 438.7556],\n",
      "        [390.0000, 231.1111, 406.0000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([28003], device='cuda:0')}, {'boxes': tensor([[187.6000,  34.8444, 420.0000, 353.4222],\n",
      "        [459.6000, 153.6000, 510.0000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([32713], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([25484], device='cuda:0')}, {'boxes': tensor([[115.2000,   1.4222, 346.8000, 220.4445],\n",
      "        [221.2000, 401.0667, 296.8000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 27], device='cuda:0'), 'image_id': tensor([15742], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 30.7200, 119.3010, 409.6000, 447.3786]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4915], device='cuda:0')}, {'boxes': tensor([[230.7413, 126.9760, 333.1413, 271.3600]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10852], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   8.0593, 510.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14171], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.8445, 401.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26930], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 220.6897, 509.9520, 510.8966]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([12573], device='cuda:0')}, {'boxes': tensor([[ 27.6480,  58.7093, 438.2720, 480.5973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3365], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[157.6960, 153.7538, 512.0000, 508.9249]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3662], device='cuda:0')}, {'boxes': tensor([[140.4000, 281.6000, 399.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([17587], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[147.6923, 163.2000, 297.8462, 297.6000],\n",
      "        [248.6154, 156.8000, 285.5385, 179.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([20055], device='cuda:0')}, {'boxes': tensor([[1.8520e+02, 6.4711e+01, 3.1800e+02, 5.0631e+02],\n",
      "        [4.0000e-01, 2.8800e+02, 1.1080e+02, 4.1813e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([18295], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.1600, 238.9333, 278.5280, 378.1973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8216], device='cuda:0')}, {'boxes': tensor([[175.2000, 117.3333, 252.4000, 304.3556],\n",
      "        [289.2000, 381.1555, 328.4000, 433.7778],\n",
      "        [331.2000, 377.6000, 366.8000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18,  7,  7], device='cuda:0'), 'image_id': tensor([32879], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[192.0000,  17.0667, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4621], device='cuda:0')}, {'boxes': tensor([[ 58.3680,  15.3754, 494.5920, 493.5496]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4949], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,  81.0667, 446.4000, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([990], device='cuda:0')}, {'boxes': tensor([[259.8400,  22.1867, 454.4000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5980], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 52.0000, 112.3556, 224.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14573], device='cuda:0')}, {'boxes': tensor([[ 65.6000,  72.5333, 511.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17058], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.4800,  81.7349, 403.4560, 439.5181]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([742], device='cuda:0')}, {'boxes': tensor([[ 60.2353,  11.3778, 337.8824, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([18862], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[279.2000,  45.5111, 471.6000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20765], device='cuda:0')}, {'boxes': tensor([[  2.5600,  15.6507, 506.8800, 507.5284]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3918], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  6.4000, 102.4000, 254.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31572], device='cuda:0')}, {'boxes': tensor([[ 84.2667, 185.6000, 243.7333, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([23381], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  6.1440, 167.5916, 505.8560, 436.6607]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9329], device='cuda:0')}, {'boxes': tensor([[163.6000, 285.8667, 224.0000, 364.8000],\n",
      "        [147.6000, 325.6889, 173.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([16465], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[152.5656,  11.3778, 374.9495, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5086], device='cuda:0')}, {'boxes': tensor([[ 43.2000, 120.8889, 432.0000, 310.0444],\n",
      "        [416.0000, 174.9333, 499.2000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([19603], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[169.3013, 128.0000, 359.0827, 447.4880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10259], device='cuda:0')}, {'boxes': tensor([[227.6000, 324.9778, 266.4000, 370.4889],\n",
      "        [483.6000, 411.7333, 512.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7], device='cuda:0'), 'image_id': tensor([31547], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[272.0000,  71.1111, 511.2000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17435], device='cuda:0')}, {'boxes': tensor([[ 16.3840, 214.9834, 508.9280, 510.5856]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([635], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  3.4133,  54.3926, 382.2933, 282.6051]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([11025], device='cuda:0')}, {'boxes': tensor([[ 95.2000,   1.4222, 371.7333, 259.3185]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21898], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[195.6000, 152.8889, 240.4000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([30261], device='cuda:0')}, {'boxes': tensor([[115.7120,   5.4613, 419.8400, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6661], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[206.4000,  19.9111, 341.6000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17525], device='cuda:0')}, {'boxes': tensor([[  6.1501,   2.0480, 462.7988, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8600], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[125.9520, 147.2000, 512.0000, 360.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2117], device='cuda:0')}, {'boxes': tensor([[276.4800, 189.7813, 406.5280, 346.7947],\n",
      "        [105.4720, 182.9547, 274.4320, 341.3333],\n",
      "        [339.9680, 357.7173, 396.2880, 406.8693],\n",
      "        [ 77.8240, 346.7947, 106.4960, 397.3120],\n",
      "        [278.5280, 361.8133, 303.1040, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([7628], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 74.0766, 159.4514, 410.6894, 368.6400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11104], device='cuda:0')}, {'boxes': tensor([[195.2000, 238.9333, 274.1333, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([24178], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,  24.8889, 354.0000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([21209], device='cuda:0')}, {'boxes': tensor([[  1.0240,  41.2657, 512.0000, 510.4716]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1937], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 64.1707,  53.2480, 376.8320, 411.6480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10246], device='cuda:0')}, {'boxes': tensor([[141.4737,  73.7280, 386.6947, 484.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([53], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  7.1680,  50.1164, 463.8720, 501.1640]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2761], device='cuda:0')}, {'boxes': tensor([[218.4000, 105.2444, 333.6000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([22976], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.4000, 295.8222, 313.6000, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([25423], device='cuda:0')}, {'boxes': tensor([[ 31.7440,  23.6868, 509.9520, 497.4235]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([13260], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[280.4000, 356.2667, 319.6000, 506.3111],\n",
      "        [419.2000, 232.5333, 456.8000, 294.4000],\n",
      "        [386.4000,  68.9778, 409.2000, 135.1111],\n",
      "        [441.6000,   4.9778, 455.2000,  28.4444],\n",
      "        [215.2000, 341.3333, 250.0000, 386.8445],\n",
      "        [134.8000, 288.0000, 176.8000, 346.3111],\n",
      "        [134.4000, 209.7778, 158.4000, 269.5111],\n",
      "        [321.6000, 185.6000, 350.8000, 235.3778],\n",
      "        [109.6000, 375.4667, 153.2000, 420.9778],\n",
      "        [ 72.8000, 253.8667, 108.4000, 300.8000],\n",
      "        [ 43.2000, 387.5555,  88.0000, 430.2222],\n",
      "        [362.8000, 332.8000, 416.8000, 406.7556],\n",
      "        [489.2000, 329.9556, 511.2000, 398.9333],\n",
      "        [432.4000, 413.1555, 468.0000, 510.5778],\n",
      "        [466.0000, 201.9556, 500.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "       device='cuda:0'), 'image_id': tensor([25696], device='cuda:0')}, {'boxes': tensor([[219.2000, 283.0222, 252.0000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([31549], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 54.4900,  44.7229, 246.7470, 299.1807]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([298], device='cuda:0')}, {'boxes': tensor([[  0.0000,   8.1920, 473.0100, 494.5920]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8870], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[269.6000, 116.6222, 352.8000, 412.4444],\n",
      "        [111.2000, 104.5333, 240.0000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([19881], device='cuda:0')}, {'boxes': tensor([[118.0000, 198.4000, 376.0000, 505.6000],\n",
      "        [  0.0000,  16.3556, 509.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([16314], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[122.8000, 211.2000, 208.8000, 425.2444],\n",
      "        [279.2000, 238.2222, 361.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([25620], device='cuda:0')}, {'boxes': tensor([[245.2000, 327.1111, 292.8000, 401.7778],\n",
      "        [ 68.0000, 325.6889, 101.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([13672], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[187.3920,  24.6006, 395.2640, 373.6216]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4414], device='cuda:0')}, {'boxes': tensor([[242.8000, 163.5555, 320.8000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([31229], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.1333, 180.6222, 451.2000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([27735], device='cuda:0')}, {'boxes': tensor([[ 67.2000,  61.8667, 128.0000, 255.2889],\n",
      "        [230.8000, 204.8000, 248.8000, 238.9333],\n",
      "        [110.0000, 150.0444, 179.6000, 214.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29], device='cuda:0'), 'image_id': tensor([31200], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[106.3385, 103.0244, 403.6923, 390.2439]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3491], device='cuda:0')}, {'boxes': tensor([[123.6000, 119.4667, 348.4000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([29354], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[229.3760,  16.3840, 510.9760, 185.6853]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10055], device='cuda:0')}, {'boxes': tensor([[ 64.0000,  71.1111, 358.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([19650], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560,   6.8267, 452.6080, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10478], device='cuda:0')}, {'boxes': tensor([[145.8667, 356.5037, 167.2000, 394.4296],\n",
      "        [345.0667, 132.7407, 373.3333, 150.2815]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15308], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 508.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([17631], device='cuda:0')}, {'boxes': tensor([[ 20.0784,  64.0000, 421.6471, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([30082], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[428.8000, 141.5757, 509.8667, 269.5758],\n",
      "        [ 71.4667,  65.9394, 130.1333, 246.3030]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([23970], device='cuda:0')}, {'boxes': tensor([[160.7680,   1.5238, 512.0000, 451.0476]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4165], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 33.2000,   0.0000, 156.8000, 122.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([32469], device='cuda:0')}, {'boxes': tensor([[254.8000, 327.1111, 316.0000, 408.1778],\n",
      "        [ 61.2000, 322.1333,  99.6000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([13669], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 69.6320, 177.4933,  96.2560, 197.9733],\n",
      "        [  1.0240, 181.5893,  13.3120, 199.3387],\n",
      "        [118.7840,  81.9200, 397.3120, 330.4107]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7,  7, 26], device='cuda:0'), 'image_id': tensor([13126], device='cuda:0')}, {'boxes': tensor([[ 44.0320,  64.1707, 398.3360, 264.8747]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([9662], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[346.4000,  78.2222, 512.0000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([24375], device='cuda:0')}, {'boxes': tensor([[197.6320, 200.2149, 510.9760, 495.1881]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3410], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[171.6618, 211.9680, 477.6676, 438.2720],\n",
      "        [ 37.3178,  43.0080, 479.1603, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([5187], device='cuda:0')}, {'boxes': tensor([[348.0000, 251.7333, 363.2000, 270.2222],\n",
      "        [316.4000, 300.0889, 332.4000, 317.8667],\n",
      "        [295.2000, 325.6889, 309.6000, 343.4667],\n",
      "        [264.0000, 208.3556, 282.0000, 224.7111],\n",
      "        [248.4000, 266.6667, 263.6000, 285.1555],\n",
      "        [217.2000, 303.6444, 232.8000, 321.4222],\n",
      "        [195.6000, 173.5111, 210.8000, 189.8667],\n",
      "        [165.6000, 220.4444, 180.8000, 238.2222],\n",
      "        [143.2000, 254.5778, 157.6000, 272.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17750], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 42.8901,  72.0000, 404.7749, 452.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2434], device='cuda:0')}, {'boxes': tensor([[  1.0240,   5.4613, 512.0000, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4624], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.4587,  62.4640, 105.1307, 113.6640],\n",
      "        [116.0533,  89.0880, 173.3973, 149.5040],\n",
      "        [173.3973,  82.9440, 228.0107, 158.7200],\n",
      "        [191.1467, 195.5840, 229.3760, 215.0400],\n",
      "        [409.6000,  89.0880, 461.4827, 134.1440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([12436], device='cuda:0')}, {'boxes': tensor([[338.0000,  98.1333, 498.4000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([24126], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[165.6000, 226.1333, 234.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([23479], device='cuda:0')}, {'boxes': tensor([[422.4000, 311.4667, 511.2000, 418.1333],\n",
      "        [ 98.4000, 263.1111, 165.6000, 420.9778],\n",
      "        [  0.8000, 364.0889,  48.8000, 432.3556],\n",
      "        [360.0000, 287.2889, 430.4000, 371.2000],\n",
      "        [200.0000, 318.5778, 256.0000, 401.0667],\n",
      "        [221.6000, 283.0222, 245.6000, 329.9556],\n",
      "        [236.8000, 311.4667, 272.0000, 341.3333],\n",
      "        [276.8000, 308.6222, 308.0000, 354.1333],\n",
      "        [300.8000, 298.6667, 352.8000, 366.9333],\n",
      "        [276.8000, 354.1333, 329.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([20542], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[4.0000e-01, 5.6889e+01, 3.3960e+02, 4.2667e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14433], device='cuda:0')}, {'boxes': tensor([[ 43.2000, 123.0222, 220.4000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([25104], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[327.2000, 233.2444, 404.8000, 293.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14619], device='cuda:0')}, {'boxes': tensor([[ 66.5600,   0.0000, 424.9600, 510.7200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10169], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[117.7600,  90.1120, 423.6800, 407.5520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4087], device='cuda:0')}, {'boxes': tensor([[ 37.8880,  55.9787, 468.9920, 442.3680]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9449], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.5920,  46.2650, 435.2000, 354.6988]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([12222], device='cuda:0')}, {'boxes': tensor([[146.4320,  71.8596, 419.8400, 446.8772]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([243], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[320.0000, 202.6667, 338.8000, 220.4444],\n",
      "        [296.8000, 184.8889, 316.0000, 204.8000],\n",
      "        [277.2000, 171.3778, 296.0000, 189.1555],\n",
      "        [248.0000, 152.1778, 268.0000, 173.5111],\n",
      "        [218.8000, 133.6889, 239.2000, 157.8667],\n",
      "        [206.0000, 167.8222, 225.6000, 189.8667],\n",
      "        [196.4000, 197.6889, 214.8000, 216.8889],\n",
      "        [186.0000, 226.1333, 202.8000, 243.9111],\n",
      "        [176.8000, 250.3111, 194.4000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17867], device='cuda:0')}, {'boxes': tensor([[199.2000, 103.8222, 330.4000, 366.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([15950], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[146.4320, 165.2053, 297.9840, 402.7733]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6339], device='cuda:0')}, {'boxes': tensor([[  6.0000,  56.1778, 510.8000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26684], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 64.1707,   2.0480, 509.2693, 465.9200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8706], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 254.5778, 171.2000, 374.0444],\n",
      "        [120.8000, 261.6889, 140.8000, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([20303], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560, 263.1680, 431.4453, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6516], device='cuda:0')}, {'boxes': tensor([[ 27.3067,  11.2640, 501.0773, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([11819], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 16.3840,  30.7200, 506.8800, 480.2560]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4592], device='cuda:0')}, {'boxes': tensor([[219.1360, 116.8528, 510.9760, 456.6486]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([569], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.0480,   0.0000, 471.0400, 510.4716]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3280], device='cuda:0')}, {'boxes': tensor([[ 82.8000, 122.3111, 263.2000, 214.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([31091], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 99.3280,   2.3326, 403.4560, 439.6902]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8777], device='cuda:0')}, {'boxes': tensor([[  0.0000, 102.4000, 495.6160, 187.0507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10109], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([24370], device='cuda:0')}, {'boxes': tensor([[  1.0240,   0.0000, 433.1520, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4167], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 91.7333, 172.0889, 188.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([22004], device='cuda:0')}, {'boxes': tensor([[  1.0240, 262.1440, 106.4960, 430.0800],\n",
      "        [  1.0240, 116.0533, 217.0880, 319.4880],\n",
      "        [ 83.9680, 121.5147, 448.5120, 338.6027]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([7806], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000, 105.2444, 368.8000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26106], device='cuda:0')}, {'boxes': tensor([[116.1437,  47.2823, 481.0284, 470.1214]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6724], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 32.0000, 369.7778, 211.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([24166], device='cuda:0')}, {'boxes': tensor([[  2.0480,   5.7143, 338.9440, 508.5714]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5161], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[164.8640, 101.0347, 314.3680, 349.5253],\n",
      "        [269.3120, 116.0533, 422.9120, 364.5440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([12607], device='cuda:0')}, {'boxes': tensor([[233.6000, 135.1111, 245.6000, 150.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17174], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   5.1200, 372.0533, 496.6400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7678], device='cuda:0')}, {'boxes': tensor([[  3.2000, 219.0222, 243.2000, 452.2667],\n",
      "        [269.8667, 163.5556, 432.0000, 310.0444],\n",
      "        [376.5333, 265.9556, 473.6000, 351.2889],\n",
      "        [184.5333, 190.5778, 246.4000, 237.5111],\n",
      "        [  3.2000, 221.8667,  62.9333, 275.9111],\n",
      "        [423.4667, 196.2667, 485.3333, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([23185], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([15429], device='cuda:0')}, {'boxes': tensor([[309.2000, 184.1778, 412.0000, 316.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([17954], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[178.9919,  61.1556, 477.6585, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([23670], device='cuda:0')}, {'boxes': tensor([[216.0640, 128.3963, 424.9600, 408.9659],\n",
      "        [  4.0960, 112.5449,  52.2240, 399.4551],\n",
      "        [ 27.6480, 128.3963, 223.2320, 418.4768]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6], device='cuda:0'), 'image_id': tensor([9940], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([15401], device='cuda:0')}, {'boxes': tensor([[208.0000, 210.4889, 280.0000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20923], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[222.2703, 204.1905, 294.0540, 382.4762]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26450], device='cuda:0')}, {'boxes': tensor([[  0.8000, 179.2000, 438.4000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([17605], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 40.8000,  54.4000, 460.8000, 370.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2498], device='cuda:0')}, {'boxes': tensor([[152.5760, 155.6480, 371.7120, 391.8507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5728], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[233.4720, 143.3600, 299.0080, 187.0507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3502], device='cuda:0')}, {'boxes': tensor([[ 80.5926, 131.5556, 431.4074, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3434], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.8000,   4.7850, 368.0000, 425.8692]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2807], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([30524], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[265.6000, 115.9111, 307.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26221], device='cuda:0')}, {'boxes': tensor([[143.3600,   4.6126, 510.9760, 462.7988]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8102], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[118.4000,  82.4889, 478.9333, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([26387], device='cuda:0')}, {'boxes': tensor([[121.6000, 292.2667, 217.6000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([25904], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 33.2800, 143.6444, 362.6667, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([14406], device='cuda:0')}, {'boxes': tensor([[ 90.4000,  41.2444, 301.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18810], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.6006, 181.5458, 429.5977, 487.5219]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([9674], device='cuda:0')}, {'boxes': tensor([[105.9310, 110.9333, 355.6256, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([26365], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 84.9920, 107.8613, 422.9120, 376.8320]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([9936], device='cuda:0')}, {'boxes': tensor([[163.2000,   1.4222, 511.6000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([19114], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 34.2395,  94.0907, 449.8911, 499.7804]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10250], device='cuda:0')}, {'boxes': tensor([[  0.0000,  64.0000, 364.0000, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([24794], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.2815,  59.7333, 365.0370, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([30635], device='cuda:0')}, {'boxes': tensor([[142.4000,  24.8889, 431.2000, 285.8667],\n",
      "        [313.6000, 213.3333, 390.8000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32140], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[225.6000, 199.1111, 294.4000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18663], device='cuda:0')}, {'boxes': tensor([[215.0400,  13.7964, 291.8400, 311.1856]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8872], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[318.0000, 193.4222, 380.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([26280], device='cuda:0')}, {'boxes': tensor([[169.6000,  93.8667, 294.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26046], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[116.8000, 119.4667, 349.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([20720], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([20870], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 24.0000, 109.8667, 313.6000, 404.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([4023], device='cuda:0')}, {'boxes': tensor([[153.6000,  91.0222, 265.2000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([27105], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[107.6276, 120.8320, 216.7928, 211.9680],\n",
      "        [230.6306, 133.1200, 508.9249, 386.0480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([12969], device='cuda:0')}, {'boxes': tensor([[111.6000,  83.2000, 291.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([14861], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   2.7307, 510.9760, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3231], device='cuda:0')}, {'boxes': tensor([[299.2000, 125.1555, 358.4000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([28833], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[104.4480,   1.5375, 447.4880, 495.0871]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4045], device='cuda:0')}, {'boxes': tensor([[174.0800, 173.7417, 442.3680, 465.8739]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2202], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 69.6000,  79.6444, 262.4000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18678], device='cuda:0')}, {'boxes': tensor([[419.2756,  81.0667, 510.3874, 174.9333],\n",
      "        [  0.0000, 253.8667, 100.3843, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([25952], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000, 204.8000, 116.8000, 326.4000],\n",
      "        [188.4000, 155.0222, 302.8000, 373.3333],\n",
      "        [244.0000, 169.2444, 315.2000, 338.4889],\n",
      "        [106.8000, 199.8222, 183.6000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([20099], device='cuda:0')}, {'boxes': tensor([[ 58.8000,  92.4445, 356.8000, 511.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15619], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 31.7440,  97.1566, 485.3760, 456.4819]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1916], device='cuda:0')}, {'boxes': tensor([[173.0560, 163.8400, 342.0160, 379.5627],\n",
      "        [482.3040, 456.0213, 497.6640, 486.0587]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([3625], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 99.8400,  57.3991, 432.6400, 450.0090]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6364], device='cuda:0')}, {'boxes': tensor([[228.0000, 193.4222, 314.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([18975], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[240.0000,   1.4222, 497.2000, 236.8000],\n",
      "        [  0.8000,  66.1333, 175.2000, 272.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15790], device='cuda:0')}, {'boxes': tensor([[ 16.0000, 204.0889,  51.6000, 272.3556],\n",
      "        [358.4000, 129.4222, 432.0000, 284.4444],\n",
      "        [478.4000, 258.1333, 511.2000, 307.2000],\n",
      "        [346.8000, 275.9111, 366.8000, 322.8445],\n",
      "        [192.4000, 225.4222, 214.0000, 290.8445],\n",
      "        [236.0000, 267.3778, 251.6000, 301.5111],\n",
      "        [260.0000, 277.3333, 272.0000, 302.2222],\n",
      "        [356.0000, 297.2444, 380.4000, 336.3556],\n",
      "        [303.6000, 249.6000, 320.4000, 301.5111],\n",
      "        [213.2000, 261.6889, 227.2000, 305.0667],\n",
      "        [334.4000, 246.7556, 350.8000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19, 19,  7, 19, 19, 19,  6, 19, 19, 19], device='cuda:0'), 'image_id': tensor([28659], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,   1.4222, 246.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15688], device='cuda:0')}, {'boxes': tensor([[229.6000,  83.9111, 498.8000, 399.6444],\n",
      "        [ 37.2000, 147.2000, 186.0000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([25032], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,  41.7778, 383.2000, 509.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13539], device='cuda:0')}, {'boxes': tensor([[249.6000, 155.7333, 360.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([28053], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 17.8087,   3.4133, 492.7072, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([6127], device='cuda:0')}, {'boxes': tensor([[209.6000, 145.7778, 295.6000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21464], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.0667, 172.0889, 380.8000, 324.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([29259], device='cuda:0')}, {'boxes': tensor([[110.9333, 185.8370, 202.6667, 311.9407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([21618], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[141.6000, 130.8445, 339.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17519], device='cuda:0')}, {'boxes': tensor([[ 19.9880,   6.1440, 512.0000, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8430], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0667,  49.7778, 184.5333, 386.8444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([13978], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([17733], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 15.3600,  12.2635, 460.8000, 416.9581]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3278], device='cuda:0')}, {'boxes': tensor([[462.8000,   6.4000, 510.8000, 155.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([18839], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[440.5333, 295.8222, 487.4667, 339.9111],\n",
      "        [ 45.8667, 241.7778, 358.4000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([23295], device='cuda:0')}, {'boxes': tensor([[147.2000,   0.0000, 428.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17714], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[243.7120,   1.3653, 374.7840, 322.2187],\n",
      "        [  1.0240, 147.4560, 182.2720, 327.6800]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([11602], device='cuda:0')}, {'boxes': tensor([[103.0244,  42.6667, 423.5447, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([23668], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 77.3333,  41.7185, 511.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21643], device='cuda:0')}, {'boxes': tensor([[141.5385, 134.7368, 464.0000, 394.1053],\n",
      "        [  3.6923, 146.5263, 151.3846, 424.4211]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32568], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[135.1680, 157.3012, 512.0000, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([957], device='cuda:0')}, {'boxes': tensor([[135.2000, 100.9778, 187.2000, 240.3556],\n",
      "        [454.4000, 105.2444, 511.2000, 250.3111],\n",
      "        [288.0000, 125.1555, 415.2000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([18581], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   7.8222, 510.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27088], device='cuda:0')}, {'boxes': tensor([[211.2000, 254.5778, 300.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([23908], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[389.6352, 109.5111, 485.4340, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([25970], device='cuda:0')}, {'boxes': tensor([[  8.1920,  83.9788, 499.7120, 442.9206]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10400], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000, 133.6889, 126.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([22221], device='cuda:0')}, {'boxes': tensor([[148.8000, 238.2222, 335.2000, 373.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([31821], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 10.2400, 155.2913, 483.3280, 379.7718]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9213], device='cuda:0')}, {'boxes': tensor([[256.0000, 393.0064, 349.1840, 469.4243]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1409], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[185.6000,  56.1778, 296.0000, 184.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([19305], device='cuda:0')}, {'boxes': tensor([[  0.0000, 145.7778, 280.0000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27019], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000,   0.0000, 460.8000, 381.7006]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10205], device='cuda:0')}, {'boxes': tensor([[  1.0240, 147.4560, 462.8480, 424.6187]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4636], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.2000,  36.9778, 382.4000, 290.8445],\n",
      "        [191.6000, 111.6444, 313.6000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([17247], device='cuda:0')}, {'boxes': tensor([[393.1086, 162.1333, 512.0000, 321.4222],\n",
      "        [ 75.7453, 179.2000, 269.4232, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([20651], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[346.4000, 204.0889, 433.2000, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([25520], device='cuda:0')}, {'boxes': tensor([[  0.0000,  67.2000, 430.4000, 396.8000],\n",
      "        [300.0000,  93.8667, 511.2000, 188.8000],\n",
      "        [312.8000,  67.2000, 511.2000, 212.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([14360], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   1.5422, 413.6960, 442.6024]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2092], device='cuda:0')}, {'boxes': tensor([[  1.0240, 106.0901, 409.6000, 424.3604]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2493], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[471.2000, 192.7111, 509.6000, 437.3333],\n",
      "        [259.2000, 189.1555, 352.4000, 276.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 12], device='cuda:0'), 'image_id': tensor([27703], device='cuda:0')}, {'boxes': tensor([[180.8000, 118.7556, 230.0000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([26484], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[354.6667,  27.9704, 454.1333, 161.1852]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([15246], device='cuda:0')}, {'boxes': tensor([[248.7066,  63.4467, 395.3048, 430.8473],\n",
      "        [388.0114,  81.1527, 474.0741, 383.6311],\n",
      "        [ 65.6410,  51.6427, 347.1681, 451.5043]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26, 26], device='cuda:0'), 'image_id': tensor([11126], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[146.4000, 165.6889, 404.0000, 189.8667],\n",
      "        [223.2000, 265.9556, 256.0000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  1], device='cuda:0'), 'image_id': tensor([29887], device='cuda:0')}, {'boxes': tensor([[ 84.9920, 105.1307, 395.2640, 230.7413]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10132], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[205.6000, 333.2741, 297.3333, 467.4370],\n",
      "        [ 94.4000,  75.8519, 121.6000, 146.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 5], device='cuda:0'), 'image_id': tensor([21609], device='cuda:0')}, {'boxes': tensor([[ 54.2720,  21.5904, 510.9760, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8765], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.3399, 125.1555, 506.9557, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([28040], device='cuda:0')}, {'boxes': tensor([[351.7333,   1.4222, 512.0000, 225.1852]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([13811], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[115.7120, 148.7462, 366.5920, 366.3853],\n",
      "        [ 14.3360, 192.5872,  95.2320, 302.1896],\n",
      "        [384.0000, 200.4159, 504.8320, 292.7951],\n",
      "        [  1.0240, 248.9541,  20.4800, 299.0581]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([9985], device='cuda:0')}, {'boxes': tensor([[  1.0240,   0.0000, 510.9760, 510.1779]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10416], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[450.1333,  31.2889, 509.8667, 164.9778],\n",
      "        [162.1333,  98.1333, 281.6000, 194.8445],\n",
      "        [184.5333, 258.8445, 282.6667, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17, 17, 17], device='cuda:0'), 'image_id': tensor([28130], device='cuda:0')}, {'boxes': tensor([[221.8667, 210.4889, 336.0000, 375.4667],\n",
      "        [178.1333, 237.5111, 229.3333, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([21994], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[383.3991, 290.1333, 512.0000, 487.8222],\n",
      "        [  7.2113,  32.7111, 364.1690, 217.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 23], device='cuda:0'), 'image_id': tensor([29021], device='cuda:0')}, {'boxes': tensor([[  1.0240,  61.4400, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4826], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.4000, 287.2889, 229.3333, 366.9333],\n",
      "        [162.1333, 233.2444, 250.6667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 3, 19], device='cuda:0'), 'image_id': tensor([29193], device='cuda:0')}, {'boxes': tensor([[  9.2160,  58.7093, 508.9280, 507.9040]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5753], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.8000, 162.8445, 140.4000, 356.2667],\n",
      "        [ 82.0000,   8.5333, 278.4000, 335.6444],\n",
      "        [237.6000,  94.5778, 352.8000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30], device='cuda:0'), 'image_id': tensor([19159], device='cuda:0')}, {'boxes': tensor([[118.8000,  24.1778, 294.8000, 209.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18071], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[252.8000,   3.5555, 369.6000, 271.6444],\n",
      "        [296.4000, 433.7778, 370.8000, 512.0000],\n",
      "        [ 26.0000, 249.6000,  64.4000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([17986], device='cuda:0')}, {'boxes': tensor([[129.0240,  64.1707, 297.9840, 484.6933]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7666], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[248.4000,  64.7111, 404.8000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20884], device='cuda:0')}, {'boxes': tensor([[180.0000,  36.9778, 249.2000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32779], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.4000,   0.0000, 268.8000, 506.3111],\n",
      "        [138.8000,   0.0000, 344.4000, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([16770], device='cuda:0')}, {'boxes': tensor([[130.0480,  70.9973, 430.0800, 447.8293]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8858], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[256.0000, 177.7778, 362.8000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([22082], device='cuda:0')}, {'boxes': tensor([[131.2000, 129.4222, 338.4000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21387], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 70.6560,  57.5805, 472.0640, 368.8268]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([12603], device='cuda:0')}, {'boxes': tensor([[ 30.7200,  36.8640, 436.2240, 509.2693]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([11571], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[104.5333,   8.5333, 331.7333, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([30606], device='cuda:0')}, {'boxes': tensor([[  2.7307,   4.0960, 502.4427, 483.3280]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([9907], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[245.6000, 218.3111, 290.4000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([32405], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 324.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([26714], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[130.0480,  19.6342, 390.1440, 389.6637]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5113], device='cuda:0')}, {'boxes': tensor([[203.6000,  44.8000, 377.2000, 321.4222],\n",
      "        [ 10.0000, 263.1111,  80.4000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19,  7], device='cuda:0'), 'image_id': tensor([20823], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.4000,  87.4667, 512.0000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27014], device='cuda:0')}, {'boxes': tensor([[ 62.4640, 144.5285, 353.2800, 419.7477]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1334], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.5422, 267.2640, 245.2048]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10053], device='cuda:0')}, {'boxes': tensor([[228.8000, 224.7111, 291.2000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20924], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[282.4000, 204.8000, 396.8000, 388.2667],\n",
      "        [340.0000, 136.5333, 409.6000, 310.0444],\n",
      "        [ 49.6000, 170.6667, 297.6000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([29613], device='cuda:0')}, {'boxes': tensor([[288.0000, 164.9778, 400.0000, 324.2667],\n",
      "        [105.6000, 113.7778, 153.2000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([26872], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[252.8000, 196.9778, 344.4000, 315.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([29161], device='cuda:0')}, {'boxes': tensor([[  3.2000, 147.3073, 302.4000, 509.1397]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([18521], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[100.0000,  12.8000, 333.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([16183], device='cuda:0')}, {'boxes': tensor([[ 64.4000, 216.1778, 294.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([25358], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[116.7360, 227.3837, 177.1520, 337.2085]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([6931], device='cuda:0')}, {'boxes': tensor([[300.8000, 315.7333, 358.4000, 379.2592],\n",
      "        [349.8667, 222.3407, 374.1333, 256.4741]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 5], device='cuda:0'), 'image_id': tensor([21627], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.6560, 316.1446, 272.3840, 468.8193],\n",
      "        [335.8720,   1.5422, 414.7200, 211.2771]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 12], device='cuda:0'), 'image_id': tensor([12442], device='cuda:0')}, {'boxes': tensor([[104.4000, 420.9778, 304.8000, 510.5778],\n",
      "        [ 86.4000,  81.7778, 176.8000, 361.2444],\n",
      "        [ 24.0000, 206.9333,  98.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([22058], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[257.2000, 273.0667, 264.4000, 283.0222],\n",
      "        [174.8000, 218.3111, 185.6000, 229.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([17839], device='cuda:0')}, {'boxes': tensor([[180.8000,   0.0000, 452.8000, 509.6727]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([301], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 27.6480,  89.0435, 454.6560, 489.7391]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([83], device='cuda:0')}, {'boxes': tensor([[  0.0000,   1.0240, 348.1600, 478.2080]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1449], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[154.6240,  91.9760, 512.0000, 487.4731]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3064], device='cuda:0')}, {'boxes': tensor([[294.4000, 182.0444, 374.8000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26631], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[228.3520,  87.6906, 289.7920, 281.4586]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3730], device='cuda:0')}, {'boxes': tensor([[158.8000,   2.1333, 474.0000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27827], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.9259,   3.1125, 489.4815, 413.9575]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7451], device='cuda:0')}, {'boxes': tensor([[ 54.8000, 226.8445, 350.8000, 452.9778],\n",
      "        [101.6000, 168.5333, 198.4000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32146], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.6000, 120.8889, 282.4000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([28450], device='cuda:0')}, {'boxes': tensor([[358.4000, 312.8889, 420.2667, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([25885], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[388.0960, 347.6711, 417.7920, 391.1300]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10950], device='cuda:0')}, {'boxes': tensor([[ 41.9840,  41.1192, 506.8800, 506.6943]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([11978], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[248.8000,   1.4222, 334.0000, 147.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14659], device='cuda:0')}, {'boxes': tensor([[  5.3895,  50.5408, 234.4421, 468.0515],\n",
      "        [261.3895,   2.1974, 512.0000, 501.0129]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8297], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[144.4000,   0.8889, 288.0000, 510.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13534], device='cuda:0')}, {'boxes': tensor([[146.4320,  51.0582, 330.7520, 445.3407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5142], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 59.6000, 148.6222, 448.0000, 504.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([32211], device='cuda:0')}, {'boxes': tensor([[239.6000, 242.4889, 267.2000, 295.8222],\n",
      "        [211.6000, 164.2667, 291.2000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([33070], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 19.4783,  19.4783, 470.2609, 495.3044]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2707], device='cuda:0')}, {'boxes': tensor([[376.0000,  91.0222, 511.2000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15673], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[178.1760,  79.9520, 392.1920, 362.8589]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7435], device='cuda:0')}, {'boxes': tensor([[206.4000, 229.6889, 401.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18010], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[210.4000, 279.4667, 466.4000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14637], device='cuda:0')}, {'boxes': tensor([[223.2320, 112.2402, 414.7200, 467.4114],\n",
      "        [113.6640, 209.1051, 184.3200, 393.6096],\n",
      "        [  1.0240, 295.2072,  34.8160, 338.2583]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15], device='cuda:0'), 'image_id': tensor([11577], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.8000, 253.8667, 374.4000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([17738], device='cuda:0')}, {'boxes': tensor([[375.4667, 217.6000, 483.2000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([24031], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 35.4987, 353.2800, 248.4907, 465.9200],\n",
      "        [ 95.5733, 184.3200, 400.0427, 283.6480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6], device='cuda:0'), 'image_id': tensor([12670], device='cuda:0')}, {'boxes': tensor([[ 52.8000,   1.4222, 288.0000, 216.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([20324], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 78.8000,  77.5111, 303.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([14667], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([23490], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[218.0000, 427.3778, 272.0000, 504.8889],\n",
      "        [192.0000, 331.3778, 243.6000, 399.6444],\n",
      "        [174.8000, 228.9778, 218.8000, 297.2444],\n",
      "        [161.2000, 165.6889, 203.2000, 219.0222],\n",
      "        [218.0000, 137.9556, 261.6000, 191.2889],\n",
      "        [270.8000, 119.4667, 314.0000, 168.5333],\n",
      "        [328.4000,  88.8889, 373.2000, 140.8000],\n",
      "        [386.0000,  62.5778, 432.0000, 111.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17874], device='cuda:0')}, {'boxes': tensor([[262.1440,  30.6921, 477.1840, 474.3324]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10244], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([19518], device='cuda:0')}, {'boxes': tensor([[314.7673, 233.2444, 412.1761, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([28864], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.0000,  35.5555, 217.6000, 241.0667],\n",
      "        [237.2000,  39.1111, 332.4000, 309.3333],\n",
      "        [310.8000,  11.3778, 448.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([29537], device='cuda:0')}, {'boxes': tensor([[  1.0240, 121.9866, 427.0080, 372.8322]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2159], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 49.1520,  48.2575, 512.0000, 390.7678]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8786], device='cuda:0')}, {'boxes': tensor([[ 13.4737,  79.8720, 456.6082, 370.6880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([11617], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[251.2000,  49.0667, 512.0000, 500.6222],\n",
      "        [ 74.0000,  81.7778, 306.8000, 414.5778],\n",
      "        [132.4000, 208.3556, 243.2000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30], device='cuda:0'), 'image_id': tensor([24285], device='cuda:0')}, {'boxes': tensor([[ 93.1840, 200.7040, 148.4800, 327.6800]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([12294], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0667,   2.8445, 133.3333, 122.3111],\n",
      "        [440.5333, 302.9333, 510.9333, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 10], device='cuda:0'), 'image_id': tensor([19827], device='cuda:0')}, {'boxes': tensor([[  1.0240,  98.1078, 150.5280, 196.2156],\n",
      "        [300.0320, 104.2395, 470.0160, 447.6168]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([3435], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 70.6560, 151.1619, 455.6800, 370.5905]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9560], device='cuda:0')}, {'boxes': tensor([[136.0000, 109.5111, 172.4000, 166.4000],\n",
      "        [192.8000, 174.2222, 229.2000, 229.6889],\n",
      "        [246.8000, 236.0889, 284.8000, 288.0000],\n",
      "        [257.6000, 290.1333, 293.2000, 342.0444],\n",
      "        [268.4000, 342.0444, 304.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17786], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[134.1440,  41.6386, 512.0000, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([5029], device='cuda:0')}, {'boxes': tensor([[165.8880, 188.4160, 297.9840, 333.1413]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5817], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 13.3120, 164.3319, 195.5840, 509.7642]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3742], device='cuda:0')}, {'boxes': tensor([[134.1440,  95.5733, 472.0640, 356.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9526], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 68.8000,   0.0000, 328.0000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([32251], device='cuda:0')}, {'boxes': tensor([[200.8000, 366.2222, 226.4000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([30294], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[111.2000,  98.8445, 217.6000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([19028], device='cuda:0')}, {'boxes': tensor([[  1.0240,   1.3653, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10402], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   3.0751, 451.5840, 465.8739]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([921], device='cuda:0')}, {'boxes': tensor([[248.0000, 302.9333, 416.4000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([25898], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[224.4000, 295.8222, 270.8000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([17971], device='cuda:0')}, {'boxes': tensor([[226.0000, 237.5111, 256.0000, 277.3333],\n",
      "        [213.2000, 140.0889, 302.8000, 276.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([33076], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 66.5600, 136.5333, 362.4960, 413.6960]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8207], device='cuda:0')}, {'boxes': tensor([[173.2000, 100.9778, 434.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21384], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[286.2660, 106.6667, 506.9557, 290.8445],\n",
      "        [  0.0000,   1.4222, 264.8276, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([32123], device='cuda:0')}, {'boxes': tensor([[110.5920, 145.5847, 415.7440, 449.8402]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10390], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[242.4019, 152.8889, 334.6328, 400.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5689], device='cuda:0')}, {'boxes': tensor([[ 70.0000,   0.0000, 512.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26932], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000, 118.0444, 402.4000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([24799], device='cuda:0')}, {'boxes': tensor([[ 90.1120,  22.9254, 448.5120, 417.2418],\n",
      "        [161.7920,  30.5672, 374.7840, 265.9343]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([12037], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 77.8240,   0.0000, 510.9760, 364.3964]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4778], device='cuda:0')}, {'boxes': tensor([[168.0000,  61.8667, 472.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([20409], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[309.2480,  56.3670, 475.1360, 369.5168],\n",
      "        [132.0960, 109.6024, 245.7600, 233.2966]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([97], device='cuda:0')}, {'boxes': tensor([[311.2960,   9.2530, 417.7920,  77.1084],\n",
      "        [  1.0240,  15.4217, 115.7120,  81.7350]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([12523], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560,  63.8302, 297.9840, 441.3793]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([131], device='cuda:0')}, {'boxes': tensor([[ 22.4330,  58.0619, 500.1237, 473.2921]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6662], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[148.8000, 249.6000, 303.2000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([32642], device='cuda:0')}, {'boxes': tensor([[ 52.2240, 215.7389, 510.9760, 448.1899]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1848], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[149.5040,  32.0000, 368.6400, 419.0476]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2203], device='cuda:0')}, {'boxes': tensor([[213.6000,   2.8445, 471.6000, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15634], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 260.7787,  67.5840, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([11744], device='cuda:0')}, {'boxes': tensor([[209.6000, 147.9111, 236.5333, 245.0963]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21580], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 88.0640, 182.9670, 432.1280, 399.7598]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1558], device='cuda:0')}, {'boxes': tensor([[ 96.4000, 119.4667, 202.4000, 381.1555],\n",
      "        [202.0000,   7.1111, 450.8000, 364.0889],\n",
      "        [  0.0000, 150.0444,  86.4000, 322.1333],\n",
      "        [432.8000, 136.5333, 511.2000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([25564], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[196.2667, 227.5556, 268.8000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([20140], device='cuda:0')}, {'boxes': tensor([[ 94.8000, 238.9333, 130.4000, 405.3333],\n",
      "        [152.0000, 260.2667, 213.6000, 418.1333],\n",
      "        [372.4000, 238.2222, 430.0000, 390.4000],\n",
      "        [319.6000, 212.6222, 363.2000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([16226], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   0.0000, 512.0000, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10481], device='cuda:0')}, {'boxes': tensor([[ 38.9120, 116.8529, 436.2240, 484.3243],\n",
      "        [228.3520, 201.4174, 474.1120, 498.1622]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8601], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[121.6000,   3.5555, 460.0000, 508.4444],\n",
      "        [406.4000, 135.8222, 512.0000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21, 21], device='cuda:0'), 'image_id': tensor([15882], device='cuda:0')}, {'boxes': tensor([[137.6000, 311.4667, 279.2000, 511.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([14844], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 234.4960, 508.9249]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8393], device='cuda:0')}, {'boxes': tensor([[ 35.4699,  43.0080, 508.9156, 424.9600]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([847], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[272.0000, 170.6667, 287.2000, 191.2889],\n",
      "        [244.4000, 189.8667, 258.8000, 214.0444],\n",
      "        [206.0000, 329.2444, 224.4000, 354.1333],\n",
      "        [252.4000, 312.8889, 268.8000, 339.2000],\n",
      "        [226.8000, 274.4889, 244.4000, 297.2444],\n",
      "        [247.2000, 222.5778, 262.8000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([21307], device='cuda:0')}, {'boxes': tensor([[ 15.2000, 160.7111, 153.6000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([25017], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[448.0000, 231.1111, 483.6000, 299.3778],\n",
      "        [  2.4000, 242.4889,  58.4000, 448.7111],\n",
      "        [ 84.8000, 198.4000, 116.8000, 246.0444],\n",
      "        [292.4000, 236.0889, 313.6000, 301.5111],\n",
      "        [250.4000, 216.8889, 266.0000, 251.0222],\n",
      "        [231.2000, 211.9111, 240.4000, 236.0889],\n",
      "        [118.4000, 175.6444, 144.0000, 229.6889],\n",
      "        [168.0000, 214.7556, 190.0000, 270.2222],\n",
      "        [274.8000, 218.3111, 288.8000, 261.6889],\n",
      "        [135.2000, 216.8889, 156.8000, 273.7778],\n",
      "        [208.0000, 211.9111, 219.2000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19,  7, 19, 19, 19,  6, 19, 19, 19, 19], device='cuda:0'), 'image_id': tensor([28661], device='cuda:0')}, {'boxes': tensor([[241.0667, 150.7556, 311.4667, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([24773], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([28775], device='cuda:0')}, {'boxes': tensor([[  1.6000, 368.3556,  26.4000, 430.9333],\n",
      "        [ 19.2000, 236.0889, 161.6000, 433.7778],\n",
      "        [209.6000, 283.0222, 232.0000, 341.3333],\n",
      "        [211.2000, 321.4222, 268.8000, 406.7556],\n",
      "        [288.0000, 298.6667, 320.0000, 369.7778],\n",
      "        [275.2000, 318.5778, 313.6000, 401.0667],\n",
      "        [275.2000, 368.3556, 313.6000, 426.6667],\n",
      "        [301.6000, 307.2000, 349.6000, 386.8444],\n",
      "        [360.8000, 295.8222, 402.4000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([20547], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.0667,   2.8445, 376.2667, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([15141], device='cuda:0')}, {'boxes': tensor([[215.0400, 102.7160, 373.7600, 391.9012]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7588], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.9333, 196.2667, 307.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([23904], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.4222e+00, 3.7080e+02, 5.1129e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([19133], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 25.6000,  61.4400, 363.5200, 389.1200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4927], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([24246], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[227.5556,  95.2320, 456.2963, 437.2480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8469], device='cuda:0')}, {'boxes': tensor([[ 53.2000,   0.7111, 511.2000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15641], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "[{'boxes': tensor([[143.6000, 218.3111, 262.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1968], device='cuda:0')}, {'boxes': tensor([[  0.0000, 187.7333,  76.8000, 318.5778],\n",
      "        [358.4000, 224.7111, 441.6000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([672], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 41.6000,  80.3556, 511.2000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1584], device='cuda:0')}, {'boxes': tensor([[ 85.3333,  51.2000, 413.8667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1694], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.4000, 185.6000, 369.6000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1290], device='cuda:0')}, {'boxes': tensor([[153.6000,   0.0000, 509.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1312], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[359.6000, 278.7556, 442.0000, 372.6222],\n",
      "        [278.0000, 305.7778, 356.0000, 393.9556],\n",
      "        [212.4000, 347.0222, 288.4000, 433.0667],\n",
      "        [172.8000, 245.3333, 248.0000, 329.9556],\n",
      "        [276.4000, 176.3556, 359.6000, 270.2222],\n",
      "        [204.0000,  78.2222, 284.0000, 167.1111],\n",
      "        [158.8000, 105.9556, 235.6000, 203.3778],\n",
      "        [117.2000, 145.0667, 199.6000, 238.9333],\n",
      "        [225.2000, 204.8000, 304.0000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([111], device='cuda:0')}, {'boxes': tensor([[414.6479,   0.0000, 511.0986, 337.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1485], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 278.7556, 160.8000, 510.5778],\n",
      "        [113.6000,  56.8889, 205.2000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([502], device='cuda:0')}, {'boxes': tensor([[108.4000, 209.7778, 135.2000, 273.7778],\n",
      "        [ 79.6000, 280.1778, 110.8000, 342.7556],\n",
      "        [154.8000,  78.2222, 171.6000, 110.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([625], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000, 185.6000, 316.8000, 509.8667],\n",
      "        [310.4000, 204.8000, 476.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1414], device='cuda:0')}, {'boxes': tensor([[199.2000,  79.6444, 351.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1782], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 208.3556, 348.4000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([77], device='cuda:0')}, {'boxes': tensor([[170.6667, 227.5556, 390.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2127], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.6000,  62.5778, 224.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1070], device='cuda:0')}, {'boxes': tensor([[ 87.6000, 225.4222, 190.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 189.8667, 293.2000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1375], device='cuda:0')}, {'boxes': tensor([[270.0000, 223.2889, 356.8000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.3333, 233.2444, 241.0667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2130], device='cuda:0')}, {'boxes': tensor([[202.6667, 182.0444, 249.6000, 241.7778],\n",
      "        [235.7333, 174.9333, 297.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([366], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 96.0000, 213.3333, 486.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1038], device='cuda:0')}, {'boxes': tensor([[137.6000, 248.8889, 324.2667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2140], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.0000, 271.6444, 297.6000, 371.2000],\n",
      "        [166.0000, 172.8000, 187.2000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([831], device='cuda:0')}, {'boxes': tensor([[288.0000, 255.2889, 326.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([193], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.8000, 204.8000, 336.0000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1778], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  17.0667, 487.4667, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.6000, 224.7111, 347.2000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2190], device='cuda:0')}, {'boxes': tensor([[251.2000, 274.4889, 292.8000, 324.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([192], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.2000,  56.8889, 453.6000, 258.8445],\n",
      "        [166.4000,  68.2667, 300.8000, 263.1111],\n",
      "        [102.4000, 119.4667, 247.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1758], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 5.5467e+01, 4.5800e+02, 4.4160e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([276], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 118.7556, 266.4000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([811], device='cuda:0')}, {'boxes': tensor([[179.2000, 190.5778, 282.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[377.6000, 139.3778, 402.4000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2146], device='cuda:0')}, {'boxes': tensor([[178.8000, 202.6667, 328.8000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1599], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 206.2222, 301.2000, 488.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2183], device='cuda:0')}, {'boxes': tensor([[194.8000, 135.1111, 473.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([336], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.4000, 200.5333, 250.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1245], device='cuda:0')}, {'boxes': tensor([[358.8000, 421.6889, 375.2000, 452.2667],\n",
      "        [177.6000, 213.3333, 192.4000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1872], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  81.7778, 322.4000, 245.3333],\n",
      "        [245.2000, 288.0000, 370.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([69], device='cuda:0')}, {'boxes': tensor([[101.3333,  31.2889, 326.4000, 494.9333],\n",
      "        [410.6667, 139.3778, 508.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([607], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[279.2000, 189.1555, 398.0000, 376.1778],\n",
      "        [201.2000,  86.7556, 361.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([419], device='cuda:0')}, {'boxes': tensor([[198.4000, 135.1111, 281.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([813], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [147.2000,  93.8667, 334.9333, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([603], device='cuda:0')}, {'boxes': tensor([[146.4000, 126.5778, 509.6000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([322], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.4000,  73.9556, 240.8000, 234.6667],\n",
      "        [243.2000,  54.0444, 364.0000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1738], device='cuda:0')}, {'boxes': tensor([[122.4000, 169.2444, 276.8000, 384.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2038], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.4000,  70.4000, 331.2000, 400.3556],\n",
      "        [222.4000, 161.4222, 329.6000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1535], device='cuda:0')}, {'boxes': tensor([[ 66.4000, 297.9556, 138.0000, 343.4667],\n",
      "        [154.4000, 234.6667, 222.4000, 280.1778],\n",
      "        [238.8000, 156.4444, 300.4000, 234.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([124], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000, 196.9778, 278.0000, 401.7778],\n",
      "        [255.6000, 209.7778, 438.4000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([569], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 6.3289e+01, 2.5680e+02, 4.9422e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([300], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000, 263.1111, 187.7333, 384.0000],\n",
      "        [371.2000, 244.6222, 430.9333, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([702], device='cuda:0')}, {'boxes': tensor([[129.3617, 105.2444, 239.6596, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1089], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.4000, 187.7333, 266.4000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1340], device='cuda:0')}, {'boxes': tensor([[181.3333, 136.5333, 428.8000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([232], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 124.4444, 510.0000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([995], device='cuda:0')}, {'boxes': tensor([[ 34.8000,   3.5556, 290.4000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([267], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 91.2000, 206.9333, 180.8000, 283.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1276], device='cuda:0')}, {'boxes': tensor([[249.6000, 275.9111, 298.8000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000,  18.4000, 104.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1650], device='cuda:0')}, {'boxes': tensor([[187.6000, 145.0667, 292.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1841], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  77.5111, 348.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([11], device='cuda:0')}, {'boxes': tensor([[116.4000, 349.8667, 350.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([15], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.2000, 128.0000, 497.2000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([380], device='cuda:0')}, {'boxes': tensor([[160.0000, 229.6889, 316.8000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,  88.8889, 339.6000, 431.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([102], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 396.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1894], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000,  96.5246, 385.6000, 497.3115]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([957], device='cuda:0')}, {'boxes': tensor([[422.8000, 177.0667, 471.2000, 210.4889],\n",
      "        [323.2000, 169.9556, 416.0000, 211.9111],\n",
      "        [254.8000, 186.3111, 328.8000, 219.0222],\n",
      "        [ 17.6000, 225.4222,  92.0000, 280.1778],\n",
      "        [164.0000, 222.5778, 191.6000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29, 29], device='cuda:0'), 'image_id': tensor([537], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[379.6000, 239.6444, 412.4000, 341.3333],\n",
      "        [  0.0000, 216.8889, 144.8000, 444.4445],\n",
      "        [105.6000, 216.8889, 169.2000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7, 7], device='cuda:0'), 'image_id': tensor([1989], device='cuda:0')}, {'boxes': tensor([[219.0222, 231.8222, 269.2741, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([167], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000,   0.0000, 407.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([617], device='cuda:0')}, {'boxes': tensor([[139.2000, 304.3556, 235.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2007], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 390.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1834], device='cuda:0')}, {'boxes': tensor([[  7.6000,  84.6222, 271.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1433], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.8000, 211.2000, 270.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2058], device='cuda:0')}, {'boxes': tensor([[238.8000, 155.0222, 322.0000, 285.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([4], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.8000, 195.5556, 310.4000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([804], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 125.8667, 251.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1475], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1272], device='cuda:0')}, {'boxes': tensor([[213.2000, 159.2889, 313.6000, 286.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1125], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 128.7111, 228.0000, 210.4889],\n",
      "        [242.4000, 192.0000, 297.2000, 266.6667],\n",
      "        [226.0000, 190.5778, 277.2000, 270.2222],\n",
      "        [290.0000, 260.2667, 344.0000, 338.4889],\n",
      "        [329.2000, 324.2667, 384.4000, 403.9111],\n",
      "        [142.8000,  73.9556, 196.0000, 147.9111],\n",
      "        [368.8000, 410.3111, 426.4000, 492.8000],\n",
      "        [ 99.2000,  14.9333, 156.8000,  99.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([141], device='cuda:0')}, {'boxes': tensor([[  0.0000, 288.0000, 202.4000, 509.1555],\n",
      "        [249.6000, 312.1778, 378.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([19], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.0000, 193.4222, 374.4000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1602], device='cuda:0')}, {'boxes': tensor([[ 31.2000, 172.8000, 426.8000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1389], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[209.2000,   0.0000, 510.4000, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1314], device='cuda:0')}, {'boxes': tensor([[136.0000, 206.9333, 183.6000, 235.3778],\n",
      "        [418.0000, 206.2222, 453.2000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([527], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000,   0.0000, 256.0000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1861], device='cuda:0')}, {'boxes': tensor([[ 14.8000,   0.0000, 299.6000, 329.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 176.3556, 268.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([928], device='cuda:0')}, {'boxes': tensor([[219.5963, 181.3333, 318.8257, 321.0667],\n",
      "        [ 11.1560, 317.8667, 510.2385, 506.6667],\n",
      "        [300.6238, 298.6667, 509.6514, 454.4000],\n",
      "        [  0.0000, 189.8667, 162.0550, 448.0000],\n",
      "        [146.2018, 291.2000, 191.4128, 334.9333],\n",
      "        [148.5505, 277.3333, 197.2844, 321.0667],\n",
      "        [187.3027, 263.4667, 211.9633, 308.2667],\n",
      "        [352.2936, 274.1333, 413.3578, 304.0000],\n",
      "        [329.3945, 274.1333, 364.0367, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([455], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000,  54.0444, 326.4000, 411.0222],\n",
      "        [272.0000, 274.4889, 307.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([510], device='cuda:0')}, {'boxes': tensor([[200.0000, 186.1818, 284.8000, 257.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1415], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 386.8445, 294.8000, 462.9333],\n",
      "        [244.4000, 291.5555, 269.6000, 366.9333],\n",
      "        [224.8000, 204.0889, 252.8000, 278.7556],\n",
      "        [263.6000, 131.5556, 289.2000, 204.8000],\n",
      "        [300.8000,  73.9556, 327.6000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([100], device='cuda:0')}, {'boxes': tensor([[282.0000, 147.9111, 384.0000, 295.8222],\n",
      "        [ 96.0000, 141.5111, 287.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([902], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.6000, 153.6000, 372.0000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([746], device='cuda:0')}, {'boxes': tensor([[ 58.1818, 176.4848, 186.1818, 364.6060]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2020], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 277.6000, 509.1555],\n",
      "        [281.6000,   0.0000, 511.2000, 237.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1430], device='cuda:0')}, {'boxes': tensor([[265.6000, 285.1555, 285.6000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 192.0000, 189.8667, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1369], device='cuda:0')}, {'boxes': tensor([[448.0000, 190.5778, 511.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([531], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 126.5778, 509.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1636], device='cuda:0')}, {'boxes': tensor([[  0.0000, 210.4889, 156.4000, 507.7333],\n",
      "        [186.4000, 156.4444, 336.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([497], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.8000,   0.0000, 288.4000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([413], device='cuda:0')}, {'boxes': tensor([[ 15.2661, 366.9333, 301.7982, 508.8000],\n",
      "        [193.7615, 337.0667, 341.7248, 497.0667],\n",
      "        [280.0734, 321.0667, 369.3211, 437.3333],\n",
      "        [314.1284, 280.5333, 390.4587, 400.0000],\n",
      "        [  7.6330, 296.5333,  94.5321, 403.2000],\n",
      "        [379.8899, 278.4000, 402.7890, 318.9333],\n",
      "        [101.5780, 277.3333, 196.6973, 348.8000],\n",
      "        [202.5688, 193.0667, 345.2477, 347.7333],\n",
      "        [442.1284, 286.9333, 462.0917, 329.6000],\n",
      "        [452.1101, 270.9333, 487.3394, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 6, 7, 7], device='cuda:0'), 'image_id': tensor([465], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.8000, 107.3778, 265.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1900], device='cuda:0')}, {'boxes': tensor([[120.5333, 130.8445, 278.4000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([200], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000, 199.8222, 313.6000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([0], device='cuda:0')}, {'boxes': tensor([[ 55.2000, 118.7556, 281.2000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([223], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 89.6000, 153.6000, 505.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1281], device='cuda:0')}, {'boxes': tensor([[  0.0000, 179.2000,  32.0000, 273.0667],\n",
      "        [379.7333, 170.6667, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([687], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[320.8000, 170.6667, 391.2000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2148], device='cuda:0')}, {'boxes': tensor([[230.8000, 155.0222, 314.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([5], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000,  92.4444, 348.8000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1780], device='cuda:0')}, {'boxes': tensor([[ 12.8000,   0.0000, 509.6000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1608], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 295.8222, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([706], device='cuda:0')}, {'boxes': tensor([[162.1333, 209.0667, 291.2000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([23], device='cuda:0')}, {'boxes': tensor([[ 58.1284, 249.6000, 209.0275, 357.3333],\n",
      "        [457.9817, 222.9333, 484.4037, 269.8667],\n",
      "        [354.0551, 171.7333, 460.9174, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([479], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 169.2444, 301.2000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1442], device='cuda:0')}, {'boxes': tensor([[174.8000,   0.0000, 316.8000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1308], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[272.8000, 123.7333, 339.2000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([115], device='cuda:0')}, {'boxes': tensor([[398.0917, 228.2667, 509.6514, 321.0667],\n",
      "        [391.0459, 284.8000, 510.2385, 396.8000],\n",
      "        [ 48.7339, 249.6000, 185.5413, 443.7333],\n",
      "        [423.9266, 309.3333, 510.2385, 466.1333],\n",
      "        [409.2477, 298.6667, 510.2385, 425.6000],\n",
      "        [ 37.5780, 320.0000, 132.6973, 340.2667],\n",
      "        [ 28.7706, 332.8000, 128.5872, 363.7333],\n",
      "        [ 11.7431, 362.6667, 142.0917, 404.2667],\n",
      "        [  0.5872, 400.0000, 162.6422, 505.6000],\n",
      "        [197.8716,  87.4667, 367.5596, 451.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([461], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2000, 199.8222, 318.8000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1550], device='cuda:0')}, {'boxes': tensor([[160.4000, 268.8000, 332.4000, 491.3778],\n",
      "        [ 51.6000, 235.3778, 364.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([556], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.2000, 160.0000, 302.8000, 358.4000],\n",
      "        [174.0000, 259.5555, 256.4000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([522], device='cuda:0')}, {'boxes': tensor([[101.2000, 239.6444, 313.2000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1158], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.0000,  89.6000, 261.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([91], device='cuda:0')}, {'boxes': tensor([[172.8000,  25.6000, 509.8667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1713], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 182.0444, 228.4000, 295.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([631], device='cuda:0')}, {'boxes': tensor([[137.9817,  85.3333, 345.8349, 439.4667],\n",
      "        [  4.6972, 246.4000, 114.4954, 435.2000],\n",
      "        [422.1651, 222.9333, 453.2844, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([485], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000,  96.7111, 367.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([406], device='cuda:0')}, {'boxes': tensor([[208.8000, 107.3778, 511.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([991], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 125.8667, 301.2000, 444.4445],\n",
      "        [280.0000, 187.0222, 388.8000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1541], device='cuda:0')}, {'boxes': tensor([[211.2000, 219.7333, 284.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([661], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[127.2000, 209.7778, 338.0000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1348], device='cuda:0')}, {'boxes': tensor([[120.0000, 213.3333, 199.2000, 500.6222],\n",
      "        [252.8000, 193.4222, 295.2000, 358.4000],\n",
      "        [454.4000, 203.3778, 509.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([781], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000,  75.3778, 510.4000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1455], device='cuda:0')}, {'boxes': tensor([[132.0000,  45.5111, 293.6000, 411.0222],\n",
      "        [112.8000, 297.2444, 136.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([507], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 239.6444, 234.4000, 344.8889],\n",
      "        [ 80.0000, 149.3333, 267.6000, 354.1333],\n",
      "        [ 66.8000, 236.0889, 134.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([518], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.1662e+02, 3.4000e+02, 4.9351e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([297], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.5630,  96.7111, 508.2074, 403.9111],\n",
      "        [240.8296, 339.9111, 332.8000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([182], device='cuda:0')}, {'boxes': tensor([[142.8000, 103.1111, 379.6000, 494.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([344], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000, 153.6000, 338.0000, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1954], device='cuda:0')}, {'boxes': tensor([[  0.0000, 256.0000, 147.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([946], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.8000, 204.0889, 259.6000, 392.5333],\n",
      "        [191.2000, 234.6667, 263.2000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1565], device='cuda:0')}, {'boxes': tensor([[120.8000, 274.4889, 231.2000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2001], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[39.6000,  0.0000, 99.2000, 76.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1836], device='cuda:0')}, {'boxes': tensor([[268.8000, 137.2444, 397.2000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([423], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.8000, 142.9333, 268.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2042], device='cuda:0')}, {'boxes': tensor([[160.0000, 147.9111, 424.5333, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1306], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 136.5333, 299.2000, 341.3333],\n",
      "        [244.8000,  44.0889, 404.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1230], device='cuda:0')}, {'boxes': tensor([[213.3333, 133.6889, 462.9333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([204], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[229.6000, 167.8222, 331.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2176], device='cuda:0')}, {'boxes': tensor([[ 81.0667,  49.7778, 410.6667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1695], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([735], device='cuda:0')}, {'boxes': tensor([[196.4000, 217.6000, 236.4000, 357.6889],\n",
      "        [432.8000, 132.9778, 484.0000, 199.1111],\n",
      "        [310.8000, 128.0000, 358.8000, 197.6889],\n",
      "        [304.0000, 128.7111, 343.6000, 175.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1950], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000,  96.7111, 280.5333, 231.8222],\n",
      "        [304.0000, 219.0222, 381.8667, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([668], device='cuda:0')}, {'boxes': tensor([[  0.0000, 230.4000, 274.4000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1634], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([34], device='cuda:0')}, {'boxes': tensor([[202.8000, 183.4667, 348.8000, 268.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1930], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1866], device='cuda:0')}, {'boxes': tensor([[231.6000, 231.1111, 278.8000, 268.8000],\n",
      "        [294.4000, 210.4889, 310.4000, 238.9333],\n",
      "        [248.0000, 191.2889, 265.2000, 226.1333],\n",
      "        [232.4000, 194.1333, 256.0000, 224.7111],\n",
      "        [483.6000, 354.8445, 500.8000, 387.5555],\n",
      "        [104.4000, 378.3111, 122.8000, 418.8445],\n",
      "        [358.4000,  84.6222, 379.6000, 140.0889],\n",
      "        [109.2000,  94.5778, 118.4000, 118.0444],\n",
      "        [ 86.8000,  93.8667, 101.6000, 114.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2032], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[239.2000, 132.2667, 349.6000, 211.2000],\n",
      "        [225.2000, 179.9111, 330.8000, 260.2667],\n",
      "        [220.0000, 236.8000, 325.6000, 315.0222],\n",
      "        [207.2000, 270.2222, 312.0000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([147], device='cuda:0')}, {'boxes': tensor([[159.2000, 127.2889, 383.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1099], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.7333, 184.8889, 332.8000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([201], device='cuda:0')}, {'boxes': tensor([[408.0000,  93.3771, 492.0000, 220.3279]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([972], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 275.2000, 384.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([14], device='cuda:0')}, {'boxes': tensor([[204.8000, 115.9111, 219.2000, 159.2889],\n",
      "        [131.2000, 135.8222, 148.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([622], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872,   1.0667, 497.3211, 503.4667],\n",
      "        [219.5963, 256.0000, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([454], device='cuda:0')}, {'boxes': tensor([[ 93.8667,  35.5556, 338.1333, 507.7333],\n",
      "        [408.5333, 136.5333, 510.9333, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([606], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 183.2727, 476.8000, 384.0000],\n",
      "        [228.0000, 206.5455, 345.6000, 370.9091]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1327], device='cuda:0')}, {'boxes': tensor([[174.9333, 108.0889, 245.3333, 233.2444],\n",
      "        [326.4000, 156.4444, 387.2000, 231.8222],\n",
      "        [290.1333,  56.8889, 309.3333,  72.5333],\n",
      "        [343.4667,  68.2667, 365.8667,  86.7556],\n",
      "        [458.6667,  66.8444, 482.1333,  88.1778],\n",
      "        [156.8000,  71.1111, 178.1333,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([359], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000, 135.8222, 340.4000, 187.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1380], device='cuda:0')}, {'boxes': tensor([[156.8000, 310.0444, 330.6667, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000, 395.6364, 210.4000, 420.3636]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1424], device='cuda:0')}, {'boxes': tensor([[196.4000,  93.1556, 396.0000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1350], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.8667, 154.3111, 216.5333, 281.6000],\n",
      "        [242.1333, 164.9778, 316.2667, 247.4667],\n",
      "        [189.8667, 263.1111, 261.3333, 392.5333],\n",
      "        [219.7333, 211.9111, 312.0000, 335.6444],\n",
      "        [418.1333, 150.7556, 484.2667, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([54], device='cuda:0')}, {'boxes': tensor([[236.0000, 228.2667, 331.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1918], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 182.0444,  26.6667, 264.5333],\n",
      "        [356.2667, 137.9556, 509.8667, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([689], device='cuda:0')}, {'boxes': tensor([[ 14.4000, 155.0222, 234.4000, 285.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([214], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.0367, 116.2667, 294.7523, 300.8000],\n",
      "        [385.1743, 241.0667, 509.0642, 350.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([484], device='cuda:0')}, {'boxes': tensor([[235.2000, 120.8889, 444.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1452], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 192.0000, 265.2000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1357], device='cuda:0')}, {'boxes': tensor([[  0.0000,  19.2000, 303.2000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[158.0000, 199.1111, 321.6000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([163], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1617], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.2667, 197.6889, 509.8667, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([244], device='cuda:0')}, {'boxes': tensor([[172.8000, 211.9111, 249.6000, 285.1555],\n",
      "        [ 59.6000, 252.4444, 170.4000, 327.1111],\n",
      "        [199.6000, 237.5111, 275.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1572], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000, 176.3556, 297.2000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([888], device='cuda:0')}, {'boxes': tensor([[352.0000, 180.6222, 397.6000, 290.8445],\n",
      "        [278.0000, 182.7556, 382.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1521], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.7333, 139.3778, 475.7333, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1305], device='cuda:0')}, {'boxes': tensor([[207.6000, 157.8667, 281.6000, 320.7111],\n",
      "        [247.2000, 187.7333, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1571], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 46.9333,   0.0000, 273.0667, 510.5778],\n",
      "        [362.6667,   0.0000, 510.9333, 157.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([596], device='cuda:0')}, {'boxes': tensor([[  0.0000, 147.9111, 462.9333, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1942], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 160.0000, 205.6000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1401], device='cuda:0')}, {'boxes': tensor([[162.8000, 187.0222, 377.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2171], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 460.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2099], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([985], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.6000, 260.9778, 348.0000, 357.6889],\n",
      "        [233.6000, 268.8000, 275.2000, 364.8000],\n",
      "        [132.4000, 320.7111, 176.4000, 422.4000],\n",
      "        [138.0000, 211.2000, 181.6000, 305.7778],\n",
      "        [298.4000, 148.6222, 340.8000, 241.7778],\n",
      "        [271.2000,  54.0444, 316.4000, 148.6222],\n",
      "        [207.2000,  73.2444, 252.0000, 169.9556],\n",
      "        [152.0000, 109.5111, 194.4000, 201.2444],\n",
      "        [230.4000, 174.9333, 273.6000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([110], device='cuda:0')}, {'boxes': tensor([[ 51.5220,  27.0222, 396.0755, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1029], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.5333, 240.3556, 215.4667, 261.6889],\n",
      "        [296.5333, 231.8222, 410.6667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2110], device='cuda:0')}, {'boxes': tensor([[156.8000,  79.6444, 393.6000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1821], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[285.7465,   0.0000, 510.1972, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1484], device='cuda:0')}, {'boxes': tensor([[281.6000, 196.2667, 359.4667, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 210.4889, 164.2667, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1363], device='cuda:0')}, {'boxes': tensor([[221.8667,  83.9111, 332.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1934], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[215.4667, 129.4222, 321.0667, 186.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1591], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 214.7556, 299.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.8000, 160.7111, 300.0000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([542], device='cuda:0')}, {'boxes': tensor([[121.6000, 183.4667, 192.0000, 247.4667],\n",
      "        [198.4000, 176.3556, 275.2000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([363], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.9333, 153.6000, 510.9333, 334.2222],\n",
      "        [105.6000,  61.1556, 435.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([48], device='cuda:0')}, {'boxes': tensor([[111.6596, 130.8445, 253.2766, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1091], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.4000, 187.0222, 375.2000, 447.2889],\n",
      "        [147.2000, 310.7556, 226.8000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([867], device='cuda:0')}, {'boxes': tensor([[115.2000, 263.1111, 258.1333, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2142], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.4000,  12.8000, 500.0000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([287], device='cuda:0')}, {'boxes': tensor([[188.0000, 177.7778, 292.8000, 306.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1127], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 24.5333,   1.4222, 270.9333, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1069], device='cuda:0')}, {'boxes': tensor([[  0.0000,  28.4444, 509.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([801], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[311.2000,  39.1111, 408.8000, 125.8667],\n",
      "        [230.4000, 105.9556, 342.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27], device='cuda:0'), 'image_id': tensor([1347], device='cuda:0')}, {'boxes': tensor([[193.6000, 206.2222, 352.8000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1779], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[121.5413, 201.6000, 243.6697, 326.4000],\n",
      "        [  4.6972, 317.8667, 510.2385, 505.6000],\n",
      "        [292.9908, 300.8000, 509.6514, 456.5333],\n",
      "        [140.3303, 292.2667, 186.7156, 334.9333],\n",
      "        [140.9174, 277.3333, 191.4128, 320.0000],\n",
      "        [348.1835, 277.3333, 409.2477, 307.2000],\n",
      "        [323.5229, 278.4000, 357.5780, 313.6000],\n",
      "        [298.8624, 276.2667, 335.8532, 318.9333],\n",
      "        [274.2018, 265.6000, 325.8716, 324.2667],\n",
      "        [253.6514, 269.8667, 279.4862, 321.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([459], device='cuda:0')}, {'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [165.6000, 160.0000, 205.2000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.8000, 138.6667, 441.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([328], device='cuda:0')}, {'boxes': tensor([[208.0000,  57.6000, 508.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.8000, 178.4889, 259.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([855], device='cuda:0')}, {'boxes': tensor([[306.4000, 386.8445, 328.4000, 418.1333],\n",
      "        [234.0000, 228.2667, 254.8000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.8000, 223.2889, 306.4000, 328.5333],\n",
      "        [ 17.6000, 151.4667, 205.2000, 338.4889],\n",
      "        [177.2000, 222.5778, 275.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([517], device='cuda:0')}, {'boxes': tensor([[155.2000, 368.3556, 243.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2013], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.1867e+01, 4.3400e+02, 4.4302e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([275], device='cuda:0')}, {'boxes': tensor([[136.0000,  58.3111, 371.6000, 434.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1859], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 113.7778, 364.8000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2143], device='cuda:0')}, {'boxes': tensor([[324.6972, 179.2000, 480.2936, 306.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([470], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.2000, 142.2222, 364.0000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1932], device='cuda:0')}, {'boxes': tensor([[265.9155,   0.0000, 511.0986, 288.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1489], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.7333,   0.0000, 509.8667, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([684], device='cuda:0')}, {'boxes': tensor([[ 38.4000, 182.7556, 264.4000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1561], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.0000, 136.5333, 297.6000, 339.9111],\n",
      "        [243.2000,  45.5111, 403.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1229], device='cuda:0')}, {'boxes': tensor([[251.7333,   0.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1729], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.8000,   8.5333, 292.8000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1046], device='cuda:0')}, {'boxes': tensor([[171.2000, 186.1818, 315.2000, 290.9091]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1416], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 189.1555,  45.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1905], device='cuda:0')}, {'boxes': tensor([[115.2000,  45.5111, 267.2000, 226.1333],\n",
      "        [232.0000,  28.4444, 365.6000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1751], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.0000, 113.7778, 380.4000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([879], device='cuda:0')}, {'boxes': tensor([[183.2000, 136.5333, 288.0000, 332.8000],\n",
      "        [240.0000,  44.0889, 390.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1228], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000,   9.9556, 252.8000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1839], device='cuda:0')}, {'boxes': tensor([[224.0000, 108.0889, 510.4000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000,  64.0000, 470.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([218], device='cuda:0')}, {'boxes': tensor([[292.8000,  68.2667, 511.2000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1980], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[327.0459, 218.6667, 423.3394, 330.6667],\n",
      "        [178.4954, 291.2000, 243.6697, 339.2000],\n",
      "        [258.9358, 284.8000, 298.2752, 337.0667],\n",
      "        [294.1651, 281.6000, 332.9174, 329.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([469], device='cuda:0')}, {'boxes': tensor([[112.8000, 133.6889, 258.0000, 324.2667],\n",
      "        [218.0000, 146.4889, 394.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([567], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 91.2000, 136.5333, 308.0000, 388.2667],\n",
      "        [160.0000, 182.0444, 428.8000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([60], device='cuda:0')}, {'boxes': tensor([[368.0000, 281.6000, 509.8667, 395.3778],\n",
      "        [  0.0000, 250.3111, 226.1333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.5333, 221.8667, 338.1333, 278.7556],\n",
      "        [  0.0000, 149.3333,  58.6667, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([256], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.0000,  45.5111, 304.8000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2045], device='cuda:0')}, {'boxes': tensor([[263.2000, 112.3556, 402.4000, 302.9333],\n",
      "        [ 76.0000,  98.1333, 233.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1754], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000, 190.5778, 219.2000, 367.6444],\n",
      "        [277.2000, 172.8000, 425.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1113], device='cuda:0')}, {'boxes': tensor([[186.8000, 161.4222, 301.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[277.2000, 184.1778, 378.0000, 374.0444],\n",
      "        [263.2000, 201.9556, 420.8000, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([418], device='cuda:0')}, {'boxes': tensor([[206.0000,  75.3778, 340.4000, 393.9556],\n",
      "        [307.6000, 151.4667, 365.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1539], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 230.4000, 279.4667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2094], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 230.4000, 206.2222],\n",
      "        [403.2000, 320.0000, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1625], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 164.2667, 509.6000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([572], device='cuda:0')}, {'boxes': tensor([[379.6000, 195.5556, 492.8000, 425.9556],\n",
      "        [226.8000, 165.6889, 320.4000, 293.6889],\n",
      "        [  8.4000, 193.4222,  45.2000, 214.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([890], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0183, 186.6667, 293.5780, 322.1333],\n",
      "        [  0.0000, 314.6667, 510.2385, 503.4667],\n",
      "        [289.4679, 293.3333, 509.6514, 449.0667],\n",
      "        [132.6973, 289.0667, 177.9083, 331.7333],\n",
      "        [133.8716, 273.0667, 185.5413, 325.3333],\n",
      "        [341.1376, 270.9333, 402.2018, 299.7333],\n",
      "        [316.4771, 269.8667, 350.5321, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([458], device='cuda:0')}, {'boxes': tensor([[188.8000, 122.3111, 266.4000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1130], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 247.4667, 158.4000, 492.0889],\n",
      "        [355.2000, 233.2444, 409.6000, 465.0667],\n",
      "        [304.8000, 217.6000, 328.0000, 308.6222],\n",
      "        [467.2000, 260.2667, 510.4000, 398.2222],\n",
      "        [173.6000, 227.5556, 205.6000, 341.3333],\n",
      "        [199.2000, 237.5111, 268.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([776], device='cuda:0')}, {'boxes': tensor([[252.8000, 139.3778, 282.0000, 180.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2055], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000, 187.0222, 290.8000, 371.2000],\n",
      "        [295.6000, 105.9556, 336.0000, 170.6667],\n",
      "        [388.8000, 107.3778, 425.6000, 160.0000],\n",
      "        [228.4000, 106.6667, 264.0000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1951], device='cuda:0')}, {'boxes': tensor([[196.0000,  66.8444, 317.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([878], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.1333, 237.5111, 387.2000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1706], device='cuda:0')}, {'boxes': tensor([[ 64.4000,  59.0222, 277.2000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([841], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 236.0889, 275.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1732], device='cuda:0')}, {'boxes': tensor([[264.4000, 273.7778, 470.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([576], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.0000, 174.2222, 472.0000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1288], device='cuda:0')}, {'boxes': tensor([[  3.2000,  38.4000, 280.0000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1045], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.0000,  96.0000, 326.8000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([84], device='cuda:0')}, {'boxes': tensor([[  0.0000, 143.6444, 150.4000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1373], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.8000,   0.0000, 284.8000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([414], device='cuda:0')}, {'boxes': tensor([[172.8000,  59.7333, 328.0000, 396.8000],\n",
      "        [248.0000, 150.7556, 358.4000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1237], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.2000, 295.8222, 429.2000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([655], device='cuda:0')}, {'boxes': tensor([[191.2000,  79.6444, 300.0000, 341.3333],\n",
      "        [108.8000,   0.0000, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([979], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.4000, 160.7111, 281.6000, 241.7778],\n",
      "        [281.6000, 162.1333, 356.2667, 238.9333],\n",
      "        [254.9333,  59.7333, 276.2667,  76.8000],\n",
      "        [307.2000,  72.5333, 328.5333,  93.8667],\n",
      "        [424.5333,  75.3778, 446.9333,  93.8667],\n",
      "        [126.9333,  73.9556, 148.2667,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([358], device='cuda:0')}, {'boxes': tensor([[  0.0000, 199.1111, 145.0667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1733], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 120.1778, 258.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([222], device='cuda:0')}, {'boxes': tensor([[  0.0000, 386.8445, 171.2000, 510.5778],\n",
      "        [371.2000, 317.1555, 394.4000, 509.1555],\n",
      "        [484.8000, 371.2000, 511.2000, 510.5778],\n",
      "        [189.6000, 402.4889, 318.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([783], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.5333, 116.6222, 510.9333, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1710], device='cuda:0')}, {'boxes': tensor([[ 66.0000,  59.0222, 288.4000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([849], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.4000, 386.8445, 253.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2017], device='cuda:0')}, {'boxes': tensor([[  2.1333, 273.0667, 365.8667, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2138], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 72.0000,   0.0000, 314.4000, 426.6667],\n",
      "        [292.8000, 251.7333, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1628], device='cuda:0')}, {'boxes': tensor([[218.6667, 227.5556, 370.1333, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2105], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.8000, 117.3333, 300.0000, 210.4889],\n",
      "        [202.4000, 122.3111, 270.8000, 182.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([873], device='cuda:0')}, {'boxes': tensor([[152.0000, 138.1818, 345.6000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1419], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.8661,  83.9111, 472.0882, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2098], device='cuda:0')}, {'boxes': tensor([[145.0667, 202.6667, 169.6000, 283.0222],\n",
      "        [192.0000, 219.0222, 254.9333, 287.2889],\n",
      "        [263.4667, 224.7111, 312.5333, 291.5555],\n",
      "        [365.3333, 231.1111, 390.9333, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([58], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000,  75.3778, 376.0000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1456], device='cuda:0')}, {'boxes': tensor([[194.4000,  83.2000, 226.8000, 125.8667],\n",
      "        [185.6000, 158.5778, 217.6000, 200.5333],\n",
      "        [179.6000, 243.9111, 213.6000, 287.2889],\n",
      "        [180.0000, 329.2444, 212.0000, 371.2000],\n",
      "        [178.4000, 400.3556, 210.4000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.6000, 182.7556, 445.2000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([156], device='cuda:0')}, {'boxes': tensor([[187.6000, 177.7778, 351.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([494], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000,  85.3333, 509.6000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([393], device='cuda:0')}, {'boxes': tensor([[ 58.4000,   0.0000, 412.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([66], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[138.8000,  46.2222, 306.8000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2046], device='cuda:0')}, {'boxes': tensor([[158.8000, 280.1778, 230.0000, 386.8445],\n",
      "        [  0.4000, 204.8000, 176.4000, 385.4222],\n",
      "        [147.2000, 284.4445, 240.4000, 393.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([512], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.0000,  62.5778, 371.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1862], device='cuda:0')}, {'boxes': tensor([[250.0000, 132.2667, 386.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([375], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 177.7778, 314.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1964], device='cuda:0')}, {'boxes': tensor([[206.0000, 247.4667, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1220], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.0000, 258.8445, 429.2000, 507.7333],\n",
      "        [141.6000, 140.0889, 225.2000, 377.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1789], device='cuda:0')}, {'boxes': tensor([[202.4000, 177.7778, 332.4000, 448.7111],\n",
      "        [ 87.6000,  14.9333, 142.4000,  91.0222],\n",
      "        [ 34.4000,  76.8000,  80.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([648], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 125.1556,  91.2000, 320.0000],\n",
      "        [ 76.8000,  96.7111, 225.6000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1761], device='cuda:0')}, {'boxes': tensor([[220.8000, 164.2667, 342.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1448], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 111.6444, 297.2000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([726], device='cuda:0')}, {'boxes': tensor([[  0.0000, 175.6444, 106.4000, 369.7778],\n",
      "        [120.0000, 172.0889, 258.0000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1098], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000, 104.5333, 270.0000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1460], device='cuda:0')}, {'boxes': tensor([[ 24.8000,  11.3778, 508.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  45.5111, 250.6667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1074], device='cuda:0')}, {'boxes': tensor([[170.4000,  68.2667, 436.4000, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([73], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[317.8667, 210.4889, 385.0667, 338.4889],\n",
      "        [284.8000, 179.2000, 370.1333, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([262], device='cuda:0')}, {'boxes': tensor([[ 75.7333,  56.8889, 411.7333, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1698], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.2000,   0.7111, 479.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([273], device='cuda:0')}, {'boxes': tensor([[136.0000, 188.4444, 361.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2160], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[302.0000, 172.8000, 354.4000, 260.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1446], device='cuda:0')}, {'boxes': tensor([[214.0000, 125.1556, 250.0000, 210.4889],\n",
      "        [230.4000, 150.0444, 294.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([885], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.9852, 228.9778, 283.4963, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([753], device='cuda:0')}, {'boxes': tensor([[194.4000, 379.0222, 357.2000, 509.8667],\n",
      "        [ 64.4000, 375.4667, 362.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([554], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.4000,  54.0444, 320.0000, 420.9778],\n",
      "        [  0.0000,  28.4444,  49.6000, 147.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1769], device='cuda:0')}, {'boxes': tensor([[193.2000,   0.0000, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([387], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 199.1111, 381.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2168], device='cuda:0')}, {'boxes': tensor([[ 38.8000, 332.0889,  85.6000, 509.1555],\n",
      "        [108.8000, 161.4222, 147.2000, 360.5333],\n",
      "        [234.4000, 128.7111, 264.0000, 338.4889],\n",
      "        [422.4000, 153.6000, 454.4000, 224.7111],\n",
      "        [202.4000, 137.2444, 233.6000, 216.8889],\n",
      "        [220.4000, 182.7556, 240.8000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([1667], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 156.4444, 272.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1129], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  68.9778, 453.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.2000, 200.5333, 433.2000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1912], device='cuda:0')}, {'boxes': tensor([[411.0092, 254.9333, 510.8257, 343.4667],\n",
      "        [404.5504, 313.6000, 510.8257, 423.4667],\n",
      "        [ 62.2385, 277.3333, 200.2202, 469.3333],\n",
      "        [437.4312, 337.0667, 510.2385, 480.0000],\n",
      "        [420.4037, 326.4000, 509.6514, 453.3333],\n",
      "        [ 43.4495, 342.4000, 137.9817, 365.8667],\n",
      "        [ 42.8624, 362.6667, 140.3303, 390.4000],\n",
      "        [ 24.6606, 388.2667, 154.4220, 429.8667],\n",
      "        [  7.0459, 425.6000, 158.5321, 507.7333],\n",
      "        [193.7615, 125.8667, 374.0183, 466.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([460], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.1333, 253.1555, 177.0667, 379.7333],\n",
      "        [388.2667, 230.4000, 435.2000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([697], device='cuda:0')}, {'boxes': tensor([[ 22.4000,  70.4000, 259.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1432], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[159.2000, 201.9556, 347.6000, 478.5778],\n",
      "        [ 60.8000, 204.8000, 361.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([550], device='cuda:0')}, {'boxes': tensor([[ 64.5872, 121.6000, 376.3670, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([427], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.4000, 111.6444, 510.8000, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1001], device='cuda:0')}, {'boxes': tensor([[165.6000, 201.9556, 383.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1595], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.2000, 314.3111, 328.0000, 342.0444],\n",
      "        [308.8000, 272.3556, 330.4000, 305.0667],\n",
      "        [310.4000, 236.8000, 331.6000, 265.2444],\n",
      "        [311.2000, 200.5333, 332.4000, 230.4000],\n",
      "        [309.6000, 167.8222, 330.8000, 199.1111],\n",
      "        [282.0000, 158.5778, 303.2000, 190.5778],\n",
      "        [256.0000, 157.1555, 276.4000, 187.7333],\n",
      "        [232.8000, 145.0667, 254.0000, 176.3556],\n",
      "        [204.8000, 138.6667, 225.6000, 170.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([119], device='cuda:0')}, {'boxes': tensor([[194.8000, 109.5111, 432.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([540], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[126.4000, 259.1476, 306.4000, 382.9508]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([973], device='cuda:0')}, {'boxes': tensor([[118.4000,  12.8000, 428.8000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([665], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 236.8000,  48.7339, 352.0000],\n",
      "        [430.3853, 235.7333, 472.0734, 284.8000],\n",
      "        [472.0734, 213.3333, 510.2385, 268.8000],\n",
      "        [297.6881, 176.0000, 437.4312, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([480], device='cuda:0')}, {'boxes': tensor([[143.6000, 190.5778, 368.4000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[121.6000,  85.3333, 293.6000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1853], device='cuda:0')}, {'boxes': tensor([[168.4000, 177.7778, 333.2000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 42.6667,  51.2000, 282.6667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1501], device='cuda:0')}, {'boxes': tensor([[140.0000,   7.1111, 236.0000, 182.0444],\n",
      "        [225.6000,  17.0667, 311.2000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.2000, 206.9333, 287.2000, 229.6889],\n",
      "        [262.8000, 238.9333, 283.6000, 263.8222],\n",
      "        [259.2000, 270.2222, 281.6000, 292.9778],\n",
      "        [257.2000, 302.9333, 278.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([153], device='cuda:0')}, {'boxes': tensor([[275.6000,  32.7111, 375.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([807], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.4000, 284.4445, 429.6000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([579], device='cuda:0')}, {'boxes': tensor([[ 63.2000, 227.5556, 176.0000, 507.7333],\n",
      "        [286.4000, 194.8445, 343.2000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([777], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.8000,   0.0000, 266.4000, 159.2889],\n",
      "        [253.6000,   0.0000, 396.8000, 159.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1748], device='cuda:0')}, {'boxes': tensor([[194.8000, 176.3556, 301.2000, 270.2222],\n",
      "        [ 42.4000, 203.3778, 179.2000, 312.1778],\n",
      "        [189.6000, 243.2000, 316.8000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1576], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 216.8889, 264.4000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2059], device='cuda:0')}, {'boxes': tensor([[ 68.0000, 170.6667, 295.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([865], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 33.6000,   9.2444, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1116], device='cuda:0')}, {'boxes': tensor([[139.7333, 275.9111, 315.7333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2124], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 163.0815, 237.8667, 297.7185]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1144], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 130.1333, 340.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1299], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 133.6889, 461.2000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([341], device='cuda:0')}, {'boxes': tensor([[103.6000, 117.3333, 511.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([731], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[494.8732, 148.8000, 510.1972, 334.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1486], device='cuda:0')}, {'boxes': tensor([[240.4000, 147.2000, 377.2000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([89], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[376.9541, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 263.4667,  69.8716, 412.8000],\n",
      "        [238.3853, 200.5333, 381.6514, 485.3333],\n",
      "        [258.3486, 306.1333, 413.9449, 507.7333],\n",
      "        [111.5596, 244.2667, 216.0734, 361.6000],\n",
      "        [380.4771, 274.1333, 458.5688, 345.6000],\n",
      "        [ 46.9725, 265.6000, 140.9174, 403.2000],\n",
      "        [  0.0000, 210.1333,  78.6789, 275.2000],\n",
      "        [125.0642, 245.3333, 233.1009, 352.0000],\n",
      "        [236.0367, 125.8667, 510.2385, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([446], device='cuda:0')}, {'boxes': tensor([[200.0000, 299.6364, 371.2000, 500.3636],\n",
      "        [152.8000, 336.0000, 233.6000, 485.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1322], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.8000, 272.7869, 377.6000, 375.6066]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([977], device='cuda:0')}, {'boxes': tensor([[ 71.2000,  96.5246, 240.8000, 500.4590]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([960], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.8000,  14.2222, 324.0000, 496.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([264], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([226], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[266.4000, 237.5111, 362.8000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([129], device='cuda:0')}, {'boxes': tensor([[ 23.6000,  11.3778, 508.8000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1582], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 110.9333, 422.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([208], device='cuda:0')}, {'boxes': tensor([[217.6000, 170.6667, 288.0000, 325.6889],\n",
      "        [224.0000,  68.2667, 361.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1227], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  88.1778, 243.2000, 253.1555],\n",
      "        [243.2000,  69.6889, 366.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1740], device='cuda:0')}, {'boxes': tensor([[262.0000, 136.5333, 338.8000, 184.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1381], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[326.4000, 264.5333, 406.4000, 285.8667],\n",
      "        [151.4667, 268.8000, 230.4000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2116], device='cuda:0')}, {'boxes': tensor([[232.4000, 164.2667, 335.6000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([216], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.8963, 120.8889, 511.0518, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([169], device='cuda:0')}, {'boxes': tensor([[240.7339, 172.8000, 496.1468, 314.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([472], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000, 172.8000, 339.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2175], device='cuda:0')}, {'boxes': tensor([[ 62.4000,   0.7111, 448.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 233.2444, 510.9333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([242], device='cuda:0')}, {'boxes': tensor([[243.2000,  60.4444, 346.8000, 384.0000],\n",
      "        [319.2000, 143.6444, 362.4000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1537], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.4519, 106.6667, 508.2074, 399.6444],\n",
      "        [181.0963, 322.8445, 275.9111, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([177], device='cuda:0')}, {'boxes': tensor([[ 62.5778,  21.3333, 485.4518, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1826], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 341.3333, 249.5413, 503.4667],\n",
      "        [128.5872,  23.4667, 386.3486, 487.4667],\n",
      "        [390.4587, 217.6000, 506.1284, 281.6000],\n",
      "        [423.9266, 288.0000, 504.3670, 471.4667],\n",
      "        [382.2385, 270.9333, 479.1193, 457.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([467], device='cuda:0')}, {'boxes': tensor([[  3.2000,  12.8000, 311.6000, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([294], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.2000, 140.0889, 288.4000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1909], device='cuda:0')}, {'boxes': tensor([[308.8000,  51.2000, 438.4000, 261.6889],\n",
      "        [128.0000,  71.1111, 272.0000, 261.6889],\n",
      "        [ 64.0000, 113.7778, 223.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1757], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 367.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1386], device='cuda:0')}, {'boxes': tensor([[ 65.6000, 200.5333, 369.6000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1269], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.8000, 100.9778, 253.6000, 475.0222],\n",
      "        [268.8000, 139.3778, 412.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1428], device='cuda:0')}, {'boxes': tensor([[149.2000, 247.4667, 320.4000, 477.8667],\n",
      "        [ 40.4000, 221.1555, 352.8000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([557], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 214.7556, 396.8000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([70], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 511.2000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([796], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.6000,  70.4000, 233.2000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1907], device='cuda:0')}, {'boxes': tensor([[  0.0000, 102.4000, 255.2000, 289.4222],\n",
      "        [239.6000, 211.9111, 398.8000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1406], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.2667, 253.1555, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([247], device='cuda:0')}, {'boxes': tensor([[386.0000, 154.3111, 510.8000, 233.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([534], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 344.5333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1257], device='cuda:0')}, {'boxes': tensor([[ 53.3333,   0.0000, 509.8667, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1493], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[264.8000, 272.7869, 388.0000, 375.6066]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([978], device='cuda:0')}, {'boxes': tensor([[236.8000, 213.3333, 302.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1337], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 122.3111, 250.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1006], device='cuda:0')}, {'boxes': tensor([[211.2000, 125.1556, 309.3333, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1590], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 317.1555, 194.1333, 438.0444],\n",
      "        [372.2667, 298.6667, 432.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([703], device='cuda:0')}, {'boxes': tensor([[ 67.2000,   0.0000, 313.6000, 457.9556],\n",
      "        [394.6667,  73.9556, 509.8667, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([609], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000,   0.0000, 164.0000,  66.8444],\n",
      "        [193.6000, 107.3778, 370.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([390], device='cuda:0')}, {'boxes': tensor([[  0.0000, 108.0889, 320.0000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1949], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 23.2000,  74.6667, 453.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1115], device='cuda:0')}, {'boxes': tensor([[ 50.4000,  76.0889, 452.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1114], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 160.0000, 276.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([887], device='cuda:0')}, {'boxes': tensor([[136.4000, 169.2444, 265.2000, 377.6000],\n",
      "        [262.4000, 127.2889, 412.4000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([561], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000, 146.4889,  69.3333, 223.2889],\n",
      "        [339.2000, 173.5111, 482.1333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([679], device='cuda:0')}, {'boxes': tensor([[ 37.2000,  90.3111, 237.6000, 482.8445],\n",
      "        [222.8000, 142.2222, 324.8000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([914], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.6000, 236.8000, 263.2000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([864], device='cuda:0')}, {'boxes': tensor([[149.7248, 129.0667, 419.2294, 437.3333],\n",
      "        [408.6606,  89.6000, 438.0183, 192.0000],\n",
      "        [ 35.2294, 106.6667,  94.5321, 172.8000],\n",
      "        [ 85.7248, 118.4000, 156.1835, 173.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([435], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[100.0000,   0.0000, 352.8000, 384.0000],\n",
      "        [292.8000, 256.0000, 506.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1629], device='cuda:0')}, {'boxes': tensor([[132.8000, 196.9778, 382.0000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1606], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 157.1555, 400.4000, 297.2444],\n",
      "        [ 95.6000, 142.2222, 289.2000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([903], device='cuda:0')}, {'boxes': tensor([[234.8000, 202.6667, 250.0000, 225.4222],\n",
      "        [280.8000, 224.0000, 305.6000, 256.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([845], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 206.9333, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2074], device='cuda:0')}, {'boxes': tensor([[259.2000, 200.5333, 406.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([30], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.6000, 239.6444, 308.4000, 305.7778],\n",
      "        [373.2000, 337.0667, 400.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([882], device='cuda:0')}, {'boxes': tensor([[119.2000, 291.6721, 137.6000, 312.6557],\n",
      "        [272.0000, 286.4262, 291.2000, 310.5574],\n",
      "        [185.6000, 210.8852, 250.4000, 375.6066],\n",
      "        [365.6000, 313.7049, 503.2000, 443.8033],\n",
      "        [337.6000, 329.4426, 410.4000, 422.8197]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([965], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.5333, 224.7111, 384.0000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2104], device='cuda:0')}, {'boxes': tensor([[121.6000, 179.2000, 371.2000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1302], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.8000, 216.1778, 353.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([116], device='cuda:0')}, {'boxes': tensor([[188.4000, 202.6667, 250.4000, 335.6444],\n",
      "        [116.4000, 150.0444, 185.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([1244], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  82.4889, 288.0000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1776], device='cuda:0')}, {'boxes': tensor([[227.2000, 122.3111, 341.3333, 133.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2107], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.2000, 140.8000, 462.4000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([338], device='cuda:0')}, {'boxes': tensor([[  0.0000,  89.6000, 277.3333, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1410], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  39.1111, 345.6000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([826], device='cuda:0')}, {'boxes': tensor([[247.2000, 257.4222, 387.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([1048], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.0000, 258.8445, 510.9333, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([252], device='cuda:0')}, {'boxes': tensor([[ 69.6000, 145.0667, 284.4000, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1560], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 177.7778, 215.4667, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1367], device='cuda:0')}, {'boxes': tensor([[ 45.8667, 273.0667, 510.9333, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([249], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.1927, 102.4000, 452.6972, 408.5333],\n",
      "        [ 54.6055, 242.1333, 186.7156, 406.4000],\n",
      "        [123.3027,  99.2000, 190.2385, 154.6667],\n",
      "        [438.0183,  80.0000, 476.1835, 172.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([433], device='cuda:0')}, {'boxes': tensor([[192.4000, 140.0889, 362.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([82], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,   5.6889, 509.6000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([310], device='cuda:0')}, {'boxes': tensor([[145.6000,  32.7111, 333.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([391], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,  44.0889, 322.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1547], device='cuda:0')}, {'boxes': tensor([[246.4000, 206.9333, 387.2000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([647], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[286.9333, 102.4000, 371.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1586], device='cuda:0')}, {'boxes': tensor([[ 81.6000, 189.1555, 239.6000, 372.6222],\n",
      "        [276.4000, 171.3778, 424.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1092], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 156.4444, 314.4000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1993], device='cuda:0')}, {'boxes': tensor([[122.3111, 130.8445, 509.1555, 420.9778],\n",
      "        [206.6963, 348.4445, 298.6667, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 242.4889, 314.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1157], device='cuda:0')}, {'boxes': tensor([[ 75.2000, 120.8889, 302.0000, 349.8667],\n",
      "        [311.2000, 223.2889, 409.6000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1554], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.3333, 315.7333, 188.8000, 393.9556],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([692], device='cuda:0')}, {'boxes': tensor([[  0.0000, 265.9556,  27.2000, 484.9778],\n",
      "        [253.6000, 288.7111, 276.0000, 372.6222],\n",
      "        [287.2000, 284.4445, 328.0000, 399.6444],\n",
      "        [129.6000, 207.6444, 198.4000, 489.2444],\n",
      "        [204.8000, 295.8222, 221.6000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([774], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 280.1778, 149.2000, 415.2889],\n",
      "        [122.4000, 137.9556, 146.8000, 177.7778],\n",
      "        [325.6000, 185.6000, 377.6000, 278.7556],\n",
      "        [ 76.4000, 128.7111, 112.8000, 167.8222],\n",
      "        [286.4000, 135.1111, 310.0000, 216.8889],\n",
      "        [174.4000, 210.4889, 257.2000, 292.9778],\n",
      "        [332.0000, 167.8222, 415.2000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2027], device='cuda:0')}, {'boxes': tensor([[ 63.2000, 169.2444, 334.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([870], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.5360e+02, 3.1360e+02, 4.9280e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([298], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2152], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.0000,  44.0889, 450.8000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([821], device='cuda:0')}, {'boxes': tensor([[186.8000,  64.0000, 281.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1901], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000,  91.7333, 278.0000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([263], device='cuda:0')}, {'boxes': tensor([[155.2000, 149.3333, 277.6000, 285.8667],\n",
      "        [  1.6000, 142.2222,  44.0000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1382], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.8000, 135.1111, 354.8000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([405], device='cuda:0')}, {'boxes': tensor([[151.6000, 164.9778, 278.4000, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1461], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.0000,  96.7111, 368.0000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1984], device='cuda:0')}, {'boxes': tensor([[ 45.2000,  53.3333, 338.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.5929e+02, 3.2760e+02, 4.9849e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([304], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 376.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1624], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[354.1333,  17.0667, 510.9333, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1725], device='cuda:0')}, {'boxes': tensor([[144.0000, 290.1333, 172.8000, 409.6000],\n",
      "        [226.4000, 284.4445, 261.6000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([767], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([320], device='cuda:0')}, {'boxes': tensor([[326.8000, 196.9778, 482.4000, 424.5333],\n",
      "        [130.8000, 104.5333, 310.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.4000, 142.9333, 329.6000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([2], device='cuda:0')}, {'boxes': tensor([[103.6000, 132.2667, 220.4000, 317.1555],\n",
      "        [195.2000,  76.8000, 370.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([566], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[362.0000, 214.0444, 510.8000, 330.6667],\n",
      "        [249.2000, 305.0667, 510.4000, 491.3778],\n",
      "        [ 64.4000, 234.6667, 189.6000, 340.6222],\n",
      "        [  0.0000, 213.3333,  33.2000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1468], device='cuda:0')}, {'boxes': tensor([[  0.0000, 191.2889,  78.8000, 295.8222],\n",
      "        [126.8000, 199.8222, 140.4000, 217.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000, 200.5333, 334.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1933], device='cuda:0')}, {'boxes': tensor([[114.0000,  46.2222, 474.0000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([352], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.2000,  46.2222, 376.8000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([806], device='cuda:0')}, {'boxes': tensor([[167.3394, 324.2667, 329.9817, 494.9333],\n",
      "        [222.5321, 259.2000, 344.0734, 449.0667],\n",
      "        [265.9817, 179.2000, 363.4496, 337.0667],\n",
      "        [428.0367, 273.0667, 452.6972, 331.7333],\n",
      "        [140.9174, 236.8000, 244.2569, 315.7333],\n",
      "        [110.3853, 264.5333, 217.2477, 327.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([466], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.7248, 129.0667, 412.7706, 437.3333],\n",
      "        [411.0092,  91.7333, 439.7798, 195.2000],\n",
      "        [ 38.7523, 109.8667,  97.4679, 176.0000],\n",
      "        [ 88.6606, 121.6000, 157.9450, 177.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([436], device='cuda:0')}, {'boxes': tensor([[  0.0000, 176.3556, 388.8000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1217], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 196.2667, 364.8000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1266], device='cuda:0')}, {'boxes': tensor([[184.0000, 255.2889, 330.8000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1924], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 32.0000, 203.3778, 187.6000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1653], device='cuda:0')}, {'boxes': tensor([[ 17.6000, 263.8222, 511.2000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2018e+02, 4.2080e+02, 3.1502e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([729], device='cuda:0')}, {'boxes': tensor([[106.4000, 211.9111, 243.2000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2033], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 213.3333, 411.7333, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1715], device='cuda:0')}, {'boxes': tensor([[  0.5872, 421.3333, 402.2018, 506.6667],\n",
      "        [452.1101, 370.1333, 510.2385, 491.7333],\n",
      "        [299.4496, 299.7333, 437.4312, 433.0667],\n",
      "        [344.6606, 336.0000, 493.2110, 504.5333],\n",
      "        [191.4128, 359.4667, 216.6606, 424.5333],\n",
      "        [214.3119, 356.2667, 260.6972, 432.0000],\n",
      "        [176.7339, 279.4667, 313.5413, 429.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([440], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.0667, 261.6889, 499.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([238], device='cuda:0')}, {'boxes': tensor([[144.8000,   0.0000, 356.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([815], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.2593, 109.5111, 510.1037, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([168], device='cuda:0')}, {'boxes': tensor([[250.0000, 161.4222, 365.2000, 309.3333],\n",
      "        [283.6000, 156.4444, 388.0000, 273.0667],\n",
      "        [ 77.2000, 172.0889, 120.0000, 199.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([889], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 110.1639, 175.2000, 401.8361]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([962], device='cuda:0')}, {'boxes': tensor([[234.6667, 219.0222, 298.6667, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2126], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 201.9556, 280.0000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1124], device='cuda:0')}, {'boxes': tensor([[149.7248, 193.0667, 395.7431, 363.7333],\n",
      "        [125.0642, 228.2667, 159.7064, 266.6667],\n",
      "        [ 65.1743, 234.6667, 112.7339, 277.3333],\n",
      "        [109.7982, 277.3333, 139.7431, 321.0667],\n",
      "        [389.8716, 252.8000, 464.4404, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7,  7, 19,  7], device='cuda:0'), 'image_id': tensor([439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.9333,  41.2444, 296.5333, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1504], device='cuda:0')}, {'boxes': tensor([[166.8000, 117.3333, 219.6000, 174.2222],\n",
      "        [334.8000,  88.1778, 380.4000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1867], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[144.0000,  54.0444, 220.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2150], device='cuda:0')}, {'boxes': tensor([[  7.4667, 179.2000, 306.1333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([196], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 197.3333, 433.7778],\n",
      "        [376.5333, 291.5555, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([708], device='cuda:0')}, {'boxes': tensor([[ 39.4667,  56.8889, 299.7333, 194.8445],\n",
      "        [317.8667, 176.3556, 395.7333, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([667], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.8000,  85.3333, 368.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([68], device='cuda:0')}, {'boxes': tensor([[171.2000, 221.8667, 454.4000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1037], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 43.7333, 201.9556, 253.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1043], device='cuda:0')}, {'boxes': tensor([[ 90.8000,  88.1778, 242.4000, 273.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2062], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,   2.8444, 323.2000, 457.9556],\n",
      "        [413.8667, 108.0889, 507.7333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([604], device='cuda:0')}, {'boxes': tensor([[ 78.4000,  29.8667, 341.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([61], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.8000, 126.5778, 262.8000, 325.6889],\n",
      "        [258.0000, 103.1111, 420.0000, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([562], device='cuda:0')}, {'boxes': tensor([[274.0000,  78.9333, 474.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[331.2000, 206.2222, 415.2000, 373.3333],\n",
      "        [109.2000, 190.5778, 239.6000, 395.3778],\n",
      "        [238.0000, 234.6667, 265.6000, 304.3556],\n",
      "        [266.4000, 236.0889, 281.6000, 289.4222],\n",
      "        [290.8000, 241.0667, 332.0000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([1908], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 428.8000, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1642], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.8000, 236.8000, 338.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([530], device='cuda:0')}, {'boxes': tensor([[  0.0000, 118.7556, 288.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1374], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 141.5111, 352.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([658], device='cuda:0')}, {'boxes': tensor([[144.8000, 115.9111, 237.2000, 419.5555],\n",
      "        [236.8000, 108.0889, 356.0000, 386.8445],\n",
      "        [223.2000, 201.9556, 274.4000, 369.0667],\n",
      "        [  0.0000, 268.8000,  24.8000, 285.1555],\n",
      "        [102.8000, 241.0667, 144.0000, 257.4222],\n",
      "        [454.8000, 335.6444, 510.4000, 364.8000],\n",
      "        [447.2000, 432.3556, 510.4000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2068], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.4000, 257.4222, 192.0000, 418.1333],\n",
      "        [277.6000, 261.6889, 318.4000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([766], device='cuda:0')}, {'boxes': tensor([[220.8000, 224.7111, 249.6000, 356.2667],\n",
      "        [267.2000, 166.4000, 297.2000, 228.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1648], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.8000,   0.0000, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1659], device='cuda:0')}, {'boxes': tensor([[ 51.2000,  76.8000, 422.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1031], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.1333,  22.7556, 346.6667, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1719], device='cuda:0')}, {'boxes': tensor([[211.2000, 224.7111, 353.0667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2101], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.0000, 125.8667, 510.4000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1039], device='cuda:0')}, {'boxes': tensor([[ 33.2000,  85.3333, 238.4000, 482.8445],\n",
      "        [224.4000, 140.0889, 358.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([913], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 305.7778, 193.0667, 433.7778],\n",
      "        [379.7333, 291.5555, 446.9333, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([710], device='cuda:0')}, {'boxes': tensor([[193.2000, 108.8000, 393.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1352], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 97.6000, 347.0222, 197.6000, 509.1555],\n",
      "        [353.6000, 342.7556, 455.2000, 510.5778],\n",
      "        [ 15.2000, 325.6889,  92.8000, 510.5778],\n",
      "        [277.6000, 315.7333, 328.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([785], device='cuda:0')}, {'boxes': tensor([[213.3333, 119.4667, 407.4667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([205], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000, 207.6444, 280.8000, 241.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([940], device='cuda:0')}, {'boxes': tensor([[134.4000, 116.2667, 176.0000, 163.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([793], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 206.2222, 168.5333, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1362], device='cuda:0')}, {'boxes': tensor([[101.3333, 234.6667, 155.7333, 300.0889],\n",
      "        [133.3333, 194.8445, 185.6000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([682], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 140.0889, 285.6000, 290.1333],\n",
      "        [230.0000, 205.5111, 378.8000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1407], device='cuda:0')}, {'boxes': tensor([[ 75.2000,  45.5111, 235.2000, 228.9778],\n",
      "        [216.0000,  32.7111, 369.6000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1752], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000, 176.3556, 508.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1223], device='cuda:0')}, {'boxes': tensor([[230.0000,  45.5111, 445.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([822], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.8000, 187.0222, 360.0000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2161], device='cuda:0')}, {'boxes': tensor([[104.2963, 110.9333, 509.1555, 403.9111],\n",
      "        [184.8889, 327.1111, 280.6519, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([176], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.0000, 189.8667, 162.8000, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1261], device='cuda:0')}, {'boxes': tensor([[140.8000, 284.4445, 160.0000, 388.2667],\n",
      "        [223.2000, 284.4445, 249.6000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([768], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  3.6000,  78.9333, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1210], device='cuda:0')}, {'boxes': tensor([[256.0000, 204.8000, 283.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([939], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.2000,  18.4889, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1580], device='cuda:0')}, {'boxes': tensor([[ 86.4000,  41.2444, 355.2000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([62], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.6000,  25.6000, 204.4000, 145.7778],\n",
      "        [258.0000, 219.7333, 406.0000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([388], device='cuda:0')}, {'boxes': tensor([[  0.0000, 158.5778, 107.2000, 510.5778],\n",
      "        [118.0000, 138.6667, 275.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([498], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 204.8000, 130.1333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2091], device='cuda:0')}, {'boxes': tensor([[155.7333, 261.6889, 295.4667, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2133], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000,   0.0000, 510.4000, 498.4889],\n",
      "        [168.4000,  23.4667, 418.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1665], device='cuda:0')}, {'boxes': tensor([[204.0000,   0.0000, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([386], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.8000, 133.6889, 336.0000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([741], device='cuda:0')}, {'boxes': tensor([[249.6000,  79.6444, 374.4000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([828], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.3111,  85.3333, 511.0518, 395.3778],\n",
      "        [178.2518, 310.0444, 274.0148, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([178], device='cuda:0')}, {'boxes': tensor([[172.0000,  94.5778, 282.0000, 472.1778],\n",
      "        [255.2000, 156.4444, 316.8000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1529], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 40.5333,  15.6444, 302.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1076], device='cuda:0')}, {'boxes': tensor([[130.6205,  88.8889, 475.7165, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2095], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  21.3333, 364.8000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1030], device='cuda:0')}, {'boxes': tensor([[ 49.2000,  69.6889, 343.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([224], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.2667, 150.7556,  62.9333, 230.4000],\n",
      "        [343.4667, 182.0444, 478.9333, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([678], device='cuda:0')}, {'boxes': tensor([[  0.0000, 176.3556, 122.4000, 280.1778],\n",
      "        [172.0000, 199.1111, 185.6000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2079], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 147.2000, 278.8000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1215], device='cuda:0')}, {'boxes': tensor([[181.2000, 136.5333, 338.4000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([922], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.8000,  82.4889, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1773], device='cuda:0')}, {'boxes': tensor([[146.8000, 194.1333, 510.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 295.1111, 456.8000, 489.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1916], device='cuda:0')}, {'boxes': tensor([[115.2000,  92.4444, 272.8000, 261.6889],\n",
      "        [249.6000,  76.8000, 361.6000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1742], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.2000,  91.0222, 322.0000, 369.0667],\n",
      "        [403.6000, 283.7333, 415.2000, 315.7333],\n",
      "        [428.4000, 281.6000, 437.6000, 318.5778],\n",
      "        [498.8000, 269.5111, 511.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1007], device='cuda:0')}, {'boxes': tensor([[120.8000,   0.0000, 302.0000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([814], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,   0.0000, 252.8000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1177], device='cuda:0')}, {'boxes': tensor([[211.2000, 263.1111, 301.6000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1002], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 177.7778, 385.8963, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([755], device='cuda:0')}, {'boxes': tensor([[116.4000, 205.5111, 329.6000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1155], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000, 167.8222, 456.5333, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([230], device='cuda:0')}, {'boxes': tensor([[ 74.4000,   0.0000, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000, 376.8889, 249.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2015], device='cuda:0')}, {'boxes': tensor([[265.6000, 179.2000, 350.4000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([852], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 123.2000,  98.1333],\n",
      "        [333.6000, 341.3333, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1623], device='cuda:0')}, {'boxes': tensor([[ 95.2000, 104.5333, 294.8000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([266], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1513], device='cuda:0')}, {'boxes': tensor([[ 14.4000, 411.2787,  35.2000, 436.4590],\n",
      "        [233.6000, 231.8689, 248.8000, 254.9508],\n",
      "        [ 52.8000, 371.4099,  74.4000, 418.6230],\n",
      "        [ 92.8000, 393.4426, 122.4000, 437.5082],\n",
      "        [404.8000, 193.0492, 431.2000, 229.7705]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([974], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.0667, 250.3111, 510.9333, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([248], device='cuda:0')}, {'boxes': tensor([[267.2000, 179.2000, 292.0000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2054], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([283], device='cuda:0')}, {'boxes': tensor([[  0.0000,  71.1111, 278.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6741,  91.0222, 448.4741, 378.3111],\n",
      "        [178.2518, 307.2000, 270.2222, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([184], device='cuda:0')}, {'boxes': tensor([[ 60.8000,  32.7111, 302.9333, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1505], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[376.8000, 256.0000, 450.8000, 470.0444],\n",
      "        [218.8000, 155.0222, 343.2000, 323.5555],\n",
      "        [ 58.0000, 172.8000, 123.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27,  5], device='cuda:0'), 'image_id': tensor([1346], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 187.7333, 227.2000, 366.2222],\n",
      "        [280.0000, 179.2000, 425.6000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1096], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.8000, 224.0000, 510.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1040], device='cuda:0')}, {'boxes': tensor([[114.4000, 241.3115, 380.0000, 391.3443]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([968], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[207.6000,  52.6222, 352.0000, 364.0889],\n",
      "        [233.2000, 270.9333, 243.2000, 302.2222],\n",
      "        [411.2000, 252.4444, 444.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1013], device='cuda:0')}, {'boxes': tensor([[190.0000,  27.0222, 322.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1052], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[245.6000, 160.7111, 326.0000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1], device='cuda:0')}, {'boxes': tensor([[171.2000, 260.2667, 201.6000, 392.5333],\n",
      "        [256.0000, 260.2667, 283.2000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([764], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.9333, 247.4667, 219.7333, 268.8000],\n",
      "        [309.3333, 238.9333, 424.5333, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2111], device='cuda:0')}, {'boxes': tensor([[111.2000, 299.7333, 184.0000, 382.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([794], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[263.6000, 100.2667, 398.0000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1458], device='cuda:0')}, {'boxes': tensor([[ 38.4000, 164.9778, 163.2000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([199], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([761], device='cuda:0')}, {'boxes': tensor([[  0.0000,  60.4444, 210.8000, 502.7556],\n",
      "        [168.4000, 194.1333, 390.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([909], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.4667, 157.8667, 221.8667, 219.0222],\n",
      "        [214.4000, 169.2444, 296.5333, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([362], device='cuda:0')}, {'boxes': tensor([[ 90.8000, 125.8667, 300.0000, 437.3333],\n",
      "        [280.8000, 201.9556, 324.8000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([906], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.2667, 187.7333, 410.6667, 284.4445],\n",
      "        [258.1333, 186.3111, 363.7333, 280.1778],\n",
      "        [125.8667, 162.1333, 179.2000, 227.5556],\n",
      "        [396.8000, 223.2889, 490.6667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([356], device='cuda:0')}, {'boxes': tensor([[238.9333, 129.4222, 509.8667, 365.5111],\n",
      "        [  4.2667,   0.0000, 472.5333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([51], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.8000,   5.6889, 338.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([132], device='cuda:0')}, {'boxes': tensor([[ 58.7156,  76.8000, 466.2018, 407.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([476], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000, 154.3111, 454.0000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([372], device='cuda:0')}, {'boxes': tensor([[  0.4000, 135.1111, 359.6000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([728], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.7333, 176.3556, 326.1630, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([760], device='cuda:0')}, {'boxes': tensor([[ 98.0000,  44.0889, 366.8000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([818], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000, 261.6889, 280.0000, 459.3778],\n",
      "        [333.6000, 260.2667, 400.0000, 509.1555],\n",
      "        [156.8000, 253.1555, 194.4000, 413.8667],\n",
      "        [287.2000, 248.8889, 315.2000, 369.7778],\n",
      "        [ 15.2000, 311.4667, 128.8000, 506.3111],\n",
      "        [487.2000, 332.8000, 511.2000, 506.3111],\n",
      "        [468.8000, 292.9778, 500.0000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([789], device='cuda:0')}, {'boxes': tensor([[116.8000, 284.4445, 229.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.8000,   0.7111, 376.8000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([133], device='cuda:0')}, {'boxes': tensor([[ 77.8667, 253.1555, 510.9333, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([243], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 157.8667,  53.0963, 220.4444],\n",
      "        [ 45.5111, 160.7111,  82.4889, 199.1111],\n",
      "        [192.4741, 169.2444, 257.8963, 226.1333],\n",
      "        [414.3407, 160.7111, 493.0370, 223.2889],\n",
      "        [252.2074, 149.3333, 320.4741, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 3], device='cuda:0'), 'image_id': tensor([1140], device='cuda:0')}, {'boxes': tensor([[327.3114,   8.5333, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1974], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 159.2889, 455.4667, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1066], device='cuda:0')}, {'boxes': tensor([[201.6000, 151.4667, 297.6000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1845], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.8000, 276.6222, 435.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([656], device='cuda:0')}, {'boxes': tensor([[267.2000, 115.2000, 352.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1132], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.4000,  85.3333, 384.0000, 382.5778],\n",
      "        [337.6000, 130.1333, 425.2000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1543], device='cuda:0')}, {'boxes': tensor([[137.6000,  34.8444, 346.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1480], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.8000, 187.7333, 326.8000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1349], device='cuda:0')}, {'boxes': tensor([[204.0000,  82.4889, 346.4000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1781], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.6000, 241.0667, 246.0000, 393.9556],\n",
      "        [336.0000, 180.6222, 474.8000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([642], device='cuda:0')}, {'boxes': tensor([[340.8000,  79.6444, 473.6000, 275.9111],\n",
      "        [154.4000,  79.6444, 289.6000, 295.8222],\n",
      "        [ 51.2000, 132.2667, 192.0000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1756], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 159.2889, 280.8000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([932], device='cuda:0')}, {'boxes': tensor([[448.8000,   0.0000, 480.8000,  47.2131]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([975], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 109.5111, 318.4000, 200.5333],\n",
      "        [ 90.0000, 170.6667, 234.4000, 261.6889],\n",
      "        [ 61.6000, 265.2444, 170.4000, 330.6667],\n",
      "        [ 60.8000, 342.0444, 100.8000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([148], device='cuda:0')}, {'boxes': tensor([[ 94.4000, 180.6222, 507.2000, 364.0889],\n",
      "        [ 28.8000, 125.1556, 147.2000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1639], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 198.4000, 361.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1268], device='cuda:0')}, {'boxes': tensor([[  8.5333,   0.0000, 510.9333, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1022], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000, 201.9556, 328.0000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1597], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1252], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.8000,  91.0222, 355.2000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1356], device='cuda:0')}, {'boxes': tensor([[180.4000, 187.0222, 322.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1966], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.4000,  12.8000, 510.4000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([799], device='cuda:0')}, {'boxes': tensor([[147.6000, 119.4667, 194.8000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1260], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.0000, 281.6000, 280.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([982], device='cuda:0')}, {'boxes': tensor([[ 80.8000, 182.7556, 232.4000, 365.5111],\n",
      "        [276.4000, 172.8000, 424.4000, 352.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1093], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[288.0000, 214.7556, 312.8000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2052], device='cuda:0')}, {'boxes': tensor([[240.8000, 187.7333, 344.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2182], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.6000,  78.2222, 342.0000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([897], device='cuda:0')}, {'boxes': tensor([[ 56.8000, 109.5111, 238.0000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([212], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 161.4222, 423.6000, 440.8889],\n",
      "        [ 60.4000, 258.8445, 152.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([866], device='cuda:0')}, {'boxes': tensor([[ 12.8000, 157.8667,  72.5333, 226.1333],\n",
      "        [375.4667, 192.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([674], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.2000, 224.7111, 288.4000, 330.6667],\n",
      "        [112.0000, 194.1333, 193.2000, 296.5333],\n",
      "        [225.2000, 234.6667, 302.0000, 322.1333],\n",
      "        [137.6000, 209.7778, 218.0000, 297.9556],\n",
      "        [158.4000, 205.5111, 227.2000, 290.1333],\n",
      "        [250.8000, 237.5111, 321.2000, 328.5333],\n",
      "        [319.2000, 258.8445, 398.0000, 358.4000],\n",
      "        [338.4000, 283.0222, 418.0000, 387.5555],\n",
      "        [239.6000, 237.5111, 317.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([121], device='cuda:0')}, {'boxes': tensor([[122.0000, 289.4222, 150.0000, 489.9556],\n",
      "        [127.6000, 156.4444, 150.4000, 197.6889],\n",
      "        [386.0000, 200.5333, 460.8000, 276.6222],\n",
      "        [ 78.8000, 147.9111,  97.2000, 179.9111],\n",
      "        [296.0000, 172.8000, 344.8000, 243.2000],\n",
      "        [341.2000, 180.6222, 426.4000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2026], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 136.5333, 231.2000, 321.4222],\n",
      "        [221.2000,  86.7556, 374.0000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([565], device='cuda:0')}, {'boxes': tensor([[218.4000,  99.5556, 418.0000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([493], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 226.8445, 183.6000, 302.2222],\n",
      "        [278.0000, 225.4222, 330.8000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1562], device='cuda:0')}, {'boxes': tensor([[187.6000, 179.2000, 270.0000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1339], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000, 182.0444, 228.2667, 237.0370]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1149], device='cuda:0')}, {'boxes': tensor([[  0.0000, 113.7778, 395.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1298], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.0000, 244.6222, 408.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([27], device='cuda:0')}, {'boxes': tensor([[242.7259,   0.0000, 475.0222, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1829], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.4000, 187.0222, 252.4000, 364.8000],\n",
      "        [282.4000, 182.7556, 425.6000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1097], device='cuda:0')}, {'boxes': tensor([[307.6000, 239.6444, 440.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1498], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.4000,   0.0000, 482.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1832], device='cuda:0')}, {'boxes': tensor([[167.2000, 159.2889, 276.0000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([931], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 425.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([700], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([812], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000,   0.0000, 363.2000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1262], device='cuda:0')}, {'boxes': tensor([[179.6000, 201.9556, 373.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1596], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000,   0.0000, 442.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1612], device='cuda:0')}, {'boxes': tensor([[226.4000, 103.8222, 440.0000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1682], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.4000, 180.6222, 258.8000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([189], device='cuda:0')}, {'boxes': tensor([[143.3239,  76.8000, 401.1268, 438.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1062], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.2667, 130.8445, 248.5333, 197.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1592], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2083], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 154.3111,  64.0000, 252.4444],\n",
      "        [167.6000, 156.4444, 196.8000, 219.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1394], device='cuda:0')}, {'boxes': tensor([[174.4000,  29.1556, 276.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1058], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 99.6000, 238.2222, 310.0000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1162], device='cuda:0')}, {'boxes': tensor([[207.6000, 203.3778, 257.2000, 278.0444],\n",
      "        [142.8000, 238.9333, 177.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([851], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000,  73.9556, 242.4000, 247.4667],\n",
      "        [243.2000,  46.9333, 357.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1737], device='cuda:0')}, {'boxes': tensor([[211.6000,  32.0000, 338.0000, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 155.0222, 510.9333, 393.9556],\n",
      "        [  4.2667,   2.8444, 453.3333, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([52], device='cuda:0')}, {'boxes': tensor([[ 45.8667,  15.6444, 300.8000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1075], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.8000, 190.5778, 511.2000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([574], device='cuda:0')}, {'boxes': tensor([[ 56.5333,  91.0222, 401.0667, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1699], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.1111,  38.4000, 425.7185, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1825], device='cuda:0')}, {'boxes': tensor([[297.2000, 131.5556, 407.2000, 259.5555],\n",
      "        [ 43.6000, 125.1556, 126.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([895], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.2000,  28.4444, 449.2000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([817], device='cuda:0')}, {'boxes': tensor([[ 47.8384, 203.6364, 181.0101, 378.1818]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2019], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 107.3778, 262.4000, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1898], device='cuda:0')}, {'boxes': tensor([[154.0000, 103.1111, 238.4000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1360], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 211.9111, 328.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1549], device='cuda:0')}, {'boxes': tensor([[120.0000,  42.6667, 380.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([345], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.2000,  77.0909, 364.8000, 280.7273],\n",
      "        [139.2000, 101.8182, 259.2000, 257.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1328], device='cuda:0')}, {'boxes': tensor([[ 55.4667,  85.3333, 249.6000, 294.4000],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1083], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[410.8000, 103.1111, 508.4000, 494.9333],\n",
      "        [136.4000,   0.0000, 490.4000, 285.1555],\n",
      "        [ 84.4000,   0.0000, 183.2000,  37.6889],\n",
      "        [421.6000,   2.1333, 508.8000, 125.1556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1800], device='cuda:0')}, {'boxes': tensor([[223.2000, 109.5111, 510.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  24.1778, 317.2000, 491.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([272], device='cuda:0')}, {'boxes': tensor([[166.4000,  30.3407, 247.4667, 510.1037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1258], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 120.8889, 241.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1948], device='cuda:0')}, {'boxes': tensor([[152.0000, 331.3778, 221.6000, 509.1555],\n",
      "        [364.0000, 322.8445, 444.0000, 510.5778],\n",
      "        [ 79.2000, 325.6889, 145.6000, 506.3111],\n",
      "        [277.6000, 304.3556, 321.6000, 473.6000],\n",
      "        [  0.0000, 307.2000,  63.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([787], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 153.6000,  64.0000, 252.4444],\n",
      "        [169.2000, 155.0222, 197.6000, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1393], device='cuda:0')}, {'boxes': tensor([[229.3333, 182.0444, 307.2000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([261], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 40.8000, 322.0984, 137.6000, 413.3770],\n",
      "        [160.8000, 305.3115, 259.2000, 400.7869]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([963], device='cuda:0')}, {'boxes': tensor([[ 76.8000, 199.1111, 118.0000, 356.2667],\n",
      "        [356.0000, 201.9556, 401.6000, 261.6889],\n",
      "        [ 55.2000, 105.9556, 134.8000, 156.4444],\n",
      "        [268.4000, 144.3556, 308.0000, 206.2222],\n",
      "        [118.0000, 201.9556, 221.2000, 293.6889],\n",
      "        [163.6000, 132.2667, 187.2000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2028], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.0000, 135.1111, 256.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1343], device='cuda:0')}, {'boxes': tensor([[196.0000, 153.6000, 373.6000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([747], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000, 125.1556, 140.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1131], device='cuda:0')}, {'boxes': tensor([[185.2000, 128.0000, 318.0000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 278.7556, 315.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1020], device='cuda:0')}, {'boxes': tensor([[146.4000, 210.4889, 244.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([416], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.9333, 209.0667, 291.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1408], device='cuda:0')}, {'boxes': tensor([[133.3333, 146.4889, 377.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1718], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.0000,  62.5778, 291.2000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([838], device='cuda:0')}, {'boxes': tensor([[147.9111, 109.5111, 511.0518, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.8000, 109.5111, 440.8000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1985], device='cuda:0')}, {'boxes': tensor([[158.4000, 152.1778, 289.6000, 356.2667],\n",
      "        [266.4000, 170.6667, 450.4000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([570], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 295.8222, 510.9333, 473.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([250], device='cuda:0')}, {'boxes': tensor([[237.2000, 187.0222, 288.0000, 258.8445],\n",
      "        [228.8000, 193.4222, 256.4000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([846], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.0000, 211.9111, 508.8000, 507.7333],\n",
      "        [  0.0000, 113.7778, 325.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1619], device='cuda:0')}, {'boxes': tensor([[ 69.3333, 310.0444, 200.5333, 435.2000],\n",
      "        [379.7333, 295.8222, 443.7333, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([712], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.3333,  59.7333, 309.3333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([725], device='cuda:0')}, {'boxes': tensor([[170.2752,  93.8667, 355.2294, 422.4000],\n",
      "        [ 44.6239, 241.0667, 155.5963, 423.4667],\n",
      "        [411.5963, 222.9333, 443.8899, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([486], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  75.3778, 260.8000, 506.3111],\n",
      "        [317.6000, 342.0444, 378.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1645], device='cuda:0')}, {'boxes': tensor([[141.6000, 207.6444, 214.4000, 484.9778],\n",
      "        [264.8000, 182.0444, 310.4000, 359.8222],\n",
      "        [492.0000, 240.3556, 508.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([779], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.8000, 189.1555, 279.2000, 315.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([894], device='cuda:0')}, {'boxes': tensor([[320.4000, 193.4222, 460.0000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([653], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 122.3111, 510.9333, 348.4445],\n",
      "        [ 32.0000,   0.0000, 500.2667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([49], device='cuda:0')}, {'boxes': tensor([[283.7333, 109.5111, 369.0667, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1587], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[114.4000, 196.9778, 234.0000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([402], device='cuda:0')}, {'boxes': tensor([[106.0000, 193.4222, 275.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2061], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000,  66.8444, 384.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([615], device='cuda:0')}, {'boxes': tensor([[208.0000, 176.3556, 252.8000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([933], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 330.6667, 277.2000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1885], device='cuda:0')}, {'boxes': tensor([[ 71.2000,  98.6229, 197.6000, 442.7541]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([961], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.6000,  86.0444, 374.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([131], device='cuda:0')}, {'boxes': tensor([[223.2000, 227.5556, 346.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2189], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000, 236.8000, 188.4000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1507], device='cuda:0')}, {'boxes': tensor([[138.0000,  71.8222, 417.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.0000, 168.5333, 332.8000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2177], device='cuda:0')}, {'boxes': tensor([[291.2000, 236.0889, 390.4000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1705], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000,   0.0000, 510.4000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1809], device='cuda:0')}, {'boxes': tensor([[ 48.8000, 179.2000, 388.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1388], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 170.6667, 465.0667, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1065], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1516], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[287.2000, 205.5111, 432.4000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1911], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  55.4667, 450.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1118], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 63.2000,  64.7111, 445.6000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([839], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  46.9333, 377.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1687], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 194.8445,  91.7333, 509.1555],\n",
      "        [147.2000,  83.9111, 334.9333, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([601], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1637], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 145.0667, 441.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([332], device='cuda:0')}, {'boxes': tensor([[128.0000,  49.3115, 284.0000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([958], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 51.2000, 117.3333, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1203], device='cuda:0')}, {'boxes': tensor([[179.2000,   0.0000, 314.8000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1307], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[394.5688, 224.0000, 509.6514, 316.8000],\n",
      "        [388.1101, 281.6000, 510.2385, 393.6000],\n",
      "        [ 45.7982, 246.4000, 182.0183, 440.5333],\n",
      "        [420.9908, 306.1333, 510.2385, 461.8667],\n",
      "        [406.3119, 294.4000, 510.2385, 421.3333],\n",
      "        [ 34.0550, 316.8000, 129.1743, 337.0667],\n",
      "        [ 25.8349, 329.6000, 125.0642, 360.5333],\n",
      "        [ 10.5688, 359.4667, 137.9817, 401.0667],\n",
      "        [  0.5872, 396.8000, 159.7064, 504.5333],\n",
      "        [195.5229,  83.2000, 366.3853, 449.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([462], device='cuda:0')}, {'boxes': tensor([[  4.8000,   9.9556, 506.0000, 481.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([282], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.4000,   4.2667, 501.6000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([307], device='cuda:0')}, {'boxes': tensor([[180.2667,   0.0000, 377.6000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([594], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.4225,  88.0000, 396.6197, 427.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1063], device='cuda:0')}, {'boxes': tensor([[ 87.2000,  75.3778, 242.4000, 244.6222],\n",
      "        [236.8000,  64.0000, 364.0000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1741], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[309.6000, 146.4889, 511.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1450], device='cuda:0')}, {'boxes': tensor([[144.1185, 170.6667, 215.2296, 250.3111],\n",
      "        [441.8370, 169.2444, 508.2074, 250.3111],\n",
      "        [186.7852, 220.4444, 286.3407, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 3], device='cuda:0'), 'image_id': tensor([1141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.4000,  14.9333, 483.6000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([290], device='cuda:0')}, {'boxes': tensor([[119.6000, 162.8445, 212.8000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([861], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.0000, 142.2222, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1652], device='cuda:0')}, {'boxes': tensor([[ 89.6000, 172.8000, 507.2000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1280], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 164.9778, 254.4000, 330.6667],\n",
      "        [198.4000, 194.1333, 265.2000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1569], device='cuda:0')}, {'boxes': tensor([[  0.0000, 192.7111, 255.6000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1376], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000,  52.6222, 381.6000, 146.4889],\n",
      "        [132.0000, 112.3556, 283.6000, 205.5111],\n",
      "        [ 62.4000, 174.2222, 203.2000, 268.8000],\n",
      "        [ 61.6000, 276.6222, 121.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([149], device='cuda:0')}, {'boxes': tensor([[233.6000,   0.7111, 422.4000, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1453], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 192.0000, 348.8000, 364.0889],\n",
      "        [485.6000, 182.7556, 509.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1108], device='cuda:0')}, {'boxes': tensor([[181.2000, 216.1778, 457.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([577], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.8000, 107.3778, 510.0000, 450.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([989], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([736], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,  32.0000, 501.6000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([288], device='cuda:0')}, {'boxes': tensor([[116.2667,   0.0000, 349.8667, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1720], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 199.8222, 201.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1654], device='cuda:0')}, {'boxes': tensor([[133.2000, 196.9778, 381.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1605], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 362.6667, 508.2074],\n",
      "        [  8.5333,  81.5407, 359.4667, 508.2074],\n",
      "        [326.4000,   0.0000, 510.9333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([35], device='cuda:0')}, {'boxes': tensor([[178.0000, 119.4667, 328.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1377], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.8000,  41.2444, 224.0000, 224.7111],\n",
      "        [308.0000,  24.1778, 468.8000, 224.7111],\n",
      "        [486.4000,  71.1111, 511.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1760], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1466], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000,  60.4444, 322.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([876], device='cuda:0')}, {'boxes': tensor([[198.8000,  98.8444, 398.8000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1351], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 253.1555, 265.6000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2134], device='cuda:0')}, {'boxes': tensor([[145.0667,   0.0000, 454.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1711], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.6000, 119.4667, 270.0000, 434.4889],\n",
      "        [263.6000, 192.0000, 374.0000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1542], device='cuda:0')}, {'boxes': tensor([[  0.5872,   9.6000, 509.6514, 507.7333],\n",
      "        [294.1651, 309.3333, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([453], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[239.6000,  83.2000, 510.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2167], device='cuda:0')}, {'boxes': tensor([[230.4000,  59.7333, 504.8000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([312], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.4000,  64.0000, 447.2000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([840], device='cuda:0')}, {'boxes': tensor([[  9.6000, 198.4000, 454.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1271], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[295.6000,  88.1778, 416.4000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1534], device='cuda:0')}, {'boxes': tensor([[152.0000, 170.6667, 363.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.4242, 265.6970, 231.4343, 467.3940]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2023], device='cuda:0')}, {'boxes': tensor([[216.8000, 182.0444, 359.6000, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1931], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 106.6667, 284.4000, 118.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1444], device='cuda:0')}, {'boxes': tensor([[ 30.9333,  73.9556, 206.9333, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1491], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.6000, 250.3111, 292.4000, 307.2000],\n",
      "        [112.0000, 263.8222, 194.8000, 318.5778],\n",
      "        [260.8000, 192.0000, 344.0000, 256.0000],\n",
      "        [150.4000, 159.2889, 240.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([135], device='cuda:0')}, {'boxes': tensor([[159.2000, 218.3111, 236.8000, 312.8889],\n",
      "        [283.6000, 226.1333, 344.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1518], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000,  61.8667, 346.0000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([342], device='cuda:0')}, {'boxes': tensor([[258.4000, 238.9333, 290.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([951], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.2000,  47.6444, 302.0000, 238.9333],\n",
      "        [295.6000,  26.3111, 453.6000, 251.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([563], device='cuda:0')}, {'boxes': tensor([[177.3211, 241.0667, 221.3578, 327.4667],\n",
      "        [134.4587, 229.3333, 194.9358, 343.4667],\n",
      "        [423.9266, 266.6667, 509.6514, 411.7333],\n",
      "        [207.8532,  49.0667, 392.2202, 414.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([451], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000, 314.3111, 197.3333, 429.5111],\n",
      "        [377.6000, 300.0889, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([704], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1649], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 127.2889, 448.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([79], device='cuda:0')}, {'boxes': tensor([[201.6000, 204.8000, 290.1333, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([259], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[388.2667, 281.6000, 509.8667, 391.1111],\n",
      "        [  0.0000, 250.3111, 246.4000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2120], device='cuda:0')}, {'boxes': tensor([[  0.0000,  79.6444, 429.8667, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1730], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[203.7333, 201.9556, 411.7333, 506.3111],\n",
      "        [210.1333,  93.8667, 442.6667, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1734], device='cuda:0')}, {'boxes': tensor([[179.2000, 214.7556, 366.8000, 497.7778],\n",
      "        [ 82.4000, 219.0222, 381.6000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([549], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.0000, 152.1778, 265.2000, 342.7556],\n",
      "        [219.6000, 175.6444, 398.0000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([568], device='cuda:0')}, {'boxes': tensor([[104.8000,  96.7111, 376.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1021], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[313.6000, 207.6444, 352.0000, 371.2000],\n",
      "        [172.0000, 220.4444, 216.0000, 480.7111],\n",
      "        [384.0000, 204.8000, 428.8000, 422.4000],\n",
      "        [424.0000, 236.0889, 509.6000, 506.3111],\n",
      "        [  0.0000, 297.2444, 126.4000, 509.1555],\n",
      "        [195.2000, 275.9111, 308.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([775], device='cuda:0')}, {'boxes': tensor([[143.6000, 103.8222, 240.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1850], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 142.2222, 294.8000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2050], device='cuda:0')}, {'boxes': tensor([[176.0000, 139.3778, 188.4000, 172.0889],\n",
      "        [224.4000, 239.6444, 248.4000, 256.0000],\n",
      "        [215.2000, 351.2889, 269.2000, 387.5555],\n",
      "        [426.4000, 338.4889, 454.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24, 24], device='cuda:0'), 'image_id': tensor([1882], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333, 135.1111, 509.1555, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([171], device='cuda:0')}, {'boxes': tensor([[  9.6000, 185.6000, 216.0000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1034], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  61.8667, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1178], device='cuda:0')}, {'boxes': tensor([[ 86.0000, 192.0000, 236.8000, 371.2000],\n",
      "        [317.2000, 170.6667, 460.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1109], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 122.3111, 289.6000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1946], device='cuda:0')}, {'boxes': tensor([[ 44.0000, 207.6444,  82.4000, 300.0889],\n",
      "        [ 91.2000, 216.1778, 141.6000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([944], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.8000, 317.8667, 270.0000, 345.6000],\n",
      "        [238.4000, 281.6000, 258.8000, 312.1778],\n",
      "        [236.0000, 244.6222, 256.4000, 276.6222],\n",
      "        [220.8000, 174.2222, 243.6000, 204.8000],\n",
      "        [200.8000, 168.5333, 223.6000, 199.8222],\n",
      "        [177.6000, 163.5556, 201.2000, 193.4222],\n",
      "        [154.8000, 160.0000, 177.6000, 192.0000],\n",
      "        [133.2000, 162.1333, 156.0000, 193.4222],\n",
      "        [228.8000, 206.2222, 251.6000, 236.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([113], device='cuda:0')}, {'boxes': tensor([[168.4000, 255.2889, 339.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1525], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.5333, 174.9333, 308.2667, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2129], device='cuda:0')}, {'boxes': tensor([[164.8000, 219.0222, 375.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 36.0000,  80.3556, 454.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1120], device='cuda:0')}, {'boxes': tensor([[194.4000, 175.6444, 301.2000, 270.2222],\n",
      "        [ 41.6000, 201.9556, 178.4000, 310.7556],\n",
      "        [188.8000, 242.4889, 316.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1575], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.4000, 135.1111, 256.4000, 232.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([128], device='cuda:0')}, {'boxes': tensor([[256.8000, 132.9778, 352.4000, 350.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([659], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 277.3333, 240.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2004], device='cuda:0')}, {'boxes': tensor([[171.2000, 105.9556, 374.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1354], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.2000, 172.0889, 284.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1359], device='cuda:0')}, {'boxes': tensor([[377.5413, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 264.5333,  70.4587, 413.8667],\n",
      "        [238.9725, 201.6000, 382.2385, 486.4000],\n",
      "        [258.9358, 306.1333, 413.9449, 507.7333],\n",
      "        [112.1468, 244.2667, 216.0734, 362.6667],\n",
      "        [381.0642, 274.1333, 459.1560, 345.6000],\n",
      "        [ 47.5596, 265.6000, 141.5046, 403.2000],\n",
      "        [  0.0000, 210.1333,  79.2661, 276.2667],\n",
      "        [125.6514, 245.3333, 231.9266, 352.0000],\n",
      "        [233.1009, 125.8667, 510.2385, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([447], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 34.8000, 162.8445, 336.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([221], device='cuda:0')}, {'boxes': tensor([[136.8000, 153.6000, 287.2000, 301.5111],\n",
      "        [ 57.6000, 216.1778, 133.6000, 288.0000],\n",
      "        [364.0000, 146.4889, 510.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11,  7], device='cuda:0'), 'image_id': tensor([1526], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.4000,   3.5556, 503.2000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([318], device='cuda:0')}, {'boxes': tensor([[204.0000,  71.1111, 416.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1684], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.2000, 127.2889, 389.6000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([376], device='cuda:0')}, {'boxes': tensor([[249.6000, 149.3333, 480.0000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1672], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 261.6889, 412.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1500], device='cuda:0')}, {'boxes': tensor([[160.8000, 120.1778, 432.0000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2197], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000,  91.7333, 415.2000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1983], device='cuda:0')}, {'boxes': tensor([[380.8000, 223.2889, 420.8000, 278.0444],\n",
      "        [  0.0000, 315.7333, 392.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([652], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[356.8000, 159.2889, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2147], device='cuda:0')}, {'boxes': tensor([[104.4000,  93.1556, 396.8000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([752], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.8000, 233.9556, 262.0000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1796], device='cuda:0')}, {'boxes': tensor([[104.5333,   0.0000, 274.1333, 413.3926]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1256], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.0000, 190.5778, 281.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([892], device='cuda:0')}, {'boxes': tensor([[ 98.8000, 239.6444, 311.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.2000, 214.7556, 295.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([88], device='cuda:0')}, {'boxes': tensor([[  0.0000, 324.2667, 130.1333, 412.4445],\n",
      "        [473.6000, 254.5778, 509.8667, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([690], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 227.5556, 283.6000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1957], device='cuda:0')}, {'boxes': tensor([[  0.0000, 105.2444, 509.8667, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1067], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.8000, 115.2000, 396.0000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1449], device='cuda:0')}, {'boxes': tensor([[147.2000, 308.6222, 230.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2011], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.0000, 273.7778, 320.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([490], device='cuda:0')}, {'boxes': tensor([[127.2000,  84.6222, 413.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.0000,  39.1111, 348.8000, 374.7556],\n",
      "        [ 89.6000, 265.9556,  98.0000, 298.6667],\n",
      "        [ 79.6000, 263.8222,  88.4000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1016], device='cuda:0')}, {'boxes': tensor([[285.6000, 179.2000, 462.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1286], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000,  44.0889, 258.4000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([210], device='cuda:0')}, {'boxes': tensor([[100.2667, 231.8222, 210.1333, 379.7333],\n",
      "        [104.5333, 227.5556, 362.6667, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([2075], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.6000, 102.4000, 281.6000, 494.9333],\n",
      "        [205.2000, 219.7333, 310.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([917], device='cuda:0')}, {'boxes': tensor([[269.2000,  86.7556, 365.2000, 226.1333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 305.7778, 192.0000, 430.9333],\n",
      "        [373.3333, 283.0222, 443.7333, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([709], device='cuda:0')}, {'boxes': tensor([[328.5333,  31.2889, 510.9333, 226.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1726], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000,  14.2222, 492.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1671], device='cuda:0')}, {'boxes': tensor([[113.6882,  81.7778, 475.3134, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2097], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[284.8000, 271.6444, 434.4000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1917], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([44], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000, 372.6222, 336.8000, 509.1555],\n",
      "        [ 45.2000, 357.6889, 350.4000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([551], device='cuda:0')}, {'boxes': tensor([[112.8000, 221.8667, 267.2000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([41], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.8000,  80.3556, 320.4000, 450.8445],\n",
      "        [236.8000, 146.4889, 320.4000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1531], device='cuda:0')}, {'boxes': tensor([[205.2000, 143.6444, 278.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1840], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,  59.0222, 511.2000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1651], device='cuda:0')}, {'boxes': tensor([[ 87.2000, 142.2222, 285.6000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1559], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.0000,  63.2889, 357.6000, 407.4667],\n",
      "        [222.4000, 278.0444, 250.8000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1017], device='cuda:0')}, {'boxes': tensor([[ 11.2000,   0.0000, 251.6000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([412], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.6000, 193.4222, 255.2000, 357.6889],\n",
      "        [192.8000, 221.1555, 264.4000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1566], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([803], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000,   0.0000, 508.8000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1811], device='cuda:0')}, {'boxes': tensor([[258.0000, 125.8667, 391.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1441], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.0000,  46.9333, 351.6000, 404.6222],\n",
      "        [164.8000, 267.3778, 194.4000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1018], device='cuda:0')}, {'boxes': tensor([[141.6000, 226.9091, 254.4000, 322.9091],\n",
      "        [449.6000, 232.7273, 507.2000, 331.6364],\n",
      "        [352.0000, 285.0909, 388.0000, 315.6364],\n",
      "        [251.2000, 282.1818, 285.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([1420], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667,  72.5333, 390.4000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1685], device='cuda:0')}, {'boxes': tensor([[  0.0000, 136.5333, 206.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([646], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  57.6000, 316.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1004], device='cuda:0')}, {'boxes': tensor([[139.2000, 166.4000, 421.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([280], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.0000, 244.6222, 264.4000, 448.7111],\n",
      "        [303.2000, 257.4222, 366.4000, 386.1333],\n",
      "        [  6.8000, 320.7111,  39.6000, 388.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([1523], device='cuda:0')}, {'boxes': tensor([[172.4000,  78.9333, 331.6000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2048], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 201.9556, 213.3333, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1364], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2085], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[177.2000, 202.6667, 330.0000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1600], device='cuda:0')}, {'boxes': tensor([[ 97.6000, 125.1556, 382.4000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1814], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1397], device='cuda:0')}, {'boxes': tensor([[147.2000, 115.9111, 239.6000, 413.1555],\n",
      "        [236.8000, 113.7778, 356.8000, 374.0444],\n",
      "        [225.2000, 198.4000, 274.4000, 369.0667],\n",
      "        [  0.0000, 268.8000,  27.6000, 285.1555],\n",
      "        [104.4000, 239.6444, 145.6000, 262.4000],\n",
      "        [456.4000, 334.9333, 511.2000, 364.8000],\n",
      "        [448.4000, 430.9333, 511.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2065], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.0000, 103.1111, 154.0000, 201.9556],\n",
      "        [284.8000, 135.1111, 326.4000, 214.7556],\n",
      "        [333.2000, 171.3778, 383.2000, 255.2889],\n",
      "        [ 58.8000, 112.3556,  94.4000, 223.2889],\n",
      "        [234.4000, 142.2222, 284.8000, 199.1111],\n",
      "        [305.2000, 142.9333, 346.8000, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2030], device='cuda:0')}, {'boxes': tensor([[298.4000, 203.3778, 340.0000, 277.3333],\n",
      "        [ 41.6000, 102.4000, 304.8000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([899], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000,  78.2222, 280.0000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([886], device='cuda:0')}, {'boxes': tensor([[256.0000, 206.2222, 412.8000, 290.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[274.4000, 285.8667, 510.4000, 506.3111],\n",
      "        [  0.0000,   0.0000, 217.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1614], device='cuda:0')}, {'boxes': tensor([[168.4000, 112.3556, 280.0000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1846], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[330.8169,   0.0000, 511.0986, 417.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1482], device='cuda:0')}, {'boxes': tensor([[180.8000, 135.1111, 321.6000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([395], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 184.1778,  38.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1904], device='cuda:0')}, {'boxes': tensor([[  0.0000, 177.7778, 382.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1218], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.2000, 192.0000, 187.6000, 367.6444],\n",
      "        [296.4000, 174.2222, 436.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1111], device='cuda:0')}, {'boxes': tensor([[172.8000,  34.1333, 312.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1775], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000,   0.0000, 317.6000, 510.5778],\n",
      "        [232.4000,   0.7111, 402.4000, 509.1555],\n",
      "        [255.2000, 167.8222, 424.4000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1660], device='cuda:0')}, {'boxes': tensor([[246.4000, 159.2889, 300.8000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2128], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  59.0222, 396.8000, 155.0222],\n",
      "        [144.4000, 117.3333, 295.2000, 213.3333],\n",
      "        [ 70.4000, 179.2000, 213.6000, 276.6222],\n",
      "        [ 61.6000, 279.4667, 130.0000, 326.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([150], device='cuda:0')}, {'boxes': tensor([[ 66.8000, 205.5111, 222.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([403], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1060], device='cuda:0')}, {'boxes': tensor([[218.4000, 214.7556, 428.8000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1677], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.6000,  12.0889, 410.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([265], device='cuda:0')}, {'boxes': tensor([[181.0963,  86.7556, 508.2074, 395.3778],\n",
      "        [241.7778, 318.5778, 340.3852, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 28.1835,   0.0000, 510.2385, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([464], device='cuda:0')}, {'boxes': tensor([[  0.0000, 209.0667, 184.5333, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[298.6667, 224.7111, 360.5333, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1936], device='cuda:0')}, {'boxes': tensor([[135.6000,  88.1778, 290.8000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1902], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.6000, 238.9333, 436.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1497], device='cuda:0')}, {'boxes': tensor([[158.4000,  96.7111, 200.4000, 138.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000,  55.4667, 457.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1806], device='cuda:0')}, {'boxes': tensor([[370.4789,   0.0000, 510.1972, 304.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1488], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000, 119.4667, 414.4000, 509.8667],\n",
      "        [ 76.8000, 123.7333, 310.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1412], device='cuda:0')}, {'boxes': tensor([[ 64.4000,   0.0000, 509.6000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2081], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.0000,   0.0000, 300.0000, 470.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([546], device='cuda:0')}, {'boxes': tensor([[255.2000, 125.8667, 275.2000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([874], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 211.2000, 201.2000, 233.9556],\n",
      "        [439.2000, 206.2222, 474.8000, 222.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([526], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 153.6000, 276.2667, 312.8889],\n",
      "        [503.4667, 206.2222, 509.8667, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([673], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000, 144.0000, 463.2000, 349.0909],\n",
      "        [159.2000, 208.0000, 254.4000, 341.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1319], device='cuda:0')}, {'boxes': tensor([[  2.4000, 135.8222, 256.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([213], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.0000, 275.9111, 344.0000, 373.3333],\n",
      "        [229.2000, 289.4222, 270.8000, 386.1333],\n",
      "        [128.0000, 339.2000, 171.2000, 443.7333],\n",
      "        [133.6000, 232.5333, 176.4000, 330.6667],\n",
      "        [297.6000, 160.7111, 338.8000, 253.1555],\n",
      "        [270.4000,  71.1111, 316.0000, 167.1111],\n",
      "        [206.0000,  88.1778, 249.6000, 184.8889],\n",
      "        [149.6000, 124.4444, 192.0000, 220.4444],\n",
      "        [229.2000, 192.7111, 272.0000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([109], device='cuda:0')}, {'boxes': tensor([[123.6000, 201.9556, 293.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([95], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 182.0444, 319.2000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1777], device='cuda:0')}, {'boxes': tensor([[246.4000,  64.0000, 422.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([896], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.0000, 171.3778, 291.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1786], device='cuda:0')}, {'boxes': tensor([[ 84.8000, 200.5333, 368.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1265], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 145.0667, 268.8000, 487.8222],\n",
      "        [288.8000, 113.7778, 426.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1427], device='cuda:0')}, {'boxes': tensor([[194.1333, 115.2000, 430.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([206], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 260.2667, 268.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([948], device='cuda:0')}, {'boxes': tensor([[ 32.0000,  65.4222, 320.0000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2088], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[105.6000,  75.3778, 367.2000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2200], device='cuda:0')}, {'boxes': tensor([[124.4000, 125.8667, 310.0000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1855], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.0000, 371.2000, 321.2000, 405.3333],\n",
      "        [214.4000, 203.3778, 228.8000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1873], device='cuda:0')}, {'boxes': tensor([[  0.0000, 163.5556, 396.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1296], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[227.8165, 161.0667, 298.2752, 278.4000],\n",
      "        [  0.5872, 274.1333, 126.8257, 509.8667],\n",
      "        [222.5321, 199.4667, 235.4495, 234.6667],\n",
      "        [186.7156, 218.6667, 225.4679, 276.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([426], device='cuda:0')}, {'boxes': tensor([[152.8000,  99.5556, 244.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1510], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.2000, 200.5333, 270.4000, 234.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([938], device='cuda:0')}, {'boxes': tensor([[138.8000, 194.8445, 368.0000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1601], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 229.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1396], device='cuda:0')}, {'boxes': tensor([[202.6667,   0.0000, 360.5333, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2072], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000, 152.1778, 430.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1679], device='cuda:0')}, {'boxes': tensor([[236.8000, 135.1111, 396.0000, 332.8000],\n",
      "        [ 83.2000, 135.1111, 234.4000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1755], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 146.4889, 438.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([331], device='cuda:0')}, {'boxes': tensor([[155.6000, 205.5111, 510.4000, 480.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([585], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 208.3556, 250.8000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1242], device='cuda:0')}, {'boxes': tensor([[261.2000, 187.7333, 280.4000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1960], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 342.7556, 249.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2012], device='cuda:0')}, {'boxes': tensor([[226.0000, 170.6667, 326.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2178], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 270.2222, 117.3333, 509.1555],\n",
      "        [162.1333,  93.8667, 341.3333, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([599], device='cuda:0')}, {'boxes': tensor([[  0.0000, 203.3778, 221.8667, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1368], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[161.2000, 171.3778, 291.2000, 451.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1785], device='cuda:0')}, {'boxes': tensor([[217.2000, 198.4000, 255.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2064], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000, 220.4444, 349.6000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2188], device='cuda:0')}, {'boxes': tensor([[ 67.2000, 199.1111, 329.6000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[255.6000, 113.7778, 420.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1794], device='cuda:0')}, {'boxes': tensor([[385.0667, 162.1333, 461.8667, 220.4444],\n",
      "        [253.8667, 223.2889, 292.2667, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1703], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1023], device='cuda:0')}, {'boxes': tensor([[315.7333, 164.9778, 378.6667, 250.3111],\n",
      "        [254.9333, 150.7556, 338.1333, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([357], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000, 263.8222, 467.6000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([16], device='cuda:0')}, {'boxes': tensor([[144.8000, 113.0667, 240.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1851], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.0000, 176.3556, 341.2000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([805], device='cuda:0')}, {'boxes': tensor([[145.6000, 295.8222, 236.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2009], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.8716, 184.5333, 303.5596, 322.1333],\n",
      "        [  1.7615, 321.0667, 509.0642, 509.8667],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 149.7248, 440.5333],\n",
      "        [134.4587, 291.2000, 181.4312, 334.9333],\n",
      "        [136.2202, 276.2667, 187.3027, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [319.4128, 272.0000, 353.4679, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([457], device='cuda:0')}, {'boxes': tensor([[ 15.6000,  80.3556, 228.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([1404], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 190.5778,  21.3333, 248.8889],\n",
      "        [377.6000, 167.8222, 510.9333, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([688], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  59.7333, 412.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1697], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[319.6000, 267.3778, 340.4000, 316.4445],\n",
      "        [295.6000, 201.9556, 318.4000, 257.4222],\n",
      "        [276.8000, 150.0444, 299.2000, 195.5556],\n",
      "        [271.6000, 103.1111, 293.2000, 149.3333],\n",
      "        [269.2000,  59.0222, 289.6000, 103.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([98], device='cuda:0')}, {'boxes': tensor([[250.0000, 150.0444, 333.2000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([3], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 58.7156,  80.0000, 466.2018, 410.6667],\n",
      "        [ 20.5505, 257.0667, 231.3394, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([475], device='cuda:0')}, {'boxes': tensor([[128.8000,  59.7333, 357.6000, 406.7556],\n",
      "        [  0.0000,   1.4222,  76.8000, 128.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1768], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[215.2296, 260.2667, 272.1185, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([754], device='cuda:0')}, {'boxes': tensor([[204.0000, 270.2222, 435.2000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1816], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.2667,  83.9111, 433.0667, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1692], device='cuda:0')}, {'boxes': tensor([[345.6000, 176.3556, 406.4000, 274.4889],\n",
      "        [209.0667, 244.6222, 243.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1700], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  5.6000,  98.1333, 182.0000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1330], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([762], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 211.9111, 486.8000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([367], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([954], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.0963, 177.7778, 323.3185, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([759], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 510.4000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1635], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000, 152.8889, 211.2000, 221.8667],\n",
      "        [381.6000, 253.8667, 428.8000, 335.6444],\n",
      "        [248.0000, 196.9778, 296.4000, 263.8222],\n",
      "        [202.4000, 140.0889, 233.2000, 261.6889],\n",
      "        [ 44.8000, 119.4667, 112.0000, 187.7333],\n",
      "        [137.2000, 145.0667, 174.0000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2024], device='cuda:0')}, {'boxes': tensor([[  0.0000, 285.8667, 399.6000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1205], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.1867e+01, 4.5800e+02, 4.4729e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([277], device='cuda:0')}, {'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.4000, 155.0222, 197.6000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1395], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.7339, 344.5333, 510.2385, 508.8000],\n",
      "        [100.4037,  16.0000, 496.7339, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([463], device='cuda:0')}, {'boxes': tensor([[  0.0000, 223.2889, 172.0000, 507.7333],\n",
      "        [266.4000, 151.4667, 336.0000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([501], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 126.5778, 347.6000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([660], device='cuda:0')}, {'boxes': tensor([[  1.1743, 467.2000, 383.4128, 508.8000],\n",
      "        [446.2385, 417.0667, 509.0642, 508.8000],\n",
      "        [292.9908, 349.8667, 432.7339, 487.4667],\n",
      "        [342.8991, 394.6667, 483.2294, 507.7333],\n",
      "        [184.3670, 404.2667, 214.3119, 471.4667],\n",
      "        [224.8807, 265.6000, 361.1009, 470.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([442], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 320.0000, 150.8000, 408.1778],\n",
      "        [152.8000, 359.1111, 197.2000, 457.2444],\n",
      "        [165.6000,  98.8444, 181.6000, 135.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([626], device='cuda:0')}, {'boxes': tensor([[112.8000, 201.9556, 332.8000, 472.1778],\n",
      "        [  0.0000,  66.8444,  52.0000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1767], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000,  41.2444, 401.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([351], device='cuda:0')}, {'boxes': tensor([[121.6000, 110.9333, 381.8667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([715], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 107.3778, 510.4000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([990], device='cuda:0')}, {'boxes': tensor([[131.2000, 177.7778, 240.0000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2056], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[246.8000, 265.2444, 280.8000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([984], device='cuda:0')}, {'boxes': tensor([[109.6000, 164.2667, 284.8000, 351.2889],\n",
      "        [149.6000, 246.0444, 232.8000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([520], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 67.2000, 224.7111, 509.8667, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([240], device='cuda:0')}, {'boxes': tensor([[286.0000, 182.0444, 511.2000, 483.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1285], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 366.0000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1385], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1253], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.8000,  22.7556, 322.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1050], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.1333, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([798], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 198.4000, 175.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([499], device='cuda:0')}, {'boxes': tensor([[122.8000, 228.9778, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1154], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 195.5556, 317.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([80], device='cuda:0')}, {'boxes': tensor([[135.2000,  32.7111, 396.0000, 384.0000],\n",
      "        [116.8000, 257.4222, 168.0000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([505], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.6000, 206.9333, 290.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([75], device='cuda:0')}, {'boxes': tensor([[130.0000, 177.7778, 429.2000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([281], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,   0.0000, 400.4000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([820], device='cuda:0')}, {'boxes': tensor([[  0.0000, 240.3556, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([251], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.4507,   0.0000, 508.3944, 308.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1483], device='cuda:0')}, {'boxes': tensor([[152.0000,  56.8889, 204.8000, 123.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 275.9111, 165.6000, 381.1555],\n",
      "        [188.0000, 275.9111, 206.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([770], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  76.8000, 236.8000, 297.2444],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1082], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[273.6000, 226.1333, 304.8000, 299.3778],\n",
      "        [352.0000, 324.2667, 401.6000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([883], device='cuda:0')}, {'boxes': tensor([[196.0000, 322.1333, 363.2000, 510.5778],\n",
      "        [ 67.2000, 330.6667, 374.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  23.4667, 509.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([802], device='cuda:0')}, {'boxes': tensor([[103.4667,  78.2222, 413.8667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1690], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000, 192.0000, 231.6000, 374.0444],\n",
      "        [276.8000, 172.8000, 424.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1094], device='cuda:0')}, {'boxes': tensor([[300.8000, 405.3333, 428.0000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000,  39.8222, 339.6000, 364.8000],\n",
      "        [130.0000, 261.6889, 139.2000, 292.9778],\n",
      "        [123.6000, 257.4222, 132.0000, 293.6889],\n",
      "        [334.0000, 244.6222, 369.2000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1015], device='cuda:0')}, {'boxes': tensor([[  0.0000, 222.5778, 126.8000, 509.8667],\n",
      "        [164.4000, 151.4667, 240.0000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([495], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 157.8667, 433.6000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1304], device='cuda:0')}, {'boxes': tensor([[290.0000, 199.1111, 317.6000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1445], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 128.0000, 350.8000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([7], device='cuda:0')}, {'boxes': tensor([[172.0000, 198.4000, 342.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.8000,  75.3778, 418.0000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([823], device='cuda:0')}, {'boxes': tensor([[ 20.4000,  12.8000, 506.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1579], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 125.1556, 508.4000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([998], device='cuda:0')}, {'boxes': tensor([[152.8000, 105.9556, 317.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([863], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 171.3778, 302.4000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([114], device='cuda:0')}, {'boxes': tensor([[228.8000, 122.3111, 510.4000, 484.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2164], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 179.2000, 499.2000, 375.4667],\n",
      "        [ 25.6000, 123.7333, 139.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1640], device='cuda:0')}, {'boxes': tensor([[341.7248, 234.6667, 510.2385, 437.3333],\n",
      "        [  7.6330, 270.9333, 236.0367, 425.6000],\n",
      "        [ 17.0275, 130.1333, 473.8349, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([482], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 448.8000, 440.8889],\n",
      "        [238.4000, 103.8222, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1643], device='cuda:0')}, {'boxes': tensor([[138.6667,   0.0000, 493.8667, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1709], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.4000,  96.7111, 284.4000, 477.8667],\n",
      "        [215.2000, 163.5556, 305.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1528], device='cuda:0')}, {'boxes': tensor([[104.4000, 234.6667, 317.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1156], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 188.4444, 448.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([588], device='cuda:0')}, {'boxes': tensor([[179.6000, 153.6000, 307.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1844], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.8000,  62.5778, 229.6000, 484.9778],\n",
      "        [242.4000, 115.2000, 389.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1429], device='cuda:0')}, {'boxes': tensor([[128.4000, 244.6222, 301.2000, 480.0000],\n",
      "        [ 19.6000, 218.3111, 333.6000, 431.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([559], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000, 200.5333, 210.4000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([937], device='cuda:0')}, {'boxes': tensor([[102.4000, 106.6667, 511.2000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([734], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000,  62.5778, 292.0000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([836], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 3.9822e+01, 2.8640e+02, 4.6649e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([299], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 155.7333, 417.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1033], device='cuda:0')}, {'boxes': tensor([[ 54.4000,  54.0444, 289.0667, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1503], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6330, 184.5333, 304.7339, 322.1333],\n",
      "        [  2.3486, 320.0000, 509.0642, 508.8000],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 150.8991, 440.5333],\n",
      "        [135.0459, 291.2000, 182.0183, 336.0000],\n",
      "        [137.3945, 276.2667, 187.8899, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [320.0000, 273.0667, 354.0551, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([456], device='cuda:0')}, {'boxes': tensor([[ 99.2000, 115.9111, 353.2000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([104], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[231.6000, 108.8000, 384.8000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1791], device='cuda:0')}, {'boxes': tensor([[265.2000, 389.6889, 291.2000, 465.0667],\n",
      "        [242.0000, 294.4000, 266.8000, 369.0667],\n",
      "        [223.2000, 206.9333, 250.4000, 281.6000],\n",
      "        [261.2000, 134.4000, 285.2000, 207.6444],\n",
      "        [297.6000,  79.6444, 323.2000, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([99], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2123], device='cuda:0')}, {'boxes': tensor([[ 52.4000, 118.7556, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1202], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[422.4000, 156.4444, 497.0667, 216.1778],\n",
      "        [ 76.8000, 223.2889, 189.8667, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1704], device='cuda:0')}, {'boxes': tensor([[  0.0000, 220.4444, 332.4000, 509.1555],\n",
      "        [320.8000, 351.2889, 412.8000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1249], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 214.7556, 296.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1392], device='cuda:0')}, {'boxes': tensor([[183.1927, 103.4667, 452.6972, 409.6000],\n",
      "        [ 25.2477, 246.4000, 170.2752, 420.2667],\n",
      "        [ 75.7431,  86.4000, 131.5229, 138.6667],\n",
      "        [124.4771,  96.0000, 190.2385, 151.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([432], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[296.4632, 166.4000, 485.9593, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1972], device='cuda:0')}, {'boxes': tensor([[174.4000, 190.5778, 250.0000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1247], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8000, 268.8000, 141.2000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([523], device='cuda:0')}, {'boxes': tensor([[171.2000,  32.7111, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1313], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 79.6000,  81.7778, 484.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1198], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([319], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.2000, 142.2222, 340.4000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([634], device='cuda:0')}, {'boxes': tensor([[128.0000,  65.4222, 212.4000, 460.0889],\n",
      "        [236.8000, 128.7111, 357.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1186], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[411.6000, 246.0444, 509.6000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([533], device='cuda:0')}, {'boxes': tensor([[  0.4000, 108.0889, 302.0000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([727], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,  73.9556, 449.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1122], device='cuda:0')}, {'boxes': tensor([[ 34.4000,  22.7556, 472.0000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([220], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 99.2000, 104.5333, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1284], device='cuda:0')}, {'boxes': tensor([[104.0000, 160.0000, 385.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1301], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.4000, 286.5778, 279.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([981], device='cuda:0')}, {'boxes': tensor([[ 65.0667, 315.7333, 196.2667, 433.7778],\n",
      "        [377.6000, 301.5111, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([705], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000, 125.1556, 385.0667, 194.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1588], device='cuda:0')}, {'boxes': tensor([[174.9333, 109.5111, 245.3333, 228.9778],\n",
      "        [326.4000, 152.1778, 385.0667, 227.5556],\n",
      "        [290.1333,  52.6222, 309.3333,  71.1111],\n",
      "        [343.4667,  65.4222, 362.6667,  83.9111],\n",
      "        [457.6000,  65.4222, 480.0000,  83.9111],\n",
      "        [155.7333,  68.2667, 177.0667,  92.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([360], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 223.2889, 252.8000, 296.5333],\n",
      "        [298.4000, 255.2889, 354.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([884], device='cuda:0')}, {'boxes': tensor([[168.8000, 250.3111, 198.4000, 381.1555],\n",
      "        [251.2000, 251.7333, 273.6000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([763], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2231e+02, 4.2720e+02, 3.1929e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([730], device='cuda:0')}, {'boxes': tensor([[120.8000, 169.2444, 211.6000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([860], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 25.6000, 128.0000, 107.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1136], device='cuda:0')}, {'boxes': tensor([[189.6000, 200.5333, 414.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2157], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.7280e+02, 4.1440e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([740], device='cuda:0')}, {'boxes': tensor([[238.0000, 103.1111, 350.4000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1532], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.2000, 146.4889, 288.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1335], device='cuda:0')}, {'boxes': tensor([[100.4000, 244.6222, 313.6000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 204.8000, 174.9333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1370], device='cuda:0')}, {'boxes': tensor([[142.9333, 221.8667, 509.8667, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([233], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[393.3945, 314.6667, 510.2385, 504.5333],\n",
      "        [  0.5872, 265.6000,  86.3119, 423.4667],\n",
      "        [252.4771, 203.7333, 396.3303, 487.4667],\n",
      "        [273.0275, 308.2667, 428.0367, 504.5333],\n",
      "        [126.8257, 251.7333, 207.2661, 361.6000],\n",
      "        [395.7431, 272.0000, 473.8349, 344.5333],\n",
      "        [ 61.6514, 269.8667, 154.4220, 405.3333],\n",
      "        [  0.0000, 214.4000,  95.1193, 281.6000],\n",
      "        [137.9817, 246.4000, 227.2294, 344.5333],\n",
      "        [  0.5872, 315.7333,  34.6422, 430.9333],\n",
      "        [193.7615, 113.0667, 487.9266, 397.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([448], device='cuda:0')}, {'boxes': tensor([[154.0000, 157.8667, 290.0000, 278.7556],\n",
      "        [ 26.8000, 184.1778,  66.8000, 218.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1464], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.0000,   3.5556, 497.2000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([289], device='cuda:0')}, {'boxes': tensor([[174.8000, 224.7111, 342.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 192.0000, 243.2000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([401], device='cuda:0')}, {'boxes': tensor([[ 98.1333,  49.7778, 320.0000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([722], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 318.4000, 510.5778],\n",
      "        [302.4000, 228.9778, 466.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1632], device='cuda:0')}, {'boxes': tensor([[152.4000,   0.0000, 510.0000, 475.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1311], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.8000, 113.7778, 455.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1200], device='cuda:0')}, {'boxes': tensor([[128.4000,  55.4667, 336.8000, 507.7333],\n",
      "        [  0.0000,   0.0000, 176.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1664], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[1.2680e+02, 2.1049e+02, 2.5400e+02, 3.5129e+02],\n",
      "        [4.0000e-01, 1.5502e+02, 1.1800e+02, 2.8302e+02],\n",
      "        [2.2560e+02, 1.1591e+02, 3.0800e+02, 2.4604e+02],\n",
      "        [1.1160e+02, 2.6169e+02, 2.5520e+02, 4.4871e+02],\n",
      "        [3.5680e+02, 2.6169e+02, 4.9640e+02, 4.4231e+02],\n",
      "        [4.2760e+02, 2.1120e+02, 5.1080e+02, 3.1644e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8, 8, 8, 8], device='cuda:0'), 'image_id': tensor([638], device='cuda:0')}, {'boxes': tensor([[210.4000, 132.2667, 312.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([81], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.2000, 145.7778, 378.0000, 224.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([127], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([13], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.6000, 118.7556, 282.0000, 157.8667],\n",
      "        [250.8000, 171.3778, 270.8000, 211.9111],\n",
      "        [239.6000, 241.0667, 260.0000, 278.0444],\n",
      "        [226.8000, 309.3333, 248.0000, 347.0222],\n",
      "        [218.8000, 369.7778, 240.0000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([144], device='cuda:0')}, {'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 426.6667, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([698], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 203.3778,  90.6667, 509.1555],\n",
      "        [145.0667,  93.8667, 336.0000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([602], device='cuda:0')}, {'boxes': tensor([[161.6000, 146.4889, 235.2000, 362.6667],\n",
      "        [227.2000,  48.3556, 410.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1231], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 274.4889, 230.4000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2002], device='cuda:0')}, {'boxes': tensor([[  4.2667, 302.9333, 245.3333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2122], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([284], device='cuda:0')}, {'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 294.4000, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([707], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 128.0000, 507.2000, 496.3556],\n",
      "        [165.6000,   0.0000, 316.8000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1611], device='cuda:0')}, {'boxes': tensor([[119.2000,  54.0444, 336.0000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([825], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1512], device='cuda:0')}, {'boxes': tensor([[123.7333,  69.6889, 331.7333, 352.7111],\n",
      "        [292.2667,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1080], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 135.1111, 334.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1762], device='cuda:0')}, {'boxes': tensor([[201.2000,  85.3333, 408.8000, 289.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1982], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2000,  81.0667, 337.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([65], device='cuda:0')}, {'boxes': tensor([[ 95.7630,  79.6444, 476.9185, 403.9111],\n",
      "        [164.9778, 318.5778, 255.0518, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([180], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[141.2741,  98.1333, 475.0222, 378.3111],\n",
      "        [201.0074, 314.3111, 300.5630, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([185], device='cuda:0')}, {'boxes': tensor([[184.5333,   9.9556, 375.4667, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([593], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.0667, 118.0444, 492.8000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([663], device='cuda:0')}, {'boxes': tensor([[168.5333, 267.3778, 181.3333, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2114], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.0000,  41.2444, 356.0000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([63], device='cuda:0')}, {'boxes': tensor([[106.4000, 189.1555, 275.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2060], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 166.4000, 324.2667, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([719], device='cuda:0')}, {'boxes': tensor([[ 78.0000, 128.7111, 454.8000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([278], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 156.4444, 210.0000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1402], device='cuda:0')}, {'boxes': tensor([[  9.6000, 278.0444, 352.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([47], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.6000, 155.0222, 277.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2039], device='cuda:0')}, {'boxes': tensor([[345.6000,   0.0000, 510.4000, 509.1555],\n",
      "        [179.2000,  79.6444, 496.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1236], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000,   0.0000, 430.8000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1438], device='cuda:0')}, {'boxes': tensor([[307.2000,  51.2000, 451.2000, 250.3111],\n",
      "        [164.8000,  62.5778, 300.0000, 261.6889],\n",
      "        [ 97.6000, 109.5111, 250.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1759], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.6000, 130.8445, 193.6000, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2151], device='cuda:0')}, {'boxes': tensor([[237.2000, 117.3333, 388.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1790], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 159.2889, 342.0000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([745], device='cuda:0')}, {'boxes': tensor([[ 92.8000,   9.2444, 450.8000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([292], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 115.2000, 365.8667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1473], device='cuda:0')}, {'boxes': tensor([[218.8000, 258.8445, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1221], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000,  78.2222, 448.8000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1681], device='cuda:0')}, {'boxes': tensor([[222.8148, 237.5111, 250.3111, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[345.6000, 354.1333, 364.0000, 428.0889],\n",
      "        [288.0000, 393.9556, 305.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([772], device='cuda:0')}, {'boxes': tensor([[  8.4000,  18.4889, 311.2000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1799], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 193.4222, 223.2000, 232.5333],\n",
      "        [276.4000, 208.3556, 319.2000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([847], device='cuda:0')}, {'boxes': tensor([[243.2000, 136.5333, 509.6000, 502.0444],\n",
      "        [  0.0000,   0.0000, 265.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1621], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6000, 143.6444, 250.8000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2036], device='cuda:0')}, {'boxes': tensor([[208.0000, 238.9333, 441.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1914], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [151.4667,  82.4889, 340.2667, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([600], device='cuda:0')}, {'boxes': tensor([[200.4000,  86.0444, 323.6000, 364.0889],\n",
      "        [402.4000, 279.4667, 414.0000, 311.4667],\n",
      "        [427.2000, 275.9111, 436.8000, 312.8889],\n",
      "        [496.0000, 265.2444, 511.2000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1008], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 224.0000, 342.4000, 510.5778],\n",
      "        [339.2000, 351.2889, 414.4000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1251], device='cuda:0')}, {'boxes': tensor([[  9.6000,  49.0667, 345.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1546], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 270.2222, 487.4667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([236], device='cuda:0')}, {'boxes': tensor([[ 26.6667,   0.0000, 285.8667, 405.8074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.2000, 201.9556, 281.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([927], device='cuda:0')}, {'boxes': tensor([[188.8000, 202.6667, 325.2000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1598], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 256.0000, 259.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1036], device='cuda:0')}, {'boxes': tensor([[206.0000,  65.4222, 322.0000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([837], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000, 167.1111, 388.0000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([279], device='cuda:0')}, {'boxes': tensor([[268.4000, 137.2444, 398.0000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([421], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 160.7111, 263.5852, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([188], device='cuda:0')}, {'boxes': tensor([[113.6000, 204.8000, 288.8000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([926], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[259.2000, 216.1778, 326.8000, 286.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([130], device='cuda:0')}, {'boxes': tensor([[ 71.6000, 204.8000, 396.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([651], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 24.0000, 217.6000, 508.8000, 506.3111],\n",
      "        [  0.0000,   0.0000, 274.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1644], device='cuda:0')}, {'boxes': tensor([[ 85.6000,  90.2295, 257.6000, 489.9672]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.8000, 110.9333, 420.0000, 427.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1795], device='cuda:0')}, {'boxes': tensor([[118.4000, 290.1333, 231.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2006], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[341.2000, 354.8445, 492.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1495], device='cuda:0')}, {'boxes': tensor([[257.2000,  96.0000, 392.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1440], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 179.2000, 257.2000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2037], device='cuda:0')}, {'boxes': tensor([[ 57.6000, 271.6444, 185.6000, 309.3333],\n",
      "        [237.2000, 275.2000, 361.2000, 325.6889],\n",
      "        [321.2000, 271.6444, 368.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29], device='cuda:0'), 'image_id': tensor([528], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 109.5111, 509.2000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([993], device='cuda:0')}, {'boxes': tensor([[158.0000,   3.5556, 502.8000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([308], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.8000,  66.8444, 447.2000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([108], device='cuda:0')}, {'boxes': tensor([[299.4496, 126.9333, 442.1284, 364.8000],\n",
      "        [ 47.5596, 105.6000, 105.1009, 153.6000],\n",
      "        [ 98.0550, 118.4000, 162.6422, 170.6667],\n",
      "        [159.7064, 124.8000, 236.0367, 179.2000],\n",
      "        [  5.2844, 272.0000, 143.8532, 486.4000],\n",
      "        [ 63.4128, 122.6667, 142.6789, 185.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([438], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,   1.4222, 324.2667, 457.9556],\n",
      "        [412.8000, 108.0889, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([605], device='cuda:0')}, {'boxes': tensor([[203.2000,  47.6444, 371.6000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([827], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 226.8445, 288.4000, 282.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1926], device='cuda:0')}, {'boxes': tensor([[123.2000, 133.6889, 510.0000, 406.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([589], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 256.0000, 162.0000, 507.7333],\n",
      "        [ 75.2000,  68.2667, 144.8000, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([503], device='cuda:0')}, {'boxes': tensor([[ 55.2000, 130.1333, 458.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1201], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  73.9556, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2153], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 280.1778, 193.2000, 352.7111],\n",
      "        [214.0000, 271.6444, 300.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1823], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 105.9556, 263.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1899], device='cuda:0')}, {'boxes': tensor([[  0.0000, 196.2667, 293.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1391], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000,  83.2000, 452.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1833], device='cuda:0')}, {'boxes': tensor([[217.2000,  66.8444, 371.2000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1545], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2294, 100.2667, 452.6972, 424.5333],\n",
      "        [457.3945,  75.7333, 489.6881, 171.7333],\n",
      "        [  0.5872, 272.0000,  71.6330, 504.5333],\n",
      "        [ 88.6606,  86.4000, 146.7890, 141.8667],\n",
      "        [136.8073,  94.9333, 195.5229, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([431], device='cuda:0')}, {'boxes': tensor([[148.8000,   0.0000, 274.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([415], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 199.8222, 336.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([162], device='cuda:0')}, {'boxes': tensor([[ 66.9358, 170.6667, 374.0183, 359.4667],\n",
      "        [154.4220, 321.0667, 510.2385, 508.8000],\n",
      "        [  0.5872, 300.8000,  62.2385, 442.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7, 19], device='cuda:0'), 'image_id': tensor([483], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.2676, 179.2000, 511.1988, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1973], device='cuda:0')}, {'boxes': tensor([[159.7064, 119.4667, 417.4679, 430.9333],\n",
      "        [416.2936,  82.1333, 449.1743, 188.8000],\n",
      "        [ 46.9725,  98.1333, 104.5138, 162.1333],\n",
      "        [ 97.4679, 112.0000, 166.1651, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([437], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.6000, 100.9778, 246.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1857], device='cuda:0')}, {'boxes': tensor([[132.2667, 240.3556, 169.6000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1708], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.8000,  12.0889, 510.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([571], device='cuda:0')}, {'boxes': tensor([[116.4000, 223.2889, 253.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([22], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 162.8445, 147.2000, 338.4889],\n",
      "        [132.8000, 157.1555, 323.7333, 373.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([56], device='cuda:0')}, {'boxes': tensor([[160.4000,  64.0000, 509.6000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([986], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 177.7778, 200.5333, 206.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2136], device='cuda:0')}, {'boxes': tensor([[198.8000,  88.1778, 331.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1459], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.2000,   0.0000, 312.0000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1079], device='cuda:0')}, {'boxes': tensor([[217.6000, 200.5333, 427.2000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1678], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[135.2000, 162.1333, 314.4000, 354.1333],\n",
      "        [354.0000, 266.6667, 392.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1553], device='cuda:0')}, {'boxes': tensor([[188.4000, 185.6000, 256.8000, 252.4444],\n",
      "        [241.6000, 263.1111, 263.2000, 298.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([1656], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[373.1831,   0.0000, 510.1972, 305.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1487], device='cuda:0')}, {'boxes': tensor([[204.8000,   0.0000, 381.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([616], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.6000, 113.7778, 402.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([377], device='cuda:0')}, {'boxes': tensor([[  0.4000,  76.8000, 218.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([370], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 228.2667, 470.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1104], device='cuda:0')}, {'boxes': tensor([[204.0000, 193.4222, 349.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([126], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000,  47.6444, 511.2000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([751], device='cuda:0')}, {'boxes': tensor([[140.8000, 169.9556, 176.8000, 221.8667],\n",
      "        [ 67.2000, 217.6000,  91.6000, 297.2444],\n",
      "        [158.8000,  71.8222, 176.8000, 106.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([623], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000,  85.3333, 329.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([835], device='cuda:0')}, {'boxes': tensor([[108.9362,   0.0000, 183.8298, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1090], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[156.8000,  78.2222, 391.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1820], device='cuda:0')}, {'boxes': tensor([[164.0000, 230.4000, 260.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1958], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 216.8889, 345.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([921], device='cuda:0')}, {'boxes': tensor([[128.0000, 214.7556, 340.8000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.0000, 206.9333, 220.8000, 226.1333],\n",
      "        [455.6000, 199.1111, 490.4000, 211.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([525], device='cuda:0')}, {'boxes': tensor([[109.6000, 204.8000, 337.6000, 477.8667],\n",
      "        [  0.0000,  68.2667,  52.8000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1766], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.1333, 253.1555, 184.5333, 392.5333],\n",
      "        [421.3333, 201.9556, 491.7333, 257.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([695], device='cuda:0')}, {'boxes': tensor([[ 25.6000, 315.7333, 188.8000, 392.5333],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([693], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.2000, 179.9111, 303.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([76], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1492], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[233.6000, 184.8889, 339.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2180], device='cuda:0')}, {'boxes': tensor([[182.0000, 145.0667, 321.2000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([396], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 29.8667,  32.7111, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1941], device='cuda:0')}, {'boxes': tensor([[248.8000,  88.1778, 505.6000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([324], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 32.0000,  78.9333, 300.8000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1044], device='cuda:0')}, {'boxes': tensor([[147.2000,  96.7111, 305.6000, 501.3333],\n",
      "        [255.2000,  16.3556, 416.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1123], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[403.2000, 242.4889, 510.4000, 506.3111],\n",
      "        [132.8000,  81.7778, 487.6000, 419.5555],\n",
      "        [ 56.0000,  56.8889, 133.6000, 146.4889],\n",
      "        [ 22.0000,  80.3556,  57.6000, 132.2667],\n",
      "        [229.6000,  46.2222, 385.2000, 123.7333],\n",
      "        [  0.0000,  68.9778,  28.8000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1801], device='cuda:0')}, {'boxes': tensor([[348.8000, 128.0000, 510.9333, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1727], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000,  11.3778, 468.2667, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1723], device='cuda:0')}, {'boxes': tensor([[329.7152,  10.6667, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1975], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[38.4000, 11.3778, 96.4000, 86.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1837], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 206.2222, 258.1333, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([686], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.8000, 269.5111, 276.0000, 320.7111],\n",
      "        [260.0000, 222.5778, 280.4000, 276.6222],\n",
      "        [266.8000, 171.3778, 287.6000, 223.2889],\n",
      "        [240.0000, 139.3778, 259.2000, 189.8667],\n",
      "        [213.2000, 115.2000, 233.2000, 168.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([142], device='cuda:0')}, {'boxes': tensor([[221.6000, 223.2889, 320.4000, 280.1778],\n",
      "        [388.8000,  91.7333, 410.0000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1890], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 105.9556, 348.8000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2144], device='cuda:0')}, {'boxes': tensor([[304.0000, 191.2889, 470.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1292], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 77.6000,   0.0000, 232.0000, 159.2889],\n",
      "        [211.2000,   0.0000, 364.0000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1749], device='cuda:0')}, {'boxes': tensor([[ 68.2667, 317.1555, 200.5333, 435.2000],\n",
      "        [379.7333, 300.0889, 442.6667, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([713], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000,  86.7556, 489.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1195], device='cuda:0')}, {'boxes': tensor([[205.2000,  59.0222, 410.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([824], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000,  93.1556, 462.8000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2194], device='cuda:0')}, {'boxes': tensor([[ 60.7677, 246.3030, 159.0303, 434.4243]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2021], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000,   8.5333, 458.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2149], device='cuda:0')}, {'boxes': tensor([[270.4000, 347.7333, 320.0000, 408.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([795], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 192.0000, 511.2000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([575], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 511.2000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2084], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.4000, 273.7778, 281.6000, 340.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([983], device='cuda:0')}, {'boxes': tensor([[380.8000, 151.4667, 438.4000, 214.7556],\n",
      "        [274.4000, 167.1111, 328.8000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([629], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  99.5556, 163.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([211], device='cuda:0')}, {'boxes': tensor([[107.2000, 109.5111, 511.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([732], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.6000, 171.3778, 310.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([809], device='cuda:0')}, {'boxes': tensor([[153.6000, 196.9778, 315.6000, 354.8445],\n",
      "        [354.8000, 294.4000, 376.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1552], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[135.2000,  32.7111, 396.0000, 384.0000],\n",
      "        [119.2000, 261.6889, 172.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([506], device='cuda:0')}, {'boxes': tensor([[123.2000,   1.4222, 510.8000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([309], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.2000,   0.7111, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([640], device='cuda:0')}, {'boxes': tensor([[231.2000, 263.1111, 275.2000, 463.6444],\n",
      "        [328.8000, 264.5333, 395.2000, 509.1555],\n",
      "        [156.8000, 256.0000, 196.0000, 415.2889],\n",
      "        [284.0000, 250.3111, 312.0000, 371.2000],\n",
      "        [ 13.6000, 312.8889, 130.4000, 507.7333],\n",
      "        [483.2000, 334.2222, 511.2000, 507.7333],\n",
      "        [469.6000, 297.2444, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1764], device='cuda:0')}, {'boxes': tensor([[206.0000, 216.8889, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1222], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000, 227.5556, 251.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1239], device='cuda:0')}, {'boxes': tensor([[136.0000, 162.1333, 262.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([930], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.0000, 104.5333, 372.4000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([78], device='cuda:0')}, {'boxes': tensor([[221.8667, 234.6667, 251.2593, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  8.5333, 182.0444, 299.7333, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([195], device='cuda:0')}, {'boxes': tensor([[ 59.7333,  27.0222, 360.5333, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1721], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 124.4444, 302.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1003], device='cuda:0')}, {'boxes': tensor([[219.7333,  76.8000, 509.8667, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([664], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.7333, 143.6444,  87.4667, 223.2889],\n",
      "        [338.1333, 169.2444, 474.6667, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([680], device='cuda:0')}, {'boxes': tensor([[219.7333, 203.3778, 358.4000, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667,  11.3778, 380.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([592], device='cuda:0')}, {'boxes': tensor([[190.4000, 159.2889, 272.0000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1128], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.4000,   0.0000, 511.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1633], device='cuda:0')}, {'boxes': tensor([[122.8000, 157.8667, 310.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000, 200.5333, 363.2000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1267], device='cuda:0')}, {'boxes': tensor([[155.2340,  41.2444, 332.2553, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1087], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[348.8000, 473.6000, 389.6000, 510.5778],\n",
      "        [187.6000, 258.1333, 203.6000, 293.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1871], device='cuda:0')}, {'boxes': tensor([[166.4000, 185.6000, 288.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1967], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.0000, 199.8222, 316.8000, 289.4222],\n",
      "        [ 60.4000, 226.1333, 197.6000, 337.0667],\n",
      "        [202.0000, 252.4444, 338.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1577], device='cuda:0')}, {'boxes': tensor([[188.4000, 199.8222, 296.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.0881,   0.0000, 322.8176, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1027], device='cuda:0')}, {'boxes': tensor([[  0.0000, 251.7333, 179.2000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1035], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000,  93.1556, 432.0000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([394], device='cuda:0')}, {'boxes': tensor([[240.8000, 192.0000, 291.2000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1886], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.3852, 204.8000, 343.2296, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([186], device='cuda:0')}, {'boxes': tensor([[125.6000,  97.4222, 285.6000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1852], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 23.4667, 260.2667, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([245], device='cuda:0')}, {'boxes': tensor([[224.8000, 243.2000, 273.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([737], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.6000, 148.6222, 280.8000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1887], device='cuda:0')}, {'boxes': tensor([[360.0000, 209.0667, 444.0000, 504.8889],\n",
      "        [164.0000, 240.3556, 268.0000, 509.1555],\n",
      "        [  0.0000, 237.5111,  88.8000, 507.7333],\n",
      "        [324.8000, 164.9778, 343.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([773], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000,   0.0000, 268.8000, 455.1111],\n",
      "        [267.2000, 388.2667, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1627], device='cuda:0')}, {'boxes': tensor([[227.2000, 156.4444, 308.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1997], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.6000, 166.4000, 411.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31], device='cuda:0')}, {'boxes': tensor([[171.2000,  91.7333, 280.8000, 473.6000],\n",
      "        [215.2000, 157.8667, 305.6000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1527], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.8000,  61.8667, 340.4000, 386.8445],\n",
      "        [322.0000, 138.6667, 362.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1538], device='cuda:0')}, {'boxes': tensor([[188.0000, 244.6222, 236.0000, 337.0667],\n",
      "        [324.4000, 240.3556, 402.8000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1563], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 218.3111, 232.4000, 263.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([856], device='cuda:0')}, {'boxes': tensor([[205.8667, 209.0667, 355.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000, 221.3770, 201.6000, 386.0984],\n",
      "        [348.8000, 287.4754, 480.8000, 454.2951],\n",
      "        [304.8000, 347.2787, 357.6000, 430.1639],\n",
      "        [314.4000,   0.0000, 372.0000,  64.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([966], device='cuda:0')}, {'boxes': tensor([[ 26.8000,   0.0000, 460.8000, 494.2222],\n",
      "        [205.2000,  62.5778, 339.2000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1666], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[379.6000, 275.2000, 450.8000, 349.8667],\n",
      "        [260.0000, 156.4444, 356.8000, 258.8445],\n",
      "        [179.2000, 110.9333, 274.4000, 216.8889],\n",
      "        [296.4000, 227.5556, 393.2000, 325.6889],\n",
      "        [428.0000, 364.8000, 450.8000, 398.9333],\n",
      "        [219.6000, 174.2222, 315.6000, 275.2000],\n",
      "        [351.2000, 228.2667, 445.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([87], device='cuda:0')}, {'boxes': tensor([[192.0000, 257.4222, 221.8667, 275.9111],\n",
      "        [311.4667, 250.3111, 426.6667, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2112], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  9.2000,  47.6444, 510.8000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([378], device='cuda:0')}, {'boxes': tensor([[262.8000, 133.6889, 379.6000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([657], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.2000, 189.1555, 336.0000, 234.6667],\n",
      "        [288.8000, 219.0222, 322.0000, 261.6889],\n",
      "        [241.6000, 211.2000, 272.4000, 260.9778],\n",
      "        [213.6000, 256.0000, 248.8000, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([151], device='cuda:0')}, {'boxes': tensor([[ 35.2294, 256.0000, 169.1009, 406.4000],\n",
      "        [343.4862, 185.6000, 489.6881, 475.7333],\n",
      "        [365.2110, 292.2667, 510.2385, 506.6667],\n",
      "        [ 39.3395, 268.8000, 126.2385, 416.0000],\n",
      "        [  0.0000, 265.6000,  75.1560, 437.3333],\n",
      "        [182.0183,  78.9333, 502.0183, 404.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([450], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.4000, 136.5333, 308.0000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([215], device='cuda:0')}, {'boxes': tensor([[ 62.4000, 159.2889, 444.8000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([155], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.8000, 102.4000, 390.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([643], device='cuda:0')}, {'boxes': tensor([[236.0000, 364.8000, 293.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1888], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 46.0000, 108.0889, 165.6000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1259], device='cuda:0')}, {'boxes': tensor([[270.9333, 209.0667, 464.0000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1106], device='cuda:0')}, {'boxes': tensor([[208.8000, 104.5333, 334.8000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1842], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.4000, 184.1778, 293.6000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1331], device='cuda:0')}, {'boxes': tensor([[122.4000, 167.8222, 262.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([929], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.7333, 100.9778, 309.3333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1470], device='cuda:0')}, {'boxes': tensor([[ 26.6667, 157.1555,  72.5333, 307.9111],\n",
      "        [101.3333, 194.8445, 219.7333, 312.8889],\n",
      "        [233.6000, 214.0444, 342.4000, 315.7333],\n",
      "        [408.5333, 209.0667, 461.3333, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([59], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 112.3556, 412.8000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1294], device='cuda:0')}, {'boxes': tensor([[188.8000, 285.1555, 269.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1884], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[305.0667, 228.9778, 362.6667, 284.4445],\n",
      "        [ 25.6000, 153.6000,  83.2000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([257], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 302.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2082], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.0000,   3.5556, 419.6000, 465.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([293], device='cuda:0')}, {'boxes': tensor([[247.2000, 283.0222, 262.4000, 320.7111],\n",
      "        [216.8000, 252.4444, 234.4000, 292.9778],\n",
      "        [232.4000, 271.6444, 248.8000, 312.1778],\n",
      "        [212.4000, 208.3556, 228.8000, 248.8889],\n",
      "        [243.2000, 247.4667, 260.8000, 288.0000],\n",
      "        [240.0000, 210.4889, 256.4000, 250.3111],\n",
      "        [224.0000, 189.1555, 238.8000, 228.2667],\n",
      "        [208.0000, 174.2222, 224.4000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([137], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[270.8000,  88.1778, 365.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1192], device='cuda:0')}, {'boxes': tensor([[ 53.3333, 263.1111, 183.4667, 382.5778],\n",
      "        [361.6000, 250.3111, 429.8667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([701], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([955], device='cuda:0')}, {'boxes': tensor([[272.0000,  95.2889, 418.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1673], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  76.8000, 236.8000, 312.8889],\n",
      "        [224.0000,   0.0000, 508.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1081], device='cuda:0')}, {'boxes': tensor([[116.8000, 151.2727, 307.2000, 269.0909]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1418], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[292.0000, 248.8889, 408.8000, 419.5555],\n",
      "        [  0.0000, 164.9778,  93.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([898], device='cuda:0')}, {'boxes': tensor([[ 14.8000, 164.2667, 189.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[271.6000,  88.1778, 365.2000, 226.1333],\n",
      "        [139.2000, 105.9556, 177.6000, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1191], device='cuda:0')}, {'boxes': tensor([[108.8000,  81.0667, 350.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([64], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000,   0.0000, 384.4000, 231.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([32], device='cuda:0')}, {'boxes': tensor([[ 89.6000,  72.5333, 413.8667, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1693], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.6000, 182.7556, 320.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1965], device='cuda:0')}, {'boxes': tensor([[ 13.6000,   0.0000, 299.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([407], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000,  73.2444, 372.4000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1797], device='cuda:0')}, {'boxes': tensor([[ 53.2000, 467.2000, 234.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1163], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000,  62.5778, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([392], device='cuda:0')}, {'boxes': tensor([[209.6000, 296.5333, 248.8000, 403.2000],\n",
      "        [250.0000, 205.5111, 269.2000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([832], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.6000, 289.4222, 293.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1889], device='cuda:0')}, {'boxes': tensor([[197.6000,  61.8667, 362.8000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([842], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 156.4444, 275.2000, 304.3556],\n",
      "        [174.9333, 244.6222, 411.7333, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([2076], device='cuda:0')}, {'boxes': tensor([[216.0000,  47.6444, 458.0000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([379], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 123.0222, 308.8000, 204.0889],\n",
      "        [347.6000, 204.0889, 398.0000, 292.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([881], device='cuda:0')}, {'boxes': tensor([[ 81.0667,   0.0000, 277.3333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1255], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [170.4000, 158.5778, 202.0000, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1399], device='cuda:0')}, {'boxes': tensor([[184.8889, 183.4667, 511.0518, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 432.3556, 181.6000, 509.1555],\n",
      "        [377.6000, 348.4445, 401.6000, 506.3111],\n",
      "        [476.0000, 403.9111, 510.4000, 509.1555],\n",
      "        [200.8000, 440.8889, 324.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([782], device='cuda:0')}, {'boxes': tensor([[209.6000, 125.1556, 508.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([999], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[100.8000, 223.2889, 308.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1167], device='cuda:0')}, {'boxes': tensor([[ 53.2000,  86.7556, 440.0000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([217], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 164.9778, 276.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1956], device='cuda:0')}, {'boxes': tensor([[  0.0000, 123.7333, 297.6000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1945], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([12], device='cuda:0')}, {'boxes': tensor([[128.4000,   0.0000, 510.4000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2100], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 193.4222, 254.0000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1892], device='cuda:0')}, {'boxes': tensor([[  0.0000, 258.8445,  76.0000, 405.3333],\n",
      "        [128.0000, 247.4667, 184.0000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([949], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,   0.0000, 261.6000, 509.1555],\n",
      "        [220.8000,   0.0000, 398.8000, 510.5778],\n",
      "        [265.6000, 105.2444, 412.0000, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1661], device='cuda:0')}, {'boxes': tensor([[260.4000, 123.0222, 277.6000, 165.6889],\n",
      "        [244.8000, 176.3556, 262.0000, 216.8889],\n",
      "        [230.4000, 244.6222, 249.6000, 285.1555],\n",
      "        [215.6000, 316.4445, 233.6000, 354.1333],\n",
      "        [204.8000, 379.7333, 222.4000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([143], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000,   0.0000, 355.2000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2073], device='cuda:0')}, {'boxes': tensor([[194.1333, 193.4222, 356.2667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1716], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[453.3333, 288.7111, 510.9333, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1707], device='cuda:0')}, {'boxes': tensor([[ 74.8000,  91.0222, 349.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[242.3787, 161.4222, 494.7731, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1969], device='cuda:0')}, {'boxes': tensor([[  9.6000, 290.1333, 294.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1042], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.0000,  55.4667, 320.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1668], device='cuda:0')}, {'boxes': tensor([[ 89.2000, 221.8667, 190.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([857], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  28.4444, 315.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1051], device='cuda:0')}, {'boxes': tensor([[ 75.2000, 329.9556, 189.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([808], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.2000, 204.8000, 224.4000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1465], device='cuda:0')}, {'boxes': tensor([[179.6000, 280.8889, 252.8000, 378.3111],\n",
      "        [ 14.0000, 202.6667, 197.6000, 384.0000],\n",
      "        [139.6000, 278.7556, 226.4000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([513], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000,  91.0222, 480.0000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([662], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([953], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.7333, 186.3111, 330.6667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([202], device='cuda:0')}, {'boxes': tensor([[150.4000,  64.0000, 449.2000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([848], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 187.0222, 259.2000, 366.2222],\n",
      "        [185.6000, 216.8889, 270.8000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1564], device='cuda:0')}, {'boxes': tensor([[228.8000, 123.7333, 333.6000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1379], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.8000,  54.0444, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1025], device='cuda:0')}, {'boxes': tensor([[222.0000,   0.0000, 397.6000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1454], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000, 156.4444, 288.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1332], device='cuda:0')}, {'boxes': tensor([[ 62.9333,  58.3111, 394.6667, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1696], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[291.6557, 149.3333, 493.5712, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1971], device='cuda:0')}, {'boxes': tensor([[169.6000, 271.6444, 251.2000, 337.0667],\n",
      "        [120.8000, 275.9111, 207.2000, 342.0444],\n",
      "        [272.0000, 233.9556, 356.8000, 301.5111],\n",
      "        [226.8000, 184.8889, 320.0000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([136], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.1333, 174.9333, 342.4000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1064], device='cuda:0')}, {'boxes': tensor([[ 50.8000, 156.4444, 111.6000, 201.9556],\n",
      "        [337.6000, 206.2222, 350.4000, 221.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([2080], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[320.0000, 248.8889, 507.2000, 509.1555],\n",
      "        [ 86.4000,   0.0000, 236.8000, 280.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1613], device='cuda:0')}, {'boxes': tensor([[  0.0000,  17.7778, 304.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1180], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.8000, 266.6667, 343.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1923], device='cuda:0')}, {'boxes': tensor([[256.4000, 110.9333, 378.0000, 471.4667],\n",
      "        [306.4000, 190.5778, 379.6000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1533], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[286.4000, 117.3333, 403.2000, 509.8667],\n",
      "        [ 81.6000, 145.0667, 273.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1411], device='cuda:0')}, {'boxes': tensor([[ 44.8000,  44.0889, 282.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([547], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 216.1778, 389.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2169], device='cuda:0')}, {'boxes': tensor([[113.6000, 211.9111, 264.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([40], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.9185, 173.5111, 297.7185, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([756], device='cuda:0')}, {'boxes': tensor([[196.0000, 283.0222, 289.2000, 349.8667],\n",
      "        [238.8000, 271.6444, 315.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1822], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000, 182.7556, 282.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([368], device='cuda:0')}, {'boxes': tensor([[141.2000, 244.6222, 315.6000, 477.8667],\n",
      "        [ 35.6000, 221.1555, 348.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([558], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 125.8667, 350.8000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([8], device='cuda:0')}, {'boxes': tensor([[176.0000, 104.5333, 191.2000, 155.0222],\n",
      "        [238.0000, 244.6222, 251.6000, 268.8000],\n",
      "        [244.4000, 405.3333, 314.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24], device='cuda:0'), 'image_id': tensor([1880], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  98.1333, 425.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1295], device='cuda:0')}, {'boxes': tensor([[199.2000, 104.5333, 478.8000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([313], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.4000, 245.3333, 309.2000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1160], device='cuda:0')}, {'boxes': tensor([[162.0000, 238.9333, 473.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1646], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.2000, 114.4889, 220.4000, 247.4667],\n",
      "        [272.8000, 159.2889, 314.0000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([850], device='cuda:0')}, {'boxes': tensor([[ 88.8000, 175.6444, 241.6000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([21], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[257.2000, 276.6222, 326.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1883], device='cuda:0')}, {'boxes': tensor([[ 67.2000,  27.0222, 361.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([595], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000,  62.5778, 313.6000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1848], device='cuda:0')}, {'boxes': tensor([[219.2000, 192.0000, 396.8000, 395.6364],\n",
      "        [141.6000, 244.3636, 229.6000, 385.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[131.6000,   7.1111, 502.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([305], device='cuda:0')}, {'boxes': tensor([[255.2000, 186.1818, 400.8000, 320.0000],\n",
      "        [203.2000, 221.0909, 276.8000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.4000, 201.9556, 510.4000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([584], device='cuda:0')}, {'boxes': tensor([[178.4000,  57.6000, 306.4000, 257.4222],\n",
      "        [294.4000,  36.9778, 450.8000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([564], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[175.6000, 278.0444, 258.8000, 375.4667],\n",
      "        [ 22.4000, 200.5333, 210.0000, 381.8667],\n",
      "        [140.8000, 269.5111, 238.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([514], device='cuda:0')}, {'boxes': tensor([[148.4000, 125.1556, 318.4000, 395.3778],\n",
      "        [ 21.6000, 147.2000, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([552], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.2000, 264.5333, 347.2000, 334.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1922], device='cuda:0')}, {'boxes': tensor([[167.6000,  34.8444, 243.2000, 115.9111],\n",
      "        [298.4000, 251.0222, 364.8000, 349.8667],\n",
      "        [373.2000,  91.0222, 404.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24, 24], device='cuda:0'), 'image_id': tensor([1868], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 258.8445, 203.2000, 402.4889],\n",
      "        [266.4000, 261.6889, 301.6000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([765], device='cuda:0')}, {'boxes': tensor([[  4.0000, 218.3111, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1211], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[480.0000, 273.0667, 509.6000, 366.9333],\n",
      "        [185.6000,  68.2667, 298.4000, 409.6000],\n",
      "        [158.4000, 331.3778, 214.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2,  2, 20], device='cuda:0'), 'image_id': tensor([508], device='cuda:0')}, {'boxes': tensor([[128.8000, 110.9333, 305.6000, 453.6889],\n",
      "        [  0.0000,  89.6000,  64.0000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1770], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 151.4667, 357.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1978], device='cuda:0')}, {'boxes': tensor([[248.8000,   0.7111, 510.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([274], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 435.2000, 301.5111],\n",
      "        [340.8000, 284.4445, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1622], device='cuda:0')}, {'boxes': tensor([[224.8000, 147.9111, 314.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1992], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000, 159.2889, 311.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1994], device='cuda:0')}, {'boxes': tensor([[134.0000, 193.4222, 375.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1603], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.2000, 145.0667, 369.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([83], device='cuda:0')}, {'boxes': tensor([[ 74.4000, 125.8667, 348.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([649], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 142.2222, 468.0000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([334], device='cuda:0')}, {'boxes': tensor([[118.0000, 226.1333, 442.8000, 510.5778],\n",
      "        [  0.0000, 229.6889, 135.6000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.4000, 106.6667, 194.4000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1138], device='cuda:0')}, {'boxes': tensor([[282.0000, 179.9111, 383.6000, 292.9778],\n",
      "        [100.0000, 135.8222, 292.8000, 462.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([901], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 182.0444, 226.4000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([630], device='cuda:0')}, {'boxes': tensor([[192.4000, 119.4667, 505.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([227], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000, 192.0000, 429.8667, 268.8000],\n",
      "        [240.0000, 275.9111, 277.3333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1702], device='cuda:0')}, {'boxes': tensor([[108.4000, 108.0889, 273.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2047], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,   0.0000, 510.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1658], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.7280e+02, 4.0680e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([739], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667, 179.2000, 229.3333, 244.6222],\n",
      "        [224.0000, 176.3556, 289.0667, 244.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([365], device='cuda:0')}, {'boxes': tensor([[224.0000,  80.3556, 292.8000, 219.7333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1189], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.8667,   0.0000, 394.6667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2087], device='cuda:0')}, {'boxes': tensor([[180.4000,  56.8889, 329.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 251.0222, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1921], device='cuda:0')}, {'boxes': tensor([[224.8000, 216.1778, 348.4000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333,  46.9333, 419.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([716], device='cuda:0')}, {'boxes': tensor([[201.2000, 206.9333, 300.0000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000, 123.7333, 270.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1333], device='cuda:0')}, {'boxes': tensor([[  0.0000, 172.8000, 292.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1216], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1273], device='cuda:0')}, {'boxes': tensor([[ 61.6000, 302.9333, 164.0000, 420.9778],\n",
      "        [ 60.4000, 237.5111,  98.0000, 309.3333],\n",
      "        [109.2000, 223.2889, 222.4000, 334.9333],\n",
      "        [ 60.8000, 166.4000, 156.8000, 270.2222],\n",
      "        [106.4000, 110.9333, 213.2000, 219.7333],\n",
      "        [208.8000, 157.8667, 317.6000, 286.5778],\n",
      "        [264.4000, 228.2667, 369.6000, 338.4889],\n",
      "        [324.8000, 227.5556, 432.0000, 332.0889],\n",
      "        [162.0000, 187.0222, 269.2000, 294.4000],\n",
      "        [400.8000, 381.1555, 448.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([122], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 258.8445, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1225], device='cuda:0')}, {'boxes': tensor([[151.4667, 159.2889, 222.9333, 219.0222],\n",
      "        [216.5333, 169.2444, 300.8000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.4000, 185.6000, 258.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1338], device='cuda:0')}, {'boxes': tensor([[111.2000,  98.8444, 430.8000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([645], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 118.7556, 500.8000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([228], device='cuda:0')}, {'boxes': tensor([[  0.0000,  41.2444, 510.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([580], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 247.4667, 179.2000, 375.4667],\n",
      "        [405.3333, 228.9778, 434.1333, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([696], device='cuda:0')}, {'boxes': tensor([[189.6000,  66.0984, 396.8000, 481.5738]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([956], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[154.8000,  52.6222, 362.4000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([343], device='cuda:0')}, {'boxes': tensor([[288.0000,  98.1333, 372.2667, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1585], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000, 164.2667, 307.2000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([543], device='cuda:0')}, {'boxes': tensor([[ 28.8000, 175.6444, 201.6000, 381.1555],\n",
      "        [388.8000, 179.2000, 460.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1522], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 196.2667, 216.0000, 477.8667],\n",
      "        [264.8000, 170.6667, 308.0000, 335.6444],\n",
      "        [478.4000, 213.3333, 509.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([780], device='cuda:0')}, {'boxes': tensor([[333.8667,  29.8667, 510.9333, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1724], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 20.4000,   9.9556, 509.2000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1581], device='cuda:0')}, {'boxes': tensor([[ 43.6000, 217.6000, 191.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1655], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  36.9778, 228.2667, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1476], device='cuda:0')}, {'boxes': tensor([[317.6000, 234.6667, 366.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1870], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  15.6444, 234.6667, 465.0667],\n",
      "        [296.5333,  48.3556, 509.8667, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([611], device='cuda:0')}, {'boxes': tensor([[ 97.6000,  76.8000, 253.6000, 250.3111],\n",
      "        [254.4000,  51.2000, 369.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1736], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.2667, 193.4222, 410.6667, 290.1333],\n",
      "        [254.9333, 192.0000, 358.4000, 285.8667],\n",
      "        [148.2667, 157.8667, 204.8000, 236.0889],\n",
      "        [433.0667, 221.8667, 510.9333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([355], device='cuda:0')}, {'boxes': tensor([[106.0000,  49.0667, 511.2000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([749], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.6000, 230.4000, 509.6000, 499.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([586], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1607], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.3333,  91.0222, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1731], device='cuda:0')}, {'boxes': tensor([[142.8000, 127.2889, 239.6000, 425.9556],\n",
      "        [236.8000, 117.3333, 354.0000, 388.9778],\n",
      "        [222.4000, 201.9556, 274.4000, 369.7778],\n",
      "        [  0.0000, 273.0667,  24.0000, 291.5555],\n",
      "        [101.6000, 252.4444, 143.6000, 270.2222],\n",
      "        [455.6000, 343.4667, 510.4000, 371.2000],\n",
      "        [444.8000, 437.3333, 511.2000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2069], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.0000, 179.2000, 374.0000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2158], device='cuda:0')}, {'boxes': tensor([[282.8000, 161.4222, 393.6000, 299.3778],\n",
      "        [ 94.0000, 142.2222, 290.4000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([904], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1515], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2090], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1, 4] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e455798daba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 50,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-b1dbdd86237c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                         \u001b[0mvalid_loss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                         \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mregression_targets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             loss_classifier, loss_box_reg = fastrcnn_loss(\n\u001b[0;32m--> 761\u001b[0;31m                 class_logits, box_regression, labels, regression_targets)\n\u001b[0m\u001b[1;32m    762\u001b[0m             losses = {\n\u001b[1;32m    763\u001b[0m                 \u001b[0;34m\"loss_classifier\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mfastrcnn_loss\u001b[0;34m(class_logits, box_regression, labels, regression_targets)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlabels_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_pos_inds_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mbox_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     box_loss = det_utils.smooth_l1_loss(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1, 4] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 50,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 50.0\n",
      "Device: cuda\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/10 | Batch Number: 50 | LR: 0.00100 | Train_loss: 904.50 | Valid_loss: 235.18 | Valid mAP: 0.00% | Valid Missed Images 100 / 100\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 75.7760, 136.8408, 510.9760, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([421], device='cuda:0')}, {'boxes': tensor([[188.4160, 101.0347, 355.3280, 248.4907]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([665], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-bcdb84b15e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmob_net_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmob_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-90869e855fe9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.001, weight_decay = 1e-5, print_times_per_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 6499.0\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    initial_lr: 0.0001\n",
      "    k: 6\n",
      "    lr: 0.0001\n",
      "    rho: 0.05\n",
      "    step_counter: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/10 | Batch Number: 6499 | LR: 0.00010 | Train_loss: 2358.17 | Valid_loss: 504.38 | Valid mAP: 10.56% | Valid Missed Images 24 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/10 | Batch Number: 12998 | LR: 0.00010 | Train_loss: 2171.53 | Valid_loss: 506.35 | Valid mAP: 10.90% | Valid Missed Images 27 / 3082\n",
      "Epoch 1/10 | Batch Number: 19497 | LR: 0.00010 | Train_loss: 2285.98 | Valid_loss: 490.59 | Valid mAP: 9.40% | Valid Missed Images 13 / 3082\n",
      "Epoch 1/10 | Batch Number: 25996 | LR: 0.00010 | Train_loss: 2500.76 | Valid_loss: 542.19 | Valid mAP: 23.81% | Valid Missed Images 801 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/10 | Batch Number: 32495 | LR: 0.00010 | Train_loss: 12414371.06 | Valid_loss: 1925.38 | Valid mAP: 2.00% | Valid Missed Images 0 / 3082\n",
      "\n",
      " Epoch 1 | Epoch Time 66608.08 | Final Train mAP: 13.40% | Final Train Missed Images 5064 / 64995 \n",
      "\n",
      "Saving Model path to directory Faster_rcnn_Saved_Models ... \n",
      "Succesfully saved model data to file path. \n",
      "\n",
      "Epoch 2/10 | Batch Number: 6499 | LR: 0.00010 | Train_loss: 23351.43 | Valid_loss: 675.11 | Valid mAP: 20.61% | Valid Missed Images 1790 / 3082\n",
      "Epoch 2/10 | Batch Number: 12998 | LR: 0.00010 | Train_loss: 3715.10 | Valid_loss: 605.79 | Valid mAP: 4.40% | Valid Missed Images 2890 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 2/10 | Batch Number: 19497 | LR: 0.00009 | Train_loss: 2779.39 | Valid_loss: 604.81 | Valid mAP: 0.56% | Valid Missed Images 3051 / 3082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-449305a17999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.0001, weight_decay = 1e-5, print_times_per_epoch = 5,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV1\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-e6e43a2f926b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Check for degenerate boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m                                  \"of shape [C, H, W], got {}\".format(image.shape))\n\u001b[1;32m    104\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, image, target)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mresize_boxes\u001b[0;34m(boxes, original_size, new_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     ]\n\u001b[1;32m    273\u001b[0m     \u001b[0mratio_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     ]\n\u001b[1;32m    273\u001b[0m     \u001b[0mratio_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.0001, weight_decay = 1e-5, print_times_per_epoch = 5,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model function. \n",
    "* Only will run if you have .pth file that configures nicely with Faster RCNN Resnet50FPN\n",
    "* If model crashes while training, then might have to load in optimizer.\n",
    "\n",
    "#### Example Code of Succesful save: \n",
    "`\n",
    "checkpoint_file = \"Faster_rcnn_Saved_Models/Epoch3FastRCNNResNetV1.pth\"\n",
    "new_mob_net = load_model_fast_rcnn(checkpoint_file) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_fast_rcnn(checkpoint_file, mished = True):\n",
    "    \n",
    "    #Get model configuration\n",
    "    model = torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn(pretrained = False)\n",
    "    model.roi_heads.box_predictor.cls_score.out_features = len(get_class_info())\n",
    "    model.roi_heads.box_predictor.bbox_pred.out_features = len(get_class_info()) * 4\n",
    "    \n",
    "    if mished:\n",
    "        convert_it(mob_net, Mish(), nn.ReLU6)\n",
    "    \n",
    "    #Load in state dicts \n",
    "    if os.path.isfile(checkpoint_file):\n",
    "        checkpoint = torch.load(checkpoint_file)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])   \n",
    "    else:\n",
    "        raise ValueError(\"Checkpoint File does not exist\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Effecient Det Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1122397 train images in total\n",
      "\n",
      "\n",
      "BEFORE DET: Amount of image files in Dataset 54647\n",
      "BEFORE DET: Amount of annotation files in Dataset 54647 \n",
      "\n",
      "Amount of images in Det Set (Approx.) 21455\n",
      "Amount of image files in Dataset 76102\n",
      "Amount of annotation files in Dataset 76102\n",
      "\n",
      "\n",
      "Loading with Effecient Det Structure ... \n",
      "\n",
      "Amount of image files in Dataset 2201\n",
      "Amount of annotation files in Dataset 2201\n",
      "\n",
      "\n",
      "Loading with Effecient Det Structure ... \n",
      "\n",
      " \n",
      " ... Seperate from Data Loader \n",
      "\n",
      "Length of train_dataset 500\n",
      "Length of valid_dataset 100\n"
     ]
    }
   ],
   "source": [
    "#Util Scoring Function\n",
    "def run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, mAP, missed_images, device):\n",
    "    assert (len(scores) == len(classification) == len(transformed_anchors))\n",
    "    if len(transformed_anchors) != 0:\n",
    "        curr_mAP = calculate_metrics(targets[0][:, :4], transformed_anchors, scores, device)\n",
    "        mAP += curr_mAP\n",
    "    else:\n",
    "        missed_images += 1 \n",
    "      \n",
    "    return mAP, missed_images\n",
    "\n",
    "def detection_collate(batch):\n",
    "    imgs = [s['image'] for s in batch]\n",
    "    annots = [s['bboxes'] for s in batch]\n",
    "    labels = [s['category_id'] for s in batch]\n",
    "\n",
    "    max_num_annots = max(len(annot) for annot in annots)\n",
    "    annot_padded = np.ones((len(annots), max_num_annots, 5))*-1\n",
    "\n",
    "    if max_num_annots > 0:\n",
    "        for idx, (annot, lab) in enumerate(zip(annots, labels)):\n",
    "            if len(annot) > 0:\n",
    "                annot_padded[idx, :len(annot), :4] = annot\n",
    "                annot_padded[idx, :len(annot), 4] = lab\n",
    "    return (torch.stack(imgs, 0), torch.FloatTensor(annot_padded))\n",
    "\n",
    "eff_train_batch = 8\n",
    "eff_test_batch = 1\n",
    "det_text_file = \"/data1/group/mlgroup/train_data/ILSVRC2015/DET_train_30classes.txt\"\n",
    "\n",
    "eff_train_dataset = VideoFrameDataset(\"train\", os.path.join(\"Data/VID\", \"train\"), os.path.join(\"Annotations/VID\", \"train\"), get_transforms(mode = \"effdet_train\"), \n",
    "                                  seg_len = 20, det_text_file_paths = det_text_file, effdet_data = True, data_size = 500)\n",
    "eff_valid_dataset = VideoFrameDataset(\"validation\", os.path.join(\"Data/VID\", \"val\"), os.path.join(\"Annotations/VID\", \"val\"), get_transforms(mode = \"effdet_test\"),\n",
    "                                  make_valid_smaller_percent = 0.0125, effdet_data = True, data_size = 100)\n",
    "\n",
    "eff_train_loader = torch.utils.data.DataLoader(eff_train_dataset, batch_size = eff_train_batch, shuffle = True, collate_fn= detection_collate)\n",
    "eff_valid_loader = torch.utils.data.DataLoader(eff_valid_dataset, batch_size = eff_test_batch, shuffle = True, collate_fn = detection_collate)\n",
    "\n",
    "print(\" \\n ... Seperate from Data Loader \\n\")\n",
    "print(\"Length of train_dataset {}\".format(len(eff_train_dataset)))\n",
    "print(\"Length of valid_dataset {}\".format(len(eff_valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Run with DataParallel ....\n",
      "Mish activation loaded...\n"
     ]
    }
   ],
   "source": [
    "MODEL_MAP = {\n",
    "    'efficientdet-d0': 'efficientnet-b0',\n",
    "    'efficientdet-d1': 'efficientnet-b1',\n",
    "    'efficientdet-d2': 'efficientnet-b2',\n",
    "    'efficientdet-d3': 'efficientnet-b3',\n",
    "    'efficientdet-d4': 'efficientnet-b4',\n",
    "    'efficientdet-d5': 'efficientnet-b5',\n",
    "    'efficientdet-d6': 'efficientnet-b6',\n",
    "    'efficientdet-d7': 'efficientnet-b6',\n",
    "}\n",
    "class EfficientDet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 network='efficientdet-d0',\n",
    "                 D_bifpn=3,\n",
    "                 W_bifpn=88,\n",
    "                 D_class=3,\n",
    "                 is_training=True,\n",
    "                 threshold=0.01, #can change this value 0.01\n",
    "                 iou_threshold=0.5): # can change this value 0.5\n",
    "        super(EfficientDet, self).__init__()\n",
    "        \n",
    "        self.backbone = EfficientNet.from_pretrained(MODEL_MAP[network])\n",
    "        self.is_training = is_training\n",
    "        self.neck = BIFPN(in_channels=self.backbone.get_list_features()[-5:],\n",
    "                          out_channels=W_bifpn,\n",
    "                          stack=D_bifpn,\n",
    "                          num_outs=5)\n",
    "        self.bbox_head = RetinaHead(num_classes=num_classes,\n",
    "                                    in_channels=W_bifpn)\n",
    "\n",
    "        self.anchors = Anchors()\n",
    "        self.regressBoxes = BBoxTransform()\n",
    "        self.clipBoxes = ClipBoxes()\n",
    "        self.threshold = threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        self.freeze_bn()\n",
    "        self.criterion = FocalLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.is_training:\n",
    "            inputs, annotations = inputs\n",
    "        else:\n",
    "            inputs = inputs\n",
    "        x = self.extract_feat(inputs)\n",
    "        outs = self.bbox_head(x)\n",
    "        classification = torch.cat([out for out in outs[0]], dim=1)\n",
    "        regression = torch.cat([out for out in outs[1]], dim=1)\n",
    "        anchors = self.anchors(inputs)\n",
    "        if self.is_training:\n",
    "            return self.criterion(classification, regression, anchors, annotations)\n",
    "        else:\n",
    "            transformed_anchors = self.regressBoxes(anchors, regression)\n",
    "            transformed_anchors = self.clipBoxes(transformed_anchors, inputs)\n",
    "            scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "            scores_over_thresh = (scores > self.threshold)[0, :, 0]\n",
    "\n",
    "            if scores_over_thresh.sum() == 0:\n",
    "                # print('No boxes to NMS')\n",
    "                # no boxes to NMS, just return\n",
    "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\n",
    "            classification = classification[:, scores_over_thresh, :]\n",
    "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\n",
    "            scores = scores[:, scores_over_thresh, :]\n",
    "            anchors_nms_idx = nms(\n",
    "                transformed_anchors[0, :, :], scores[0, :, 0], iou_threshold=self.iou_threshold)\n",
    "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(\n",
    "                dim=1)\n",
    "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        '''Freeze BatchNorm layers.'''\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.eval()\n",
    "\n",
    "    def extract_feat(self, img):\n",
    "        \"\"\"\n",
    "            Directly extract features from the backbone+neck\n",
    "        \"\"\"\n",
    "        x = self.backbone(img)\n",
    "        x = self.neck(x[-5:])\n",
    "        return x\n",
    "\n",
    "model= EfficientDet(num_classes=len(get_class_info()),is_training=True)\n",
    "model.train()\n",
    "\n",
    "model.freeze_bn()\n",
    "\n",
    "model = model.cuda()\n",
    "print('Run with DataParallel ....')\n",
    "\n",
    "## Make sure that you add this line, even though you are not using more than one \n",
    "# GPU DataParallel adds \"module\" to the start of the model structure \n",
    "# allowing for the syntax to be correct when calling \"model.module.freeze_bn()\" for example\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# I am doing this here an example, you do not have to call the lines below here\n",
    "model.module.is_training = True\n",
    "model.module.freeze_bn()\n",
    "\n",
    "convert_it(model, Mish(), nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_effdet(net, epochs, train_loader, test_loader, lr, weight_decay, \n",
    "          print_times_per_epoch, lo_test_dataset = len(eff_valid_dataset), lo_train_dataset = len(eff_train_dataset)):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: {}\".format(device))\n",
    "    print(\"Note: Train Accuracies are only run through one train image per batch\")\n",
    "    \n",
    "    print_every = lo_train_dataset / eff_train_batch // print_times_per_epoch\n",
    "    print(\"Print Every: {}\".format(print_every))\n",
    "\n",
    "    if device == torch.device(\"cpu\"):\n",
    "        warnings.warn(\"Code does not support running on CPU but only GPU\")\n",
    "\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "#     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
    "\n",
    "    start_time = time.time()\n",
    "    net.module.freeze_bn()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "        net.module.is_training = True\n",
    "        \n",
    "        train_loss = steps = train_mAP = missed_train_images = 0\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "\n",
    "            net.train()\n",
    "            net.module.is_training = True\n",
    "\n",
    "            steps += 1\n",
    "            \n",
    "            images = images.cuda().float()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            classification_loss, regression_loss = net([images, targets])\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "            loss = classification_loss + regression_loss\n",
    "            if bool(loss == 0):\n",
    "                print('loss equal zero(0)')\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            net.eval()\n",
    "            net.module.is_training = False\n",
    "            \n",
    "            #Constant CPU gather error. It was working one time when trying to infer from image\n",
    "#             print(images[0].unsqueeze(0)[0].is_cuda)\n",
    "#             print(images[0].unsqueeze(0)[0][0].is_cuda)\n",
    "            scores, classification, transformed_anchors = net(images[0].unsqueeze(0))\n",
    "            \n",
    "            try:\n",
    "                #Constant CPU gather error. It was working one time\n",
    "                \n",
    "                train_mAP, missed_train_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, train_mAP, \n",
    "                                                                          missed_train_images, device)\n",
    "            except:\n",
    "                print(images.size(), targets.size())\n",
    "                print(\"Caught an exception in an image could not predict metric for it\")\n",
    "                \n",
    "            net.train()\n",
    "            net.module.is_training = True\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if (steps % print_every) == 0:\n",
    "                with torch.no_grad():\n",
    "                    test_mAP = missed_test_images = test_loss = 0\n",
    "\n",
    "                    for images, targets in test_loader:\n",
    "                        if images.size(0) != 1:\n",
    "                            warning.warn(\"Only can validate fully with batch size of 1, \\\n",
    "                            bigger batch sizes risk Errors or Incomplete Validation\")\n",
    "                        \n",
    "                        net.eval()\n",
    "                        net.module.is_training = False\n",
    "\n",
    "                        if device == torch.device(\"cuda\"):\n",
    "                            images = images.cuda().float()\n",
    "                            targets = targets.cuda()\n",
    "\n",
    "                        scores, classification, transformed_anchors = net(images)\n",
    "                        try:\n",
    "                            test_mAP, missed_test_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, \n",
    "                                                                                        test_mAP,missed_test_images, device)\n",
    "                        except:\n",
    "                            print(images.size(), targets.size())\n",
    "                            print(\"Caught exception with running metrics for one valid image (skipped)\")\n",
    "\n",
    "                        net.train()\n",
    "                        net.module.is_training = True\n",
    "\n",
    "                        classification_loss, regression_loss = net([images, targets])\n",
    "                        classification_loss = classification_loss.mean()\n",
    "                        regression_loss = regression_loss.mean()\n",
    "                        loss = classification_loss + regression_loss\n",
    "\n",
    "                        test_loss += loss.item()\n",
    "\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        learning_rate_extract = param_group[\"lr\"]\n",
    "                    print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Test_loss: {:0.2f} | Test mAP: {:0.2f}% | Missed Valid Images: {} / {}\".format(\n",
    "                        epoch + 1, epochs, steps, learning_rate_extract, train_loss, test_loss,  \n",
    "                        (test_mAP / float(lo_test_dataset)) * 100.,missed_test_images, lo_test_dataset))\n",
    "                assert (steps % print_every) == 0\n",
    "                train_loss = 0\n",
    "              # scheduler.step(test_loss / float(lo_test_dataset))\n",
    "             \n",
    "        print(\"\\n Epoch {} | Epoch Time {:0.2f} | Final Train mAP: {:0.2f}% | Epoch {} Final Missed Train Images: {} out of {} images \\n\".format(\n",
    "            epoch + 1, time.time() - epoch_time, (train_mAP / float(lo_train_dataset)) * 100., \n",
    "            epoch + 1, missed_train_images, lo_train_dataset\n",
    "        ))\n",
    "    \n",
    "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Note: Train Accuracies are only run through one train image per batch\n",
      "Print Every: 6.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Gather function not implemented for CPU tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-63558a85fb48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_effdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meff_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meff_valid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-a413e41d27fb>\u001b[0m in \u001b[0;36mtrain_effdet\u001b[0;34m(net, epochs, train_loader, test_loader, lr, weight_decay, print_times_per_epoch, lo_test_dataset, lo_train_dataset)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#             print(images[0].unsqueeze(0)[0].is_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             print(images[0].unsqueeze(0)[0][0].is_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, outputs, output_device)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(outputs, target_device, dim)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Setting the function to None clears the refcycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgather_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             return type(out)(((k, gather_map([d[k] for d in outputs]))\n\u001b[1;32m     62\u001b[0m                               for k in out))\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Recursive function calls like this create reference cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mGather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_device, dim, *inputs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         assert all(map(lambda i: i.device.type != 'cpu', inputs)), (\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;34m'Gather function not implemented for CPU tensors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m         \u001b[0mtarget_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Gather function not implemented for CPU tensors"
     ]
    }
   ],
   "source": [
    "train_effdet(model, 5, eff_train_loader, eff_valid_loader, 0.01, 1e-5, print_times_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aShMihw2d4tB"
   },
   "source": [
    "### Extra Snippets: Using Recurrent Neural Networks with Faster R CNNs\n",
    "\n",
    "https://arxiv.org/pdf/2010.15740.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH2vWjX4IG_U"
   },
   "source": [
    "####  Get all images file paths in a folder and all xml file paths in a folder. Then put in tuple [(image file path1, xml file path1), (image2, xml 2)]\n",
    "\n",
    "Pair the image file paths and xml file paths into a particular scene. \n",
    "So all_scenes dict(): {folder name of one scene: list[(imf_path1, xml1), (img_path2, xml2), (img_path3, xml3)], foler name of second scene}\n",
    "\n",
    "key_path: [scene 1, scene 2, scene 3, scene 4, scene 5]\n",
    "\n",
    "class will get certain_scene = key_path[index] and then all_scenes[certain_scene] -> get access to list of images and labels and then load into image file path. \n",
    "\n",
    "create a tensor called single_scene\n",
    "\n",
    "For one indexed scene\n",
    "for tuple in list we get a tupe like this (img file path, annot file path)\n",
    "open image file path of (tup[0])\n",
    "open xml file and parse to get bounding boxes and other info (tup[1])\n",
    "\n",
    "use torch.stack()\n",
    "\n",
    "Now we have image tensor and target tensor. We can append to the single_scene.\n",
    "\n",
    "return single_scene which is [(image 1 tensor, target tensor of 1), (image 2 tensor, target tensor of 2)] also known as all the images and targets of one scene\n",
    "\n",
    "return this data to dataloader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFgKvZ_k19LQ"
   },
   "outputs": [],
   "source": [
    "def get_per_scene_dict(img_root_path, annotations_root_path):\n",
    "  scene_names = glob.glob(\"{}/*\".format(img_root_path))\n",
    "  all_scenes = dict()\n",
    "  for scene in scene_names:\n",
    "  \n",
    "    image_file_paths = glob.glob(\"{}{}/*.JPEG\".format(img_root_path, scene.split(\"/\")[-1]))\n",
    "    xml_file_paths = glob.glob(\"{}{}/*.xml\".format(annotations_root_path, scene.split(\"/\")[-1]))\n",
    "    image_file_paths, xml_file_paths = sorted(image_file_paths), sorted(xml_file_paths)\n",
    "\n",
    "    assert len(image_file_paths) == len(xml_file_paths)\n",
    "\n",
    "    scene_list = [(image_file_path, xml_file_paths[ii]) for ii, image_file_path in enumerate(image_file_paths)]\n",
    "    all_scenes[scene] = scene_list\n",
    "  \n",
    "  return all_scenes\n",
    "\n",
    "class VideoFrameDataset():\n",
    "    \n",
    "    def __init__(self, all_scenes_dict, transforms, seg_len = 5):\n",
    "\n",
    "      self.all_scenes_dict = all_scenes_dict\n",
    "      self.seg_len = seg_len\n",
    "      self.transforms = transforms\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "      \n",
    "      current_scene = list(self.all_scenes_dict.keys())[idx]\n",
    "      list_of_fp_per_scene = self.all_scenes_dict[current_scene]\n",
    "\n",
    "      #Random Sampling. \n",
    "      if seg_len % 5 != 0:\n",
    "        raise ValueError(\"Not allowed value for seg_len must be divisible by 5\")\n",
    "      if seg_len >= len(list_of_fp_per_scene):\n",
    "        raise ValueError(\"Segments are bigger than the amount of frames available for a scene\")\n",
    "      \n",
    "      list_of_fp_per_scene = list_of_fp_per_scene[:-(len(list_of_fp_per_scene) % seg_len)]\n",
    "      reduced_fp_per_scene, start_index = list(), 0\n",
    "      for window in range(int(len(list_of_fp_per_scene) / self.seg_len))\n",
    "        end_index = start_index + self.seg_len\n",
    "        reduced_fp_per_scene.append(random.sample(list_of_fp_per_scene[start_index: end_index], 1)[0])\n",
    "        start_index = end_index\n",
    "      \n",
    "      scene_images, scene_bboxes = [], []\n",
    "      for data in reduced_fp_per_scene:\n",
    "        img_path, xml_path = data\n",
    "\n",
    "        img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        xml_doc = ElementTree.parse(xml_path)\n",
    "\n",
    "        bounding_boxes = xml_doc.findall(\"object/bndbox\")\n",
    "\n",
    "        bbox = []\n",
    "        for node in bounding_boxes:\n",
    "          xmax = node.find(\"xmax\").text\n",
    "          xmin = node.find(\"xmin\").text\n",
    "          ymax = node.find(\"ymax\").text\n",
    "          ymin = node.find(\"ymin\").text\n",
    "\n",
    "          bbox.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n",
    "        \n",
    "        bbox = torch.as_tensor(bbox, dtype = torch.float32)\n",
    "        \n",
    "        if self.transforms: \n",
    "          sample = {\n",
    "              'image': img,\n",
    "              'bboxes': bbox,\n",
    "              'labels': labels\n",
    "              }\n",
    "\n",
    "        sample = self.transforms(**sample)\n",
    "        augmented_img = sample['image']\n",
    "        augmented_bbox = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        scene_bboxes.append(augmented_bbox)\n",
    "        scene_images.append(augmented_img)\n",
    "      \n",
    "      scene_images, scene_bboxes = torch.stack(scene_images), torch.stack(scene_bboxes)\n",
    "\n",
    "      scene_target = dict() \n",
    "      scene_target[\"boxes\"] = scene_bboxes\n",
    "\n",
    "      scene_target[\"image_id\"] = ###############################################\n",
    "      scene_target[\"labels\"] = #################################################\n",
    "\n",
    "      return scene_images, scene_target\n",
    "      \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nChPPsoeUE2M"
   },
   "outputs": [],
   "source": [
    "def test(net, test_loader, ####):\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_mAP = test_loss = test_missed_images = 0\n",
    "    for images, targets in test_loader:\n",
    "\n",
    "        if device == torch.device(\"cuda\"):\n",
    "          images = [image.to(device) for image in images]\n",
    "          targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "\n",
    "        net.eval()\n",
    "        output = net(images)\n",
    "        test_mAP, test_missed_images = run_metrics_for_batch(output, targets, test_mAP, test_missed_images, device)\n",
    "\n",
    "        net.train()\n",
    "        test_loss_dict = net(images, targets)\n",
    "        test_losses = sum(loss for loss in test_loss_dict.values())\n",
    "        test_loss += test_losses\n",
    "\n",
    "    print(\"Test mAP {:0.2f}% | Test Loss {:0.2f} | Test Missed Images {} / {}\".format(test_mAP, test_loss, test_missed_images, #####))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links that I used to get notebook running with correct 3rd party packages\n",
    "\n",
    "* https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "* https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-18-04\n",
    "* Make sure after running packages update on conda environment to shut down and reopen notebook for update.\n",
    "* Just git clone in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resizer(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512):\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "        height, width, _ = image.shape\n",
    "        if height > width:\n",
    "            scale = self.img_size / height\n",
    "            resized_height = self.img_size\n",
    "            resized_width = int(width * scale)\n",
    "        else:\n",
    "            scale = self.img_size / width\n",
    "            resized_height = int(height * scale)\n",
    "            resized_width = self.img_size\n",
    "\n",
    "        image = cv2.resize(image, (resized_width, resized_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        new_image = np.zeros((self.img_size, self.img_size, 3))\n",
    "        new_image[0:resized_height, 0:resized_width] = image\n",
    "\n",
    "        annots[:, :4] *= scale\n",
    "\n",
    "        return {'img': torch.from_numpy(new_image).to(torch.float32), 'annot': torch.from_numpy(annots), 'scale': scale}\n",
    "\n",
    "\n",
    "class Augmenter(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, flip_x=0.5):\n",
    "        if np.random.rand() < flip_x:\n",
    "            image, annots = sample['img'], sample['annot']\n",
    "            image = image[:, ::-1, :]\n",
    "\n",
    "            rows, cols, channels = image.shape\n",
    "\n",
    "            x1 = annots[:, 0].copy()\n",
    "            x2 = annots[:, 2].copy()\n",
    "\n",
    "            x_tmp = x1.copy()\n",
    "\n",
    "            annots[:, 0] = cols - x2\n",
    "            annots[:, 2] = cols - x_tmp\n",
    "\n",
    "            sample = {'img': image, 'annot': annots}\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "\n",
    "    def __init__(self, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        self.mean = np.array([[mean]])\n",
    "        self.std = np.array([[std]])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        return {'img': ((image.astype(np.float32) - self.mean) / self.std), 'annot': annots}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ILSVRCVid2015VideoDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "169081d5b0d94288a2b0ebb020b790d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1c3baca68a4e42afa680e581e92a7e82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28ba486f593a4109bd152e94c871919d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c3baca68a4e42afa680e581e92a7e82",
      "max": 14212972,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_169081d5b0d94288a2b0ebb020b790d3",
      "value": 14212972
     }
    },
    "4839a59e79b6413bab12980f433870dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc398d009abc4ff7872a46b6e7bd497e",
      "placeholder": "",
      "style": "IPY_MODEL_cb9ef1bcc2334f7190b70c08a16090f7",
      "value": " 13.6M/13.6M [00:16&lt;00:00, 875kB/s]"
     }
    },
    "afba5dfb1b1a4811b1b0c02f03cb3c8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbfa8ade6ff548aab08c392fe4bb20f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28ba486f593a4109bd152e94c871919d",
       "IPY_MODEL_4839a59e79b6413bab12980f433870dc"
      ],
      "layout": "IPY_MODEL_afba5dfb1b1a4811b1b0c02f03cb3c8d"
     }
    },
    "cb9ef1bcc2334f7190b70c08a16090f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc398d009abc4ff7872a46b6e7bd497e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
