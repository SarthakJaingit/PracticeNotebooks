{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jvvfb1riBioe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch \n",
    "from torch import nn, optim \n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.utils.data\n",
    "import time\n",
    "import itertools\n",
    "import glob \n",
    "from PIL import Image\n",
    "import csv \n",
    "import cv2\n",
    "import re\n",
    "import torchvision\n",
    "import random\n",
    "from xml.etree import ElementTree\n",
    "from torchvision.ops.boxes import box_iou\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sarthak/DataSets/ILSVRC2015/EfficientDet.Pytorch-Updated\n",
      "/home/sarthak/DataSets/ILSVRC2015\n"
     ]
    }
   ],
   "source": [
    "#Packages commonly needed to install pycocotools, tqdm, and requests.\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "%cd EfficientDet.Pytorch-Updated/\n",
    "import math\n",
    "from models.efficientnet import EfficientNet\n",
    "from models.bifpn import BIFPN\n",
    "from models.retinahead import RetinaHead\n",
    "from models.module import RegressionModel, ClassificationModel, Anchors, ClipBoxes, BBoxTransform\n",
    "from torchvision.ops import nms\n",
    "from models.losses import FocalLoss\n",
    "from models.efficientdet import EfficientDet\n",
    "from models.losses import FocalLoss\n",
    "from datasets import VOCDetection, CocoDataset, get_augumentation, detection_collate, Resizer, Normalizer, Augmenter, collater\n",
    "from utils import EFFICIENTDET, get_state_dict\n",
    "from eval import evaluate, evaluate_coco\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Ranger-Deep-Learning-Optimizer' already exists and is not an empty directory.\n",
      "/home/sarthak/DataSets/ILSVRC2015/Ranger-Deep-Learning-Optimizer\n",
      "Obtaining file:///home/sarthak/DataSets/ILSVRC2015/Ranger-Deep-Learning-Optimizer\n",
      "Requirement already satisfied: torch in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from ranger==0.1.dev0) (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch->ranger==0.1.dev0) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch->ranger==0.1.dev0) (3.7.4.3)\n",
      "Installing collected packages: ranger\n",
      "  Attempting uninstall: ranger\n",
      "    Found existing installation: ranger 0.1.dev0\n",
      "    Uninstalling ranger-0.1.dev0:\n",
      "      Successfully uninstalled ranger-0.1.dev0\n",
      "  Running setup.py develop for ranger\n",
      "Successfully installed ranger\n",
      "/home/sarthak/DataSets/ILSVRC2015\n",
      "fatal: destination path 'sam' already exists and is not an empty directory.\n",
      "/home/sarthak/DataSets/ILSVRC2015/sam\n",
      "Imported SAM Successfully from github .py file\n",
      "/home/sarthak/DataSets/ILSVRC2015\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
    "%cd Ranger-Deep-Learning-Optimizer\n",
    "!pip install -e .\n",
    "from ranger import Ranger  \n",
    "%cd ..\n",
    "#https://paperswithcode.com/paper/sharpness-aware-minimization-for-efficiently-1\n",
    "!git clone https://github.com/davda54/sam.git\n",
    "%cd sam\n",
    "import sam\n",
    "print(\"Imported SAM Successfully from github .py file\")\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPKm4C39fzGD"
   },
   "source": [
    "## To DO \n",
    "\n",
    "### Configure fast rcnn model for training overnight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Fix the metric creating of Effecient Det Model. \n",
    "\n",
    "* Fix assertion when trying to predict on an image.\n",
    "* Try different learning rates and see what gets constant improvement.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Goal:\n",
    "\n",
    "Get acceptable resukts with a rcnn torchvision model\n",
    "Get acceptable results with effecient det\n",
    "\n",
    "### Some Errors I get\n",
    "\n",
    "Value Error in Det dataset\n",
    "Model sometimes gets error while running on data.\n",
    "\n",
    "### Advice\n",
    "\n",
    "Try to start with simplest (Adam basics) and keep on adding stuff to improve mAP\n",
    " How much data 57 k in Det dataset\n",
    " Full validation has 170,00 but use \n",
    " \n",
    " * (2,000 images in valid loader).\n",
    "* 10 - 15 images per folder.\n",
    "\n",
    "Great Proportions is that around 35 - 40% should be the Det Dataset and 60 - 65 % should be the sampled VID Dataset. \n",
    "\n",
    "### Get better results\n",
    "\n",
    "* Reduce dataset to 5000 train images and 500 valid images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (1.8.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "collapsed": true,
    "id": "G9vLpqYsehKW",
    "outputId": "5ae89189-d6ba-4cdd-d080-4a77f7c5a410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (0.5.2)\n",
      "Requirement already satisfied: PyYAML in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (0.18.1)\n",
      "Requirement already satisfied: imgaug>=0.4.0 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (0.4.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: scipy in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from albumentations) (1.19.2)\n",
      "Requirement already satisfied: Shapely in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
      "Requirement already satisfied: opencv-python in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (4.5.1.48)\n",
      "Requirement already satisfied: six in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (3.3.4)\n",
      "Requirement already satisfied: imageio in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (2.9.0)\n",
      "Requirement already satisfied: Pillow in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from imgaug>=0.4.0->albumentations) (8.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "juEv3bvw0yYp"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uXvczm7BMhQw"
   },
   "outputs": [],
   "source": [
    "def get_class_info(get_keys = False, smaller_mb_net = False):\n",
    "    obj_dict = {\n",
    "    \"n02691156\": \"airplane\", \n",
    "    \"n02419796\": \"antelope\", \n",
    "    \"n02131653\": \"bear\", \n",
    "    \"n02834778\": \"bicycle\", \n",
    "    \"n01503061\": \"bird\", \n",
    "    \"n02924116\": \"bus\", \n",
    "    \"n02958343\": \"car\", \n",
    "    \"n02402425\": \"cattle\", \n",
    "    \"n02084071\": \"dog\", \n",
    "    \"n02121808\": \"domestic_cat\", \n",
    "    \"n02503517\": \"elephant\", \n",
    "    \"n02118333\": \"fox\",\n",
    "    \"n02510455\": \"giant_panda\", \n",
    "    \"n02342885\": \"hamster\", \n",
    "    \"n02374451\": \"horse\", \n",
    "    \"n02129165\": \"lion\", \n",
    "    \"n01674464\": \"lizard\", \n",
    "    \"n02484322\": \"monkey\", \n",
    "    \"n03790512\": \"motorcycle\", \n",
    "    \"n02324045\": \"rabbit\",\n",
    "    \"n02509815\": \"red_panda\", \n",
    "    \"n02411705\": \"sheep\", \n",
    "    \"n01726692\": \"snake\", \n",
    "    \"n02355227\": \"squirrel\", \n",
    "    \"n02129604\": \"tiger\", \n",
    "    \"n04468005\": \"train\", \n",
    "    \"n01662784\": \"turtle\", \n",
    "    \"n04530566\": \"watercraft\", \n",
    "    \"n02062744\": \"whale\",\n",
    "    \"n02391049\": \"zebra\"\n",
    "    }\n",
    "    \n",
    "    if get_keys:\n",
    "        return list(obj_dict.keys())\n",
    "    \n",
    "    return obj_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameDataset():\n",
    "    \n",
    "    def __init__(self, mode, vid_data_root_dir, vid_annotations_root_dir, transforms, seg_len = None, \n",
    "               make_valid_smaller_percent = None, effdet_data = None, rcnn_big = None, det_text_file_paths = None, \n",
    "               data_size = None):\n",
    "                 \n",
    "        \n",
    "    # If valid smaller is true cut the length of valid list to certain length with if statement. \n",
    "        if (mode == \"train\"):\n",
    "            if (seg_len):\n",
    "                ORIG_SEG_LEN = seg_len\n",
    "                #Subset images from every scene there are 3862 data folders.\n",
    "                print(\"There are 1122397 train images in total\")\n",
    "                globbed_image_file_paths = sorted(glob.glob(\"{}/*/*\".format(vid_data_root_dir)))\n",
    "                globbed_annotations_file_paths = sorted(glob.glob(\"{}/*/*\".format(vid_annotations_root_dir)))\n",
    "                \n",
    "                self.image_file_paths, self.annotations_file_paths = list(), list()\n",
    "                \n",
    "                for folder in list(zip(globbed_image_file_paths, globbed_annotations_file_paths)):\n",
    "                    scene_images = sorted(glob.glob(\"{}/*.JPEG\".format(folder[0])))\n",
    "                    scene_annotations = sorted(glob.glob(\"{}/*.xml\".format(folder[1])))\n",
    "                    \n",
    "                    image_annot = list(zip(scene_images, scene_annotations))\n",
    "\n",
    "                    if seg_len % 5 != 0:\n",
    "                        raise ValueError(\"Not allowed value for seg_len must be divisible by 5\")\n",
    "                    if seg_len >= len(image_annot):\n",
    "                        seg_len = 5\n",
    "                    \n",
    "                    if len(image_annot) % seg_len != 0:\n",
    "                        image_annot = image_annot[:-(len(image_annot) % seg_len)]\n",
    "                    \n",
    "                    red_img_annot, start_index = list(), 0 \n",
    "                    \n",
    "                    for window in range(int(len(image_annot) / seg_len)):\n",
    "                        end_index = start_index + seg_len\n",
    "                        red_img_annot.append(image_annot[end_index - 1])\n",
    "                        #red_img_annot.append(random.sample(image_annot[start_index : end_index], 1)[0])\n",
    "                        start_index = end_index\n",
    "                    \n",
    "                   \n",
    "                    scene_images, scene_annotations = zip(*red_img_annot) \n",
    "                    \n",
    "                    self.annotations_file_paths.extend(scene_annotations)\n",
    "                    self.image_file_paths.extend(scene_images)\n",
    "                    \n",
    "                    seg_len = ORIG_SEG_LEN\n",
    "                    \n",
    "            else:\n",
    "                self.image_file_paths = sorted(glob.glob(\"{}/*/*/*.JPEG\".format(vid_data_root_dir))) \n",
    "                self.annotations_file_paths = sorted(glob.glob(\"{}/*/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "            \n",
    "        elif (mode == \"validation\"):\n",
    "            if make_valid_smaller_percent:\n",
    "                #Subset a percent of the valid data\n",
    "                valid_image_list = sorted(glob.glob(\"{}/*/*.JPEG\".format(vid_data_root_dir)))\n",
    "                valid_annotations_list = sorted(glob.glob(\"{}/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "\n",
    "                subset = int(len(valid_image_list) * make_valid_smaller_percent)\n",
    "\n",
    "                #Shuffle both lists at once with same order\n",
    "                mapIndexPosition = list(zip(valid_image_list, valid_annotations_list))\n",
    "                random.shuffle(mapIndexPosition)\n",
    "                valid_image_list, valid_annotations_list = zip(*mapIndexPosition)\n",
    "                valid_image_list, valid_annotations_list = list(valid_image_list), list(valid_annotations_list)\n",
    "\n",
    "                self.image_file_paths = valid_image_list[:subset]\n",
    "                self.annotations_file_paths = valid_annotations_list[:subset]\n",
    "            else:\n",
    "                self.image_file_paths = sorted(glob.glob(\"{}/*/*.JPEG\".format(vid_data_root_dir))) \n",
    "                self.annotations_file_paths = sorted(glob.glob(\"{}/*/*.xml\".format(vid_annotations_root_dir)))\n",
    "        else:\n",
    "            raise ValueError(\"Choose mode between train or validation only\")\n",
    "\n",
    "        self.labels_key = get_class_info(get_keys = True)\n",
    "\n",
    "        self.data_size = data_size\n",
    "        self.transforms = transforms\n",
    "        self.effdet_data = effdet_data\n",
    "        self.rcnn_big = rcnn_big\n",
    "        \n",
    "        if det_text_file_paths:\n",
    "            home_file_path_data = \"/data1/group/mlgroup/train_data/ILSVRC2015/Data/DET/\"\n",
    "            home_file_path_annot = \"/data1/group/mlgroup/train_data/ILSVRC2015/Annotations/DET/\"\n",
    "            \n",
    "            assert len(self.image_file_paths) == len(self.annotations_file_paths)\n",
    "            print(\"\\n\")\n",
    "            print(\"BEFORE DET: Amount of image files in Dataset {}\".format(len(self.image_file_paths)))\n",
    "            print(\"BEFORE DET: Amount of annotation files in Dataset {} \\n\".format(len(self.annotations_file_paths)))\n",
    "            det_txt = open(det_text_file_paths, \"r\").readlines()\n",
    "            np.random.shuffle(det_txt)\n",
    "            \n",
    "            #I am gonna sample about 10k images or around 20% of Det Dataset\n",
    "            det_txt = det_txt[:int(len(det_txt) * 0.25)]\n",
    "            print(\"Amount of images in Det Set (Approx.) {}\".format(len(det_txt)))\n",
    "            \n",
    "            for line in det_txt:\n",
    "                self.image_file_paths.append((home_file_path_data + line.split(\" \")[0] + \".JPEG\"))\n",
    "                self.annotations_file_paths.append((home_file_path_annot + line.split(\" \")[0] + \".xml\"))\n",
    "        \n",
    "        #Final sort to keep annotations and image file paths in same config\n",
    "        self.image_file_paths, self.annotations_file_paths = sorted(self.image_file_paths), sorted(self.annotations_file_paths)\n",
    "        \n",
    "        assert len(self.image_file_paths) == len(self.annotations_file_paths)\n",
    "        print(\"Amount of image files in Dataset {}\".format(len(self.image_file_paths)))\n",
    "        print(\"Amount of annotation files in Dataset {}\".format(len(self.annotations_file_paths)))\n",
    "        \n",
    "        \n",
    "        if self.effdet_data:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with Effecient Det Structure ... \\n\")\n",
    "        elif self.rcnn_big:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with bigger rcnn with ROI Structure ... \\n\")\n",
    "        else:\n",
    "            print(\"\\n\")\n",
    "            print(\"Loading with mobilenet Faster R CNN Structure ... \\n\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path, xml_path = self.image_file_paths[idx], self.annotations_file_paths[idx]\n",
    "        img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        # img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        marking = False\n",
    "        xml_doc = ElementTree.parse(xml_path)\n",
    "\n",
    "        bounding_boxes_nodes = xml_doc.findall(\"object/bndbox\")\n",
    "        labels_nodes = xml_doc.findall(\"object/name\")\n",
    "\n",
    "        bbox, labels = [], []\n",
    "\n",
    "        for node in bounding_boxes_nodes:\n",
    "            xmax = node.find(\"xmax\").text\n",
    "            xmin = node.find(\"xmin\").text\n",
    "            ymax = node.find(\"ymax\").text\n",
    "            ymin = node.find(\"ymin\").text\n",
    "            bbox.append([int(xmin), int(ymin), int(xmax), int(ymax)])  \n",
    "            \n",
    "\n",
    "        for node in labels_nodes:\n",
    "            if node.text in self.labels_key:\n",
    "                label = self.labels_key.index(node.text)    \n",
    "            else:\n",
    "                label = \"DNE\"\n",
    "                marking = True\n",
    "            labels.append(label)\n",
    "        \n",
    "        if (marking):\n",
    "            removed_indices = list()\n",
    "            \n",
    "            for ii in range(len(labels)):\n",
    "                if (labels[ii] == \"DNE\"):\n",
    "                    removed_indices.append(ii)\n",
    "            labels = [i for j, i in enumerate(labels) if j not in removed_indices]\n",
    "            bbox = [i for j, i in enumerate(bbox) if j not in removed_indices]\n",
    "                \n",
    "        if not(self.effdet_data or self.rcnn_big):\n",
    "            #Need to add one to labels\n",
    "            labels = [label + 1 for label in labels]\n",
    "        \n",
    "        bbox = torch.as_tensor(bbox, dtype = torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype = torch.int64)\n",
    "\n",
    "        # labels = tf.cast(labels, dtype = tf.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        \n",
    "        try:\n",
    "            if self.transforms:  \n",
    "                sample = {\n",
    "                    'image': img,\n",
    "                    'bboxes': bbox,\n",
    "                    'labels': labels\n",
    "                      }\n",
    "\n",
    "                sample = self.transforms(**sample)\n",
    "                img = sample['image']\n",
    "                try:\n",
    "                    bbox = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                except:\n",
    "                    bbox = torch.zeros((0, 4), dtype=torch.float32)\n",
    "                    \n",
    "        except:\n",
    "            print(\"Caught error. Now trying to instill transforms using Pytorch transforms\")\n",
    "            \n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            emergency_transforms = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "            \n",
    "            \n",
    "            img = emergency_transforms(img)\n",
    "                \n",
    "                \n",
    "          # img = tf.cast(sample['image'], dtype = tf.float32) / 255.0\n",
    "          # bbox = tf.convert_to_tensor(torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0), dtype = tf.float32)\n",
    "\n",
    "        if self.effdet_data:\n",
    "            return {\"image\": img, \"bboxes\": bbox, \"category_id\": labels}\n",
    "        \n",
    "        target = dict()\n",
    "        target[\"boxes\"] = bbox\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "\n",
    "        return img, target  \n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.data_size:\n",
    "            return self.data_size\n",
    "        return len(self.image_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change image size and try and except in dataclass before transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(mode):\n",
    "    if (mode == \"train\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(512, 512), \n",
    "                          A.OneOf([\n",
    "                          A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                         val_shift_limit=0.2, p=0.9),\n",
    "                          A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                               contrast_limit=0.2, p=0.9)],p=0.9),\n",
    "                          A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.5),\n",
    "                          A.HorizontalFlip(),\n",
    "                          A.VerticalFlip(), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"test\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(512, 512), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"effdet_train\"):\n",
    "        return A.Compose([\n",
    "                          A.OneOf([\n",
    "                          A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                         val_shift_limit=0.2, p=0.9),\n",
    "                          A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                               contrast_limit=0.2, p=0.9)],p=0.9),\n",
    "                          A.Cutout(num_holes=8, max_h_size=4, max_w_size=4, p=0.5),\n",
    "                          A.HorizontalFlip(),\n",
    "                          A.VerticalFlip(), \n",
    "                          A.Resize(height = 512, width=512), \n",
    "                          ToTensorV2()\n",
    "                          ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "    elif (mode == \"effdet_test\"):\n",
    "        return A.Compose([\n",
    "                          A.Resize(height = 512, width = 512), \n",
    "                          ToTensorV2()])\n",
    "    else:\n",
    "        raise ValueError(\"mode is wrong value can either be train or test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IwHLAJZQjrt6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1122397 train images in total\n",
      "\n",
      "\n",
      "BEFORE DET: Amount of image files in Dataset 19743\n",
      "BEFORE DET: Amount of annotation files in Dataset 19743 \n",
      "\n",
      "Amount of images in Det Set (Approx.) 13409\n",
      "Amount of image files in Dataset 33152\n",
      "Amount of annotation files in Dataset 33152\n",
      "\n",
      "\n",
      "Loading with mobilenet Faster R CNN Structure ... \n",
      "\n",
      "Amount of image files in Dataset 2201\n",
      "Amount of annotation files in Dataset 2201\n",
      "\n",
      "\n",
      "Loading with mobilenet Faster R CNN Structure ... \n",
      "\n",
      " \n",
      " ... Seperate from Data Loader \n",
      "\n",
      "Length of train_dataset 33152\n",
      "Length of valid_dataset 2201\n"
     ]
    }
   ],
   "source": [
    "# 1122397 Files in train set total\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "#The amount of scenes to load in one go. # 2 and 2 are the best values\n",
    "train_batch_size = 2\n",
    "valid_batch_size = 2\n",
    "det_text_file = \"/data1/group/mlgroup/train_data/ILSVRC2015/DET_train_30classes.txt\"\n",
    "\n",
    "\n",
    "train_dataset = VideoFrameDataset(\"train\", os.path.join(\"Data/VID\", \"train\"), os.path.join(\"Annotations/VID\", \"train\"), get_transforms(mode = \"train\"), \n",
    "                                  seg_len = 80, det_text_file_paths = det_text_file, data_size = None)\n",
    "valid_dataset = VideoFrameDataset(\"validation\", os.path.join(\"Data/VID\", \"val\"), os.path.join(\"Annotations/VID\", \"val\"), get_transforms(mode = \"test\"),\n",
    "                                  make_valid_smaller_percent = 0.0125, data_size = None)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True, collate_fn= collate_fn)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = valid_batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "\n",
    "print(\" \\n ... Seperate from Data Loader \\n\")\n",
    "print(\"Length of train_dataset {}\".format(len(train_dataset)))\n",
    "print(\"Length of valid_dataset {}\".format(len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "3iCwxnxIcRsr"
   },
   "outputs": [],
   "source": [
    "COLORS = [(0, 0, 0), (0, 255, 0), (0, 0 , 255), (255, 255, 0), (255, 0, 0)]\n",
    "\n",
    "def draw_boxes(boxes, labels, image, infer = False, put_text = True):\n",
    "    classes = get_class_info()\n",
    "    keys = list(classes.keys())\n",
    "\n",
    "    # read the image with OpenCV\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    if infer:\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = COLORS[1]\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 5\n",
    "        )\n",
    "        if put_text:\n",
    "          cv2.putText(image, classes[keys[labels[i] - 1]], (int(box[0]), int(box[1]-5)),\n",
    "                      cv2.FONT_HERSHEY_SIMPLEX, 2, color, 3, \n",
    "                      lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBIf0ODU0Aod"
   },
   "source": [
    "### Create a draw function to visualize some data (Will give index error if batch size < 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "YMd58kVzZd2L",
    "outputId": "3c70eca3-8a99-4b35-8df9-99b0b895efc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthak/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  \n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6c2b8dd2ea90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    image = draw_boxes(labels[idx][\"boxes\"], labels[idx][\"labels\"], images[idx], put_text = True)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "5ytYP752Zd7S"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(target_box,predictions_box,scores, device):\n",
    "\n",
    "    #Get most confident boxes first and least confident last\n",
    "    predictions_box = predictions_box[scores.argsort().flip(-1)]\n",
    "    iou_mat = box_iou(target_box,predictions_box)\n",
    "    #return a one by one matrix that is form (target_box, prediction_box) or (1, 1)\n",
    "    target_boxes_count, prediction_boxes_count = iou_mat.shape\n",
    "    \n",
    "    mAP_Matrix = torch.zeros_like(iou_mat)\n",
    "    # if not matrix coordinates that relate to nothing.\n",
    "    if not iou_mat[:,0].eq(0.).all():\n",
    "      index_of_biggest_iou = iou_mat[:,0].argsort()[-1]\n",
    "      mAP_Matrix[index_of_biggest_iou,0] = 1\n",
    "\n",
    "    for pr_idx in range(1,prediction_boxes_count):\n",
    "        not_assigned = torch.logical_not(mAP_Matrix[:,:pr_idx].sum(1)).long()\n",
    "        targets = not_assigned * iou_mat[:,pr_idx]\n",
    "\n",
    "        if targets.eq(0).all():\n",
    "            continue\n",
    "\n",
    "        pivot = targets.argsort()[-1]\n",
    "        mAP_Matrix[pivot,pr_idx] = 1\n",
    "\n",
    "    # mAP calculation\n",
    "    tp = mAP_Matrix.sum()\n",
    "    fp = mAP_Matrix.sum(0).eq(0).sum()\n",
    "    fn = mAP_Matrix.sum(1).eq(0).sum()\n",
    "\n",
    "    mAP = tp / (tp+fp)\n",
    "\n",
    "    return mAP\n",
    "\n",
    "def run_metrics_for_batch(output, targets, mAP, missed_images, device):\n",
    "  for pos_in_batch, image_pred in enumerate(output):\n",
    "    assert (len(image_pred[\"boxes\"]) == len(image_pred[\"labels\"]) == len(image_pred[\"scores\"]))\n",
    "    if len(image_pred[\"boxes\"]) != 0:\n",
    "      mAP += calculate_metrics(targets[pos_in_batch][\"boxes\"], output[pos_in_batch][\"boxes\"], output[pos_in_batch][\"scores\"], device)\n",
    "    else:\n",
    "      missed_images += 1\n",
    "  \n",
    "  return mAP, missed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "IN1fBHzJZd92"
   },
   "outputs": [],
   "source": [
    "def train(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch,\n",
    "          lo_valid_dataset = len(valid_dataset), lo_train_dataset = len(train_dataset), saving_directory = None,\n",
    "          unique_char_for_saving = None):\n",
    "\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print_every = len(train_dataset) / train_batch_size // print_times_per_epoch\n",
    "    print(\"Print Every: {}\".format(print_every))\n",
    "\n",
    "    #Check which parameters can calculate gradients. \n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "\n",
    "    base_optimizer = Ranger\n",
    "    optimizer = sam.SAM(net.parameters(), base_optimizer, lr = lr, weight_decay = weight_decay)\n",
    "#     optimizer = optim.Adam(params, lr = lr, weight_decay = weight_decay)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
    "\n",
    "    #Might be some problems with the Data Parallel code\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#         net = Some Distrubuted Parallel Function\n",
    "    net.to(device)\n",
    "    \n",
    "    print(\"Device: {}\".format(device))\n",
    "    print(\"Optimizer: {}\".format(optimizer))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_time = time.time()\n",
    "        net.train()\n",
    "        \n",
    "        train_loss = train_mAP = steps = train_missed_images = 0\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            \n",
    "            marking = False\n",
    "            \n",
    "            net.train()\n",
    "            steps += 1\n",
    "\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "            \n",
    "            if len(images) != len(targets):\n",
    "                print(\"Images and targets not same size for Valid\")\n",
    "                continue\n",
    "            \n",
    "            for ii in range(len(images)):\n",
    "                if len(targets[ii][\"boxes\"]) != len(targets[ii][\"labels\"]):\n",
    "                    print(\"Boxes and Labels are not same size\")\n",
    "                    marking = True\n",
    "                if (images[ii].size(-1) == 0) or (targets[ii][\"boxes\"].size(-1) == 0):\n",
    "                    print(\"Passed in empty image or target\")\n",
    "                    marking = True\n",
    "            \n",
    "            if marking:\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_dict = net(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            if bool(losses == 0):\n",
    "                print('loss equal zero(0)')\n",
    "                continue\n",
    "\n",
    "            net.eval()\n",
    "            try:\n",
    "                train_mAP, train_missed_images = run_metrics_for_batch(net(images), targets, train_mAP, train_missed_images, device)\n",
    "            except:\n",
    "                print(images[0].size(), targets)\n",
    "                print(\"Caught an exception in an image could not predict metric for it\")\n",
    "            net.train()\n",
    "\n",
    "            losses.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1e18)\n",
    "#             optimizer.step()\n",
    "\n",
    "            optimizer.first_step(zero_grad = True)\n",
    "\n",
    "            loss_dict = net(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            losses.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1e18)\n",
    "            optimizer.second_step(zero_grad = True)\n",
    "\n",
    "            train_loss +=  losses.item()\n",
    "            scheduler.step()\n",
    "\n",
    "            if (steps % print_every) == 0:  \n",
    "                with torch.no_grad():\n",
    "                \n",
    "                    valid_mAP = valid_loss = valid_missed_images = 0\n",
    "\n",
    "                    for images, targets in valid_loader:\n",
    "                        \n",
    "                        valid_marking = False\n",
    "                        \n",
    "                        net.eval()\n",
    "                        if device == torch.device(\"cuda\"):\n",
    "                            images = [image.to(device) for image in images]\n",
    "                            targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "                        \n",
    "                        if len(images) != len(targets):\n",
    "                            print(\"Images and targets not same size for Valid\")\n",
    "                            continue\n",
    "                        \n",
    "                        for ii in range(len(images)):\n",
    "                            if len(targets[ii][\"boxes\"]) != len(targets[ii][\"labels\"]):\n",
    "                                print(\"Boxes and Labels are not same size\")\n",
    "                                valid_marking = True\n",
    "                            if (images[ii].size(-1) == 0) or (targets[ii][\"boxes\"].size(-1) == 0):\n",
    "                                print(\"Passed in empty image or target\")\n",
    "                                valid_marking = True\n",
    "                        \n",
    "                        if valid_marking:\n",
    "                            continue\n",
    "                        \n",
    "                        try:\n",
    "                            output = net(images)\n",
    "                            valid_mAP, valid_missed_images = run_metrics_for_batch(output, targets, valid_mAP, valid_missed_images, device)\n",
    "                        except:\n",
    "                            print(targets, images[0].size())\n",
    "                            print(\"Caught exception with running metrics for one valid image (skipped)\")\n",
    "\n",
    "                        net.train()\n",
    "                        valid_loss_dict = net(images, targets)\n",
    "                        valid_losses = sum(loss for loss in valid_loss_dict.values())\n",
    "                        valid_loss += valid_losses.item()\n",
    "\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        learning_rate_extract = param_group[\"lr\"]\n",
    "                    print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Valid_loss: {:0.2f} | Valid mAP: {:0.2f}% | Valid Missed Images {} / {}\".format(\n",
    "                        epoch + 1, epochs, steps, learning_rate_extract, train_loss, valid_loss,  \n",
    "                        (valid_mAP / float(lo_valid_dataset)) * 100., valid_missed_images, lo_valid_dataset))\n",
    "                    \n",
    "                    if (valid_mAP / float(lo_valid_dataset))\n",
    "\n",
    "                assert (steps % print_every) == 0\n",
    "                train_loss = 0\n",
    "                \n",
    "        print(\"\\n Epoch {} | Epoch Time {:0.2f} | Final Train mAP: {:0.2f}% | Final Train Missed Images {} / {} \\n\".format(\n",
    "            epoch + 1, (time.time() - epoch_time),(train_mAP / float(lo_train_dataset)) * 100., train_missed_images, lo_train_dataset\n",
    "        ))\n",
    "        if saving_directory:\n",
    "            if os.path.isdir(saving_directory):\n",
    "                print(\"Saving Model path to directory {} ... \".format(saving_directory))\n",
    "                saving_path = os.path.join(saving_directory, \"Epoch\" + str(epoch + 1) + str(unique_char_for_saving) + \".pth\")\n",
    "                saving_content = {\"model_state_dict\": net.state_dict(), \n",
    "                                  \"optimizer_state_dict\": optimizer.state_dict(), \n",
    "                                  \"epoch\": epoch + 1, \n",
    "                                  \"model_type\": \"FasterRCNNResnet50FPN\"}\n",
    "                torch.save(saving_content, saving_path)\n",
    "                print(\"Succesfully saved model data to file path. \\n\")\n",
    "            else:\n",
    "                print(\"Directory Provided does not exist, hence will skip saving the model\")\n",
    "    \n",
    "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))\n",
    "    \n",
    "        # Example File path: /saved_models/epoch10small.pth \n",
    "        \n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mish helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU to Mish conversion for models \n",
    "#Option to switch any activation function for another.\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print(\"Mish activation loaded...\")\n",
    "\n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = x *( torch.tanh(F.softplus(x)))\n",
    "\n",
    "        return x\n",
    "    \n",
    "def convert_it(model, new, replaced_act):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, replaced_act):\n",
    "            setattr(model, child_name, new)\n",
    "        else:\n",
    "            convert_it(child, new, replaced_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuNTqGHFaAyU"
   },
   "source": [
    "## Faster R CNN with mobile net backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "z-R_qJ3haFf-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mish activation loaded...\n"
     ]
    }
   ],
   "source": [
    "mob_net = torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn(pretrained = True)\n",
    "# mob_net = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)\n",
    "mob_net.roi_heads.box_predictor.cls_score.out_features = len(get_class_info())\n",
    "mob_net.roi_heads.box_predictor.bbox_pred.out_features = len(get_class_info()) * 4\n",
    "convert_it(mob_net, Mish(), nn.ReLU6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33152, 2201)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too High Learning Rate can cause Exploding Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If this gets 50% in any of the training sequence then I will run saving through batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 331.0\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    initial_lr: 0.0005\n",
      "    k: 6\n",
      "    lr: 0.0005\n",
      "    rho: 0.05\n",
      "    step_counter: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/3 | Batch Number: 331 | LR: 0.00050 | Train_loss: 155.50 | Valid_loss: 455.95 | Valid mAP: 29.20% | Valid Missed Images 200 / 2201\n",
      "Epoch 1/3 | Batch Number: 662 | LR: 0.00050 | Train_loss: 122.84 | Valid_loss: 435.71 | Valid mAP: 23.32% | Valid Missed Images 131 / 2201\n",
      "Epoch 1/3 | Batch Number: 993 | LR: 0.00050 | Train_loss: 117.10 | Valid_loss: 409.04 | Valid mAP: 19.93% | Valid Missed Images 113 / 2201\n",
      "Epoch 1/3 | Batch Number: 1324 | LR: 0.00050 | Train_loss: 125.09 | Valid_loss: 451.03 | Valid mAP: 31.01% | Valid Missed Images 196 / 2201\n",
      "Epoch 1/3 | Batch Number: 1655 | LR: 0.00050 | Train_loss: 118.27 | Valid_loss: 434.58 | Valid mAP: 21.47% | Valid Missed Images 158 / 2201\n",
      "Epoch 1/3 | Batch Number: 1986 | LR: 0.00050 | Train_loss: 117.27 | Valid_loss: 425.81 | Valid mAP: 22.33% | Valid Missed Images 19 / 2201\n",
      "Epoch 1/3 | Batch Number: 2317 | LR: 0.00050 | Train_loss: 122.80 | Valid_loss: 421.53 | Valid mAP: 10.11% | Valid Missed Images 8 / 2201\n",
      "Epoch 1/3 | Batch Number: 2648 | LR: 0.00050 | Train_loss: 118.73 | Valid_loss: 408.01 | Valid mAP: 18.31% | Valid Missed Images 39 / 2201\n",
      "Epoch 1/3 | Batch Number: 2979 | LR: 0.00050 | Train_loss: 127.61 | Valid_loss: 437.36 | Valid mAP: 51.04% | Valid Missed Images 374 / 2201\n",
      "Epoch 1/3 | Batch Number: 3310 | LR: 0.00049 | Train_loss: 125.76 | Valid_loss: 412.12 | Valid mAP: 67.90% | Valid Missed Images 197 / 2201\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[111.6125,  60.7256, 449.9931, 429.8419]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4653], device='cuda:0')}, {'boxes': tensor([[ 11.2640, 132.7407, 376.8320, 410.2896]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([598], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[3.7200e+01, 5.1911e+01, 1.7440e+02, 2.6596e+02],\n",
      "        [3.6760e+02, 6.9689e+01, 4.5000e+02, 3.0791e+02],\n",
      "        [2.7400e+02, 4.6933e+01, 4.1240e+02, 2.7307e+02],\n",
      "        [1.9480e+02, 4.1244e+01, 2.5840e+02, 2.7520e+02],\n",
      "        [8.5200e+01, 2.7022e+01, 1.6920e+02, 2.3040e+02],\n",
      "        [4.0000e-01, 4.7644e+01, 5.2000e+01, 2.2898e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([18382], device='cuda:0')}, {'boxes': tensor([[397.6000, 273.0667, 510.8000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17165], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 55.2000, 179.2000, 395.2000, 359.8222],\n",
      "        [412.8000,  44.0889, 510.8000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([23357], device='cuda:0')}, {'boxes': tensor([[218.4000,   1.4222, 328.8000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([24576], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 98.4000,  34.8444, 424.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([29302], device='cuda:0')}, {'boxes': tensor([[  0.8000,   0.0000, 448.0000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([20436], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 235.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([24953], device='cuda:0')}, {'boxes': tensor([[  1.0240, 132.7914, 293.8880, 344.9840]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([13385], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([30702], device='cuda:0')}, {'boxes': tensor([[251.6000, 176.3556, 299.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([31617], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[189.4400, 156.8074, 489.4720, 507.2483]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1517], device='cuda:0')}, {'boxes': tensor([[160.0000, 314.3111, 267.7333, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([24312], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[100.3520,  75.0933, 505.8560, 441.0027]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1182], device='cuda:0')}, {'boxes': tensor([[138.2400,  39.0737, 369.6640, 455.4105]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2809], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[158.7200, 180.9323, 304.6400, 311.8195]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5149], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 8.8889e-01, 4.3160e+02, 5.0667e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13575], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 54.0000,   2.8445, 509.6000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([31965], device='cuda:0')}, {'boxes': tensor([[238.0000, 118.7556, 384.0000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32160], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([17035], device='cuda:0')}, {'boxes': tensor([[201.0667,  72.0593, 296.5333, 186.3111],\n",
      "        [360.8000,  96.7111, 399.7333, 158.3407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([13913], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[330.6667,  92.4445, 434.1333, 265.9556],\n",
      "        [ 39.4667, 122.3111, 248.5333, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([29117], device='cuda:0')}, {'boxes': tensor([[103.2127,  55.4667, 217.8032, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([32628], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[236.8000, 280.1778, 326.8000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([32601], device='cuda:0')}, {'boxes': tensor([[233.2000, 207.6444, 346.0000, 355.5555],\n",
      "        [352.0000, 198.4000, 401.6000, 264.5333],\n",
      "        [418.0000, 177.7778, 448.4000, 226.1333],\n",
      "        [480.4000, 168.5333, 506.8000, 207.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([15439], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.8000,  32.0000, 278.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([28845], device='cuda:0')}, {'boxes': tensor([[358.4000, 281.6000, 376.4000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([28554], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[203.2000, 167.8222, 510.4000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([28273], device='cuda:0')}, {'boxes': tensor([[200.0000, 256.7111, 222.8000, 320.0000],\n",
      "        [249.2000,  98.1333, 294.8000, 241.0667],\n",
      "        [375.2000, 182.0444, 412.0000, 236.8000],\n",
      "        [430.8000,  44.8000, 458.4000, 116.6222],\n",
      "        [398.8000, 268.8000, 417.6000, 322.8445],\n",
      "        [446.8000, 248.1778, 482.4000, 298.6667],\n",
      "        [136.8000, 123.0222, 183.2000, 184.8889],\n",
      "        [ 58.4000, 447.2889,  74.0000, 470.0444],\n",
      "        [145.6000, 396.8000, 166.0000, 427.3778],\n",
      "        [178.0000, 409.6000, 192.0000, 445.1556],\n",
      "        [478.4000, 114.4889, 501.2000, 173.5111],\n",
      "        [ 30.0000,   4.2667,  64.4000,  56.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0'), 'image_id': tensor([25704], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[110.0000,  86.7556, 354.8000, 133.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([28517], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([18132], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[237.2000, 144.3556, 318.0000, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([32689], device='cuda:0')}, {'boxes': tensor([[135.3956, 221.8667, 188.8711, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([25397], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 92.4000,   0.0000, 322.8000, 213.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([28984], device='cuda:0')}, {'boxes': tensor([[101.3760, 287.9113, 257.0240, 428.3213]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([10522], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[310.4000, 377.6000, 374.4000, 433.0667],\n",
      "        [378.0000, 354.8445, 500.8000, 481.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([26137], device='cuda:0')}, {'boxes': tensor([[279.2000, 264.8276, 300.8000, 288.3678],\n",
      "        [232.0000, 256.0000, 283.2000, 291.3103],\n",
      "        [ 54.4000, 267.7701, 110.4000, 306.0230]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7], device='cuda:0'), 'image_id': tensor([27805], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[148.0000,   0.0000, 512.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([24818], device='cuda:0')}, {'boxes': tensor([[306.4000, 180.6222, 345.6000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18158], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.8000, 221.8667,  99.2000, 362.6667],\n",
      "        [248.8000, 234.6667, 298.4000, 328.5333],\n",
      "        [336.0000, 216.1778, 398.4000, 348.4445],\n",
      "        [239.2000, 196.2667, 284.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([29220], device='cuda:0')}, {'boxes': tensor([[  0.0000, 197.6889, 508.2074, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27767], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[288.0000,  62.5778, 428.0000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18736], device='cuda:0')}, {'boxes': tensor([[137.6000, 163.5556, 512.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27052], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 98.8000,  50.4889, 416.0000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([16481], device='cuda:0')}, {'boxes': tensor([[229.6000, 198.6370, 320.5333, 292.5037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14041], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 88.4000,  76.0889, 402.8000, 438.7556],\n",
      "        [390.0000, 231.1111, 406.0000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([28003], device='cuda:0')}, {'boxes': tensor([[187.6000,  34.8444, 420.0000, 353.4222],\n",
      "        [459.6000, 153.6000, 510.0000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([32713], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([25484], device='cuda:0')}, {'boxes': tensor([[115.2000,   1.4222, 346.8000, 220.4445],\n",
      "        [221.2000, 401.0667, 296.8000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 27], device='cuda:0'), 'image_id': tensor([15742], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 30.7200, 119.3010, 409.6000, 447.3786]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4915], device='cuda:0')}, {'boxes': tensor([[230.7413, 126.9760, 333.1413, 271.3600]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10852], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   8.0593, 510.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14171], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.8445, 401.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26930], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 220.6897, 509.9520, 510.8966]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([12573], device='cuda:0')}, {'boxes': tensor([[ 27.6480,  58.7093, 438.2720, 480.5973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3365], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[157.6960, 153.7538, 512.0000, 508.9249]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3662], device='cuda:0')}, {'boxes': tensor([[140.4000, 281.6000, 399.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([17587], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[147.6923, 163.2000, 297.8462, 297.6000],\n",
      "        [248.6154, 156.8000, 285.5385, 179.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([20055], device='cuda:0')}, {'boxes': tensor([[1.8520e+02, 6.4711e+01, 3.1800e+02, 5.0631e+02],\n",
      "        [4.0000e-01, 2.8800e+02, 1.1080e+02, 4.1813e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([18295], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.1600, 238.9333, 278.5280, 378.1973]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8216], device='cuda:0')}, {'boxes': tensor([[175.2000, 117.3333, 252.4000, 304.3556],\n",
      "        [289.2000, 381.1555, 328.4000, 433.7778],\n",
      "        [331.2000, 377.6000, 366.8000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18,  7,  7], device='cuda:0'), 'image_id': tensor([32879], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[192.0000,  17.0667, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4621], device='cuda:0')}, {'boxes': tensor([[ 58.3680,  15.3754, 494.5920, 493.5496]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4949], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,  81.0667, 446.4000, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([990], device='cuda:0')}, {'boxes': tensor([[259.8400,  22.1867, 454.4000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5980], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 52.0000, 112.3556, 224.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14573], device='cuda:0')}, {'boxes': tensor([[ 65.6000,  72.5333, 511.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17058], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.4800,  81.7349, 403.4560, 439.5181]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([742], device='cuda:0')}, {'boxes': tensor([[ 60.2353,  11.3778, 337.8824, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([18862], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[279.2000,  45.5111, 471.6000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20765], device='cuda:0')}, {'boxes': tensor([[  2.5600,  15.6507, 506.8800, 507.5284]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3918], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  6.4000, 102.4000, 254.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31572], device='cuda:0')}, {'boxes': tensor([[ 84.2667, 185.6000, 243.7333, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([23381], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  6.1440, 167.5916, 505.8560, 436.6607]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9329], device='cuda:0')}, {'boxes': tensor([[163.6000, 285.8667, 224.0000, 364.8000],\n",
      "        [147.6000, 325.6889, 173.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([16465], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[152.5656,  11.3778, 374.9495, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5086], device='cuda:0')}, {'boxes': tensor([[ 43.2000, 120.8889, 432.0000, 310.0444],\n",
      "        [416.0000, 174.9333, 499.2000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([19603], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[169.3013, 128.0000, 359.0827, 447.4880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10259], device='cuda:0')}, {'boxes': tensor([[227.6000, 324.9778, 266.4000, 370.4889],\n",
      "        [483.6000, 411.7333, 512.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7], device='cuda:0'), 'image_id': tensor([31547], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[272.0000,  71.1111, 511.2000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17435], device='cuda:0')}, {'boxes': tensor([[ 16.3840, 214.9834, 508.9280, 510.5856]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([635], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  3.4133,  54.3926, 382.2933, 282.6051]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([11025], device='cuda:0')}, {'boxes': tensor([[ 95.2000,   1.4222, 371.7333, 259.3185]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21898], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[195.6000, 152.8889, 240.4000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([30261], device='cuda:0')}, {'boxes': tensor([[115.7120,   5.4613, 419.8400, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6661], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[206.4000,  19.9111, 341.6000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17525], device='cuda:0')}, {'boxes': tensor([[  6.1501,   2.0480, 462.7988, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8600], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[125.9520, 147.2000, 512.0000, 360.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2117], device='cuda:0')}, {'boxes': tensor([[276.4800, 189.7813, 406.5280, 346.7947],\n",
      "        [105.4720, 182.9547, 274.4320, 341.3333],\n",
      "        [339.9680, 357.7173, 396.2880, 406.8693],\n",
      "        [ 77.8240, 346.7947, 106.4960, 397.3120],\n",
      "        [278.5280, 361.8133, 303.1040, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([7628], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 74.0766, 159.4514, 410.6894, 368.6400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([11104], device='cuda:0')}, {'boxes': tensor([[195.2000, 238.9333, 274.1333, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([24178], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,  24.8889, 354.0000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([21209], device='cuda:0')}, {'boxes': tensor([[  1.0240,  41.2657, 512.0000, 510.4716]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1937], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 64.1707,  53.2480, 376.8320, 411.6480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10246], device='cuda:0')}, {'boxes': tensor([[141.4737,  73.7280, 386.6947, 484.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([53], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  7.1680,  50.1164, 463.8720, 501.1640]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2761], device='cuda:0')}, {'boxes': tensor([[218.4000, 105.2444, 333.6000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([22976], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.4000, 295.8222, 313.6000, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([25423], device='cuda:0')}, {'boxes': tensor([[ 31.7440,  23.6868, 509.9520, 497.4235]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([13260], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[280.4000, 356.2667, 319.6000, 506.3111],\n",
      "        [419.2000, 232.5333, 456.8000, 294.4000],\n",
      "        [386.4000,  68.9778, 409.2000, 135.1111],\n",
      "        [441.6000,   4.9778, 455.2000,  28.4444],\n",
      "        [215.2000, 341.3333, 250.0000, 386.8445],\n",
      "        [134.8000, 288.0000, 176.8000, 346.3111],\n",
      "        [134.4000, 209.7778, 158.4000, 269.5111],\n",
      "        [321.6000, 185.6000, 350.8000, 235.3778],\n",
      "        [109.6000, 375.4667, 153.2000, 420.9778],\n",
      "        [ 72.8000, 253.8667, 108.4000, 300.8000],\n",
      "        [ 43.2000, 387.5555,  88.0000, 430.2222],\n",
      "        [362.8000, 332.8000, 416.8000, 406.7556],\n",
      "        [489.2000, 329.9556, 511.2000, 398.9333],\n",
      "        [432.4000, 413.1555, 468.0000, 510.5778],\n",
      "        [466.0000, 201.9556, 500.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
      "       device='cuda:0'), 'image_id': tensor([25696], device='cuda:0')}, {'boxes': tensor([[219.2000, 283.0222, 252.0000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([31549], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 54.4900,  44.7229, 246.7470, 299.1807]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([298], device='cuda:0')}, {'boxes': tensor([[  0.0000,   8.1920, 473.0100, 494.5920]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8870], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[269.6000, 116.6222, 352.8000, 412.4444],\n",
      "        [111.2000, 104.5333, 240.0000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([19881], device='cuda:0')}, {'boxes': tensor([[118.0000, 198.4000, 376.0000, 505.6000],\n",
      "        [  0.0000,  16.3556, 509.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([16314], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[122.8000, 211.2000, 208.8000, 425.2444],\n",
      "        [279.2000, 238.2222, 361.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([25620], device='cuda:0')}, {'boxes': tensor([[245.2000, 327.1111, 292.8000, 401.7778],\n",
      "        [ 68.0000, 325.6889, 101.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([13672], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[187.3920,  24.6006, 395.2640, 373.6216]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4414], device='cuda:0')}, {'boxes': tensor([[242.8000, 163.5555, 320.8000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([31229], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.1333, 180.6222, 451.2000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([27735], device='cuda:0')}, {'boxes': tensor([[ 67.2000,  61.8667, 128.0000, 255.2889],\n",
      "        [230.8000, 204.8000, 248.8000, 238.9333],\n",
      "        [110.0000, 150.0444, 179.6000, 214.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29], device='cuda:0'), 'image_id': tensor([31200], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[106.3385, 103.0244, 403.6923, 390.2439]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3491], device='cuda:0')}, {'boxes': tensor([[123.6000, 119.4667, 348.4000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([29354], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[229.3760,  16.3840, 510.9760, 185.6853]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10055], device='cuda:0')}, {'boxes': tensor([[ 64.0000,  71.1111, 358.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([19650], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560,   6.8267, 452.6080, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10478], device='cuda:0')}, {'boxes': tensor([[145.8667, 356.5037, 167.2000, 394.4296],\n",
      "        [345.0667, 132.7407, 373.3333, 150.2815]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15308], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 508.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([17631], device='cuda:0')}, {'boxes': tensor([[ 20.0784,  64.0000, 421.6471, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([30082], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[428.8000, 141.5757, 509.8667, 269.5758],\n",
      "        [ 71.4667,  65.9394, 130.1333, 246.3030]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([23970], device='cuda:0')}, {'boxes': tensor([[160.7680,   1.5238, 512.0000, 451.0476]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4165], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 33.2000,   0.0000, 156.8000, 122.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([32469], device='cuda:0')}, {'boxes': tensor([[254.8000, 327.1111, 316.0000, 408.1778],\n",
      "        [ 61.2000, 322.1333,  99.6000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([13669], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 69.6320, 177.4933,  96.2560, 197.9733],\n",
      "        [  1.0240, 181.5893,  13.3120, 199.3387],\n",
      "        [118.7840,  81.9200, 397.3120, 330.4107]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7,  7, 26], device='cuda:0'), 'image_id': tensor([13126], device='cuda:0')}, {'boxes': tensor([[ 44.0320,  64.1707, 398.3360, 264.8747]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([9662], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[346.4000,  78.2222, 512.0000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([24375], device='cuda:0')}, {'boxes': tensor([[197.6320, 200.2149, 510.9760, 495.1881]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3410], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[171.6618, 211.9680, 477.6676, 438.2720],\n",
      "        [ 37.3178,  43.0080, 479.1603, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([5187], device='cuda:0')}, {'boxes': tensor([[348.0000, 251.7333, 363.2000, 270.2222],\n",
      "        [316.4000, 300.0889, 332.4000, 317.8667],\n",
      "        [295.2000, 325.6889, 309.6000, 343.4667],\n",
      "        [264.0000, 208.3556, 282.0000, 224.7111],\n",
      "        [248.4000, 266.6667, 263.6000, 285.1555],\n",
      "        [217.2000, 303.6444, 232.8000, 321.4222],\n",
      "        [195.6000, 173.5111, 210.8000, 189.8667],\n",
      "        [165.6000, 220.4444, 180.8000, 238.2222],\n",
      "        [143.2000, 254.5778, 157.6000, 272.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17750], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 42.8901,  72.0000, 404.7749, 452.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2434], device='cuda:0')}, {'boxes': tensor([[  1.0240,   5.4613, 512.0000, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4624], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.4587,  62.4640, 105.1307, 113.6640],\n",
      "        [116.0533,  89.0880, 173.3973, 149.5040],\n",
      "        [173.3973,  82.9440, 228.0107, 158.7200],\n",
      "        [191.1467, 195.5840, 229.3760, 215.0400],\n",
      "        [409.6000,  89.0880, 461.4827, 134.1440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([12436], device='cuda:0')}, {'boxes': tensor([[338.0000,  98.1333, 498.4000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([24126], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[165.6000, 226.1333, 234.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([23479], device='cuda:0')}, {'boxes': tensor([[422.4000, 311.4667, 511.2000, 418.1333],\n",
      "        [ 98.4000, 263.1111, 165.6000, 420.9778],\n",
      "        [  0.8000, 364.0889,  48.8000, 432.3556],\n",
      "        [360.0000, 287.2889, 430.4000, 371.2000],\n",
      "        [200.0000, 318.5778, 256.0000, 401.0667],\n",
      "        [221.6000, 283.0222, 245.6000, 329.9556],\n",
      "        [236.8000, 311.4667, 272.0000, 341.3333],\n",
      "        [276.8000, 308.6222, 308.0000, 354.1333],\n",
      "        [300.8000, 298.6667, 352.8000, 366.9333],\n",
      "        [276.8000, 354.1333, 329.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([20542], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[4.0000e-01, 5.6889e+01, 3.3960e+02, 4.2667e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([14433], device='cuda:0')}, {'boxes': tensor([[ 43.2000, 123.0222, 220.4000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([25104], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[327.2000, 233.2444, 404.8000, 293.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14619], device='cuda:0')}, {'boxes': tensor([[ 66.5600,   0.0000, 424.9600, 510.7200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10169], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[117.7600,  90.1120, 423.6800, 407.5520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4087], device='cuda:0')}, {'boxes': tensor([[ 37.8880,  55.9787, 468.9920, 442.3680]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9449], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.5920,  46.2650, 435.2000, 354.6988]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([12222], device='cuda:0')}, {'boxes': tensor([[146.4320,  71.8596, 419.8400, 446.8772]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([243], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[320.0000, 202.6667, 338.8000, 220.4444],\n",
      "        [296.8000, 184.8889, 316.0000, 204.8000],\n",
      "        [277.2000, 171.3778, 296.0000, 189.1555],\n",
      "        [248.0000, 152.1778, 268.0000, 173.5111],\n",
      "        [218.8000, 133.6889, 239.2000, 157.8667],\n",
      "        [206.0000, 167.8222, 225.6000, 189.8667],\n",
      "        [196.4000, 197.6889, 214.8000, 216.8889],\n",
      "        [186.0000, 226.1333, 202.8000, 243.9111],\n",
      "        [176.8000, 250.3111, 194.4000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17867], device='cuda:0')}, {'boxes': tensor([[199.2000, 103.8222, 330.4000, 366.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([15950], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[146.4320, 165.2053, 297.9840, 402.7733]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6339], device='cuda:0')}, {'boxes': tensor([[  6.0000,  56.1778, 510.8000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26684], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 64.1707,   2.0480, 509.2693, 465.9200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8706], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 254.5778, 171.2000, 374.0444],\n",
      "        [120.8000, 261.6889, 140.8000, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([20303], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560, 263.1680, 431.4453, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6516], device='cuda:0')}, {'boxes': tensor([[ 27.3067,  11.2640, 501.0773, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([11819], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 16.3840,  30.7200, 506.8800, 480.2560]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4592], device='cuda:0')}, {'boxes': tensor([[219.1360, 116.8528, 510.9760, 456.6486]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([569], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.0480,   0.0000, 471.0400, 510.4716]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3280], device='cuda:0')}, {'boxes': tensor([[ 82.8000, 122.3111, 263.2000, 214.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([31091], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 99.3280,   2.3326, 403.4560, 439.6902]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8777], device='cuda:0')}, {'boxes': tensor([[  0.0000, 102.4000, 495.6160, 187.0507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10109], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([24370], device='cuda:0')}, {'boxes': tensor([[  1.0240,   0.0000, 433.1520, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4167], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 91.7333, 172.0889, 188.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([22004], device='cuda:0')}, {'boxes': tensor([[  1.0240, 262.1440, 106.4960, 430.0800],\n",
      "        [  1.0240, 116.0533, 217.0880, 319.4880],\n",
      "        [ 83.9680, 121.5147, 448.5120, 338.6027]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([7806], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000, 105.2444, 368.8000, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26106], device='cuda:0')}, {'boxes': tensor([[116.1437,  47.2823, 481.0284, 470.1214]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6724], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 32.0000, 369.7778, 211.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([24166], device='cuda:0')}, {'boxes': tensor([[  2.0480,   5.7143, 338.9440, 508.5714]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5161], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[164.8640, 101.0347, 314.3680, 349.5253],\n",
      "        [269.3120, 116.0533, 422.9120, 364.5440]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([12607], device='cuda:0')}, {'boxes': tensor([[233.6000, 135.1111, 245.6000, 150.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([17174], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   5.1200, 372.0533, 496.6400]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7678], device='cuda:0')}, {'boxes': tensor([[  3.2000, 219.0222, 243.2000, 452.2667],\n",
      "        [269.8667, 163.5556, 432.0000, 310.0444],\n",
      "        [376.5333, 265.9556, 473.6000, 351.2889],\n",
      "        [184.5333, 190.5778, 246.4000, 237.5111],\n",
      "        [  3.2000, 221.8667,  62.9333, 275.9111],\n",
      "        [423.4667, 196.2667, 485.3333, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([23185], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([15429], device='cuda:0')}, {'boxes': tensor([[309.2000, 184.1778, 412.0000, 316.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([17954], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[178.9919,  61.1556, 477.6585, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([23670], device='cuda:0')}, {'boxes': tensor([[216.0640, 128.3963, 424.9600, 408.9659],\n",
      "        [  4.0960, 112.5449,  52.2240, 399.4551],\n",
      "        [ 27.6480, 128.3963, 223.2320, 418.4768]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6], device='cuda:0'), 'image_id': tensor([9940], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([15401], device='cuda:0')}, {'boxes': tensor([[208.0000, 210.4889, 280.0000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20923], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[222.2703, 204.1905, 294.0540, 382.4762]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26450], device='cuda:0')}, {'boxes': tensor([[  0.8000, 179.2000, 438.4000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([17605], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 40.8000,  54.4000, 460.8000, 370.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2498], device='cuda:0')}, {'boxes': tensor([[152.5760, 155.6480, 371.7120, 391.8507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5728], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[233.4720, 143.3600, 299.0080, 187.0507]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3502], device='cuda:0')}, {'boxes': tensor([[ 80.5926, 131.5556, 431.4074, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([3434], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[220.8000,   4.7850, 368.0000, 425.8692]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2807], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([30524], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[265.6000, 115.9111, 307.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26221], device='cuda:0')}, {'boxes': tensor([[143.3600,   4.6126, 510.9760, 462.7988]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8102], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[118.4000,  82.4889, 478.9333, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([26387], device='cuda:0')}, {'boxes': tensor([[121.6000, 292.2667, 217.6000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([25904], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 33.2800, 143.6444, 362.6667, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([14406], device='cuda:0')}, {'boxes': tensor([[ 90.4000,  41.2444, 301.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18810], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.6006, 181.5458, 429.5977, 487.5219]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([9674], device='cuda:0')}, {'boxes': tensor([[105.9310, 110.9333, 355.6256, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([26365], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 84.9920, 107.8613, 422.9120, 376.8320]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([9936], device='cuda:0')}, {'boxes': tensor([[163.2000,   1.4222, 511.6000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([19114], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 34.2395,  94.0907, 449.8911, 499.7804]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10250], device='cuda:0')}, {'boxes': tensor([[  0.0000,  64.0000, 364.0000, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([24794], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.2815,  59.7333, 365.0370, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([30635], device='cuda:0')}, {'boxes': tensor([[142.4000,  24.8889, 431.2000, 285.8667],\n",
      "        [313.6000, 213.3333, 390.8000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32140], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[225.6000, 199.1111, 294.4000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18663], device='cuda:0')}, {'boxes': tensor([[215.0400,  13.7964, 291.8400, 311.1856]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8872], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[318.0000, 193.4222, 380.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([26280], device='cuda:0')}, {'boxes': tensor([[169.6000,  93.8667, 294.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([26046], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[116.8000, 119.4667, 349.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([20720], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([20870], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 24.0000, 109.8667, 313.6000, 404.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([4023], device='cuda:0')}, {'boxes': tensor([[153.6000,  91.0222, 265.2000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([27105], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[107.6276, 120.8320, 216.7928, 211.9680],\n",
      "        [230.6306, 133.1200, 508.9249, 386.0480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([12969], device='cuda:0')}, {'boxes': tensor([[111.6000,  83.2000, 291.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([14861], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   2.7307, 510.9760, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3231], device='cuda:0')}, {'boxes': tensor([[299.2000, 125.1555, 358.4000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([28833], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[104.4480,   1.5375, 447.4880, 495.0871]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([4045], device='cuda:0')}, {'boxes': tensor([[174.0800, 173.7417, 442.3680, 465.8739]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2202], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 69.6000,  79.6444, 262.4000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([18678], device='cuda:0')}, {'boxes': tensor([[419.2756,  81.0667, 510.3874, 174.9333],\n",
      "        [  0.0000, 253.8667, 100.3843, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([25952], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000, 204.8000, 116.8000, 326.4000],\n",
      "        [188.4000, 155.0222, 302.8000, 373.3333],\n",
      "        [244.0000, 169.2444, 315.2000, 338.4889],\n",
      "        [106.8000, 199.8222, 183.6000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([20099], device='cuda:0')}, {'boxes': tensor([[ 58.8000,  92.4445, 356.8000, 511.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15619], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 31.7440,  97.1566, 485.3760, 456.4819]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1916], device='cuda:0')}, {'boxes': tensor([[173.0560, 163.8400, 342.0160, 379.5627],\n",
      "        [482.3040, 456.0213, 497.6640, 486.0587]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([3625], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 99.8400,  57.3991, 432.6400, 450.0090]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([6364], device='cuda:0')}, {'boxes': tensor([[228.0000, 193.4222, 314.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([18975], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[240.0000,   1.4222, 497.2000, 236.8000],\n",
      "        [  0.8000,  66.1333, 175.2000, 272.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19], device='cuda:0'), 'image_id': tensor([15790], device='cuda:0')}, {'boxes': tensor([[ 16.0000, 204.0889,  51.6000, 272.3556],\n",
      "        [358.4000, 129.4222, 432.0000, 284.4444],\n",
      "        [478.4000, 258.1333, 511.2000, 307.2000],\n",
      "        [346.8000, 275.9111, 366.8000, 322.8445],\n",
      "        [192.4000, 225.4222, 214.0000, 290.8445],\n",
      "        [236.0000, 267.3778, 251.6000, 301.5111],\n",
      "        [260.0000, 277.3333, 272.0000, 302.2222],\n",
      "        [356.0000, 297.2444, 380.4000, 336.3556],\n",
      "        [303.6000, 249.6000, 320.4000, 301.5111],\n",
      "        [213.2000, 261.6889, 227.2000, 305.0667],\n",
      "        [334.4000, 246.7556, 350.8000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19, 19,  7, 19, 19, 19,  6, 19, 19, 19], device='cuda:0'), 'image_id': tensor([28659], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,   1.4222, 246.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15688], device='cuda:0')}, {'boxes': tensor([[229.6000,  83.9111, 498.8000, 399.6444],\n",
      "        [ 37.2000, 147.2000, 186.0000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([25032], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000,  41.7778, 383.2000, 509.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13539], device='cuda:0')}, {'boxes': tensor([[249.6000, 155.7333, 360.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([28053], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 17.8087,   3.4133, 492.7072, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([6127], device='cuda:0')}, {'boxes': tensor([[209.6000, 145.7778, 295.6000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21464], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.0667, 172.0889, 380.8000, 324.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([29259], device='cuda:0')}, {'boxes': tensor([[110.9333, 185.8370, 202.6667, 311.9407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([21618], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[141.6000, 130.8445, 339.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17519], device='cuda:0')}, {'boxes': tensor([[ 19.9880,   6.1440, 512.0000, 509.9520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8430], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0667,  49.7778, 184.5333, 386.8444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([13978], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([17733], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 15.3600,  12.2635, 460.8000, 416.9581]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3278], device='cuda:0')}, {'boxes': tensor([[462.8000,   6.4000, 510.8000, 155.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([18839], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[440.5333, 295.8222, 487.4667, 339.9111],\n",
      "        [ 45.8667, 241.7778, 358.4000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([23295], device='cuda:0')}, {'boxes': tensor([[147.2000,   0.0000, 428.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([17714], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[243.7120,   1.3653, 374.7840, 322.2187],\n",
      "        [  1.0240, 147.4560, 182.2720, 327.6800]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([11602], device='cuda:0')}, {'boxes': tensor([[103.0244,  42.6667, 423.5447, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([23668], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 77.3333,  41.7185, 511.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21643], device='cuda:0')}, {'boxes': tensor([[141.5385, 134.7368, 464.0000, 394.1053],\n",
      "        [  3.6923, 146.5263, 151.3846, 424.4211]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32568], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[135.1680, 157.3012, 512.0000, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([957], device='cuda:0')}, {'boxes': tensor([[135.2000, 100.9778, 187.2000, 240.3556],\n",
      "        [454.4000, 105.2444, 511.2000, 250.3111],\n",
      "        [288.0000, 125.1555, 415.2000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([18581], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   7.8222, 510.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27088], device='cuda:0')}, {'boxes': tensor([[211.2000, 254.5778, 300.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([23908], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[389.6352, 109.5111, 485.4340, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([25970], device='cuda:0')}, {'boxes': tensor([[  8.1920,  83.9788, 499.7120, 442.9206]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10400], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.8000, 133.6889, 126.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([22221], device='cuda:0')}, {'boxes': tensor([[148.8000, 238.2222, 335.2000, 373.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([31821], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 10.2400, 155.2913, 483.3280, 379.7718]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([9213], device='cuda:0')}, {'boxes': tensor([[256.0000, 393.0064, 349.1840, 469.4243]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1409], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[185.6000,  56.1778, 296.0000, 184.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([19305], device='cuda:0')}, {'boxes': tensor([[  0.0000, 145.7778, 280.0000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27019], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 76.8000,   0.0000, 460.8000, 381.7006]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10205], device='cuda:0')}, {'boxes': tensor([[  1.0240, 147.4560, 462.8480, 424.6187]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4636], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.2000,  36.9778, 382.4000, 290.8445],\n",
      "        [191.6000, 111.6444, 313.6000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([17247], device='cuda:0')}, {'boxes': tensor([[393.1086, 162.1333, 512.0000, 321.4222],\n",
      "        [ 75.7453, 179.2000, 269.4232, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([20651], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[346.4000, 204.0889, 433.2000, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([25520], device='cuda:0')}, {'boxes': tensor([[  0.0000,  67.2000, 430.4000, 396.8000],\n",
      "        [300.0000,  93.8667, 511.2000, 188.8000],\n",
      "        [312.8000,  67.2000, 511.2000, 212.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([14360], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   1.5422, 413.6960, 442.6024]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2092], device='cuda:0')}, {'boxes': tensor([[  1.0240, 106.0901, 409.6000, 424.3604]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2493], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[471.2000, 192.7111, 509.6000, 437.3333],\n",
      "        [259.2000, 189.1555, 352.4000, 276.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 12], device='cuda:0'), 'image_id': tensor([27703], device='cuda:0')}, {'boxes': tensor([[180.8000, 118.7556, 230.0000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([26484], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[354.6667,  27.9704, 454.1333, 161.1852]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([15246], device='cuda:0')}, {'boxes': tensor([[248.7066,  63.4467, 395.3048, 430.8473],\n",
      "        [388.0114,  81.1527, 474.0741, 383.6311],\n",
      "        [ 65.6410,  51.6427, 347.1681, 451.5043]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26, 26], device='cuda:0'), 'image_id': tensor([11126], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[146.4000, 165.6889, 404.0000, 189.8667],\n",
      "        [223.2000, 265.9556, 256.0000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  1], device='cuda:0'), 'image_id': tensor([29887], device='cuda:0')}, {'boxes': tensor([[ 84.9920, 105.1307, 395.2640, 230.7413]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10132], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[205.6000, 333.2741, 297.3333, 467.4370],\n",
      "        [ 94.4000,  75.8519, 121.6000, 146.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 5], device='cuda:0'), 'image_id': tensor([21609], device='cuda:0')}, {'boxes': tensor([[ 54.2720,  21.5904, 510.9760, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8765], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.3399, 125.1555, 506.9557, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([28040], device='cuda:0')}, {'boxes': tensor([[351.7333,   1.4222, 512.0000, 225.1852]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([13811], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[115.7120, 148.7462, 366.5920, 366.3853],\n",
      "        [ 14.3360, 192.5872,  95.2320, 302.1896],\n",
      "        [384.0000, 200.4159, 504.8320, 292.7951],\n",
      "        [  1.0240, 248.9541,  20.4800, 299.0581]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([9985], device='cuda:0')}, {'boxes': tensor([[  1.0240,   0.0000, 510.9760, 510.1779]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10416], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[450.1333,  31.2889, 509.8667, 164.9778],\n",
      "        [162.1333,  98.1333, 281.6000, 194.8445],\n",
      "        [184.5333, 258.8445, 282.6667, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17, 17, 17], device='cuda:0'), 'image_id': tensor([28130], device='cuda:0')}, {'boxes': tensor([[221.8667, 210.4889, 336.0000, 375.4667],\n",
      "        [178.1333, 237.5111, 229.3333, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([21994], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[383.3991, 290.1333, 512.0000, 487.8222],\n",
      "        [  7.2113,  32.7111, 364.1690, 217.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 23], device='cuda:0'), 'image_id': tensor([29021], device='cuda:0')}, {'boxes': tensor([[  1.0240,  61.4400, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4826], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.4000, 287.2889, 229.3333, 366.9333],\n",
      "        [162.1333, 233.2444, 250.6667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 3, 19], device='cuda:0'), 'image_id': tensor([29193], device='cuda:0')}, {'boxes': tensor([[  9.2160,  58.7093, 508.9280, 507.9040]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5753], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 20.8000, 162.8445, 140.4000, 356.2667],\n",
      "        [ 82.0000,   8.5333, 278.4000, 335.6444],\n",
      "        [237.6000,  94.5778, 352.8000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30], device='cuda:0'), 'image_id': tensor([19159], device='cuda:0')}, {'boxes': tensor([[118.8000,  24.1778, 294.8000, 209.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18071], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[252.8000,   3.5555, 369.6000, 271.6444],\n",
      "        [296.4000, 433.7778, 370.8000, 512.0000],\n",
      "        [ 26.0000, 249.6000,  64.4000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([17986], device='cuda:0')}, {'boxes': tensor([[129.0240,  64.1707, 297.9840, 484.6933]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7666], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[248.4000,  64.7111, 404.8000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20884], device='cuda:0')}, {'boxes': tensor([[180.0000,  36.9778, 249.2000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([32779], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  2.4000,   0.0000, 268.8000, 506.3111],\n",
      "        [138.8000,   0.0000, 344.4000, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([16770], device='cuda:0')}, {'boxes': tensor([[130.0480,  70.9973, 430.0800, 447.8293]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([8858], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[256.0000, 177.7778, 362.8000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([22082], device='cuda:0')}, {'boxes': tensor([[131.2000, 129.4222, 338.4000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21387], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 70.6560,  57.5805, 472.0640, 368.8268]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([12603], device='cuda:0')}, {'boxes': tensor([[ 30.7200,  36.8640, 436.2240, 509.2693]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([11571], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[104.5333,   8.5333, 331.7333, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([30606], device='cuda:0')}, {'boxes': tensor([[  2.7307,   4.0960, 502.4427, 483.3280]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([9907], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[245.6000, 218.3111, 290.4000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([32405], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 324.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([26714], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[130.0480,  19.6342, 390.1440, 389.6637]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5113], device='cuda:0')}, {'boxes': tensor([[203.6000,  44.8000, 377.2000, 321.4222],\n",
      "        [ 10.0000, 263.1111,  80.4000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19,  7], device='cuda:0'), 'image_id': tensor([20823], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.4000,  87.4667, 512.0000, 317.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([27014], device='cuda:0')}, {'boxes': tensor([[ 62.4640, 144.5285, 353.2800, 419.7477]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1334], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   1.5422, 267.2640, 245.2048]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10053], device='cuda:0')}, {'boxes': tensor([[228.8000, 224.7111, 291.2000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([20924], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[282.4000, 204.8000, 396.8000, 388.2667],\n",
      "        [340.0000, 136.5333, 409.6000, 310.0444],\n",
      "        [ 49.6000, 170.6667, 297.6000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([29613], device='cuda:0')}, {'boxes': tensor([[288.0000, 164.9778, 400.0000, 324.2667],\n",
      "        [105.6000, 113.7778, 153.2000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([26872], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[252.8000, 196.9778, 344.4000, 315.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([29161], device='cuda:0')}, {'boxes': tensor([[  3.2000, 147.3073, 302.4000, 509.1397]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([18521], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[100.0000,  12.8000, 333.2000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([16183], device='cuda:0')}, {'boxes': tensor([[ 64.4000, 216.1778, 294.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([25358], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[116.7360, 227.3837, 177.1520, 337.2085]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([6931], device='cuda:0')}, {'boxes': tensor([[300.8000, 315.7333, 358.4000, 379.2592],\n",
      "        [349.8667, 222.3407, 374.1333, 256.4741]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 5], device='cuda:0'), 'image_id': tensor([21627], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.6560, 316.1446, 272.3840, 468.8193],\n",
      "        [335.8720,   1.5422, 414.7200, 211.2771]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 12], device='cuda:0'), 'image_id': tensor([12442], device='cuda:0')}, {'boxes': tensor([[104.4000, 420.9778, 304.8000, 510.5778],\n",
      "        [ 86.4000,  81.7778, 176.8000, 361.2444],\n",
      "        [ 24.0000, 206.9333,  98.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([22058], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[257.2000, 273.0667, 264.4000, 283.0222],\n",
      "        [174.8000, 218.3111, 185.6000, 229.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([17839], device='cuda:0')}, {'boxes': tensor([[180.8000,   0.0000, 452.8000, 509.6727]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([301], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 27.6480,  89.0435, 454.6560, 489.7391]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([83], device='cuda:0')}, {'boxes': tensor([[  0.0000,   1.0240, 348.1600, 478.2080]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1449], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[154.6240,  91.9760, 512.0000, 487.4731]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([3064], device='cuda:0')}, {'boxes': tensor([[294.4000, 182.0444, 374.8000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26631], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[228.3520,  87.6906, 289.7920, 281.4586]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3730], device='cuda:0')}, {'boxes': tensor([[158.8000,   2.1333, 474.0000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([27827], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.9259,   3.1125, 489.4815, 413.9575]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7451], device='cuda:0')}, {'boxes': tensor([[ 54.8000, 226.8445, 350.8000, 452.9778],\n",
      "        [101.6000, 168.5333, 198.4000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([32146], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[209.6000, 120.8889, 282.4000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([28450], device='cuda:0')}, {'boxes': tensor([[358.4000, 312.8889, 420.2667, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([25885], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[388.0960, 347.6711, 417.7920, 391.1300]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([10950], device='cuda:0')}, {'boxes': tensor([[ 41.9840,  41.1192, 506.8800, 506.6943]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([11978], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[248.8000,   1.4222, 334.0000, 147.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14659], device='cuda:0')}, {'boxes': tensor([[  5.3895,  50.5408, 234.4421, 468.0515],\n",
      "        [261.3895,   2.1974, 512.0000, 501.0129]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8297], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[144.4000,   0.8889, 288.0000, 510.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([13534], device='cuda:0')}, {'boxes': tensor([[146.4320,  51.0582, 330.7520, 445.3407]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([5142], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 59.6000, 148.6222, 448.0000, 504.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([32211], device='cuda:0')}, {'boxes': tensor([[239.6000, 242.4889, 267.2000, 295.8222],\n",
      "        [211.6000, 164.2667, 291.2000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([33070], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 19.4783,  19.4783, 470.2609, 495.3044]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2707], device='cuda:0')}, {'boxes': tensor([[376.0000,  91.0222, 511.2000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15673], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[178.1760,  79.9520, 392.1920, 362.8589]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7435], device='cuda:0')}, {'boxes': tensor([[206.4000, 229.6889, 401.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([18010], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[210.4000, 279.4667, 466.4000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([14637], device='cuda:0')}, {'boxes': tensor([[223.2320, 112.2402, 414.7200, 467.4114],\n",
      "        [113.6640, 209.1051, 184.3200, 393.6096],\n",
      "        [  1.0240, 295.2072,  34.8160, 338.2583]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15], device='cuda:0'), 'image_id': tensor([11577], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[198.8000, 253.8667, 374.4000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([17738], device='cuda:0')}, {'boxes': tensor([[375.4667, 217.6000, 483.2000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([24031], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 35.4987, 353.2800, 248.4907, 465.9200],\n",
      "        [ 95.5733, 184.3200, 400.0427, 283.6480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6], device='cuda:0'), 'image_id': tensor([12670], device='cuda:0')}, {'boxes': tensor([[ 52.8000,   1.4222, 288.0000, 216.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([20324], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 78.8000,  77.5111, 303.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([14667], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([23490], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[218.0000, 427.3778, 272.0000, 504.8889],\n",
      "        [192.0000, 331.3778, 243.6000, 399.6444],\n",
      "        [174.8000, 228.9778, 218.8000, 297.2444],\n",
      "        [161.2000, 165.6889, 203.2000, 219.0222],\n",
      "        [218.0000, 137.9556, 261.6000, 191.2889],\n",
      "        [270.8000, 119.4667, 314.0000, 168.5333],\n",
      "        [328.4000,  88.8889, 373.2000, 140.8000],\n",
      "        [386.0000,  62.5778, 432.0000, 111.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17874], device='cuda:0')}, {'boxes': tensor([[262.1440,  30.6921, 477.1840, 474.3324]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([10244], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([19518], device='cuda:0')}, {'boxes': tensor([[314.7673, 233.2444, 412.1761, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([28864], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 86.0000,  35.5555, 217.6000, 241.0667],\n",
      "        [237.2000,  39.1111, 332.4000, 309.3333],\n",
      "        [310.8000,  11.3778, 448.4000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([29537], device='cuda:0')}, {'boxes': tensor([[  1.0240, 121.9866, 427.0080, 372.8322]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2159], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 49.1520,  48.2575, 512.0000, 390.7678]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([8786], device='cuda:0')}, {'boxes': tensor([[ 13.4737,  79.8720, 456.6082, 370.6880]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([11617], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[251.2000,  49.0667, 512.0000, 500.6222],\n",
      "        [ 74.0000,  81.7778, 306.8000, 414.5778],\n",
      "        [132.4000, 208.3556, 243.2000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30], device='cuda:0'), 'image_id': tensor([24285], device='cuda:0')}, {'boxes': tensor([[ 93.1840, 200.7040, 148.4800, 327.6800]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([12294], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0667,   2.8445, 133.3333, 122.3111],\n",
      "        [440.5333, 302.9333, 510.9333, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 10], device='cuda:0'), 'image_id': tensor([19827], device='cuda:0')}, {'boxes': tensor([[  1.0240,  98.1078, 150.5280, 196.2156],\n",
      "        [300.0320, 104.2395, 470.0160, 447.6168]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([3435], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 70.6560, 151.1619, 455.6800, 370.5905]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9560], device='cuda:0')}, {'boxes': tensor([[136.0000, 109.5111, 172.4000, 166.4000],\n",
      "        [192.8000, 174.2222, 229.2000, 229.6889],\n",
      "        [246.8000, 236.0889, 284.8000, 288.0000],\n",
      "        [257.6000, 290.1333, 293.2000, 342.0444],\n",
      "        [268.4000, 342.0444, 304.0000, 392.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([17786], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[134.1440,  41.6386, 512.0000, 510.4578]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([5029], device='cuda:0')}, {'boxes': tensor([[165.8880, 188.4160, 297.9840, 333.1413]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5817], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 13.3120, 164.3319, 195.5840, 509.7642]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([3742], device='cuda:0')}, {'boxes': tensor([[134.1440,  95.5733, 472.0640, 356.3520]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([9526], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 68.8000,   0.0000, 328.0000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([32251], device='cuda:0')}, {'boxes': tensor([[200.8000, 366.2222, 226.4000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([30294], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[111.2000,  98.8445, 217.6000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([19028], device='cuda:0')}, {'boxes': tensor([[  1.0240,   1.3653, 512.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10402], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   3.0751, 451.5840, 465.8739]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([921], device='cuda:0')}, {'boxes': tensor([[248.0000, 302.9333, 416.4000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([25898], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[224.4000, 295.8222, 270.8000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([17971], device='cuda:0')}, {'boxes': tensor([[226.0000, 237.5111, 256.0000, 277.3333],\n",
      "        [213.2000, 140.0889, 302.8000, 276.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([33076], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 66.5600, 136.5333, 362.4960, 413.6960]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([8207], device='cuda:0')}, {'boxes': tensor([[173.2000, 100.9778, 434.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([21384], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[286.2660, 106.6667, 506.9557, 290.8445],\n",
      "        [  0.0000,   1.4222, 264.8276, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([32123], device='cuda:0')}, {'boxes': tensor([[110.5920, 145.5847, 415.7440, 449.8402]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10390], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[242.4019, 152.8889, 334.6328, 400.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([5689], device='cuda:0')}, {'boxes': tensor([[ 70.0000,   0.0000, 512.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([26932], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000, 118.0444, 402.4000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([24799], device='cuda:0')}, {'boxes': tensor([[ 90.1120,  22.9254, 448.5120, 417.2418],\n",
      "        [161.7920,  30.5672, 374.7840, 265.9343]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([12037], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 77.8240,   0.0000, 510.9760, 364.3964]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([4778], device='cuda:0')}, {'boxes': tensor([[168.0000,  61.8667, 472.0000, 512.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([20409], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[309.2480,  56.3670, 475.1360, 369.5168],\n",
      "        [132.0960, 109.6024, 245.7600, 233.2966]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([97], device='cuda:0')}, {'boxes': tensor([[311.2960,   9.2530, 417.7920,  77.1084],\n",
      "        [  1.0240,  15.4217, 115.7120,  81.7350]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([12523], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 45.0560,  63.8302, 297.9840, 441.3793]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([131], device='cuda:0')}, {'boxes': tensor([[ 22.4330,  58.0619, 500.1237, 473.2921]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([6662], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[148.8000, 249.6000, 303.2000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([32642], device='cuda:0')}, {'boxes': tensor([[ 52.2240, 215.7389, 510.9760, 448.1899]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1848], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[149.5040,  32.0000, 368.6400, 419.0476]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2203], device='cuda:0')}, {'boxes': tensor([[213.6000,   2.8445, 471.6000, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15634], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240, 260.7787,  67.5840, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([11744], device='cuda:0')}, {'boxes': tensor([[209.6000, 147.9111, 236.5333, 245.0963]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([21580], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 88.0640, 182.9670, 432.1280, 399.7598]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1558], device='cuda:0')}, {'boxes': tensor([[ 96.4000, 119.4667, 202.4000, 381.1555],\n",
      "        [202.0000,   7.1111, 450.8000, 364.0889],\n",
      "        [  0.0000, 150.0444,  86.4000, 322.1333],\n",
      "        [432.8000, 136.5333, 511.2000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([25564], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[196.2667, 227.5556, 268.8000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([20140], device='cuda:0')}, {'boxes': tensor([[ 94.8000, 238.9333, 130.4000, 405.3333],\n",
      "        [152.0000, 260.2667, 213.6000, 418.1333],\n",
      "        [372.4000, 238.2222, 430.0000, 390.4000],\n",
      "        [319.6000, 212.6222, 363.2000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([16226], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  1.0240,   0.0000, 512.0000, 510.6347]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([10481], device='cuda:0')}, {'boxes': tensor([[ 38.9120, 116.8529, 436.2240, 484.3243],\n",
      "        [228.3520, 201.4174, 474.1120, 498.1622]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([8601], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[121.6000,   3.5555, 460.0000, 508.4444],\n",
      "        [406.4000, 135.8222, 512.0000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21, 21], device='cuda:0'), 'image_id': tensor([15882], device='cuda:0')}, {'boxes': tensor([[137.6000, 311.4667, 279.2000, 511.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([14844], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[  0.0000,   0.0000, 234.4960, 508.9249]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8393], device='cuda:0')}, {'boxes': tensor([[ 35.4699,  43.0080, 508.9156, 424.9600]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([847], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[272.0000, 170.6667, 287.2000, 191.2889],\n",
      "        [244.4000, 189.8667, 258.8000, 214.0444],\n",
      "        [206.0000, 329.2444, 224.4000, 354.1333],\n",
      "        [252.4000, 312.8889, 268.8000, 339.2000],\n",
      "        [226.8000, 274.4889, 244.4000, 297.2444],\n",
      "        [247.2000, 222.5778, 262.8000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([21307], device='cuda:0')}, {'boxes': tensor([[ 15.2000, 160.7111, 153.6000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([25017], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[448.0000, 231.1111, 483.6000, 299.3778],\n",
      "        [  2.4000, 242.4889,  58.4000, 448.7111],\n",
      "        [ 84.8000, 198.4000, 116.8000, 246.0444],\n",
      "        [292.4000, 236.0889, 313.6000, 301.5111],\n",
      "        [250.4000, 216.8889, 266.0000, 251.0222],\n",
      "        [231.2000, 211.9111, 240.4000, 236.0889],\n",
      "        [118.4000, 175.6444, 144.0000, 229.6889],\n",
      "        [168.0000, 214.7556, 190.0000, 270.2222],\n",
      "        [274.8000, 218.3111, 288.8000, 261.6889],\n",
      "        [135.2000, 216.8889, 156.8000, 273.7778],\n",
      "        [208.0000, 211.9111, 219.2000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19, 19,  7, 19, 19, 19,  6, 19, 19, 19, 19], device='cuda:0'), 'image_id': tensor([28661], device='cuda:0')}, {'boxes': tensor([[241.0667, 150.7556, 311.4667, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([24773], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([28775], device='cuda:0')}, {'boxes': tensor([[  1.6000, 368.3556,  26.4000, 430.9333],\n",
      "        [ 19.2000, 236.0889, 161.6000, 433.7778],\n",
      "        [209.6000, 283.0222, 232.0000, 341.3333],\n",
      "        [211.2000, 321.4222, 268.8000, 406.7556],\n",
      "        [288.0000, 298.6667, 320.0000, 369.7778],\n",
      "        [275.2000, 318.5778, 313.6000, 401.0667],\n",
      "        [275.2000, 368.3556, 313.6000, 426.6667],\n",
      "        [301.6000, 307.2000, 349.6000, 386.8444],\n",
      "        [360.8000, 295.8222, 402.4000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11, 11, 11, 11, 11, 11, 11], device='cuda:0'), 'image_id': tensor([20547], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[101.0667,   2.8445, 376.2667, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([15141], device='cuda:0')}, {'boxes': tensor([[215.0400, 102.7160, 373.7600, 391.9012]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2], device='cuda:0'), 'image_id': tensor([7588], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[238.9333, 196.2667, 307.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([23904], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.4222e+00, 3.7080e+02, 5.1129e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([19133], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 25.6000,  61.4400, 363.5200, 389.1200]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([4927], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([24246], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[227.5556,  95.2320, 456.2963, 437.2480]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([8469], device='cuda:0')}, {'boxes': tensor([[ 53.2000,   0.7111, 511.2000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([15641], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n",
      "[{'boxes': tensor([[143.6000, 218.3111, 262.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1968], device='cuda:0')}, {'boxes': tensor([[  0.0000, 187.7333,  76.8000, 318.5778],\n",
      "        [358.4000, 224.7111, 441.6000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([672], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 41.6000,  80.3556, 511.2000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1584], device='cuda:0')}, {'boxes': tensor([[ 85.3333,  51.2000, 413.8667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1694], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.4000, 185.6000, 369.6000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1290], device='cuda:0')}, {'boxes': tensor([[153.6000,   0.0000, 509.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1312], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[359.6000, 278.7556, 442.0000, 372.6222],\n",
      "        [278.0000, 305.7778, 356.0000, 393.9556],\n",
      "        [212.4000, 347.0222, 288.4000, 433.0667],\n",
      "        [172.8000, 245.3333, 248.0000, 329.9556],\n",
      "        [276.4000, 176.3556, 359.6000, 270.2222],\n",
      "        [204.0000,  78.2222, 284.0000, 167.1111],\n",
      "        [158.8000, 105.9556, 235.6000, 203.3778],\n",
      "        [117.2000, 145.0667, 199.6000, 238.9333],\n",
      "        [225.2000, 204.8000, 304.0000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([111], device='cuda:0')}, {'boxes': tensor([[414.6479,   0.0000, 511.0986, 337.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1485], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 278.7556, 160.8000, 510.5778],\n",
      "        [113.6000,  56.8889, 205.2000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([502], device='cuda:0')}, {'boxes': tensor([[108.4000, 209.7778, 135.2000, 273.7778],\n",
      "        [ 79.6000, 280.1778, 110.8000, 342.7556],\n",
      "        [154.8000,  78.2222, 171.6000, 110.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([625], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000, 185.6000, 316.8000, 509.8667],\n",
      "        [310.4000, 204.8000, 476.8000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1414], device='cuda:0')}, {'boxes': tensor([[199.2000,  79.6444, 351.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1782], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 208.3556, 348.4000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([77], device='cuda:0')}, {'boxes': tensor([[170.6667, 227.5556, 390.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2127], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.6000,  62.5778, 224.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1070], device='cuda:0')}, {'boxes': tensor([[ 87.6000, 225.4222, 190.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 189.8667, 293.2000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1375], device='cuda:0')}, {'boxes': tensor([[270.0000, 223.2889, 356.8000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.3333, 233.2444, 241.0667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2130], device='cuda:0')}, {'boxes': tensor([[202.6667, 182.0444, 249.6000, 241.7778],\n",
      "        [235.7333, 174.9333, 297.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([366], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 96.0000, 213.3333, 486.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1038], device='cuda:0')}, {'boxes': tensor([[137.6000, 248.8889, 324.2667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2140], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.0000, 271.6444, 297.6000, 371.2000],\n",
      "        [166.0000, 172.8000, 187.2000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([831], device='cuda:0')}, {'boxes': tensor([[288.0000, 255.2889, 326.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([193], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.8000, 204.8000, 336.0000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1778], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  17.0667, 487.4667, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.6000, 224.7111, 347.2000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2190], device='cuda:0')}, {'boxes': tensor([[251.2000, 274.4889, 292.8000, 324.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([192], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.2000,  56.8889, 453.6000, 258.8445],\n",
      "        [166.4000,  68.2667, 300.8000, 263.1111],\n",
      "        [102.4000, 119.4667, 247.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1758], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 5.5467e+01, 4.5800e+02, 4.4160e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([276], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.0000, 118.7556, 266.4000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([811], device='cuda:0')}, {'boxes': tensor([[179.2000, 190.5778, 282.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[377.6000, 139.3778, 402.4000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2146], device='cuda:0')}, {'boxes': tensor([[178.8000, 202.6667, 328.8000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1599], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 206.2222, 301.2000, 488.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2183], device='cuda:0')}, {'boxes': tensor([[194.8000, 135.1111, 473.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([336], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.4000, 200.5333, 250.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1245], device='cuda:0')}, {'boxes': tensor([[358.8000, 421.6889, 375.2000, 452.2667],\n",
      "        [177.6000, 213.3333, 192.4000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1872], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  81.7778, 322.4000, 245.3333],\n",
      "        [245.2000, 288.0000, 370.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([69], device='cuda:0')}, {'boxes': tensor([[101.3333,  31.2889, 326.4000, 494.9333],\n",
      "        [410.6667, 139.3778, 508.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([607], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[279.2000, 189.1555, 398.0000, 376.1778],\n",
      "        [201.2000,  86.7556, 361.6000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([419], device='cuda:0')}, {'boxes': tensor([[198.4000, 135.1111, 281.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([813], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [147.2000,  93.8667, 334.9333, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([603], device='cuda:0')}, {'boxes': tensor([[146.4000, 126.5778, 509.6000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([322], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.4000,  73.9556, 240.8000, 234.6667],\n",
      "        [243.2000,  54.0444, 364.0000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1738], device='cuda:0')}, {'boxes': tensor([[122.4000, 169.2444, 276.8000, 384.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2038], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.4000,  70.4000, 331.2000, 400.3556],\n",
      "        [222.4000, 161.4222, 329.6000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1535], device='cuda:0')}, {'boxes': tensor([[ 66.4000, 297.9556, 138.0000, 343.4667],\n",
      "        [154.4000, 234.6667, 222.4000, 280.1778],\n",
      "        [238.8000, 156.4444, 300.4000, 234.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1], device='cuda:0'), 'image_id': tensor([124], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000, 196.9778, 278.0000, 401.7778],\n",
      "        [255.6000, 209.7778, 438.4000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([569], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 6.3289e+01, 2.5680e+02, 4.9422e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([300], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000, 263.1111, 187.7333, 384.0000],\n",
      "        [371.2000, 244.6222, 430.9333, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([702], device='cuda:0')}, {'boxes': tensor([[129.3617, 105.2444, 239.6596, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1089], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.4000, 187.7333, 266.4000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1340], device='cuda:0')}, {'boxes': tensor([[181.3333, 136.5333, 428.8000, 469.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([232], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 124.4444, 510.0000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([995], device='cuda:0')}, {'boxes': tensor([[ 34.8000,   3.5556, 290.4000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([267], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 91.2000, 206.9333, 180.8000, 283.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1276], device='cuda:0')}, {'boxes': tensor([[249.6000, 275.9111, 298.8000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000,  18.4000, 104.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1650], device='cuda:0')}, {'boxes': tensor([[187.6000, 145.0667, 292.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1841], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  77.5111, 348.0000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([11], device='cuda:0')}, {'boxes': tensor([[116.4000, 349.8667, 350.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([15], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.2000, 128.0000, 497.2000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([380], device='cuda:0')}, {'boxes': tensor([[160.0000, 229.6889, 316.8000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,  88.8889, 339.6000, 431.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([102], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 396.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1894], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000,  96.5246, 385.6000, 497.3115]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([957], device='cuda:0')}, {'boxes': tensor([[422.8000, 177.0667, 471.2000, 210.4889],\n",
      "        [323.2000, 169.9556, 416.0000, 211.9111],\n",
      "        [254.8000, 186.3111, 328.8000, 219.0222],\n",
      "        [ 17.6000, 225.4222,  92.0000, 280.1778],\n",
      "        [164.0000, 222.5778, 191.6000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 29, 29], device='cuda:0'), 'image_id': tensor([537], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[379.6000, 239.6444, 412.4000, 341.3333],\n",
      "        [  0.0000, 216.8889, 144.8000, 444.4445],\n",
      "        [105.6000, 216.8889, 169.2000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 7, 7], device='cuda:0'), 'image_id': tensor([1989], device='cuda:0')}, {'boxes': tensor([[219.0222, 231.8222, 269.2741, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([167], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000,   0.0000, 407.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([617], device='cuda:0')}, {'boxes': tensor([[139.2000, 304.3556, 235.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2007], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 390.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1834], device='cuda:0')}, {'boxes': tensor([[  7.6000,  84.6222, 271.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1433], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.8000, 211.2000, 270.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2058], device='cuda:0')}, {'boxes': tensor([[238.8000, 155.0222, 322.0000, 285.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([4], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.8000, 195.5556, 310.4000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([804], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 125.8667, 251.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1475], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1272], device='cuda:0')}, {'boxes': tensor([[213.2000, 159.2889, 313.6000, 286.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1125], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 128.7111, 228.0000, 210.4889],\n",
      "        [242.4000, 192.0000, 297.2000, 266.6667],\n",
      "        [226.0000, 190.5778, 277.2000, 270.2222],\n",
      "        [290.0000, 260.2667, 344.0000, 338.4889],\n",
      "        [329.2000, 324.2667, 384.4000, 403.9111],\n",
      "        [142.8000,  73.9556, 196.0000, 147.9111],\n",
      "        [368.8000, 410.3111, 426.4000, 492.8000],\n",
      "        [ 99.2000,  14.9333, 156.8000,  99.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([141], device='cuda:0')}, {'boxes': tensor([[  0.0000, 288.0000, 202.4000, 509.1555],\n",
      "        [249.6000, 312.1778, 378.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([19], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.0000, 193.4222, 374.4000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1602], device='cuda:0')}, {'boxes': tensor([[ 31.2000, 172.8000, 426.8000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1389], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[209.2000,   0.0000, 510.4000, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1314], device='cuda:0')}, {'boxes': tensor([[136.0000, 206.9333, 183.6000, 235.3778],\n",
      "        [418.0000, 206.2222, 453.2000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([527], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000,   0.0000, 256.0000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1861], device='cuda:0')}, {'boxes': tensor([[ 14.8000,   0.0000, 299.6000, 329.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 176.3556, 268.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([928], device='cuda:0')}, {'boxes': tensor([[219.5963, 181.3333, 318.8257, 321.0667],\n",
      "        [ 11.1560, 317.8667, 510.2385, 506.6667],\n",
      "        [300.6238, 298.6667, 509.6514, 454.4000],\n",
      "        [  0.0000, 189.8667, 162.0550, 448.0000],\n",
      "        [146.2018, 291.2000, 191.4128, 334.9333],\n",
      "        [148.5505, 277.3333, 197.2844, 321.0667],\n",
      "        [187.3027, 263.4667, 211.9633, 308.2667],\n",
      "        [352.2936, 274.1333, 413.3578, 304.0000],\n",
      "        [329.3945, 274.1333, 364.0367, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([455], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000,  54.0444, 326.4000, 411.0222],\n",
      "        [272.0000, 274.4889, 307.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([510], device='cuda:0')}, {'boxes': tensor([[200.0000, 186.1818, 284.8000, 257.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1415], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 386.8445, 294.8000, 462.9333],\n",
      "        [244.4000, 291.5555, 269.6000, 366.9333],\n",
      "        [224.8000, 204.0889, 252.8000, 278.7556],\n",
      "        [263.6000, 131.5556, 289.2000, 204.8000],\n",
      "        [300.8000,  73.9556, 327.6000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([100], device='cuda:0')}, {'boxes': tensor([[282.0000, 147.9111, 384.0000, 295.8222],\n",
      "        [ 96.0000, 141.5111, 287.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([902], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[193.6000, 153.6000, 372.0000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([746], device='cuda:0')}, {'boxes': tensor([[ 58.1818, 176.4848, 186.1818, 364.6060]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2020], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 277.6000, 509.1555],\n",
      "        [281.6000,   0.0000, 511.2000, 237.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1430], device='cuda:0')}, {'boxes': tensor([[265.6000, 285.1555, 285.6000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 192.0000, 189.8667, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1369], device='cuda:0')}, {'boxes': tensor([[448.0000, 190.5778, 511.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([531], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 126.5778, 509.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1636], device='cuda:0')}, {'boxes': tensor([[  0.0000, 210.4889, 156.4000, 507.7333],\n",
      "        [186.4000, 156.4444, 336.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([497], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.8000,   0.0000, 288.4000, 310.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([413], device='cuda:0')}, {'boxes': tensor([[ 15.2661, 366.9333, 301.7982, 508.8000],\n",
      "        [193.7615, 337.0667, 341.7248, 497.0667],\n",
      "        [280.0734, 321.0667, 369.3211, 437.3333],\n",
      "        [314.1284, 280.5333, 390.4587, 400.0000],\n",
      "        [  7.6330, 296.5333,  94.5321, 403.2000],\n",
      "        [379.8899, 278.4000, 402.7890, 318.9333],\n",
      "        [101.5780, 277.3333, 196.6973, 348.8000],\n",
      "        [202.5688, 193.0667, 345.2477, 347.7333],\n",
      "        [442.1284, 286.9333, 462.0917, 329.6000],\n",
      "        [452.1101, 270.9333, 487.3394, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 6, 7, 7], device='cuda:0'), 'image_id': tensor([465], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.8000, 107.3778, 265.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1900], device='cuda:0')}, {'boxes': tensor([[120.5333, 130.8445, 278.4000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([200], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000, 199.8222, 313.6000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([0], device='cuda:0')}, {'boxes': tensor([[ 55.2000, 118.7556, 281.2000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([223], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 89.6000, 153.6000, 505.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1281], device='cuda:0')}, {'boxes': tensor([[  0.0000, 179.2000,  32.0000, 273.0667],\n",
      "        [379.7333, 170.6667, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([687], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[320.8000, 170.6667, 391.2000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2148], device='cuda:0')}, {'boxes': tensor([[230.8000, 155.0222, 314.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([5], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[204.0000,  92.4444, 348.8000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1780], device='cuda:0')}, {'boxes': tensor([[ 12.8000,   0.0000, 509.6000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1608], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 295.8222, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([706], device='cuda:0')}, {'boxes': tensor([[162.1333, 209.0667, 291.2000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1409], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([23], device='cuda:0')}, {'boxes': tensor([[ 58.1284, 249.6000, 209.0275, 357.3333],\n",
      "        [457.9817, 222.9333, 484.4037, 269.8667],\n",
      "        [354.0551, 171.7333, 460.9174, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([479], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 169.2444, 301.2000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1442], device='cuda:0')}, {'boxes': tensor([[174.8000,   0.0000, 316.8000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1308], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[272.8000, 123.7333, 339.2000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([115], device='cuda:0')}, {'boxes': tensor([[398.0917, 228.2667, 509.6514, 321.0667],\n",
      "        [391.0459, 284.8000, 510.2385, 396.8000],\n",
      "        [ 48.7339, 249.6000, 185.5413, 443.7333],\n",
      "        [423.9266, 309.3333, 510.2385, 466.1333],\n",
      "        [409.2477, 298.6667, 510.2385, 425.6000],\n",
      "        [ 37.5780, 320.0000, 132.6973, 340.2667],\n",
      "        [ 28.7706, 332.8000, 128.5872, 363.7333],\n",
      "        [ 11.7431, 362.6667, 142.0917, 404.2667],\n",
      "        [  0.5872, 400.0000, 162.6422, 505.6000],\n",
      "        [197.8716,  87.4667, 367.5596, 451.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([461], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2000, 199.8222, 318.8000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1550], device='cuda:0')}, {'boxes': tensor([[160.4000, 268.8000, 332.4000, 491.3778],\n",
      "        [ 51.6000, 235.3778, 364.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([556], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.2000, 160.0000, 302.8000, 358.4000],\n",
      "        [174.0000, 259.5555, 256.4000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([522], device='cuda:0')}, {'boxes': tensor([[101.2000, 239.6444, 313.2000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1158], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.0000,  89.6000, 261.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([91], device='cuda:0')}, {'boxes': tensor([[172.8000,  25.6000, 509.8667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1713], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 182.0444, 228.4000, 295.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([631], device='cuda:0')}, {'boxes': tensor([[137.9817,  85.3333, 345.8349, 439.4667],\n",
      "        [  4.6972, 246.4000, 114.4954, 435.2000],\n",
      "        [422.1651, 222.9333, 453.2844, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([485], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000,  96.7111, 367.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([406], device='cuda:0')}, {'boxes': tensor([[208.8000, 107.3778, 511.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([991], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 125.8667, 301.2000, 444.4445],\n",
      "        [280.0000, 187.0222, 388.8000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1541], device='cuda:0')}, {'boxes': tensor([[211.2000, 219.7333, 284.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([661], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[127.2000, 209.7778, 338.0000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1348], device='cuda:0')}, {'boxes': tensor([[120.0000, 213.3333, 199.2000, 500.6222],\n",
      "        [252.8000, 193.4222, 295.2000, 358.4000],\n",
      "        [454.4000, 203.3778, 509.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([781], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000,  75.3778, 510.4000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1455], device='cuda:0')}, {'boxes': tensor([[132.0000,  45.5111, 293.6000, 411.0222],\n",
      "        [112.8000, 297.2444, 136.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([507], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 239.6444, 234.4000, 344.8889],\n",
      "        [ 80.0000, 149.3333, 267.6000, 354.1333],\n",
      "        [ 66.8000, 236.0889, 134.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([518], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.1662e+02, 3.4000e+02, 4.9351e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([297], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.5630,  96.7111, 508.2074, 403.9111],\n",
      "        [240.8296, 339.9111, 332.8000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([182], device='cuda:0')}, {'boxes': tensor([[142.8000, 103.1111, 379.6000, 494.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([344], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000, 153.6000, 338.0000, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1954], device='cuda:0')}, {'boxes': tensor([[  0.0000, 256.0000, 147.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([946], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.8000, 204.0889, 259.6000, 392.5333],\n",
      "        [191.2000, 234.6667, 263.2000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1565], device='cuda:0')}, {'boxes': tensor([[120.8000, 274.4889, 231.2000, 482.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2001], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[39.6000,  0.0000, 99.2000, 76.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1836], device='cuda:0')}, {'boxes': tensor([[268.8000, 137.2444, 397.2000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([423], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.8000, 142.9333, 268.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2042], device='cuda:0')}, {'boxes': tensor([[160.0000, 147.9111, 424.5333, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1306], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 136.5333, 299.2000, 341.3333],\n",
      "        [244.8000,  44.0889, 404.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1230], device='cuda:0')}, {'boxes': tensor([[213.3333, 133.6889, 462.9333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([204], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[229.6000, 167.8222, 331.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2176], device='cuda:0')}, {'boxes': tensor([[ 81.0667,  49.7778, 410.6667, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1695], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([735], device='cuda:0')}, {'boxes': tensor([[196.4000, 217.6000, 236.4000, 357.6889],\n",
      "        [432.8000, 132.9778, 484.0000, 199.1111],\n",
      "        [310.8000, 128.0000, 358.8000, 197.6889],\n",
      "        [304.0000, 128.7111, 343.6000, 175.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1950], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000,  96.7111, 280.5333, 231.8222],\n",
      "        [304.0000, 219.0222, 381.8667, 459.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([668], device='cuda:0')}, {'boxes': tensor([[  0.0000, 230.4000, 274.4000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1634], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([34], device='cuda:0')}, {'boxes': tensor([[202.8000, 183.4667, 348.8000, 268.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1930], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1866], device='cuda:0')}, {'boxes': tensor([[231.6000, 231.1111, 278.8000, 268.8000],\n",
      "        [294.4000, 210.4889, 310.4000, 238.9333],\n",
      "        [248.0000, 191.2889, 265.2000, 226.1333],\n",
      "        [232.4000, 194.1333, 256.0000, 224.7111],\n",
      "        [483.6000, 354.8445, 500.8000, 387.5555],\n",
      "        [104.4000, 378.3111, 122.8000, 418.8445],\n",
      "        [358.4000,  84.6222, 379.6000, 140.0889],\n",
      "        [109.2000,  94.5778, 118.4000, 118.0444],\n",
      "        [ 86.8000,  93.8667, 101.6000, 114.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2032], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[239.2000, 132.2667, 349.6000, 211.2000],\n",
      "        [225.2000, 179.9111, 330.8000, 260.2667],\n",
      "        [220.0000, 236.8000, 325.6000, 315.0222],\n",
      "        [207.2000, 270.2222, 312.0000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([147], device='cuda:0')}, {'boxes': tensor([[159.2000, 127.2889, 383.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1099], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.7333, 184.8889, 332.8000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([201], device='cuda:0')}, {'boxes': tensor([[408.0000,  93.3771, 492.0000, 220.3279]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([972], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 275.2000, 384.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([14], device='cuda:0')}, {'boxes': tensor([[204.8000, 115.9111, 219.2000, 159.2889],\n",
      "        [131.2000, 135.8222, 148.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([622], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872,   1.0667, 497.3211, 503.4667],\n",
      "        [219.5963, 256.0000, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([454], device='cuda:0')}, {'boxes': tensor([[ 93.8667,  35.5556, 338.1333, 507.7333],\n",
      "        [408.5333, 136.5333, 510.9333, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([606], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 183.2727, 476.8000, 384.0000],\n",
      "        [228.0000, 206.5455, 345.6000, 370.9091]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1327], device='cuda:0')}, {'boxes': tensor([[174.9333, 108.0889, 245.3333, 233.2444],\n",
      "        [326.4000, 156.4444, 387.2000, 231.8222],\n",
      "        [290.1333,  56.8889, 309.3333,  72.5333],\n",
      "        [343.4667,  68.2667, 365.8667,  86.7556],\n",
      "        [458.6667,  66.8444, 482.1333,  88.1778],\n",
      "        [156.8000,  71.1111, 178.1333,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([359], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000, 135.8222, 340.4000, 187.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1380], device='cuda:0')}, {'boxes': tensor([[156.8000, 310.0444, 330.6667, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000, 395.6364, 210.4000, 420.3636]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1424], device='cuda:0')}, {'boxes': tensor([[196.4000,  93.1556, 396.0000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1350], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.8667, 154.3111, 216.5333, 281.6000],\n",
      "        [242.1333, 164.9778, 316.2667, 247.4667],\n",
      "        [189.8667, 263.1111, 261.3333, 392.5333],\n",
      "        [219.7333, 211.9111, 312.0000, 335.6444],\n",
      "        [418.1333, 150.7556, 484.2667, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([54], device='cuda:0')}, {'boxes': tensor([[236.0000, 228.2667, 331.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1918], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 182.0444,  26.6667, 264.5333],\n",
      "        [356.2667, 137.9556, 509.8667, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([689], device='cuda:0')}, {'boxes': tensor([[ 14.4000, 155.0222, 234.4000, 285.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([214], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.0367, 116.2667, 294.7523, 300.8000],\n",
      "        [385.1743, 241.0667, 509.0642, 350.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([484], device='cuda:0')}, {'boxes': tensor([[235.2000, 120.8889, 444.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1452], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 192.0000, 265.2000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1357], device='cuda:0')}, {'boxes': tensor([[  0.0000,  19.2000, 303.2000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[158.0000, 199.1111, 321.6000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([163], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1617], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.2667, 197.6889, 509.8667, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([244], device='cuda:0')}, {'boxes': tensor([[172.8000, 211.9111, 249.6000, 285.1555],\n",
      "        [ 59.6000, 252.4444, 170.4000, 327.1111],\n",
      "        [199.6000, 237.5111, 275.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1572], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000, 176.3556, 297.2000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([888], device='cuda:0')}, {'boxes': tensor([[352.0000, 180.6222, 397.6000, 290.8445],\n",
      "        [278.0000, 182.7556, 382.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1521], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.7333, 139.3778, 475.7333, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1305], device='cuda:0')}, {'boxes': tensor([[207.6000, 157.8667, 281.6000, 320.7111],\n",
      "        [247.2000, 187.7333, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1571], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 46.9333,   0.0000, 273.0667, 510.5778],\n",
      "        [362.6667,   0.0000, 510.9333, 157.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([596], device='cuda:0')}, {'boxes': tensor([[  0.0000, 147.9111, 462.9333, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1942], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 160.0000, 205.6000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1401], device='cuda:0')}, {'boxes': tensor([[162.8000, 187.0222, 377.2000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2171], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 460.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2099], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([985], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.6000, 260.9778, 348.0000, 357.6889],\n",
      "        [233.6000, 268.8000, 275.2000, 364.8000],\n",
      "        [132.4000, 320.7111, 176.4000, 422.4000],\n",
      "        [138.0000, 211.2000, 181.6000, 305.7778],\n",
      "        [298.4000, 148.6222, 340.8000, 241.7778],\n",
      "        [271.2000,  54.0444, 316.4000, 148.6222],\n",
      "        [207.2000,  73.2444, 252.0000, 169.9556],\n",
      "        [152.0000, 109.5111, 194.4000, 201.2444],\n",
      "        [230.4000, 174.9333, 273.6000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([110], device='cuda:0')}, {'boxes': tensor([[ 51.5220,  27.0222, 396.0755, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1029], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.5333, 240.3556, 215.4667, 261.6889],\n",
      "        [296.5333, 231.8222, 410.6667, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2110], device='cuda:0')}, {'boxes': tensor([[156.8000,  79.6444, 393.6000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1821], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[285.7465,   0.0000, 510.1972, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1484], device='cuda:0')}, {'boxes': tensor([[281.6000, 196.2667, 359.4667, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 210.4889, 164.2667, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1363], device='cuda:0')}, {'boxes': tensor([[221.8667,  83.9111, 332.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1934], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[215.4667, 129.4222, 321.0667, 186.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1591], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 214.7556, 299.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.8000, 160.7111, 300.0000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([542], device='cuda:0')}, {'boxes': tensor([[121.6000, 183.4667, 192.0000, 247.4667],\n",
      "        [198.4000, 176.3556, 275.2000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([363], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.9333, 153.6000, 510.9333, 334.2222],\n",
      "        [105.6000,  61.1556, 435.2000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([48], device='cuda:0')}, {'boxes': tensor([[111.6596, 130.8445, 253.2766, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1091], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.4000, 187.0222, 375.2000, 447.2889],\n",
      "        [147.2000, 310.7556, 226.8000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([867], device='cuda:0')}, {'boxes': tensor([[115.2000, 263.1111, 258.1333, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2142], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[222.4000,  12.8000, 500.0000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([287], device='cuda:0')}, {'boxes': tensor([[188.0000, 177.7778, 292.8000, 306.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1127], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 24.5333,   1.4222, 270.9333, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1069], device='cuda:0')}, {'boxes': tensor([[  0.0000,  28.4444, 509.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([801], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[311.2000,  39.1111, 408.8000, 125.8667],\n",
      "        [230.4000, 105.9556, 342.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27], device='cuda:0'), 'image_id': tensor([1347], device='cuda:0')}, {'boxes': tensor([[193.6000, 206.2222, 352.8000, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1779], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[121.5413, 201.6000, 243.6697, 326.4000],\n",
      "        [  4.6972, 317.8667, 510.2385, 505.6000],\n",
      "        [292.9908, 300.8000, 509.6514, 456.5333],\n",
      "        [140.3303, 292.2667, 186.7156, 334.9333],\n",
      "        [140.9174, 277.3333, 191.4128, 320.0000],\n",
      "        [348.1835, 277.3333, 409.2477, 307.2000],\n",
      "        [323.5229, 278.4000, 357.5780, 313.6000],\n",
      "        [298.8624, 276.2667, 335.8532, 318.9333],\n",
      "        [274.2018, 265.6000, 325.8716, 324.2667],\n",
      "        [253.6514, 269.8667, 279.4862, 321.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([459], device='cuda:0')}, {'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [165.6000, 160.0000, 205.2000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.8000, 138.6667, 441.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([328], device='cuda:0')}, {'boxes': tensor([[208.0000,  57.6000, 508.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[206.8000, 178.4889, 259.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([855], device='cuda:0')}, {'boxes': tensor([[306.4000, 386.8445, 328.4000, 418.1333],\n",
      "        [234.0000, 228.2667, 254.8000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.8000, 223.2889, 306.4000, 328.5333],\n",
      "        [ 17.6000, 151.4667, 205.2000, 338.4889],\n",
      "        [177.2000, 222.5778, 275.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([517], device='cuda:0')}, {'boxes': tensor([[155.2000, 368.3556, 243.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2013], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.1867e+01, 4.3400e+02, 4.4302e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([275], device='cuda:0')}, {'boxes': tensor([[136.0000,  58.3111, 371.6000, 434.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1859], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 113.7778, 364.8000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2143], device='cuda:0')}, {'boxes': tensor([[324.6972, 179.2000, 480.2936, 306.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([470], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.2000, 142.2222, 364.0000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1932], device='cuda:0')}, {'boxes': tensor([[265.9155,   0.0000, 511.0986, 288.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1489], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.7333,   0.0000, 509.8667, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([684], device='cuda:0')}, {'boxes': tensor([[ 38.4000, 182.7556, 264.4000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1561], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.0000, 136.5333, 297.6000, 339.9111],\n",
      "        [243.2000,  45.5111, 403.2000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1229], device='cuda:0')}, {'boxes': tensor([[251.7333,   0.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1729], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.8000,   8.5333, 292.8000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1046], device='cuda:0')}, {'boxes': tensor([[171.2000, 186.1818, 315.2000, 290.9091]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1416], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 189.1555,  45.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1905], device='cuda:0')}, {'boxes': tensor([[115.2000,  45.5111, 267.2000, 226.1333],\n",
      "        [232.0000,  28.4444, 365.6000, 219.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1751], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.0000, 113.7778, 380.4000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([879], device='cuda:0')}, {'boxes': tensor([[183.2000, 136.5333, 288.0000, 332.8000],\n",
      "        [240.0000,  44.0889, 390.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1228], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000,   9.9556, 252.8000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1839], device='cuda:0')}, {'boxes': tensor([[224.0000, 108.0889, 510.4000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000,  64.0000, 470.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([218], device='cuda:0')}, {'boxes': tensor([[292.8000,  68.2667, 511.2000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1980], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[327.0459, 218.6667, 423.3394, 330.6667],\n",
      "        [178.4954, 291.2000, 243.6697, 339.2000],\n",
      "        [258.9358, 284.8000, 298.2752, 337.0667],\n",
      "        [294.1651, 281.6000, 332.9174, 329.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([469], device='cuda:0')}, {'boxes': tensor([[112.8000, 133.6889, 258.0000, 324.2667],\n",
      "        [218.0000, 146.4889, 394.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([567], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 91.2000, 136.5333, 308.0000, 388.2667],\n",
      "        [160.0000, 182.0444, 428.8000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([60], device='cuda:0')}, {'boxes': tensor([[368.0000, 281.6000, 509.8667, 395.3778],\n",
      "        [  0.0000, 250.3111, 226.1333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.5333, 221.8667, 338.1333, 278.7556],\n",
      "        [  0.0000, 149.3333,  58.6667, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([256], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.0000,  45.5111, 304.8000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2045], device='cuda:0')}, {'boxes': tensor([[263.2000, 112.3556, 402.4000, 302.9333],\n",
      "        [ 76.0000,  98.1333, 233.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1754], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000, 190.5778, 219.2000, 367.6444],\n",
      "        [277.2000, 172.8000, 425.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1113], device='cuda:0')}, {'boxes': tensor([[186.8000, 161.4222, 301.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[277.2000, 184.1778, 378.0000, 374.0444],\n",
      "        [263.2000, 201.9556, 420.8000, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([418], device='cuda:0')}, {'boxes': tensor([[206.0000,  75.3778, 340.4000, 393.9556],\n",
      "        [307.6000, 151.4667, 365.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1539], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 230.4000, 279.4667, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2094], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 230.4000, 206.2222],\n",
      "        [403.2000, 320.0000, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1625], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 164.2667, 509.6000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([572], device='cuda:0')}, {'boxes': tensor([[379.6000, 195.5556, 492.8000, 425.9556],\n",
      "        [226.8000, 165.6889, 320.4000, 293.6889],\n",
      "        [  8.4000, 193.4222,  45.2000, 214.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([890], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0183, 186.6667, 293.5780, 322.1333],\n",
      "        [  0.0000, 314.6667, 510.2385, 503.4667],\n",
      "        [289.4679, 293.3333, 509.6514, 449.0667],\n",
      "        [132.6973, 289.0667, 177.9083, 331.7333],\n",
      "        [133.8716, 273.0667, 185.5413, 325.3333],\n",
      "        [341.1376, 270.9333, 402.2018, 299.7333],\n",
      "        [316.4771, 269.8667, 350.5321, 305.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([458], device='cuda:0')}, {'boxes': tensor([[188.8000, 122.3111, 266.4000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1130], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 247.4667, 158.4000, 492.0889],\n",
      "        [355.2000, 233.2444, 409.6000, 465.0667],\n",
      "        [304.8000, 217.6000, 328.0000, 308.6222],\n",
      "        [467.2000, 260.2667, 510.4000, 398.2222],\n",
      "        [173.6000, 227.5556, 205.6000, 341.3333],\n",
      "        [199.2000, 237.5111, 268.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([776], device='cuda:0')}, {'boxes': tensor([[252.8000, 139.3778, 282.0000, 180.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2055], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000, 187.0222, 290.8000, 371.2000],\n",
      "        [295.6000, 105.9556, 336.0000, 170.6667],\n",
      "        [388.8000, 107.3778, 425.6000, 160.0000],\n",
      "        [228.4000, 106.6667, 264.0000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15, 15, 15], device='cuda:0'), 'image_id': tensor([1951], device='cuda:0')}, {'boxes': tensor([[196.0000,  66.8444, 317.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([878], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.1333, 237.5111, 387.2000, 311.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1706], device='cuda:0')}, {'boxes': tensor([[ 64.4000,  59.0222, 277.2000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([841], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 236.0889, 275.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1732], device='cuda:0')}, {'boxes': tensor([[264.4000, 273.7778, 470.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([576], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.0000, 174.2222, 472.0000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1288], device='cuda:0')}, {'boxes': tensor([[  3.2000,  38.4000, 280.0000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1045], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.0000,  96.0000, 326.8000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([84], device='cuda:0')}, {'boxes': tensor([[  0.0000, 143.6444, 150.4000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1373], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.8000,   0.0000, 284.8000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([414], device='cuda:0')}, {'boxes': tensor([[172.8000,  59.7333, 328.0000, 396.8000],\n",
      "        [248.0000, 150.7556, 358.4000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1237], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.2000, 295.8222, 429.2000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([655], device='cuda:0')}, {'boxes': tensor([[191.2000,  79.6444, 300.0000, 341.3333],\n",
      "        [108.8000,   0.0000, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([979], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.4000, 160.7111, 281.6000, 241.7778],\n",
      "        [281.6000, 162.1333, 356.2667, 238.9333],\n",
      "        [254.9333,  59.7333, 276.2667,  76.8000],\n",
      "        [307.2000,  72.5333, 328.5333,  93.8667],\n",
      "        [424.5333,  75.3778, 446.9333,  93.8667],\n",
      "        [126.9333,  73.9556, 148.2667,  95.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([358], device='cuda:0')}, {'boxes': tensor([[  0.0000, 199.1111, 145.0667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1733], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 120.1778, 258.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([222], device='cuda:0')}, {'boxes': tensor([[  0.0000, 386.8445, 171.2000, 510.5778],\n",
      "        [371.2000, 317.1555, 394.4000, 509.1555],\n",
      "        [484.8000, 371.2000, 511.2000, 510.5778],\n",
      "        [189.6000, 402.4889, 318.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([783], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[184.5333, 116.6222, 510.9333, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1710], device='cuda:0')}, {'boxes': tensor([[ 66.0000,  59.0222, 288.4000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([849], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.4000, 386.8445, 253.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2017], device='cuda:0')}, {'boxes': tensor([[  2.1333, 273.0667, 365.8667, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2138], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 72.0000,   0.0000, 314.4000, 426.6667],\n",
      "        [292.8000, 251.7333, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1628], device='cuda:0')}, {'boxes': tensor([[218.6667, 227.5556, 370.1333, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2105], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[218.8000, 117.3333, 300.0000, 210.4889],\n",
      "        [202.4000, 122.3111, 270.8000, 182.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([873], device='cuda:0')}, {'boxes': tensor([[152.0000, 138.1818, 345.6000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1419], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.8661,  83.9111, 472.0882, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2098], device='cuda:0')}, {'boxes': tensor([[145.0667, 202.6667, 169.6000, 283.0222],\n",
      "        [192.0000, 219.0222, 254.9333, 287.2889],\n",
      "        [263.4667, 224.7111, 312.5333, 291.5555],\n",
      "        [365.3333, 231.1111, 390.9333, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([58], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000,  75.3778, 376.0000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1456], device='cuda:0')}, {'boxes': tensor([[194.4000,  83.2000, 226.8000, 125.8667],\n",
      "        [185.6000, 158.5778, 217.6000, 200.5333],\n",
      "        [179.6000, 243.9111, 213.6000, 287.2889],\n",
      "        [180.0000, 329.2444, 212.0000, 371.2000],\n",
      "        [178.4000, 400.3556, 210.4000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.6000, 182.7556, 445.2000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([156], device='cuda:0')}, {'boxes': tensor([[187.6000, 177.7778, 351.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([494], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000,  85.3333, 509.6000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([393], device='cuda:0')}, {'boxes': tensor([[ 58.4000,   0.0000, 412.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([66], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[138.8000,  46.2222, 306.8000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2046], device='cuda:0')}, {'boxes': tensor([[158.8000, 280.1778, 230.0000, 386.8445],\n",
      "        [  0.4000, 204.8000, 176.4000, 385.4222],\n",
      "        [147.2000, 284.4445, 240.4000, 393.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([512], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.0000,  62.5778, 371.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1862], device='cuda:0')}, {'boxes': tensor([[250.0000, 132.2667, 386.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([375], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 177.7778, 314.0000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1964], device='cuda:0')}, {'boxes': tensor([[206.0000, 247.4667, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1220], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.0000, 258.8445, 429.2000, 507.7333],\n",
      "        [141.6000, 140.0889, 225.2000, 377.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1789], device='cuda:0')}, {'boxes': tensor([[202.4000, 177.7778, 332.4000, 448.7111],\n",
      "        [ 87.6000,  14.9333, 142.4000,  91.0222],\n",
      "        [ 34.4000,  76.8000,  80.0000, 174.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([648], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 125.1556,  91.2000, 320.0000],\n",
      "        [ 76.8000,  96.7111, 225.6000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1761], device='cuda:0')}, {'boxes': tensor([[220.8000, 164.2667, 342.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1448], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 111.6444, 297.2000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([726], device='cuda:0')}, {'boxes': tensor([[  0.0000, 175.6444, 106.4000, 369.7778],\n",
      "        [120.0000, 172.0889, 258.0000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1098], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000, 104.5333, 270.0000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1460], device='cuda:0')}, {'boxes': tensor([[ 24.8000,  11.3778, 508.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  45.5111, 250.6667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1074], device='cuda:0')}, {'boxes': tensor([[170.4000,  68.2667, 436.4000, 347.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([73], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[317.8667, 210.4889, 385.0667, 338.4889],\n",
      "        [284.8000, 179.2000, 370.1333, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25, 25], device='cuda:0'), 'image_id': tensor([262], device='cuda:0')}, {'boxes': tensor([[ 75.7333,  56.8889, 411.7333, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1698], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.2000,   0.7111, 479.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([273], device='cuda:0')}, {'boxes': tensor([[136.0000, 188.4444, 361.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2160], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[302.0000, 172.8000, 354.4000, 260.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1446], device='cuda:0')}, {'boxes': tensor([[214.0000, 125.1556, 250.0000, 210.4889],\n",
      "        [230.4000, 150.0444, 294.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([885], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.9852, 228.9778, 283.4963, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([753], device='cuda:0')}, {'boxes': tensor([[194.4000, 379.0222, 357.2000, 509.8667],\n",
      "        [ 64.4000, 375.4667, 362.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([554], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.4000,  54.0444, 320.0000, 420.9778],\n",
      "        [  0.0000,  28.4444,  49.6000, 147.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1769], device='cuda:0')}, {'boxes': tensor([[193.2000,   0.0000, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([387], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 199.1111, 381.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2168], device='cuda:0')}, {'boxes': tensor([[ 38.8000, 332.0889,  85.6000, 509.1555],\n",
      "        [108.8000, 161.4222, 147.2000, 360.5333],\n",
      "        [234.4000, 128.7111, 264.0000, 338.4889],\n",
      "        [422.4000, 153.6000, 454.4000, 224.7111],\n",
      "        [202.4000, 137.2444, 233.6000, 216.8889],\n",
      "        [220.4000, 182.7556, 240.8000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([1667], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 156.4444, 272.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1129], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  68.9778, 453.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1119], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.2000, 200.5333, 433.2000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1912], device='cuda:0')}, {'boxes': tensor([[411.0092, 254.9333, 510.8257, 343.4667],\n",
      "        [404.5504, 313.6000, 510.8257, 423.4667],\n",
      "        [ 62.2385, 277.3333, 200.2202, 469.3333],\n",
      "        [437.4312, 337.0667, 510.2385, 480.0000],\n",
      "        [420.4037, 326.4000, 509.6514, 453.3333],\n",
      "        [ 43.4495, 342.4000, 137.9817, 365.8667],\n",
      "        [ 42.8624, 362.6667, 140.3303, 390.4000],\n",
      "        [ 24.6606, 388.2667, 154.4220, 429.8667],\n",
      "        [  7.0459, 425.6000, 158.5321, 507.7333],\n",
      "        [193.7615, 125.8667, 374.0183, 466.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([460], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.1333, 253.1555, 177.0667, 379.7333],\n",
      "        [388.2667, 230.4000, 435.2000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([697], device='cuda:0')}, {'boxes': tensor([[ 22.4000,  70.4000, 259.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1432], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[159.2000, 201.9556, 347.6000, 478.5778],\n",
      "        [ 60.8000, 204.8000, 361.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([550], device='cuda:0')}, {'boxes': tensor([[ 64.5872, 121.6000, 376.3670, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([427], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.4000, 111.6444, 510.8000, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1001], device='cuda:0')}, {'boxes': tensor([[165.6000, 201.9556, 383.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1595], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.2000, 314.3111, 328.0000, 342.0444],\n",
      "        [308.8000, 272.3556, 330.4000, 305.0667],\n",
      "        [310.4000, 236.8000, 331.6000, 265.2444],\n",
      "        [311.2000, 200.5333, 332.4000, 230.4000],\n",
      "        [309.6000, 167.8222, 330.8000, 199.1111],\n",
      "        [282.0000, 158.5778, 303.2000, 190.5778],\n",
      "        [256.0000, 157.1555, 276.4000, 187.7333],\n",
      "        [232.8000, 145.0667, 254.0000, 176.3556],\n",
      "        [204.8000, 138.6667, 225.6000, 170.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([119], device='cuda:0')}, {'boxes': tensor([[194.8000, 109.5111, 432.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([540], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[126.4000, 259.1476, 306.4000, 382.9508]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([973], device='cuda:0')}, {'boxes': tensor([[118.4000,  12.8000, 428.8000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([665], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 236.8000,  48.7339, 352.0000],\n",
      "        [430.3853, 235.7333, 472.0734, 284.8000],\n",
      "        [472.0734, 213.3333, 510.2385, 268.8000],\n",
      "        [297.6881, 176.0000, 437.4312, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([480], device='cuda:0')}, {'boxes': tensor([[143.6000, 190.5778, 368.4000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[121.6000,  85.3333, 293.6000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1853], device='cuda:0')}, {'boxes': tensor([[168.4000, 177.7778, 333.2000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([925], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 42.6667,  51.2000, 282.6667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1501], device='cuda:0')}, {'boxes': tensor([[140.0000,   7.1111, 236.0000, 182.0444],\n",
      "        [225.6000,  17.0667, 311.2000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.2000, 206.9333, 287.2000, 229.6889],\n",
      "        [262.8000, 238.9333, 283.6000, 263.8222],\n",
      "        [259.2000, 270.2222, 281.6000, 292.9778],\n",
      "        [257.2000, 302.9333, 278.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([153], device='cuda:0')}, {'boxes': tensor([[275.6000,  32.7111, 375.2000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([807], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.4000, 284.4445, 429.6000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([579], device='cuda:0')}, {'boxes': tensor([[ 63.2000, 227.5556, 176.0000, 507.7333],\n",
      "        [286.4000, 194.8445, 343.2000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([777], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.8000,   0.0000, 266.4000, 159.2889],\n",
      "        [253.6000,   0.0000, 396.8000, 159.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1748], device='cuda:0')}, {'boxes': tensor([[194.8000, 176.3556, 301.2000, 270.2222],\n",
      "        [ 42.4000, 203.3778, 179.2000, 312.1778],\n",
      "        [189.6000, 243.2000, 316.8000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1576], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 216.8889, 264.4000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2059], device='cuda:0')}, {'boxes': tensor([[ 68.0000, 170.6667, 295.6000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([865], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 33.6000,   9.2444, 510.0000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1116], device='cuda:0')}, {'boxes': tensor([[139.7333, 275.9111, 315.7333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2124], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 163.0815, 237.8667, 297.7185]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1144], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 130.1333, 340.8000, 388.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1299], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 133.6889, 461.2000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([341], device='cuda:0')}, {'boxes': tensor([[103.6000, 117.3333, 511.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([731], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[494.8732, 148.8000, 510.1972, 334.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1486], device='cuda:0')}, {'boxes': tensor([[240.4000, 147.2000, 377.2000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([89], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[376.9541, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 263.4667,  69.8716, 412.8000],\n",
      "        [238.3853, 200.5333, 381.6514, 485.3333],\n",
      "        [258.3486, 306.1333, 413.9449, 507.7333],\n",
      "        [111.5596, 244.2667, 216.0734, 361.6000],\n",
      "        [380.4771, 274.1333, 458.5688, 345.6000],\n",
      "        [ 46.9725, 265.6000, 140.9174, 403.2000],\n",
      "        [  0.0000, 210.1333,  78.6789, 275.2000],\n",
      "        [125.0642, 245.3333, 233.1009, 352.0000],\n",
      "        [236.0367, 125.8667, 510.2385, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([446], device='cuda:0')}, {'boxes': tensor([[200.0000, 299.6364, 371.2000, 500.3636],\n",
      "        [152.8000, 336.0000, 233.6000, 485.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1322], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.8000, 272.7869, 377.6000, 375.6066]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([977], device='cuda:0')}, {'boxes': tensor([[ 71.2000,  96.5246, 240.8000, 500.4590]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([960], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.8000,  14.2222, 324.0000, 496.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([264], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([226], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[266.4000, 237.5111, 362.8000, 316.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([129], device='cuda:0')}, {'boxes': tensor([[ 23.6000,  11.3778, 508.8000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1582], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 110.9333, 422.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([208], device='cuda:0')}, {'boxes': tensor([[217.6000, 170.6667, 288.0000, 325.6889],\n",
      "        [224.0000,  68.2667, 361.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1227], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  88.1778, 243.2000, 253.1555],\n",
      "        [243.2000,  69.6889, 366.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1740], device='cuda:0')}, {'boxes': tensor([[262.0000, 136.5333, 338.8000, 184.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1381], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[326.4000, 264.5333, 406.4000, 285.8667],\n",
      "        [151.4667, 268.8000, 230.4000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2116], device='cuda:0')}, {'boxes': tensor([[232.4000, 164.2667, 335.6000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([216], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.8963, 120.8889, 511.0518, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([169], device='cuda:0')}, {'boxes': tensor([[240.7339, 172.8000, 496.1468, 314.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([472], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000, 172.8000, 339.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2175], device='cuda:0')}, {'boxes': tensor([[ 62.4000,   0.7111, 448.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 233.2444, 510.9333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([242], device='cuda:0')}, {'boxes': tensor([[243.2000,  60.4444, 346.8000, 384.0000],\n",
      "        [319.2000, 143.6444, 362.4000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1537], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[101.4519, 106.6667, 508.2074, 399.6444],\n",
      "        [181.0963, 322.8445, 275.9111, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([177], device='cuda:0')}, {'boxes': tensor([[ 62.5778,  21.3333, 485.4518, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1826], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.5872, 341.3333, 249.5413, 503.4667],\n",
      "        [128.5872,  23.4667, 386.3486, 487.4667],\n",
      "        [390.4587, 217.6000, 506.1284, 281.6000],\n",
      "        [423.9266, 288.0000, 504.3670, 471.4667],\n",
      "        [382.2385, 270.9333, 479.1193, 457.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([467], device='cuda:0')}, {'boxes': tensor([[  3.2000,  12.8000, 311.6000, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([294], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.2000, 140.0889, 288.4000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1909], device='cuda:0')}, {'boxes': tensor([[308.8000,  51.2000, 438.4000, 261.6889],\n",
      "        [128.0000,  71.1111, 272.0000, 261.6889],\n",
      "        [ 64.0000, 113.7778, 223.2000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1757], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 367.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1386], device='cuda:0')}, {'boxes': tensor([[ 65.6000, 200.5333, 369.6000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1269], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.8000, 100.9778, 253.6000, 475.0222],\n",
      "        [268.8000, 139.3778, 412.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1428], device='cuda:0')}, {'boxes': tensor([[149.2000, 247.4667, 320.4000, 477.8667],\n",
      "        [ 40.4000, 221.1555, 352.8000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([557], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000, 214.7556, 396.8000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([70], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 511.2000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([796], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.6000,  70.4000, 233.2000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1907], device='cuda:0')}, {'boxes': tensor([[  0.0000, 102.4000, 255.2000, 289.4222],\n",
      "        [239.6000, 211.9111, 398.8000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1406], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.2667, 253.1555, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([247], device='cuda:0')}, {'boxes': tensor([[386.0000, 154.3111, 510.8000, 233.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([534], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 344.5333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1257], device='cuda:0')}, {'boxes': tensor([[ 53.3333,   0.0000, 509.8667, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1493], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[264.8000, 272.7869, 388.0000, 375.6066]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([978], device='cuda:0')}, {'boxes': tensor([[236.8000, 213.3333, 302.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1337], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 122.3111, 250.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1006], device='cuda:0')}, {'boxes': tensor([[211.2000, 125.1556, 309.3333, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1590], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 59.7333, 317.1555, 194.1333, 438.0444],\n",
      "        [372.2667, 298.6667, 432.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([703], device='cuda:0')}, {'boxes': tensor([[ 67.2000,   0.0000, 313.6000, 457.9556],\n",
      "        [394.6667,  73.9556, 509.8667, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([609], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000,   0.0000, 164.0000,  66.8444],\n",
      "        [193.6000, 107.3778, 370.4000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([390], device='cuda:0')}, {'boxes': tensor([[  0.0000, 108.0889, 320.0000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1949], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 23.2000,  74.6667, 453.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1115], device='cuda:0')}, {'boxes': tensor([[ 50.4000,  76.0889, 452.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1114], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 160.0000, 276.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([887], device='cuda:0')}, {'boxes': tensor([[136.4000, 169.2444, 265.2000, 377.6000],\n",
      "        [262.4000, 127.2889, 412.4000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([561], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000, 146.4889,  69.3333, 223.2889],\n",
      "        [339.2000, 173.5111, 482.1333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([679], device='cuda:0')}, {'boxes': tensor([[ 37.2000,  90.3111, 237.6000, 482.8445],\n",
      "        [222.8000, 142.2222, 324.8000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([914], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 61.6000, 236.8000, 263.2000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([864], device='cuda:0')}, {'boxes': tensor([[149.7248, 129.0667, 419.2294, 437.3333],\n",
      "        [408.6606,  89.6000, 438.0183, 192.0000],\n",
      "        [ 35.2294, 106.6667,  94.5321, 172.8000],\n",
      "        [ 85.7248, 118.4000, 156.1835, 173.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([435], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[100.0000,   0.0000, 352.8000, 384.0000],\n",
      "        [292.8000, 256.0000, 506.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1629], device='cuda:0')}, {'boxes': tensor([[132.8000, 196.9778, 382.0000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1606], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 157.1555, 400.4000, 297.2444],\n",
      "        [ 95.6000, 142.2222, 289.2000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([903], device='cuda:0')}, {'boxes': tensor([[234.8000, 202.6667, 250.0000, 225.4222],\n",
      "        [280.8000, 224.0000, 305.6000, 256.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([845], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 206.9333, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2074], device='cuda:0')}, {'boxes': tensor([[259.2000, 200.5333, 406.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([30], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.6000, 239.6444, 308.4000, 305.7778],\n",
      "        [373.2000, 337.0667, 400.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([882], device='cuda:0')}, {'boxes': tensor([[119.2000, 291.6721, 137.6000, 312.6557],\n",
      "        [272.0000, 286.4262, 291.2000, 310.5574],\n",
      "        [185.6000, 210.8852, 250.4000, 375.6066],\n",
      "        [365.6000, 313.7049, 503.2000, 443.8033],\n",
      "        [337.6000, 329.4426, 410.4000, 422.8197]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([965], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.5333, 224.7111, 384.0000, 253.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2104], device='cuda:0')}, {'boxes': tensor([[121.6000, 179.2000, 371.2000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1302], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[280.8000, 216.1778, 353.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([116], device='cuda:0')}, {'boxes': tensor([[188.4000, 202.6667, 250.4000, 335.6444],\n",
      "        [116.4000, 150.0444, 185.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([1244], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  82.4889, 288.0000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1776], device='cuda:0')}, {'boxes': tensor([[227.2000, 122.3111, 341.3333, 133.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2107], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.2000, 140.8000, 462.4000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([338], device='cuda:0')}, {'boxes': tensor([[  0.0000,  89.6000, 277.3333, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1410], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  39.1111, 345.6000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([826], device='cuda:0')}, {'boxes': tensor([[247.2000, 257.4222, 387.2000, 411.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([1048], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.0000, 258.8445, 510.9333, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([252], device='cuda:0')}, {'boxes': tensor([[ 69.6000, 145.0667, 284.4000, 365.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1560], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 177.7778, 215.4667, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1367], device='cuda:0')}, {'boxes': tensor([[ 45.8667, 273.0667, 510.9333, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([249], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[183.1927, 102.4000, 452.6972, 408.5333],\n",
      "        [ 54.6055, 242.1333, 186.7156, 406.4000],\n",
      "        [123.3027,  99.2000, 190.2385, 154.6667],\n",
      "        [438.0183,  80.0000, 476.1835, 172.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([433], device='cuda:0')}, {'boxes': tensor([[192.4000, 140.0889, 362.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([82], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,   5.6889, 509.6000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([310], device='cuda:0')}, {'boxes': tensor([[145.6000,  32.7111, 333.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([391], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,  44.0889, 322.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1547], device='cuda:0')}, {'boxes': tensor([[246.4000, 206.9333, 387.2000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([647], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[286.9333, 102.4000, 371.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1586], device='cuda:0')}, {'boxes': tensor([[ 81.6000, 189.1555, 239.6000, 372.6222],\n",
      "        [276.4000, 171.3778, 424.4000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1092], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000, 156.4444, 314.4000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1993], device='cuda:0')}, {'boxes': tensor([[122.3111, 130.8445, 509.1555, 420.9778],\n",
      "        [206.6963, 348.4445, 298.6667, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 242.4889, 314.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1157], device='cuda:0')}, {'boxes': tensor([[ 75.2000, 120.8889, 302.0000, 349.8667],\n",
      "        [311.2000, 223.2889, 409.6000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1554], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.3333, 315.7333, 188.8000, 393.9556],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([692], device='cuda:0')}, {'boxes': tensor([[  0.0000, 265.9556,  27.2000, 484.9778],\n",
      "        [253.6000, 288.7111, 276.0000, 372.6222],\n",
      "        [287.2000, 284.4445, 328.0000, 399.6444],\n",
      "        [129.6000, 207.6444, 198.4000, 489.2444],\n",
      "        [204.8000, 295.8222, 221.6000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([774], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 280.1778, 149.2000, 415.2889],\n",
      "        [122.4000, 137.9556, 146.8000, 177.7778],\n",
      "        [325.6000, 185.6000, 377.6000, 278.7556],\n",
      "        [ 76.4000, 128.7111, 112.8000, 167.8222],\n",
      "        [286.4000, 135.1111, 310.0000, 216.8889],\n",
      "        [174.4000, 210.4889, 257.2000, 292.9778],\n",
      "        [332.0000, 167.8222, 415.2000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2027], device='cuda:0')}, {'boxes': tensor([[ 63.2000, 169.2444, 334.8000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([870], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.5360e+02, 3.1360e+02, 4.9280e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([298], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2152], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.0000,  44.0889, 450.8000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([821], device='cuda:0')}, {'boxes': tensor([[186.8000,  64.0000, 281.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1901], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[211.2000,  91.7333, 278.0000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([263], device='cuda:0')}, {'boxes': tensor([[155.2000, 149.3333, 277.6000, 285.8667],\n",
      "        [  1.6000, 142.2222,  44.0000, 246.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1382], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.8000, 135.1111, 354.8000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([405], device='cuda:0')}, {'boxes': tensor([[151.6000, 164.9778, 278.4000, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1461], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.0000,  96.7111, 368.0000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1984], device='cuda:0')}, {'boxes': tensor([[ 45.2000,  53.3333, 338.4000, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.5929e+02, 3.2760e+02, 4.9849e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([304], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 376.0000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1624], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[354.1333,  17.0667, 510.9333, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1725], device='cuda:0')}, {'boxes': tensor([[144.0000, 290.1333, 172.8000, 409.6000],\n",
      "        [226.4000, 284.4445, 261.6000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([767], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([320], device='cuda:0')}, {'boxes': tensor([[326.8000, 196.9778, 482.4000, 424.5333],\n",
      "        [130.8000, 104.5333, 310.4000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.4000, 142.9333, 329.6000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([2], device='cuda:0')}, {'boxes': tensor([[103.6000, 132.2667, 220.4000, 317.1555],\n",
      "        [195.2000,  76.8000, 370.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([566], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[362.0000, 214.0444, 510.8000, 330.6667],\n",
      "        [249.2000, 305.0667, 510.4000, 491.3778],\n",
      "        [ 64.4000, 234.6667, 189.6000, 340.6222],\n",
      "        [  0.0000, 213.3333,  33.2000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1468], device='cuda:0')}, {'boxes': tensor([[  0.0000, 191.2889,  78.8000, 295.8222],\n",
      "        [126.8000, 199.8222, 140.4000, 217.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2077], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000, 200.5333, 334.0000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1933], device='cuda:0')}, {'boxes': tensor([[114.0000,  46.2222, 474.0000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([352], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[289.2000,  46.2222, 376.8000, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([806], device='cuda:0')}, {'boxes': tensor([[167.3394, 324.2667, 329.9817, 494.9333],\n",
      "        [222.5321, 259.2000, 344.0734, 449.0667],\n",
      "        [265.9817, 179.2000, 363.4496, 337.0667],\n",
      "        [428.0367, 273.0667, 452.6972, 331.7333],\n",
      "        [140.9174, 236.8000, 244.2569, 315.7333],\n",
      "        [110.3853, 264.5333, 217.2477, 327.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([466], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.7248, 129.0667, 412.7706, 437.3333],\n",
      "        [411.0092,  91.7333, 439.7798, 195.2000],\n",
      "        [ 38.7523, 109.8667,  97.4679, 176.0000],\n",
      "        [ 88.6606, 121.6000, 157.9450, 177.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([436], device='cuda:0')}, {'boxes': tensor([[  0.0000, 176.3556, 388.8000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1217], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 196.2667, 364.8000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1266], device='cuda:0')}, {'boxes': tensor([[184.0000, 255.2889, 330.8000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1924], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 32.0000, 203.3778, 187.6000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1653], device='cuda:0')}, {'boxes': tensor([[ 17.6000, 263.8222, 511.2000, 465.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([583], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2018e+02, 4.2080e+02, 3.1502e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([729], device='cuda:0')}, {'boxes': tensor([[106.4000, 211.9111, 243.2000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2033], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 213.3333, 411.7333, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1715], device='cuda:0')}, {'boxes': tensor([[  0.5872, 421.3333, 402.2018, 506.6667],\n",
      "        [452.1101, 370.1333, 510.2385, 491.7333],\n",
      "        [299.4496, 299.7333, 437.4312, 433.0667],\n",
      "        [344.6606, 336.0000, 493.2110, 504.5333],\n",
      "        [191.4128, 359.4667, 216.6606, 424.5333],\n",
      "        [214.3119, 356.2667, 260.6972, 432.0000],\n",
      "        [176.7339, 279.4667, 313.5413, 429.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([440], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.0667, 261.6889, 499.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([238], device='cuda:0')}, {'boxes': tensor([[144.8000,   0.0000, 356.0000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([815], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[123.2593, 109.5111, 510.1037, 378.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([168], device='cuda:0')}, {'boxes': tensor([[250.0000, 161.4222, 365.2000, 309.3333],\n",
      "        [283.6000, 156.4444, 388.0000, 273.0667],\n",
      "        [ 77.2000, 172.0889, 120.0000, 199.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16, 16], device='cuda:0'), 'image_id': tensor([889], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.4000, 110.1639, 175.2000, 401.8361]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([962], device='cuda:0')}, {'boxes': tensor([[234.6667, 219.0222, 298.6667, 264.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2126], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.4000, 201.9556, 280.0000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1124], device='cuda:0')}, {'boxes': tensor([[149.7248, 193.0667, 395.7431, 363.7333],\n",
      "        [125.0642, 228.2667, 159.7064, 266.6667],\n",
      "        [ 65.1743, 234.6667, 112.7339, 277.3333],\n",
      "        [109.7982, 277.3333, 139.7431, 321.0667],\n",
      "        [389.8716, 252.8000, 464.4404, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7,  7, 19,  7], device='cuda:0'), 'image_id': tensor([439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.9333,  41.2444, 296.5333, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1504], device='cuda:0')}, {'boxes': tensor([[166.8000, 117.3333, 219.6000, 174.2222],\n",
      "        [334.8000,  88.1778, 380.4000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1867], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[144.0000,  54.0444, 220.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2150], device='cuda:0')}, {'boxes': tensor([[  7.4667, 179.2000, 306.1333, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([196], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 312.8889, 197.3333, 433.7778],\n",
      "        [376.5333, 291.5555, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([708], device='cuda:0')}, {'boxes': tensor([[ 39.4667,  56.8889, 299.7333, 194.8445],\n",
      "        [317.8667, 176.3556, 395.7333, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([667], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.8000,  85.3333, 368.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([68], device='cuda:0')}, {'boxes': tensor([[171.2000, 221.8667, 454.4000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1037], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 43.7333, 201.9556, 253.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1043], device='cuda:0')}, {'boxes': tensor([[ 90.8000,  88.1778, 242.4000, 273.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2062], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,   2.8444, 323.2000, 457.9556],\n",
      "        [413.8667, 108.0889, 507.7333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([604], device='cuda:0')}, {'boxes': tensor([[ 78.4000,  29.8667, 341.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([61], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.8000, 126.5778, 262.8000, 325.6889],\n",
      "        [258.0000, 103.1111, 420.0000, 331.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([562], device='cuda:0')}, {'boxes': tensor([[274.0000,  78.9333, 474.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1439], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[331.2000, 206.2222, 415.2000, 373.3333],\n",
      "        [109.2000, 190.5778, 239.6000, 395.3778],\n",
      "        [238.0000, 234.6667, 265.6000, 304.3556],\n",
      "        [266.4000, 236.0889, 281.6000, 289.4222],\n",
      "        [290.8000, 241.0667, 332.0000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 6, 6, 6, 6], device='cuda:0'), 'image_id': tensor([1908], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 428.8000, 497.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1642], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.8000, 236.8000, 338.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([530], device='cuda:0')}, {'boxes': tensor([[  0.0000, 118.7556, 288.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1374], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[268.0000, 141.5111, 352.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([658], device='cuda:0')}, {'boxes': tensor([[144.8000, 115.9111, 237.2000, 419.5555],\n",
      "        [236.8000, 108.0889, 356.0000, 386.8445],\n",
      "        [223.2000, 201.9556, 274.4000, 369.0667],\n",
      "        [  0.0000, 268.8000,  24.8000, 285.1555],\n",
      "        [102.8000, 241.0667, 144.0000, 257.4222],\n",
      "        [454.8000, 335.6444, 510.4000, 364.8000],\n",
      "        [447.2000, 432.3556, 510.4000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2068], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.4000, 257.4222, 192.0000, 418.1333],\n",
      "        [277.6000, 261.6889, 318.4000, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([766], device='cuda:0')}, {'boxes': tensor([[220.8000, 224.7111, 249.6000, 356.2667],\n",
      "        [267.2000, 166.4000, 297.2000, 228.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1648], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 68.8000,   0.0000, 509.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1659], device='cuda:0')}, {'boxes': tensor([[ 51.2000,  76.8000, 422.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1031], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.1333,  22.7556, 346.6667, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1719], device='cuda:0')}, {'boxes': tensor([[211.2000, 224.7111, 353.0667, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2101], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.0000, 125.8667, 510.4000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1039], device='cuda:0')}, {'boxes': tensor([[ 33.2000,  85.3333, 238.4000, 482.8445],\n",
      "        [224.4000, 140.0889, 358.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([913], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 305.7778, 193.0667, 433.7778],\n",
      "        [379.7333, 291.5555, 446.9333, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([710], device='cuda:0')}, {'boxes': tensor([[193.2000, 108.8000, 393.2000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1352], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 97.6000, 347.0222, 197.6000, 509.1555],\n",
      "        [353.6000, 342.7556, 455.2000, 510.5778],\n",
      "        [ 15.2000, 325.6889,  92.8000, 510.5778],\n",
      "        [277.6000, 315.7333, 328.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([785], device='cuda:0')}, {'boxes': tensor([[213.3333, 119.4667, 407.4667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([205], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000, 207.6444, 280.8000, 241.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([940], device='cuda:0')}, {'boxes': tensor([[134.4000, 116.2667, 176.0000, 163.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([793], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 206.2222, 168.5333, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1362], device='cuda:0')}, {'boxes': tensor([[101.3333, 234.6667, 155.7333, 300.0889],\n",
      "        [133.3333, 194.8445, 185.6000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([682], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 140.0889, 285.6000, 290.1333],\n",
      "        [230.0000, 205.5111, 378.8000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([1407], device='cuda:0')}, {'boxes': tensor([[ 75.2000,  45.5111, 235.2000, 228.9778],\n",
      "        [216.0000,  32.7111, 369.6000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1752], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000, 176.3556, 508.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1223], device='cuda:0')}, {'boxes': tensor([[230.0000,  45.5111, 445.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([822], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.8000, 187.0222, 360.0000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2161], device='cuda:0')}, {'boxes': tensor([[104.2963, 110.9333, 509.1555, 403.9111],\n",
      "        [184.8889, 327.1111, 280.6519, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([176], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.0000, 189.8667, 162.8000, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1261], device='cuda:0')}, {'boxes': tensor([[140.8000, 284.4445, 160.0000, 388.2667],\n",
      "        [223.2000, 284.4445, 249.6000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([768], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  3.6000,  78.9333, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1210], device='cuda:0')}, {'boxes': tensor([[256.0000, 204.8000, 283.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([939], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 21.2000,  18.4889, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1580], device='cuda:0')}, {'boxes': tensor([[ 86.4000,  41.2444, 355.2000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([62], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.6000,  25.6000, 204.4000, 145.7778],\n",
      "        [258.0000, 219.7333, 406.0000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([388], device='cuda:0')}, {'boxes': tensor([[  0.0000, 158.5778, 107.2000, 510.5778],\n",
      "        [118.0000, 138.6667, 275.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([498], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 204.8000, 130.1333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2091], device='cuda:0')}, {'boxes': tensor([[155.7333, 261.6889, 295.4667, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2133], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000,   0.0000, 510.4000, 498.4889],\n",
      "        [168.4000,  23.4667, 418.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1665], device='cuda:0')}, {'boxes': tensor([[204.0000,   0.0000, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([386], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.8000, 133.6889, 336.0000, 371.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([741], device='cuda:0')}, {'boxes': tensor([[249.6000,  79.6444, 374.4000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([828], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[122.3111,  85.3333, 511.0518, 395.3778],\n",
      "        [178.2518, 310.0444, 274.0148, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([178], device='cuda:0')}, {'boxes': tensor([[172.0000,  94.5778, 282.0000, 472.1778],\n",
      "        [255.2000, 156.4444, 316.8000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1529], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 40.5333,  15.6444, 302.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1076], device='cuda:0')}, {'boxes': tensor([[130.6205,  88.8889, 475.7165, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2095], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,  21.3333, 364.8000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1030], device='cuda:0')}, {'boxes': tensor([[ 49.2000,  69.6889, 343.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([224], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.2667, 150.7556,  62.9333, 230.4000],\n",
      "        [343.4667, 182.0444, 478.9333, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([678], device='cuda:0')}, {'boxes': tensor([[  0.0000, 176.3556, 122.4000, 280.1778],\n",
      "        [172.0000, 199.1111, 185.6000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 7, 26], device='cuda:0'), 'image_id': tensor([2079], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 147.2000, 278.8000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1215], device='cuda:0')}, {'boxes': tensor([[181.2000, 136.5333, 338.4000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([922], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 80.8000,  82.4889, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1773], device='cuda:0')}, {'boxes': tensor([[146.8000, 194.1333, 510.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.8000, 295.1111, 456.8000, 489.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1916], device='cuda:0')}, {'boxes': tensor([[115.2000,  92.4444, 272.8000, 261.6889],\n",
      "        [249.6000,  76.8000, 361.6000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1742], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.2000,  91.0222, 322.0000, 369.0667],\n",
      "        [403.6000, 283.7333, 415.2000, 315.7333],\n",
      "        [428.4000, 281.6000, 437.6000, 318.5778],\n",
      "        [498.8000, 269.5111, 511.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1007], device='cuda:0')}, {'boxes': tensor([[120.8000,   0.0000, 302.0000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([814], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.0000,   0.0000, 252.8000, 241.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1177], device='cuda:0')}, {'boxes': tensor([[211.2000, 263.1111, 301.6000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1002], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 177.7778, 385.8963, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([755], device='cuda:0')}, {'boxes': tensor([[116.4000, 205.5111, 329.6000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1155], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000, 167.8222, 456.5333, 479.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([230], device='cuda:0')}, {'boxes': tensor([[ 74.4000,   0.0000, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000, 376.8889, 249.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2015], device='cuda:0')}, {'boxes': tensor([[265.6000, 179.2000, 350.4000, 265.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([852], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 123.2000,  98.1333],\n",
      "        [333.6000, 341.3333, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1623], device='cuda:0')}, {'boxes': tensor([[ 95.2000, 104.5333, 294.8000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([266], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1513], device='cuda:0')}, {'boxes': tensor([[ 14.4000, 411.2787,  35.2000, 436.4590],\n",
      "        [233.6000, 231.8689, 248.8000, 254.9508],\n",
      "        [ 52.8000, 371.4099,  74.4000, 418.6230],\n",
      "        [ 92.8000, 393.4426, 122.4000, 437.5082],\n",
      "        [404.8000, 193.0492, 431.2000, 229.7705]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([974], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.0667, 250.3111, 510.9333, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([248], device='cuda:0')}, {'boxes': tensor([[267.2000, 179.2000, 292.0000, 211.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2054], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([283], device='cuda:0')}, {'boxes': tensor([[  0.0000,  71.1111, 278.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6741,  91.0222, 448.4741, 378.3111],\n",
      "        [178.2518, 307.2000, 270.2222, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([184], device='cuda:0')}, {'boxes': tensor([[ 60.8000,  32.7111, 302.9333, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1505], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[376.8000, 256.0000, 450.8000, 470.0444],\n",
      "        [218.8000, 155.0222, 343.2000, 323.5555],\n",
      "        [ 58.0000, 172.8000, 123.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 27,  5], device='cuda:0'), 'image_id': tensor([1346], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 187.7333, 227.2000, 366.2222],\n",
      "        [280.0000, 179.2000, 425.6000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1096], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.8000, 224.0000, 510.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1040], device='cuda:0')}, {'boxes': tensor([[114.4000, 241.3115, 380.0000, 391.3443]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([968], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[207.6000,  52.6222, 352.0000, 364.0889],\n",
      "        [233.2000, 270.9333, 243.2000, 302.2222],\n",
      "        [411.2000, 252.4444, 444.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1013], device='cuda:0')}, {'boxes': tensor([[190.0000,  27.0222, 322.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1052], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[245.6000, 160.7111, 326.0000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1], device='cuda:0')}, {'boxes': tensor([[171.2000, 260.2667, 201.6000, 392.5333],\n",
      "        [256.0000, 260.2667, 283.2000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([764], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.9333, 247.4667, 219.7333, 268.8000],\n",
      "        [309.3333, 238.9333, 424.5333, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2111], device='cuda:0')}, {'boxes': tensor([[111.2000, 299.7333, 184.0000, 382.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([794], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[263.6000, 100.2667, 398.0000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1458], device='cuda:0')}, {'boxes': tensor([[ 38.4000, 164.9778, 163.2000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([199], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([761], device='cuda:0')}, {'boxes': tensor([[  0.0000,  60.4444, 210.8000, 502.7556],\n",
      "        [168.4000, 194.1333, 390.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([909], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.4667, 157.8667, 221.8667, 219.0222],\n",
      "        [214.4000, 169.2444, 296.5333, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([362], device='cuda:0')}, {'boxes': tensor([[ 90.8000, 125.8667, 300.0000, 437.3333],\n",
      "        [280.8000, 201.9556, 324.8000, 255.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([906], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.2667, 187.7333, 410.6667, 284.4445],\n",
      "        [258.1333, 186.3111, 363.7333, 280.1778],\n",
      "        [125.8667, 162.1333, 179.2000, 227.5556],\n",
      "        [396.8000, 223.2889, 490.6667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([356], device='cuda:0')}, {'boxes': tensor([[238.9333, 129.4222, 509.8667, 365.5111],\n",
      "        [  4.2667,   0.0000, 472.5333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([51], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.8000,   5.6889, 338.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([132], device='cuda:0')}, {'boxes': tensor([[ 58.7156,  76.8000, 466.2018, 407.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([476], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.8000, 154.3111, 454.0000, 271.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([372], device='cuda:0')}, {'boxes': tensor([[  0.4000, 135.1111, 359.6000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([728], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.7333, 176.3556, 326.1630, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([760], device='cuda:0')}, {'boxes': tensor([[ 98.0000,  44.0889, 366.8000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([818], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.0000, 261.6889, 280.0000, 459.3778],\n",
      "        [333.6000, 260.2667, 400.0000, 509.1555],\n",
      "        [156.8000, 253.1555, 194.4000, 413.8667],\n",
      "        [287.2000, 248.8889, 315.2000, 369.7778],\n",
      "        [ 15.2000, 311.4667, 128.8000, 506.3111],\n",
      "        [487.2000, 332.8000, 511.2000, 506.3111],\n",
      "        [468.8000, 292.9778, 500.0000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([789], device='cuda:0')}, {'boxes': tensor([[116.8000, 284.4445, 229.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2005], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.8000,   0.7111, 376.8000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([133], device='cuda:0')}, {'boxes': tensor([[ 77.8667, 253.1555, 510.9333, 480.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([243], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 157.8667,  53.0963, 220.4444],\n",
      "        [ 45.5111, 160.7111,  82.4889, 199.1111],\n",
      "        [192.4741, 169.2444, 257.8963, 226.1333],\n",
      "        [414.3407, 160.7111, 493.0370, 223.2889],\n",
      "        [252.2074, 149.3333, 320.4741, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 3], device='cuda:0'), 'image_id': tensor([1140], device='cuda:0')}, {'boxes': tensor([[327.3114,   8.5333, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1974], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 159.2889, 455.4667, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1066], device='cuda:0')}, {'boxes': tensor([[201.6000, 151.4667, 297.6000, 376.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1845], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.8000, 276.6222, 435.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([656], device='cuda:0')}, {'boxes': tensor([[267.2000, 115.2000, 352.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1132], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[214.4000,  85.3333, 384.0000, 382.5778],\n",
      "        [337.6000, 130.1333, 425.2000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1543], device='cuda:0')}, {'boxes': tensor([[137.6000,  34.8444, 346.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1480], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[106.8000, 187.7333, 326.8000, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1349], device='cuda:0')}, {'boxes': tensor([[204.0000,  82.4889, 346.4000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1781], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.6000, 241.0667, 246.0000, 393.9556],\n",
      "        [336.0000, 180.6222, 474.8000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([642], device='cuda:0')}, {'boxes': tensor([[340.8000,  79.6444, 473.6000, 275.9111],\n",
      "        [154.4000,  79.6444, 289.6000, 295.8222],\n",
      "        [ 51.2000, 132.2667, 192.0000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1756], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 159.2889, 280.8000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([932], device='cuda:0')}, {'boxes': tensor([[448.8000,   0.0000, 480.8000,  47.2131]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([975], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 109.5111, 318.4000, 200.5333],\n",
      "        [ 90.0000, 170.6667, 234.4000, 261.6889],\n",
      "        [ 61.6000, 265.2444, 170.4000, 330.6667],\n",
      "        [ 60.8000, 342.0444, 100.8000, 379.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([148], device='cuda:0')}, {'boxes': tensor([[ 94.4000, 180.6222, 507.2000, 364.0889],\n",
      "        [ 28.8000, 125.1556, 147.2000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1639], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000, 198.4000, 361.6000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1268], device='cuda:0')}, {'boxes': tensor([[  8.5333,   0.0000, 510.9333, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1022], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000, 201.9556, 328.0000, 420.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1597], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1252], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.8000,  91.0222, 355.2000, 396.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1356], device='cuda:0')}, {'boxes': tensor([[180.4000, 187.0222, 322.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1966], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.4000,  12.8000, 510.4000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([799], device='cuda:0')}, {'boxes': tensor([[147.6000, 119.4667, 194.8000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1260], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.0000, 281.6000, 280.4000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([982], device='cuda:0')}, {'boxes': tensor([[ 80.8000, 182.7556, 232.4000, 365.5111],\n",
      "        [276.4000, 172.8000, 424.4000, 352.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1093], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[288.0000, 214.7556, 312.8000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2052], device='cuda:0')}, {'boxes': tensor([[240.8000, 187.7333, 344.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2182], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.6000,  78.2222, 342.0000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([897], device='cuda:0')}, {'boxes': tensor([[ 56.8000, 109.5111, 238.0000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([212], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.2000, 161.4222, 423.6000, 440.8889],\n",
      "        [ 60.4000, 258.8445, 152.0000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([866], device='cuda:0')}, {'boxes': tensor([[ 12.8000, 157.8667,  72.5333, 226.1333],\n",
      "        [375.4667, 192.0000, 509.8667, 368.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([674], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[205.2000, 224.7111, 288.4000, 330.6667],\n",
      "        [112.0000, 194.1333, 193.2000, 296.5333],\n",
      "        [225.2000, 234.6667, 302.0000, 322.1333],\n",
      "        [137.6000, 209.7778, 218.0000, 297.9556],\n",
      "        [158.4000, 205.5111, 227.2000, 290.1333],\n",
      "        [250.8000, 237.5111, 321.2000, 328.5333],\n",
      "        [319.2000, 258.8445, 398.0000, 358.4000],\n",
      "        [338.4000, 283.0222, 418.0000, 387.5555],\n",
      "        [239.6000, 237.5111, 317.6000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([121], device='cuda:0')}, {'boxes': tensor([[122.0000, 289.4222, 150.0000, 489.9556],\n",
      "        [127.6000, 156.4444, 150.4000, 197.6889],\n",
      "        [386.0000, 200.5333, 460.8000, 276.6222],\n",
      "        [ 78.8000, 147.9111,  97.2000, 179.9111],\n",
      "        [296.0000, 172.8000, 344.8000, 243.2000],\n",
      "        [341.2000, 180.6222, 426.4000, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2026], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000, 136.5333, 231.2000, 321.4222],\n",
      "        [221.2000,  86.7556, 374.0000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([565], device='cuda:0')}, {'boxes': tensor([[218.4000,  99.5556, 418.0000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([493], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 226.8445, 183.6000, 302.2222],\n",
      "        [278.0000, 225.4222, 330.8000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1562], device='cuda:0')}, {'boxes': tensor([[187.6000, 179.2000, 270.0000, 380.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1339], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000, 182.0444, 228.2667, 237.0370]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1149], device='cuda:0')}, {'boxes': tensor([[  0.0000, 113.7778, 395.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1298], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.0000, 244.6222, 408.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([27], device='cuda:0')}, {'boxes': tensor([[242.7259,   0.0000, 475.0222, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1829], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 94.4000, 187.0222, 252.4000, 364.8000],\n",
      "        [282.4000, 182.7556, 425.6000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1097], device='cuda:0')}, {'boxes': tensor([[307.6000, 239.6444, 440.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1498], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.4000,   0.0000, 482.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1832], device='cuda:0')}, {'boxes': tensor([[167.2000, 159.2889, 276.0000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([931], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 425.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([700], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([812], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000,   0.0000, 363.2000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1262], device='cuda:0')}, {'boxes': tensor([[179.6000, 201.9556, 373.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1596], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[145.6000,   0.0000, 442.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1612], device='cuda:0')}, {'boxes': tensor([[226.4000, 103.8222, 440.0000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1682], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.4000, 180.6222, 258.8000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([189], device='cuda:0')}, {'boxes': tensor([[143.3239,  76.8000, 401.1268, 438.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1062], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.2667, 130.8445, 248.5333, 197.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1592], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2083], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 154.3111,  64.0000, 252.4444],\n",
      "        [167.6000, 156.4444, 196.8000, 219.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1394], device='cuda:0')}, {'boxes': tensor([[174.4000,  29.1556, 276.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1058], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 99.6000, 238.2222, 310.0000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1162], device='cuda:0')}, {'boxes': tensor([[207.6000, 203.3778, 257.2000, 278.0444],\n",
      "        [142.8000, 238.9333, 177.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([851], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000,  73.9556, 242.4000, 247.4667],\n",
      "        [243.2000,  46.9333, 357.6000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1737], device='cuda:0')}, {'boxes': tensor([[211.6000,  32.0000, 338.0000, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([26], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 155.0222, 510.9333, 393.9556],\n",
      "        [  4.2667,   2.8444, 453.3333, 422.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([52], device='cuda:0')}, {'boxes': tensor([[ 45.8667,  15.6444, 300.8000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1075], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.8000, 190.5778, 511.2000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([574], device='cuda:0')}, {'boxes': tensor([[ 56.5333,  91.0222, 401.0667, 456.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1699], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.1111,  38.4000, 425.7185, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1825], device='cuda:0')}, {'boxes': tensor([[297.2000, 131.5556, 407.2000, 259.5555],\n",
      "        [ 43.6000, 125.1556, 126.8000, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16, 16], device='cuda:0'), 'image_id': tensor([895], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[155.2000,  28.4444, 449.2000, 361.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([817], device='cuda:0')}, {'boxes': tensor([[ 47.8384, 203.6364, 181.0101, 378.1818]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2019], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 107.3778, 262.4000, 501.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1898], device='cuda:0')}, {'boxes': tensor([[154.0000, 103.1111, 238.4000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1360], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 211.9111, 328.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1549], device='cuda:0')}, {'boxes': tensor([[120.0000,  42.6667, 380.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([345], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.2000,  77.0909, 364.8000, 280.7273],\n",
      "        [139.2000, 101.8182, 259.2000, 257.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1328], device='cuda:0')}, {'boxes': tensor([[ 55.4667,  85.3333, 249.6000, 294.4000],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1083], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[410.8000, 103.1111, 508.4000, 494.9333],\n",
      "        [136.4000,   0.0000, 490.4000, 285.1555],\n",
      "        [ 84.4000,   0.0000, 183.2000,  37.6889],\n",
      "        [421.6000,   2.1333, 508.8000, 125.1556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1800], device='cuda:0')}, {'boxes': tensor([[223.2000, 109.5111, 510.4000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  24.1778, 317.2000, 491.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([272], device='cuda:0')}, {'boxes': tensor([[166.4000,  30.3407, 247.4667, 510.1037]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1258], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000, 120.8889, 241.2000, 201.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1948], device='cuda:0')}, {'boxes': tensor([[152.0000, 331.3778, 221.6000, 509.1555],\n",
      "        [364.0000, 322.8445, 444.0000, 510.5778],\n",
      "        [ 79.2000, 325.6889, 145.6000, 506.3111],\n",
      "        [277.6000, 304.3556, 321.6000, 473.6000],\n",
      "        [  0.0000, 307.2000,  63.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([787], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 153.6000,  64.0000, 252.4444],\n",
      "        [169.2000, 155.0222, 197.6000, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1393], device='cuda:0')}, {'boxes': tensor([[229.3333, 182.0444, 307.2000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([261], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 40.8000, 322.0984, 137.6000, 413.3770],\n",
      "        [160.8000, 305.3115, 259.2000, 400.7869]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([963], device='cuda:0')}, {'boxes': tensor([[ 76.8000, 199.1111, 118.0000, 356.2667],\n",
      "        [356.0000, 201.9556, 401.6000, 261.6889],\n",
      "        [ 55.2000, 105.9556, 134.8000, 156.4444],\n",
      "        [268.4000, 144.3556, 308.0000, 206.2222],\n",
      "        [118.0000, 201.9556, 221.2000, 293.6889],\n",
      "        [163.6000, 132.2667, 187.2000, 177.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2028], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.0000, 135.1111, 256.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1343], device='cuda:0')}, {'boxes': tensor([[196.0000, 153.6000, 373.6000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([747], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 12.8000, 125.1556, 140.8000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1131], device='cuda:0')}, {'boxes': tensor([[185.2000, 128.0000, 318.0000, 356.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([400], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 278.7556, 315.2000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1020], device='cuda:0')}, {'boxes': tensor([[146.4000, 210.4889, 244.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([416], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.9333, 209.0667, 291.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1408], device='cuda:0')}, {'boxes': tensor([[133.3333, 146.4889, 377.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1718], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.0000,  62.5778, 291.2000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([838], device='cuda:0')}, {'boxes': tensor([[147.9111, 109.5111, 511.0518, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[258.8000, 109.5111, 440.8000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1985], device='cuda:0')}, {'boxes': tensor([[158.4000, 152.1778, 289.6000, 356.2667],\n",
      "        [266.4000, 170.6667, 450.4000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([570], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667, 295.8222, 510.9333, 473.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([250], device='cuda:0')}, {'boxes': tensor([[237.2000, 187.0222, 288.0000, 258.8445],\n",
      "        [228.8000, 193.4222, 256.4000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([846], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[300.0000, 211.9111, 508.8000, 507.7333],\n",
      "        [  0.0000, 113.7778, 325.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1619], device='cuda:0')}, {'boxes': tensor([[ 69.3333, 310.0444, 200.5333, 435.2000],\n",
      "        [379.7333, 295.8222, 443.7333, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([712], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[117.3333,  59.7333, 309.3333, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([725], device='cuda:0')}, {'boxes': tensor([[170.2752,  93.8667, 355.2294, 422.4000],\n",
      "        [ 44.6239, 241.0667, 155.5963, 423.4667],\n",
      "        [411.5963, 222.9333, 443.8899, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7], device='cuda:0'), 'image_id': tensor([486], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  75.3778, 260.8000, 506.3111],\n",
      "        [317.6000, 342.0444, 378.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1645], device='cuda:0')}, {'boxes': tensor([[141.6000, 207.6444, 214.4000, 484.9778],\n",
      "        [264.8000, 182.0444, 310.4000, 359.8222],\n",
      "        [492.0000, 240.3556, 508.8000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([779], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.8000, 189.1555, 279.2000, 315.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([894], device='cuda:0')}, {'boxes': tensor([[320.4000, 193.4222, 460.0000, 253.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([653], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[265.6000, 122.3111, 510.9333, 348.4445],\n",
      "        [ 32.0000,   0.0000, 500.2667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 18], device='cuda:0'), 'image_id': tensor([49], device='cuda:0')}, {'boxes': tensor([[283.7333, 109.5111, 369.0667, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1587], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[114.4000, 196.9778, 234.0000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([402], device='cuda:0')}, {'boxes': tensor([[106.0000, 193.4222, 275.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2061], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000,  66.8444, 384.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([615], device='cuda:0')}, {'boxes': tensor([[208.0000, 176.3556, 252.8000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([933], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 330.6667, 277.2000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1885], device='cuda:0')}, {'boxes': tensor([[ 71.2000,  98.6229, 197.6000, 442.7541]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([961], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[109.6000,  86.0444, 374.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([131], device='cuda:0')}, {'boxes': tensor([[223.2000, 227.5556, 346.8000, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2189], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.4000, 236.8000, 188.4000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1507], device='cuda:0')}, {'boxes': tensor([[138.0000,  71.8222, 417.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[230.0000, 168.5333, 332.8000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2177], device='cuda:0')}, {'boxes': tensor([[291.2000, 236.0889, 390.4000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1705], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000,   0.0000, 510.4000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1809], device='cuda:0')}, {'boxes': tensor([[ 48.8000, 179.2000, 388.0000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1388], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 170.6667, 465.0667, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1065], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1516], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[287.2000, 205.5111, 432.4000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1911], device='cuda:0')}, {'boxes': tensor([[ 63.2000,  55.4667, 450.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1118], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 63.2000,  64.7111, 445.6000, 443.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([839], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  46.9333, 377.6000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1687], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 194.8445,  91.7333, 509.1555],\n",
      "        [147.2000,  83.9111, 334.9333, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([601], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1637], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 145.0667, 441.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([332], device='cuda:0')}, {'boxes': tensor([[128.0000,  49.3115, 284.0000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([958], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 51.2000, 117.3333, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1203], device='cuda:0')}, {'boxes': tensor([[179.2000,   0.0000, 314.8000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1307], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[394.5688, 224.0000, 509.6514, 316.8000],\n",
      "        [388.1101, 281.6000, 510.2385, 393.6000],\n",
      "        [ 45.7982, 246.4000, 182.0183, 440.5333],\n",
      "        [420.9908, 306.1333, 510.2385, 461.8667],\n",
      "        [406.3119, 294.4000, 510.2385, 421.3333],\n",
      "        [ 34.0550, 316.8000, 129.1743, 337.0667],\n",
      "        [ 25.8349, 329.6000, 125.0642, 360.5333],\n",
      "        [ 10.5688, 359.4667, 137.9817, 401.0667],\n",
      "        [  0.5872, 396.8000, 159.7064, 504.5333],\n",
      "        [195.5229,  83.2000, 366.3853, 449.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([462], device='cuda:0')}, {'boxes': tensor([[  4.8000,   9.9556, 506.0000, 481.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([282], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.4000,   4.2667, 501.6000, 448.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([307], device='cuda:0')}, {'boxes': tensor([[180.2667,   0.0000, 377.6000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([594], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[142.4225,  88.0000, 396.6197, 427.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1063], device='cuda:0')}, {'boxes': tensor([[ 87.2000,  75.3778, 242.4000, 244.6222],\n",
      "        [236.8000,  64.0000, 364.0000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1741], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[309.6000, 146.4889, 511.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1450], device='cuda:0')}, {'boxes': tensor([[144.1185, 170.6667, 215.2296, 250.3111],\n",
      "        [441.8370, 169.2444, 508.2074, 250.3111],\n",
      "        [186.7852, 220.4444, 286.3407, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 3], device='cuda:0'), 'image_id': tensor([1141], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.4000,  14.9333, 483.6000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([290], device='cuda:0')}, {'boxes': tensor([[119.6000, 162.8445, 212.8000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([861], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[164.0000, 142.2222, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1652], device='cuda:0')}, {'boxes': tensor([[ 89.6000, 172.8000, 507.2000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1280], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 164.9778, 254.4000, 330.6667],\n",
      "        [198.4000, 194.1333, 265.2000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1569], device='cuda:0')}, {'boxes': tensor([[  0.0000, 192.7111, 255.6000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1376], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000,  52.6222, 381.6000, 146.4889],\n",
      "        [132.0000, 112.3556, 283.6000, 205.5111],\n",
      "        [ 62.4000, 174.2222, 203.2000, 268.8000],\n",
      "        [ 61.6000, 276.6222, 121.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([149], device='cuda:0')}, {'boxes': tensor([[233.6000,   0.7111, 422.4000, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1453], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 192.0000, 348.8000, 364.0889],\n",
      "        [485.6000, 182.7556, 509.6000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1108], device='cuda:0')}, {'boxes': tensor([[181.2000, 216.1778, 457.2000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([577], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.8000, 107.3778, 510.0000, 450.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([989], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([736], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,  32.0000, 501.6000, 493.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([288], device='cuda:0')}, {'boxes': tensor([[116.2667,   0.0000, 349.8667, 246.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1720], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 199.8222, 201.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1654], device='cuda:0')}, {'boxes': tensor([[133.2000, 196.9778, 381.6000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1605], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 362.6667, 508.2074],\n",
      "        [  8.5333,  81.5407, 359.4667, 508.2074],\n",
      "        [326.4000,   0.0000, 510.9333, 508.2074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([35], device='cuda:0')}, {'boxes': tensor([[178.0000, 119.4667, 328.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1377], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.8000,  41.2444, 224.0000, 224.7111],\n",
      "        [308.0000,  24.1778, 468.8000, 224.7111],\n",
      "        [486.4000,  71.1111, 511.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1760], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1466], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[195.2000,  60.4444, 322.8000, 435.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([876], device='cuda:0')}, {'boxes': tensor([[198.8000,  98.8444, 398.8000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1351], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 253.1555, 265.6000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2134], device='cuda:0')}, {'boxes': tensor([[145.0667,   0.0000, 454.4000, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1711], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.6000, 119.4667, 270.0000, 434.4889],\n",
      "        [263.6000, 192.0000, 374.0000, 430.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1542], device='cuda:0')}, {'boxes': tensor([[  0.5872,   9.6000, 509.6514, 507.7333],\n",
      "        [294.1651, 309.3333, 510.8257, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([453], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[239.6000,  83.2000, 510.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2167], device='cuda:0')}, {'boxes': tensor([[230.4000,  59.7333, 504.8000, 497.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([312], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.4000,  64.0000, 447.2000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([840], device='cuda:0')}, {'boxes': tensor([[  9.6000, 198.4000, 454.4000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1271], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[295.6000,  88.1778, 416.4000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1534], device='cuda:0')}, {'boxes': tensor([[152.0000, 170.6667, 363.2000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.4242, 265.6970, 231.4343, 467.3940]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2023], device='cuda:0')}, {'boxes': tensor([[216.8000, 182.0444, 359.6000, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1931], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[278.0000, 106.6667, 284.4000, 118.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1444], device='cuda:0')}, {'boxes': tensor([[ 30.9333,  73.9556, 206.9333, 248.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1491], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[213.6000, 250.3111, 292.4000, 307.2000],\n",
      "        [112.0000, 263.8222, 194.8000, 318.5778],\n",
      "        [260.8000, 192.0000, 344.0000, 256.0000],\n",
      "        [150.4000, 159.2889, 240.0000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([135], device='cuda:0')}, {'boxes': tensor([[159.2000, 218.3111, 236.8000, 312.8889],\n",
      "        [283.6000, 226.1333, 344.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1518], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000,  61.8667, 346.0000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([342], device='cuda:0')}, {'boxes': tensor([[258.4000, 238.9333, 290.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([951], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.2000,  47.6444, 302.0000, 238.9333],\n",
      "        [295.6000,  26.3111, 453.6000, 251.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([563], device='cuda:0')}, {'boxes': tensor([[177.3211, 241.0667, 221.3578, 327.4667],\n",
      "        [134.4587, 229.3333, 194.9358, 343.4667],\n",
      "        [423.9266, 266.6667, 509.6514, 411.7333],\n",
      "        [207.8532,  49.0667, 392.2202, 414.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([451], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000, 314.3111, 197.3333, 429.5111],\n",
      "        [377.6000, 300.0889, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([704], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1649], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 127.2889, 448.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([79], device='cuda:0')}, {'boxes': tensor([[201.6000, 204.8000, 290.1333, 308.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([259], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[388.2667, 281.6000, 509.8667, 391.1111],\n",
      "        [  0.0000, 250.3111, 246.4000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2120], device='cuda:0')}, {'boxes': tensor([[  0.0000,  79.6444, 429.8667, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1730], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[203.7333, 201.9556, 411.7333, 506.3111],\n",
      "        [210.1333,  93.8667, 442.6667, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1734], device='cuda:0')}, {'boxes': tensor([[179.2000, 214.7556, 366.8000, 497.7778],\n",
      "        [ 82.4000, 219.0222, 381.6000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([549], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.0000, 152.1778, 265.2000, 342.7556],\n",
      "        [219.6000, 175.6444, 398.0000, 363.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([568], device='cuda:0')}, {'boxes': tensor([[104.8000,  96.7111, 376.8000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1021], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[313.6000, 207.6444, 352.0000, 371.2000],\n",
      "        [172.0000, 220.4444, 216.0000, 480.7111],\n",
      "        [384.0000, 204.8000, 428.8000, 422.4000],\n",
      "        [424.0000, 236.0889, 509.6000, 506.3111],\n",
      "        [  0.0000, 297.2444, 126.4000, 509.1555],\n",
      "        [195.2000, 275.9111, 308.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([775], device='cuda:0')}, {'boxes': tensor([[143.6000, 103.8222, 240.0000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1850], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 142.2222, 294.8000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2050], device='cuda:0')}, {'boxes': tensor([[176.0000, 139.3778, 188.4000, 172.0889],\n",
      "        [224.4000, 239.6444, 248.4000, 256.0000],\n",
      "        [215.2000, 351.2889, 269.2000, 387.5555],\n",
      "        [426.4000, 338.4889, 454.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24, 24], device='cuda:0'), 'image_id': tensor([1882], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333, 135.1111, 509.1555, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([171], device='cuda:0')}, {'boxes': tensor([[  9.6000, 185.6000, 216.0000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1034], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  61.8667, 302.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1178], device='cuda:0')}, {'boxes': tensor([[ 86.0000, 192.0000, 236.8000, 371.2000],\n",
      "        [317.2000, 170.6667, 460.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1109], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 122.3111, 289.6000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1946], device='cuda:0')}, {'boxes': tensor([[ 44.0000, 207.6444,  82.4000, 300.0889],\n",
      "        [ 91.2000, 216.1778, 141.6000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([944], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.8000, 317.8667, 270.0000, 345.6000],\n",
      "        [238.4000, 281.6000, 258.8000, 312.1778],\n",
      "        [236.0000, 244.6222, 256.4000, 276.6222],\n",
      "        [220.8000, 174.2222, 243.6000, 204.8000],\n",
      "        [200.8000, 168.5333, 223.6000, 199.8222],\n",
      "        [177.6000, 163.5556, 201.2000, 193.4222],\n",
      "        [154.8000, 160.0000, 177.6000, 192.0000],\n",
      "        [133.2000, 162.1333, 156.0000, 193.4222],\n",
      "        [228.8000, 206.2222, 251.6000, 236.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([113], device='cuda:0')}, {'boxes': tensor([[168.4000, 255.2889, 339.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1525], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.5333, 174.9333, 308.2667, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2129], device='cuda:0')}, {'boxes': tensor([[164.8000, 219.0222, 375.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 36.0000,  80.3556, 454.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1120], device='cuda:0')}, {'boxes': tensor([[194.4000, 175.6444, 301.2000, 270.2222],\n",
      "        [ 41.6000, 201.9556, 178.4000, 310.7556],\n",
      "        [188.8000, 242.4889, 316.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1575], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.4000, 135.1111, 256.4000, 232.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([128], device='cuda:0')}, {'boxes': tensor([[256.8000, 132.9778, 352.4000, 350.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([659], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[118.4000, 277.3333, 240.8000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2004], device='cuda:0')}, {'boxes': tensor([[171.2000, 105.9556, 374.4000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1354], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.2000, 172.0889, 284.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1359], device='cuda:0')}, {'boxes': tensor([[377.5413, 315.7333, 510.2385, 506.6667],\n",
      "        [  0.0000, 264.5333,  70.4587, 413.8667],\n",
      "        [238.9725, 201.6000, 382.2385, 486.4000],\n",
      "        [258.9358, 306.1333, 413.9449, 507.7333],\n",
      "        [112.1468, 244.2667, 216.0734, 362.6667],\n",
      "        [381.0642, 274.1333, 459.1560, 345.6000],\n",
      "        [ 47.5596, 265.6000, 141.5046, 403.2000],\n",
      "        [  0.0000, 210.1333,  79.2661, 276.2667],\n",
      "        [125.6514, 245.3333, 231.9266, 352.0000],\n",
      "        [233.1009, 125.8667, 510.2385, 364.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([447], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 34.8000, 162.8445, 336.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([221], device='cuda:0')}, {'boxes': tensor([[136.8000, 153.6000, 287.2000, 301.5111],\n",
      "        [ 57.6000, 216.1778, 133.6000, 288.0000],\n",
      "        [364.0000, 146.4889, 510.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11,  7], device='cuda:0'), 'image_id': tensor([1526], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.4000,   3.5556, 503.2000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([318], device='cuda:0')}, {'boxes': tensor([[204.0000,  71.1111, 416.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1684], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.2000, 127.2889, 389.6000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([376], device='cuda:0')}, {'boxes': tensor([[249.6000, 149.3333, 480.0000, 494.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1672], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 261.6889, 412.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1500], device='cuda:0')}, {'boxes': tensor([[160.8000, 120.1778, 432.0000, 462.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2197], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000,  91.7333, 415.2000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1983], device='cuda:0')}, {'boxes': tensor([[380.8000, 223.2889, 420.8000, 278.0444],\n",
      "        [  0.0000, 315.7333, 392.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 29], device='cuda:0'), 'image_id': tensor([652], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[356.8000, 159.2889, 396.8000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2147], device='cuda:0')}, {'boxes': tensor([[104.4000,  93.1556, 396.8000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([752], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[168.8000, 233.9556, 262.0000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1796], device='cuda:0')}, {'boxes': tensor([[104.5333,   0.0000, 274.1333, 413.3926]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1256], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[178.0000, 190.5778, 281.6000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([892], device='cuda:0')}, {'boxes': tensor([[ 98.8000, 239.6444, 311.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1159], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.2000, 214.7556, 295.2000, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([88], device='cuda:0')}, {'boxes': tensor([[  0.0000, 324.2667, 130.1333, 412.4445],\n",
      "        [473.6000, 254.5778, 509.8667, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([690], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 227.5556, 283.6000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1957], device='cuda:0')}, {'boxes': tensor([[  0.0000, 105.2444, 509.8667, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1067], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.8000, 115.2000, 396.0000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1449], device='cuda:0')}, {'boxes': tensor([[147.2000, 308.6222, 230.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2011], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[248.0000, 273.7778, 320.0000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([490], device='cuda:0')}, {'boxes': tensor([[127.2000,  84.6222, 413.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1858], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[188.0000,  39.1111, 348.8000, 374.7556],\n",
      "        [ 89.6000, 265.9556,  98.0000, 298.6667],\n",
      "        [ 79.6000, 263.8222,  88.4000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28], device='cuda:0'), 'image_id': tensor([1016], device='cuda:0')}, {'boxes': tensor([[285.6000, 179.2000, 462.0000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1286], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.4000,  44.0889, 258.4000, 319.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([210], device='cuda:0')}, {'boxes': tensor([[100.2667, 231.8222, 210.1333, 379.7333],\n",
      "        [104.5333, 227.5556, 362.6667, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([2075], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 49.6000, 102.4000, 281.6000, 494.9333],\n",
      "        [205.2000, 219.7333, 310.0000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([917], device='cuda:0')}, {'boxes': tensor([[269.2000,  86.7556, 365.2000, 226.1333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1190], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 66.1333, 305.7778, 192.0000, 430.9333],\n",
      "        [373.3333, 283.0222, 443.7333, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([709], device='cuda:0')}, {'boxes': tensor([[328.5333,  31.2889, 510.9333, 226.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1726], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000,  14.2222, 492.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1671], device='cuda:0')}, {'boxes': tensor([[113.6882,  81.7778, 475.3134, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2097], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[284.8000, 271.6444, 434.4000, 487.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1917], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([44], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[166.4000, 372.6222, 336.8000, 509.1555],\n",
      "        [ 45.2000, 357.6889, 350.4000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([551], device='cuda:0')}, {'boxes': tensor([[112.8000, 221.8667, 267.2000, 290.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([41], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[110.8000,  80.3556, 320.4000, 450.8445],\n",
      "        [236.8000, 146.4889, 320.4000, 417.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1531], device='cuda:0')}, {'boxes': tensor([[205.2000, 143.6444, 278.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1840], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,  59.0222, 511.2000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1651], device='cuda:0')}, {'boxes': tensor([[ 87.2000, 142.2222, 285.6000, 364.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1559], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.0000,  63.2889, 357.6000, 407.4667],\n",
      "        [222.4000, 278.0444, 250.8000, 342.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1017], device='cuda:0')}, {'boxes': tensor([[ 11.2000,   0.0000, 251.6000, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([412], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.6000, 193.4222, 255.2000, 357.6889],\n",
      "        [192.8000, 221.1555, 264.4000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1566], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([803], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.8000,   0.0000, 508.8000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1811], device='cuda:0')}, {'boxes': tensor([[258.0000, 125.8667, 391.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1441], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[176.0000,  46.9333, 351.6000, 404.6222],\n",
      "        [164.8000, 267.3778, 194.4000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28], device='cuda:0'), 'image_id': tensor([1018], device='cuda:0')}, {'boxes': tensor([[141.6000, 226.9091, 254.4000, 322.9091],\n",
      "        [449.6000, 232.7273, 507.2000, 331.6364],\n",
      "        [352.0000, 285.0909, 388.0000, 315.6364],\n",
      "        [251.2000, 282.1818, 285.6000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([1420], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 65.0667,  72.5333, 390.4000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1685], device='cuda:0')}, {'boxes': tensor([[  0.0000, 136.5333, 206.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([646], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  57.6000, 316.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1004], device='cuda:0')}, {'boxes': tensor([[139.2000, 166.4000, 421.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([280], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.0000, 244.6222, 264.4000, 448.7111],\n",
      "        [303.2000, 257.4222, 366.4000, 386.1333],\n",
      "        [  6.8000, 320.7111,  39.6000, 388.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11, 11], device='cuda:0'), 'image_id': tensor([1523], device='cuda:0')}, {'boxes': tensor([[172.4000,  78.9333, 331.6000, 349.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2048], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 201.9556, 213.3333, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1364], device='cuda:0')}, {'boxes': tensor([[  0.0000,  34.1333, 510.4000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2085], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[177.2000, 202.6667, 330.0000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1600], device='cuda:0')}, {'boxes': tensor([[ 97.6000, 125.1556, 382.4000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1814], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1397], device='cuda:0')}, {'boxes': tensor([[147.2000, 115.9111, 239.6000, 413.1555],\n",
      "        [236.8000, 113.7778, 356.8000, 374.0444],\n",
      "        [225.2000, 198.4000, 274.4000, 369.0667],\n",
      "        [  0.0000, 268.8000,  27.6000, 285.1555],\n",
      "        [104.4000, 239.6444, 145.6000, 262.4000],\n",
      "        [456.4000, 334.9333, 511.2000, 364.8000],\n",
      "        [448.4000, 430.9333, 511.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2065], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.0000, 103.1111, 154.0000, 201.9556],\n",
      "        [284.8000, 135.1111, 326.4000, 214.7556],\n",
      "        [333.2000, 171.3778, 383.2000, 255.2889],\n",
      "        [ 58.8000, 112.3556,  94.4000, 223.2889],\n",
      "        [234.4000, 142.2222, 284.8000, 199.1111],\n",
      "        [305.2000, 142.9333, 346.8000, 204.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2030], device='cuda:0')}, {'boxes': tensor([[298.4000, 203.3778, 340.0000, 277.3333],\n",
      "        [ 41.6000, 102.4000, 304.8000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([899], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.8000,  78.2222, 280.0000, 256.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([886], device='cuda:0')}, {'boxes': tensor([[256.0000, 206.2222, 412.8000, 290.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[274.4000, 285.8667, 510.4000, 506.3111],\n",
      "        [  0.0000,   0.0000, 217.6000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1614], device='cuda:0')}, {'boxes': tensor([[168.4000, 112.3556, 280.0000, 333.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1846], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[330.8169,   0.0000, 511.0986, 417.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1482], device='cuda:0')}, {'boxes': tensor([[180.8000, 135.1111, 321.6000, 357.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([395], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 184.1778,  38.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1904], device='cuda:0')}, {'boxes': tensor([[  0.0000, 177.7778, 382.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1218], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 71.2000, 192.0000, 187.6000, 367.6444],\n",
      "        [296.4000, 174.2222, 436.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1111], device='cuda:0')}, {'boxes': tensor([[172.8000,  34.1333, 312.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1775], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 64.0000,   0.0000, 317.6000, 510.5778],\n",
      "        [232.4000,   0.7111, 402.4000, 509.1555],\n",
      "        [255.2000, 167.8222, 424.4000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1660], device='cuda:0')}, {'boxes': tensor([[246.4000, 159.2889, 300.8000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2128], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[240.0000,  59.0222, 396.8000, 155.0222],\n",
      "        [144.4000, 117.3333, 295.2000, 213.3333],\n",
      "        [ 70.4000, 179.2000, 213.6000, 276.6222],\n",
      "        [ 61.6000, 279.4667, 130.0000, 326.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([150], device='cuda:0')}, {'boxes': tensor([[ 66.8000, 205.5111, 222.4000, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([403], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1060], device='cuda:0')}, {'boxes': tensor([[218.4000, 214.7556, 428.8000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1677], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.6000,  12.0889, 410.0000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([265], device='cuda:0')}, {'boxes': tensor([[181.0963,  86.7556, 508.2074, 395.3778],\n",
      "        [241.7778, 318.5778, 340.3852, 426.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([179], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 28.1835,   0.0000, 510.2385, 508.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([464], device='cuda:0')}, {'boxes': tensor([[  0.0000, 209.0667, 184.5333, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[298.6667, 224.7111, 360.5333, 402.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1936], device='cuda:0')}, {'boxes': tensor([[135.6000,  88.1778, 290.8000, 455.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1902], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[307.6000, 238.9333, 436.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1497], device='cuda:0')}, {'boxes': tensor([[158.4000,  96.7111, 200.4000, 138.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 81.6000,  55.4667, 457.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1806], device='cuda:0')}, {'boxes': tensor([[370.4789,   0.0000, 510.1972, 304.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1488], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000, 119.4667, 414.4000, 509.8667],\n",
      "        [ 76.8000, 123.7333, 310.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1412], device='cuda:0')}, {'boxes': tensor([[ 64.4000,   0.0000, 509.6000, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2081], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.0000,   0.0000, 300.0000, 470.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([546], device='cuda:0')}, {'boxes': tensor([[255.2000, 125.8667, 275.2000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([874], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 211.2000, 201.2000, 233.9556],\n",
      "        [439.2000, 206.2222, 474.8000, 222.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([526], device='cuda:0')}, {'boxes': tensor([[ 96.0000, 153.6000, 276.2667, 312.8889],\n",
      "        [503.4667, 206.2222, 509.8667, 260.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 10], device='cuda:0'), 'image_id': tensor([673], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000, 144.0000, 463.2000, 349.0909],\n",
      "        [159.2000, 208.0000, 254.4000, 341.8182]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1319], device='cuda:0')}, {'boxes': tensor([[  2.4000, 135.8222, 256.4000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([213], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[304.0000, 275.9111, 344.0000, 373.3333],\n",
      "        [229.2000, 289.4222, 270.8000, 386.1333],\n",
      "        [128.0000, 339.2000, 171.2000, 443.7333],\n",
      "        [133.6000, 232.5333, 176.4000, 330.6667],\n",
      "        [297.6000, 160.7111, 338.8000, 253.1555],\n",
      "        [270.4000,  71.1111, 316.0000, 167.1111],\n",
      "        [206.0000,  88.1778, 249.6000, 184.8889],\n",
      "        [149.6000, 124.4444, 192.0000, 220.4444],\n",
      "        [229.2000, 192.7111, 272.0000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([109], device='cuda:0')}, {'boxes': tensor([[123.6000, 201.9556, 293.6000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([95], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 182.0444, 319.2000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1777], device='cuda:0')}, {'boxes': tensor([[246.4000,  64.0000, 422.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([896], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[162.0000, 171.3778, 291.2000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1786], device='cuda:0')}, {'boxes': tensor([[ 84.8000, 200.5333, 368.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1265], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 44.0000, 145.0667, 268.8000, 487.8222],\n",
      "        [288.8000, 113.7778, 426.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1427], device='cuda:0')}, {'boxes': tensor([[194.1333, 115.2000, 430.9333, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([206], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 260.2667, 268.8000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([948], device='cuda:0')}, {'boxes': tensor([[ 32.0000,  65.4222, 320.0000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2088], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[105.6000,  75.3778, 367.2000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2200], device='cuda:0')}, {'boxes': tensor([[124.4000, 125.8667, 310.0000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1855], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[290.0000, 371.2000, 321.2000, 405.3333],\n",
      "        [214.4000, 203.3778, 228.8000, 252.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1873], device='cuda:0')}, {'boxes': tensor([[  0.0000, 163.5556, 396.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1296], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[227.8165, 161.0667, 298.2752, 278.4000],\n",
      "        [  0.5872, 274.1333, 126.8257, 509.8667],\n",
      "        [222.5321, 199.4667, 235.4495, 234.6667],\n",
      "        [186.7156, 218.6667, 225.4679, 276.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([426], device='cuda:0')}, {'boxes': tensor([[152.8000,  99.5556, 244.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1510], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.2000, 200.5333, 270.4000, 234.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([938], device='cuda:0')}, {'boxes': tensor([[138.8000, 194.8445, 368.0000, 416.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1601], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.0000, 155.0222, 198.8000, 229.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1396], device='cuda:0')}, {'boxes': tensor([[202.6667,   0.0000, 360.5333, 270.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2072], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000, 152.1778, 430.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1679], device='cuda:0')}, {'boxes': tensor([[236.8000, 135.1111, 396.0000, 332.8000],\n",
      "        [ 83.2000, 135.1111, 234.4000, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1755], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6000, 146.4889, 438.0000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([331], device='cuda:0')}, {'boxes': tensor([[155.6000, 205.5111, 510.4000, 480.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([585], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 208.3556, 250.8000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1242], device='cuda:0')}, {'boxes': tensor([[261.2000, 187.7333, 280.4000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1960], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 342.7556, 249.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2012], device='cuda:0')}, {'boxes': tensor([[226.0000, 170.6667, 326.4000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2178], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 270.2222, 117.3333, 509.1555],\n",
      "        [162.1333,  93.8667, 341.3333, 355.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([599], device='cuda:0')}, {'boxes': tensor([[  0.0000, 203.3778, 221.8667, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1368], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[161.2000, 171.3778, 291.2000, 451.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1785], device='cuda:0')}, {'boxes': tensor([[217.2000, 198.4000, 255.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2064], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[226.0000, 220.4444, 349.6000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2188], device='cuda:0')}, {'boxes': tensor([[ 67.2000, 199.1111, 329.6000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1146], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[255.6000, 113.7778, 420.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1794], device='cuda:0')}, {'boxes': tensor([[385.0667, 162.1333, 461.8667, 220.4444],\n",
      "        [253.8667, 223.2889, 292.2667, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1703], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1023], device='cuda:0')}, {'boxes': tensor([[315.7333, 164.9778, 378.6667, 250.3111],\n",
      "        [254.9333, 150.7556, 338.1333, 240.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([357], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000, 263.8222, 467.6000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([16], device='cuda:0')}, {'boxes': tensor([[144.8000, 113.0667, 240.0000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1851], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.0000, 176.3556, 341.2000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([805], device='cuda:0')}, {'boxes': tensor([[145.6000, 295.8222, 236.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2009], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.8716, 184.5333, 303.5596, 322.1333],\n",
      "        [  1.7615, 321.0667, 509.0642, 509.8667],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 149.7248, 440.5333],\n",
      "        [134.4587, 291.2000, 181.4312, 334.9333],\n",
      "        [136.2202, 276.2667, 187.3027, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [319.4128, 272.0000, 353.4679, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([457], device='cuda:0')}, {'boxes': tensor([[ 15.6000,  80.3556, 228.0000, 284.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([1404], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 190.5778,  21.3333, 248.8889],\n",
      "        [377.6000, 167.8222, 510.9333, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([688], device='cuda:0')}, {'boxes': tensor([[ 83.2000,  59.7333, 412.8000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1697], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[319.6000, 267.3778, 340.4000, 316.4445],\n",
      "        [295.6000, 201.9556, 318.4000, 257.4222],\n",
      "        [276.8000, 150.0444, 299.2000, 195.5556],\n",
      "        [271.6000, 103.1111, 293.2000, 149.3333],\n",
      "        [269.2000,  59.0222, 289.6000, 103.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([98], device='cuda:0')}, {'boxes': tensor([[250.0000, 150.0444, 333.2000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([3], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 58.7156,  80.0000, 466.2018, 410.6667],\n",
      "        [ 20.5505, 257.0667, 231.3394, 490.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7], device='cuda:0'), 'image_id': tensor([475], device='cuda:0')}, {'boxes': tensor([[128.8000,  59.7333, 357.6000, 406.7556],\n",
      "        [  0.0000,   1.4222,  76.8000, 128.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1768], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[215.2296, 260.2667, 272.1185, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([754], device='cuda:0')}, {'boxes': tensor([[204.0000, 270.2222, 435.2000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1816], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 84.2667,  83.9111, 433.0667, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1692], device='cuda:0')}, {'boxes': tensor([[345.6000, 176.3556, 406.4000, 274.4889],\n",
      "        [209.0667, 244.6222, 243.2000, 322.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1700], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  5.6000,  98.1333, 182.0000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1330], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([762], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[160.0000, 211.9111, 486.8000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([367], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([954], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[181.0963, 177.7778, 323.3185, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([759], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 510.4000, 502.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1635], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.4000, 152.8889, 211.2000, 221.8667],\n",
      "        [381.6000, 253.8667, 428.8000, 335.6444],\n",
      "        [248.0000, 196.9778, 296.4000, 263.8222],\n",
      "        [202.4000, 140.0889, 233.2000, 261.6889],\n",
      "        [ 44.8000, 119.4667, 112.0000, 187.7333],\n",
      "        [137.2000, 145.0667, 174.0000, 200.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 18, 18, 18], device='cuda:0'), 'image_id': tensor([2024], device='cuda:0')}, {'boxes': tensor([[  0.0000, 285.8667, 399.6000, 460.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1205], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 6.1867e+01, 4.5800e+02, 4.4729e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([277], device='cuda:0')}, {'boxes': tensor([[ 26.0000, 157.8667,  64.0000, 252.4444],\n",
      "        [166.4000, 155.0222, 197.6000, 230.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1395], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.7339, 344.5333, 510.2385, 508.8000],\n",
      "        [100.4037,  16.0000, 496.7339, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 6], device='cuda:0'), 'image_id': tensor([463], device='cuda:0')}, {'boxes': tensor([[  0.0000, 223.2889, 172.0000, 507.7333],\n",
      "        [266.4000, 151.4667, 336.0000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([501], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[216.8000, 126.5778, 347.6000, 360.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([660], device='cuda:0')}, {'boxes': tensor([[  1.1743, 467.2000, 383.4128, 508.8000],\n",
      "        [446.2385, 417.0667, 509.0642, 508.8000],\n",
      "        [292.9908, 349.8667, 432.7339, 487.4667],\n",
      "        [342.8991, 394.6667, 483.2294, 507.7333],\n",
      "        [184.3670, 404.2667, 214.3119, 471.4667],\n",
      "        [224.8807, 265.6000, 361.1009, 470.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([442], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 320.0000, 150.8000, 408.1778],\n",
      "        [152.8000, 359.1111, 197.2000, 457.2444],\n",
      "        [165.6000,  98.8444, 181.6000, 135.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([626], device='cuda:0')}, {'boxes': tensor([[112.8000, 201.9556, 332.8000, 472.1778],\n",
      "        [  0.0000,  66.8444,  52.0000, 236.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1767], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000,  41.2444, 401.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([351], device='cuda:0')}, {'boxes': tensor([[121.6000, 110.9333, 381.8667, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([715], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 107.3778, 510.4000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([990], device='cuda:0')}, {'boxes': tensor([[131.2000, 177.7778, 240.0000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2056], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[246.8000, 265.2444, 280.8000, 342.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([984], device='cuda:0')}, {'boxes': tensor([[109.6000, 164.2667, 284.8000, 351.2889],\n",
      "        [149.6000, 246.0444, 232.8000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22], device='cuda:0'), 'image_id': tensor([520], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 67.2000, 224.7111, 509.8667, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([240], device='cuda:0')}, {'boxes': tensor([[286.0000, 182.0444, 511.2000, 483.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1285], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 45.2000, 178.4889, 366.0000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1385], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1253], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[186.8000,  22.7556, 322.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1050], device='cuda:0')}, {'boxes': tensor([[  0.0000,   2.1333, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([798], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 198.4000, 175.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([499], device='cuda:0')}, {'boxes': tensor([[122.8000, 228.9778, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1154], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 195.5556, 317.6000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([80], device='cuda:0')}, {'boxes': tensor([[135.2000,  32.7111, 396.0000, 384.0000],\n",
      "        [116.8000, 257.4222, 168.0000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([505], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.6000, 206.9333, 290.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([75], device='cuda:0')}, {'boxes': tensor([[130.0000, 177.7778, 429.2000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([281], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[129.2000,   0.0000, 400.4000, 304.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([820], device='cuda:0')}, {'boxes': tensor([[  0.0000, 240.3556, 510.9333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([251], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.4507,   0.0000, 508.3944, 308.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1483], device='cuda:0')}, {'boxes': tensor([[152.0000,  56.8889, 204.8000, 123.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1175], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[148.0000, 275.9111, 165.6000, 381.1555],\n",
      "        [188.0000, 275.9111, 206.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([770], device='cuda:0')}, {'boxes': tensor([[ 53.3333,  76.8000, 236.8000, 297.2444],\n",
      "        [219.7333,   0.0000, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1082], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[273.6000, 226.1333, 304.8000, 299.3778],\n",
      "        [352.0000, 324.2667, 401.6000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([883], device='cuda:0')}, {'boxes': tensor([[196.0000, 322.1333, 363.2000, 510.5778],\n",
      "        [ 67.2000, 330.6667, 374.4000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([555], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  23.4667, 509.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([802], device='cuda:0')}, {'boxes': tensor([[103.4667,  78.2222, 413.8667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1690], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 82.4000, 192.0000, 231.6000, 374.0444],\n",
      "        [276.8000, 172.8000, 424.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([1094], device='cuda:0')}, {'boxes': tensor([[300.8000, 405.3333, 428.0000, 500.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000,  39.8222, 339.6000, 364.8000],\n",
      "        [130.0000, 261.6889, 139.2000, 292.9778],\n",
      "        [123.6000, 257.4222, 132.0000, 293.6889],\n",
      "        [334.0000, 244.6222, 369.2000, 309.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1015], device='cuda:0')}, {'boxes': tensor([[  0.0000, 222.5778, 126.8000, 509.8667],\n",
      "        [164.4000, 151.4667, 240.0000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([495], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 157.8667, 433.6000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1304], device='cuda:0')}, {'boxes': tensor([[290.0000, 199.1111, 317.6000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1445], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 128.0000, 350.8000, 296.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([7], device='cuda:0')}, {'boxes': tensor([[172.0000, 198.4000, 342.4000, 393.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[236.8000,  75.3778, 418.0000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([823], device='cuda:0')}, {'boxes': tensor([[ 20.4000,  12.8000, 506.4000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1579], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[210.0000, 125.1556, 508.4000, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([998], device='cuda:0')}, {'boxes': tensor([[152.8000, 105.9556, 317.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([863], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 171.3778, 302.4000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([114], device='cuda:0')}, {'boxes': tensor([[228.8000, 122.3111, 510.4000, 484.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2164], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 179.2000, 499.2000, 375.4667],\n",
      "        [ 25.6000, 123.7333, 139.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1640], device='cuda:0')}, {'boxes': tensor([[341.7248, 234.6667, 510.2385, 437.3333],\n",
      "        [  7.6330, 270.9333, 236.0367, 425.6000],\n",
      "        [ 17.0275, 130.1333, 473.8349, 394.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 6], device='cuda:0'), 'image_id': tensor([482], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 448.8000, 440.8889],\n",
      "        [238.4000, 103.8222, 511.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1643], device='cuda:0')}, {'boxes': tensor([[138.6667,   0.0000, 493.8667, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1709], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.4000,  96.7111, 284.4000, 477.8667],\n",
      "        [215.2000, 163.5556, 305.6000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1528], device='cuda:0')}, {'boxes': tensor([[104.4000, 234.6667, 317.6000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1156], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[182.0000, 188.4444, 448.0000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([588], device='cuda:0')}, {'boxes': tensor([[179.6000, 153.6000, 307.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1844], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.8000,  62.5778, 229.6000, 484.9778],\n",
      "        [242.4000, 115.2000, 389.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1429], device='cuda:0')}, {'boxes': tensor([[128.4000, 244.6222, 301.2000, 480.0000],\n",
      "        [ 19.6000, 218.3111, 333.6000, 431.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([559], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.8000, 200.5333, 210.4000, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([937], device='cuda:0')}, {'boxes': tensor([[102.4000, 106.6667, 511.2000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([734], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000,  62.5778, 292.0000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([836], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 3.9822e+01, 2.8640e+02, 4.6649e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([299], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 155.7333, 417.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1033], device='cuda:0')}, {'boxes': tensor([[ 54.4000,  54.0444, 289.0667, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1503], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[199.6330, 184.5333, 304.7339, 322.1333],\n",
      "        [  2.3486, 320.0000, 509.0642, 508.8000],\n",
      "        [291.2294, 295.4667, 509.6514, 450.1333],\n",
      "        [  0.0000, 187.7333, 150.8991, 440.5333],\n",
      "        [135.0459, 291.2000, 182.0183, 336.0000],\n",
      "        [137.3945, 276.2667, 187.8899, 324.2667],\n",
      "        [343.4862, 272.0000, 404.5504, 301.8667],\n",
      "        [320.0000, 273.0667, 354.0551, 308.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([456], device='cuda:0')}, {'boxes': tensor([[ 99.2000, 115.9111, 353.2000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([104], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[231.6000, 108.8000, 384.8000, 413.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1791], device='cuda:0')}, {'boxes': tensor([[265.2000, 389.6889, 291.2000, 465.0667],\n",
      "        [242.0000, 294.4000, 266.8000, 369.0667],\n",
      "        [223.2000, 206.9333, 250.4000, 281.6000],\n",
      "        [261.2000, 134.4000, 285.2000, 207.6444],\n",
      "        [297.6000,  79.6444, 323.2000, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([99], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2123], device='cuda:0')}, {'boxes': tensor([[ 52.4000, 118.7556, 460.0000, 445.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1202], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[422.4000, 156.4444, 497.0667, 216.1778],\n",
      "        [ 76.8000, 223.2889, 189.8667, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1704], device='cuda:0')}, {'boxes': tensor([[  0.0000, 220.4444, 332.4000, 509.1555],\n",
      "        [320.8000, 351.2889, 412.8000, 411.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1249], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 214.7556, 296.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1392], device='cuda:0')}, {'boxes': tensor([[183.1927, 103.4667, 452.6972, 409.6000],\n",
      "        [ 25.2477, 246.4000, 170.2752, 420.2667],\n",
      "        [ 75.7431,  86.4000, 131.5229, 138.6667],\n",
      "        [124.4771,  96.0000, 190.2385, 151.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([432], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[296.4632, 166.4000, 485.9593, 313.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1972], device='cuda:0')}, {'boxes': tensor([[174.4000, 190.5778, 250.0000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1247], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8000, 268.8000, 141.2000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([523], device='cuda:0')}, {'boxes': tensor([[171.2000,  32.7111, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1313], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 79.6000,  81.7778, 484.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1198], device='cuda:0')}, {'boxes': tensor([[ 94.4000,   5.6889, 504.8000, 401.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([319], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[167.2000, 142.2222, 340.4000, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([634], device='cuda:0')}, {'boxes': tensor([[128.0000,  65.4222, 212.4000, 460.0889],\n",
      "        [236.8000, 128.7111, 357.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1186], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[411.6000, 246.0444, 509.6000, 315.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([533], device='cuda:0')}, {'boxes': tensor([[  0.4000, 108.0889, 302.0000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([727], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,  73.9556, 449.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1122], device='cuda:0')}, {'boxes': tensor([[ 34.4000,  22.7556, 472.0000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([220], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 99.2000, 104.5333, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1284], device='cuda:0')}, {'boxes': tensor([[104.0000, 160.0000, 385.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1301], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.4000, 286.5778, 279.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([981], device='cuda:0')}, {'boxes': tensor([[ 65.0667, 315.7333, 196.2667, 433.7778],\n",
      "        [377.6000, 301.5111, 438.4000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([705], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[275.2000, 125.1556, 385.0667, 194.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1588], device='cuda:0')}, {'boxes': tensor([[174.9333, 109.5111, 245.3333, 228.9778],\n",
      "        [326.4000, 152.1778, 385.0667, 227.5556],\n",
      "        [290.1333,  52.6222, 309.3333,  71.1111],\n",
      "        [343.4667,  65.4222, 362.6667,  83.9111],\n",
      "        [457.6000,  65.4222, 480.0000,  83.9111],\n",
      "        [155.7333,  68.2667, 177.0667,  92.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([360], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[190.4000, 223.2889, 252.8000, 296.5333],\n",
      "        [298.4000, 255.2889, 354.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([884], device='cuda:0')}, {'boxes': tensor([[168.8000, 250.3111, 198.4000, 381.1555],\n",
      "        [251.2000, 251.7333, 273.6000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([763], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.2231e+02, 4.2720e+02, 3.1929e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([730], device='cuda:0')}, {'boxes': tensor([[120.8000, 169.2444, 211.6000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([860], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 25.6000, 128.0000, 107.2000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1136], device='cuda:0')}, {'boxes': tensor([[189.6000, 200.5333, 414.4000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2157], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[4.0000e-01, 1.7280e+02, 4.1440e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([740], device='cuda:0')}, {'boxes': tensor([[238.0000, 103.1111, 350.4000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1532], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.2000, 146.4889, 288.4000, 347.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1335], device='cuda:0')}, {'boxes': tensor([[100.4000, 244.6222, 313.6000, 387.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1161], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 204.8000, 174.9333, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1370], device='cuda:0')}, {'boxes': tensor([[142.9333, 221.8667, 509.8667, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([233], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[393.3945, 314.6667, 510.2385, 504.5333],\n",
      "        [  0.5872, 265.6000,  86.3119, 423.4667],\n",
      "        [252.4771, 203.7333, 396.3303, 487.4667],\n",
      "        [273.0275, 308.2667, 428.0367, 504.5333],\n",
      "        [126.8257, 251.7333, 207.2661, 361.6000],\n",
      "        [395.7431, 272.0000, 473.8349, 344.5333],\n",
      "        [ 61.6514, 269.8667, 154.4220, 405.3333],\n",
      "        [  0.0000, 214.4000,  95.1193, 281.6000],\n",
      "        [137.9817, 246.4000, 227.2294, 344.5333],\n",
      "        [  0.5872, 315.7333,  34.6422, 430.9333],\n",
      "        [193.7615, 113.0667, 487.9266, 397.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([448], device='cuda:0')}, {'boxes': tensor([[154.0000, 157.8667, 290.0000, 278.7556],\n",
      "        [ 26.8000, 184.1778,  66.8000, 218.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1464], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[116.0000,   3.5556, 497.2000, 476.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([289], device='cuda:0')}, {'boxes': tensor([[174.8000, 224.7111, 342.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([919], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 192.0000, 243.2000, 413.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([401], device='cuda:0')}, {'boxes': tensor([[ 98.1333,  49.7778, 320.0000, 278.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([722], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 318.4000, 510.5778],\n",
      "        [302.4000, 228.9778, 466.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1632], device='cuda:0')}, {'boxes': tensor([[152.4000,   0.0000, 510.0000, 475.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1311], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 56.8000, 113.7778, 455.6000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1200], device='cuda:0')}, {'boxes': tensor([[128.4000,  55.4667, 336.8000, 507.7333],\n",
      "        [  0.0000,   0.0000, 176.0000, 391.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1664], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[1.2680e+02, 2.1049e+02, 2.5400e+02, 3.5129e+02],\n",
      "        [4.0000e-01, 1.5502e+02, 1.1800e+02, 2.8302e+02],\n",
      "        [2.2560e+02, 1.1591e+02, 3.0800e+02, 2.4604e+02],\n",
      "        [1.1160e+02, 2.6169e+02, 2.5520e+02, 4.4871e+02],\n",
      "        [3.5680e+02, 2.6169e+02, 4.9640e+02, 4.4231e+02],\n",
      "        [4.2760e+02, 2.1120e+02, 5.1080e+02, 3.1644e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8, 8, 8, 8], device='cuda:0'), 'image_id': tensor([638], device='cuda:0')}, {'boxes': tensor([[210.4000, 132.2667, 312.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([81], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[281.2000, 145.7778, 378.0000, 224.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([127], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([13], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.6000, 118.7556, 282.0000, 157.8667],\n",
      "        [250.8000, 171.3778, 270.8000, 211.9111],\n",
      "        [239.6000, 241.0667, 260.0000, 278.0444],\n",
      "        [226.8000, 309.3333, 248.0000, 347.0222],\n",
      "        [218.8000, 369.7778, 240.0000, 406.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([144], device='cuda:0')}, {'boxes': tensor([[ 52.2667, 258.8445, 180.2667, 378.3111],\n",
      "        [355.2000, 244.6222, 426.6667, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([698], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 203.3778,  90.6667, 509.1555],\n",
      "        [145.0667,  93.8667, 336.0000, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([602], device='cuda:0')}, {'boxes': tensor([[161.6000, 146.4889, 235.2000, 362.6667],\n",
      "        [227.2000,  48.3556, 410.4000, 359.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1231], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 274.4889, 230.4000, 477.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2002], device='cuda:0')}, {'boxes': tensor([[  4.2667, 302.9333, 245.3333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2122], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  4.8000,   9.9556, 506.0000, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([284], device='cuda:0')}, {'boxes': tensor([[ 65.0667, 312.8889, 196.2667, 433.7778],\n",
      "        [376.5333, 294.4000, 439.4667, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([707], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 128.0000, 507.2000, 496.3556],\n",
      "        [165.6000,   0.0000, 316.8000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1611], device='cuda:0')}, {'boxes': tensor([[119.2000,  54.0444, 336.0000, 353.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([825], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1512], device='cuda:0')}, {'boxes': tensor([[123.7333,  69.6889, 331.7333, 352.7111],\n",
      "        [292.2667,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1080], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000, 135.1111, 334.4000, 425.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1762], device='cuda:0')}, {'boxes': tensor([[201.2000,  85.3333, 408.8000, 289.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1982], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2000,  81.0667, 337.6000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([65], device='cuda:0')}, {'boxes': tensor([[ 95.7630,  79.6444, 476.9185, 403.9111],\n",
      "        [164.9778, 318.5778, 255.0518, 401.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([180], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[141.2741,  98.1333, 475.0222, 378.3111],\n",
      "        [201.0074, 314.3111, 300.5630, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27, 27], device='cuda:0'), 'image_id': tensor([185], device='cuda:0')}, {'boxes': tensor([[184.5333,   9.9556, 375.4667, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([593], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[241.0667, 118.0444, 492.8000, 467.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([663], device='cuda:0')}, {'boxes': tensor([[168.5333, 267.3778, 181.3333, 281.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2114], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 88.0000,  41.2444, 356.0000, 472.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([63], device='cuda:0')}, {'boxes': tensor([[106.4000, 189.1555, 275.6000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2060], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[170.6667, 166.4000, 324.2667, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([719], device='cuda:0')}, {'boxes': tensor([[ 78.0000, 128.7111, 454.8000, 460.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([278], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [164.8000, 156.4444, 210.0000, 242.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1402], device='cuda:0')}, {'boxes': tensor([[  9.6000, 278.0444, 352.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([47], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.6000, 155.0222, 277.6000, 369.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2039], device='cuda:0')}, {'boxes': tensor([[345.6000,   0.0000, 510.4000, 509.1555],\n",
      "        [179.2000,  79.6444, 496.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15, 15], device='cuda:0'), 'image_id': tensor([1236], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000,   0.0000, 430.8000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1438], device='cuda:0')}, {'boxes': tensor([[307.2000,  51.2000, 451.2000, 250.3111],\n",
      "        [164.8000,  62.5778, 300.0000, 261.6889],\n",
      "        [ 97.6000, 109.5111, 250.4000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2], device='cuda:0'), 'image_id': tensor([1759], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[133.6000, 130.8445, 193.6000, 247.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2151], device='cuda:0')}, {'boxes': tensor([[237.2000, 117.3333, 388.8000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1790], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 159.2889, 342.0000, 354.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([745], device='cuda:0')}, {'boxes': tensor([[ 92.8000,   9.2444, 450.8000, 489.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([292], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.8000, 115.2000, 365.8667, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1473], device='cuda:0')}, {'boxes': tensor([[218.8000, 258.8445, 510.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1221], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[235.2000,  78.2222, 448.8000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1681], device='cuda:0')}, {'boxes': tensor([[222.8148, 237.5111, 250.3111, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([165], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[345.6000, 354.1333, 364.0000, 428.0889],\n",
      "        [288.0000, 393.9556, 305.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([772], device='cuda:0')}, {'boxes': tensor([[  8.4000,  18.4889, 311.2000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1799], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.8000, 193.4222, 223.2000, 232.5333],\n",
      "        [276.4000, 208.3556, 319.2000, 273.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([847], device='cuda:0')}, {'boxes': tensor([[243.2000, 136.5333, 509.6000, 502.0444],\n",
      "        [  0.0000,   0.0000, 265.6000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1621], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.6000, 143.6444, 250.8000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2036], device='cuda:0')}, {'boxes': tensor([[208.0000, 238.9333, 441.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1914], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 197.6889,  91.7333, 509.1555],\n",
      "        [151.4667,  82.4889, 340.2667, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([600], device='cuda:0')}, {'boxes': tensor([[200.4000,  86.0444, 323.6000, 364.0889],\n",
      "        [402.4000, 279.4667, 414.0000, 311.4667],\n",
      "        [427.2000, 275.9111, 436.8000, 312.8889],\n",
      "        [496.0000, 265.2444, 511.2000, 320.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([1008], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 224.0000, 342.4000, 510.5778],\n",
      "        [339.2000, 351.2889, 414.4000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1251], device='cuda:0')}, {'boxes': tensor([[  9.6000,  49.0667, 345.6000, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1546], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 270.2222, 487.4667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([236], device='cuda:0')}, {'boxes': tensor([[ 26.6667,   0.0000, 285.8667, 405.8074]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1254], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[103.2000, 201.9556, 281.6000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([927], device='cuda:0')}, {'boxes': tensor([[188.8000, 202.6667, 325.2000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1598], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 256.0000, 259.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1036], device='cuda:0')}, {'boxes': tensor([[206.0000,  65.4222, 322.0000, 405.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([837], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000, 167.1111, 388.0000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([279], device='cuda:0')}, {'boxes': tensor([[268.4000, 137.2444, 398.0000, 374.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([421], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[112.8296, 160.7111, 263.5852, 275.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([188], device='cuda:0')}, {'boxes': tensor([[113.6000, 204.8000, 288.8000, 403.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([926], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[259.2000, 216.1778, 326.8000, 286.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([130], device='cuda:0')}, {'boxes': tensor([[ 71.6000, 204.8000, 396.0000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([651], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 24.0000, 217.6000, 508.8000, 506.3111],\n",
      "        [  0.0000,   0.0000, 274.4000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1644], device='cuda:0')}, {'boxes': tensor([[ 85.6000,  90.2295, 257.6000, 489.9672]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([959], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[260.8000, 110.9333, 420.0000, 427.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1795], device='cuda:0')}, {'boxes': tensor([[118.4000, 290.1333, 231.2000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([2006], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[341.2000, 354.8445, 492.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([16], device='cuda:0'), 'image_id': tensor([1495], device='cuda:0')}, {'boxes': tensor([[257.2000,  96.0000, 392.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1440], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[120.8000, 179.2000, 257.2000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2037], device='cuda:0')}, {'boxes': tensor([[ 57.6000, 271.6444, 185.6000, 309.3333],\n",
      "        [237.2000, 275.2000, 361.2000, 325.6889],\n",
      "        [321.2000, 271.6444, 368.8000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29, 29], device='cuda:0'), 'image_id': tensor([528], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 109.5111, 509.2000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([993], device='cuda:0')}, {'boxes': tensor([[158.0000,   3.5556, 502.8000, 486.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([308], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.8000,  66.8444, 447.2000, 299.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([108], device='cuda:0')}, {'boxes': tensor([[299.4496, 126.9333, 442.1284, 364.8000],\n",
      "        [ 47.5596, 105.6000, 105.1009, 153.6000],\n",
      "        [ 98.0550, 118.4000, 162.6422, 170.6667],\n",
      "        [159.7064, 124.8000, 236.0367, 179.2000],\n",
      "        [  5.2844, 272.0000, 143.8532, 486.4000],\n",
      "        [ 63.4128, 122.6667, 142.6789, 185.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([438], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,   1.4222, 324.2667, 457.9556],\n",
      "        [412.8000, 108.0889, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([605], device='cuda:0')}, {'boxes': tensor([[203.2000,  47.6444, 371.6000, 325.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([827], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.8000, 226.8445, 288.4000, 282.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1926], device='cuda:0')}, {'boxes': tensor([[123.2000, 133.6889, 510.0000, 406.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([589], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 256.0000, 162.0000, 507.7333],\n",
      "        [ 75.2000,  68.2667, 144.8000, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 24], device='cuda:0'), 'image_id': tensor([503], device='cuda:0')}, {'boxes': tensor([[ 55.2000, 130.1333, 458.4000, 439.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1201], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000,  73.9556, 510.4000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2153], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 280.1778, 193.2000, 352.7111],\n",
      "        [214.0000, 271.6444, 300.8000, 339.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1823], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 105.9556, 263.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1899], device='cuda:0')}, {'boxes': tensor([[  0.0000, 196.2667, 293.2000, 420.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1391], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000,  83.2000, 452.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1833], device='cuda:0')}, {'boxes': tensor([[217.2000,  66.8444, 371.2000, 383.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([1545], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[163.2294, 100.2667, 452.6972, 424.5333],\n",
      "        [457.3945,  75.7333, 489.6881, 171.7333],\n",
      "        [  0.5872, 272.0000,  71.6330, 504.5333],\n",
      "        [ 88.6606,  86.4000, 146.7890, 141.8667],\n",
      "        [136.8073,  94.9333, 195.5229, 149.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([431], device='cuda:0')}, {'boxes': tensor([[148.8000,   0.0000, 274.4000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([415], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.0000, 199.8222, 336.8000, 297.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([162], device='cuda:0')}, {'boxes': tensor([[ 66.9358, 170.6667, 374.0183, 359.4667],\n",
      "        [154.4220, 321.0667, 510.2385, 508.8000],\n",
      "        [  0.5872, 300.8000,  62.2385, 442.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 6,  7, 19], device='cuda:0'), 'image_id': tensor([483], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.2676, 179.2000, 511.1988, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1973], device='cuda:0')}, {'boxes': tensor([[159.7064, 119.4667, 417.4679, 430.9333],\n",
      "        [416.2936,  82.1333, 449.1743, 188.8000],\n",
      "        [ 46.9725,  98.1333, 104.5138, 162.1333],\n",
      "        [ 97.4679, 112.0000, 166.1651, 166.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6, 7, 7, 7], device='cuda:0'), 'image_id': tensor([437], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.6000, 100.9778, 246.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1857], device='cuda:0')}, {'boxes': tensor([[132.2667, 240.3556, 169.6000, 288.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1708], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.8000,  12.0889, 510.8000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([571], device='cuda:0')}, {'boxes': tensor([[116.4000, 223.2889, 253.6000, 466.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([22], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 162.8445, 147.2000, 338.4889],\n",
      "        [132.8000, 157.1555, 323.7333, 373.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([56], device='cuda:0')}, {'boxes': tensor([[160.4000,  64.0000, 509.6000, 492.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([986], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[115.2000, 177.7778, 200.5333, 206.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2136], device='cuda:0')}, {'boxes': tensor([[198.8000,  88.1778, 331.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1459], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[143.2000,   0.0000, 312.0000, 372.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1079], device='cuda:0')}, {'boxes': tensor([[217.6000, 200.5333, 427.2000, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1678], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[135.2000, 162.1333, 314.4000, 354.1333],\n",
      "        [354.0000, 266.6667, 392.0000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1553], device='cuda:0')}, {'boxes': tensor([[188.4000, 185.6000, 256.8000, 252.4444],\n",
      "        [241.6000, 263.1111, 263.2000, 298.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([1656], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[373.1831,   0.0000, 510.1972, 305.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([6], device='cuda:0'), 'image_id': tensor([1487], device='cuda:0')}, {'boxes': tensor([[204.8000,   0.0000, 381.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([616], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[225.6000, 113.7778, 402.8000, 408.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([377], device='cuda:0')}, {'boxes': tensor([[  0.4000,  76.8000, 218.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([370], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[146.4000, 228.2667, 470.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([1104], device='cuda:0')}, {'boxes': tensor([[204.0000, 193.4222, 349.6000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([126], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[102.4000,  47.6444, 511.2000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([751], device='cuda:0')}, {'boxes': tensor([[140.8000, 169.9556, 176.8000, 221.8667],\n",
      "        [ 67.2000, 217.6000,  91.6000, 297.2444],\n",
      "        [158.8000,  71.8222, 176.8000, 106.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8, 8], device='cuda:0'), 'image_id': tensor([623], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[221.6000,  85.3333, 329.2000, 312.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([835], device='cuda:0')}, {'boxes': tensor([[108.9362,   0.0000, 183.8298, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1090], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[156.8000,  78.2222, 391.2000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1820], device='cuda:0')}, {'boxes': tensor([[164.0000, 230.4000, 260.0000, 348.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1958], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 216.8889, 345.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([921], device='cuda:0')}, {'boxes': tensor([[128.0000, 214.7556, 340.8000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1170], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[174.0000, 206.9333, 220.8000, 226.1333],\n",
      "        [455.6000, 199.1111, 490.4000, 211.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([525], device='cuda:0')}, {'boxes': tensor([[109.6000, 204.8000, 337.6000, 477.8667],\n",
      "        [  0.0000,  68.2667,  52.8000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1766], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.1333, 253.1555, 184.5333, 392.5333],\n",
      "        [421.3333, 201.9556, 491.7333, 257.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([695], device='cuda:0')}, {'boxes': tensor([[ 25.6000, 315.7333, 188.8000, 392.5333],\n",
      "        [371.2000, 257.4222, 509.8667, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([693], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[237.2000, 179.9111, 303.2000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([76], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.8667, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1492], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[233.6000, 184.8889, 339.2000, 447.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2180], device='cuda:0')}, {'boxes': tensor([[182.0000, 145.0667, 321.2000, 359.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([396], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 29.8667,  32.7111, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1941], device='cuda:0')}, {'boxes': tensor([[248.8000,  88.1778, 505.6000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([324], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 32.0000,  78.9333, 300.8000, 379.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1044], device='cuda:0')}, {'boxes': tensor([[147.2000,  96.7111, 305.6000, 501.3333],\n",
      "        [255.2000,  16.3556, 416.4000, 351.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1123], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[403.2000, 242.4889, 510.4000, 506.3111],\n",
      "        [132.8000,  81.7778, 487.6000, 419.5555],\n",
      "        [ 56.0000,  56.8889, 133.6000, 146.4889],\n",
      "        [ 22.0000,  80.3556,  57.6000, 132.2667],\n",
      "        [229.6000,  46.2222, 385.2000, 123.7333],\n",
      "        [  0.0000,  68.9778,  28.8000, 153.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 7], device='cuda:0'), 'image_id': tensor([1801], device='cuda:0')}, {'boxes': tensor([[348.8000, 128.0000, 510.9333, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1727], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[192.0000,  11.3778, 468.2667, 250.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1723], device='cuda:0')}, {'boxes': tensor([[329.7152,  10.6667, 511.1988, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1975], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[38.4000, 11.3778, 96.4000, 86.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([1837], device='cuda:0')}, {'boxes': tensor([[ 92.8000, 206.2222, 258.1333, 361.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([686], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[254.8000, 269.5111, 276.0000, 320.7111],\n",
      "        [260.0000, 222.5778, 280.4000, 276.6222],\n",
      "        [266.8000, 171.3778, 287.6000, 223.2889],\n",
      "        [240.0000, 139.3778, 259.2000, 189.8667],\n",
      "        [213.2000, 115.2000, 233.2000, 168.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([142], device='cuda:0')}, {'boxes': tensor([[221.6000, 223.2889, 320.4000, 280.1778],\n",
      "        [388.8000,  91.7333, 410.0000, 145.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24], device='cuda:0'), 'image_id': tensor([1890], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 105.9556, 348.8000, 453.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2144], device='cuda:0')}, {'boxes': tensor([[304.0000, 191.2889, 470.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1292], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 77.6000,   0.0000, 232.0000, 159.2889],\n",
      "        [211.2000,   0.0000, 364.0000, 156.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1749], device='cuda:0')}, {'boxes': tensor([[ 68.2667, 317.1555, 200.5333, 435.2000],\n",
      "        [379.7333, 300.0889, 442.6667, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([713], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000,  86.7556, 489.2000, 443.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1195], device='cuda:0')}, {'boxes': tensor([[205.2000,  59.0222, 410.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([824], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[153.6000,  93.1556, 462.8000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2194], device='cuda:0')}, {'boxes': tensor([[ 60.7677, 246.3030, 159.0303, 434.4243]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2021], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000,   8.5333, 458.4000, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([2149], device='cuda:0')}, {'boxes': tensor([[270.4000, 347.7333, 320.0000, 408.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([19], device='cuda:0'), 'image_id': tensor([795], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[208.0000, 192.0000, 511.2000, 367.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([575], device='cuda:0')}, {'boxes': tensor([[  0.0000,  32.7111, 511.2000, 382.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2084], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[250.4000, 273.7778, 281.6000, 340.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([983], device='cuda:0')}, {'boxes': tensor([[380.8000, 151.4667, 438.4000, 214.7556],\n",
      "        [274.4000, 167.1111, 328.8000, 223.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8, 8], device='cuda:0'), 'image_id': tensor([629], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  99.5556, 163.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([211], device='cuda:0')}, {'boxes': tensor([[107.2000, 109.5111, 511.2000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([732], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.6000, 171.3778, 310.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([809], device='cuda:0')}, {'boxes': tensor([[153.6000, 196.9778, 315.6000, 354.8445],\n",
      "        [354.8000, 294.4000, 376.0000, 343.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1552], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[135.2000,  32.7111, 396.0000, 384.0000],\n",
      "        [119.2000, 261.6889, 172.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2, 20], device='cuda:0'), 'image_id': tensor([506], device='cuda:0')}, {'boxes': tensor([[123.2000,   1.4222, 510.8000, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([309], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[149.2000,   0.7111, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([640], device='cuda:0')}, {'boxes': tensor([[231.2000, 263.1111, 275.2000, 463.6444],\n",
      "        [328.8000, 264.5333, 395.2000, 509.1555],\n",
      "        [156.8000, 256.0000, 196.0000, 415.2889],\n",
      "        [284.0000, 250.3111, 312.0000, 371.2000],\n",
      "        [ 13.6000, 312.8889, 130.4000, 507.7333],\n",
      "        [483.2000, 334.2222, 511.2000, 507.7333],\n",
      "        [469.6000, 297.2444, 496.0000, 415.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1764], device='cuda:0')}, {'boxes': tensor([[206.0000, 216.8889, 511.2000, 506.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1222], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[220.4000, 227.5556, 251.6000, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1239], device='cuda:0')}, {'boxes': tensor([[136.0000, 162.1333, 262.4000, 374.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([930], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[152.0000, 104.5333, 372.4000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([78], device='cuda:0')}, {'boxes': tensor([[221.8667, 234.6667, 251.2593, 258.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([166], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  8.5333, 182.0444, 299.7333, 449.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([195], device='cuda:0')}, {'boxes': tensor([[ 59.7333,  27.0222, 360.5333, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1721], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 124.4444, 302.0000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1003], device='cuda:0')}, {'boxes': tensor([[219.7333,  76.8000, 509.8667, 484.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([664], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.7333, 143.6444,  87.4667, 223.2889],\n",
      "        [338.1333, 169.2444, 474.6667, 345.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([680], device='cuda:0')}, {'boxes': tensor([[219.7333, 203.3778, 358.4000, 243.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667,  11.3778, 380.8000, 428.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([592], device='cuda:0')}, {'boxes': tensor([[190.4000, 159.2889, 272.0000, 354.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1128], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 62.4000,   0.0000, 511.2000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([1633], device='cuda:0')}, {'boxes': tensor([[122.8000, 157.8667, 310.4000, 362.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([744], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 83.2000, 200.5333, 363.2000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1267], device='cuda:0')}, {'boxes': tensor([[155.2340,  41.2444, 332.2553, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1087], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[348.8000, 473.6000, 389.6000, 510.5778],\n",
      "        [187.6000, 258.1333, 203.6000, 293.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24,  9], device='cuda:0'), 'image_id': tensor([1871], device='cuda:0')}, {'boxes': tensor([[166.4000, 185.6000, 288.4000, 346.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1967], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.0000, 199.8222, 316.8000, 289.4222],\n",
      "        [ 60.4000, 226.1333, 197.6000, 337.0667],\n",
      "        [202.0000, 252.4444, 338.4000, 400.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([1577], device='cuda:0')}, {'boxes': tensor([[188.4000, 199.8222, 296.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1891], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 78.0881,   0.0000, 322.8176, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1027], device='cuda:0')}, {'boxes': tensor([[  0.0000, 251.7333, 179.2000, 503.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1035], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.0000,  93.1556, 432.0000, 410.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([394], device='cuda:0')}, {'boxes': tensor([[240.8000, 192.0000, 291.2000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1886], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[212.3852, 204.8000, 343.2296, 302.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([186], device='cuda:0')}, {'boxes': tensor([[125.6000,  97.4222, 285.6000, 370.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1852], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 23.4667, 260.2667, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([245], device='cuda:0')}, {'boxes': tensor([[224.8000, 243.2000, 273.2000, 291.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([737], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.6000, 148.6222, 280.8000, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1887], device='cuda:0')}, {'boxes': tensor([[360.0000, 209.0667, 444.0000, 504.8889],\n",
      "        [164.0000, 240.3556, 268.0000, 509.1555],\n",
      "        [  0.0000, 237.5111,  88.8000, 507.7333],\n",
      "        [324.8000, 164.9778, 343.2000, 317.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([773], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 76.8000,   0.0000, 268.8000, 455.1111],\n",
      "        [267.2000, 388.2667, 510.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1627], device='cuda:0')}, {'boxes': tensor([[227.2000, 156.4444, 308.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1997], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.6000, 166.4000, 411.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([31], device='cuda:0')}, {'boxes': tensor([[171.2000,  91.7333, 280.8000, 473.6000],\n",
      "        [215.2000, 157.8667, 305.6000, 438.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1527], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[238.8000,  61.8667, 340.4000, 386.8445],\n",
      "        [322.0000, 138.6667, 362.4000, 358.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1538], device='cuda:0')}, {'boxes': tensor([[188.0000, 244.6222, 236.0000, 337.0667],\n",
      "        [324.4000, 240.3556, 402.8000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1563], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[198.4000, 218.3111, 232.4000, 263.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([856], device='cuda:0')}, {'boxes': tensor([[205.8667, 209.0667, 355.2000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2106], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[132.8000, 221.3770, 201.6000, 386.0984],\n",
      "        [348.8000, 287.4754, 480.8000, 454.2951],\n",
      "        [304.8000, 347.2787, 357.6000, 430.1639],\n",
      "        [314.4000,   0.0000, 372.0000,  64.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5, 5, 5], device='cuda:0'), 'image_id': tensor([966], device='cuda:0')}, {'boxes': tensor([[ 26.8000,   0.0000, 460.8000, 494.2222],\n",
      "        [205.2000,  62.5778, 339.2000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1666], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[379.6000, 275.2000, 450.8000, 349.8667],\n",
      "        [260.0000, 156.4444, 356.8000, 258.8445],\n",
      "        [179.2000, 110.9333, 274.4000, 216.8889],\n",
      "        [296.4000, 227.5556, 393.2000, 325.6889],\n",
      "        [428.0000, 364.8000, 450.8000, 398.9333],\n",
      "        [219.6000, 174.2222, 315.6000, 275.2000],\n",
      "        [351.2000, 228.2667, 445.6000, 323.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([87], device='cuda:0')}, {'boxes': tensor([[192.0000, 257.4222, 221.8667, 275.9111],\n",
      "        [311.4667, 250.3111, 426.6667, 267.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29, 29], device='cuda:0'), 'image_id': tensor([2112], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  9.2000,  47.6444, 510.8000, 423.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([378], device='cuda:0')}, {'boxes': tensor([[262.8000, 133.6889, 379.6000, 341.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([657], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[299.2000, 189.1555, 336.0000, 234.6667],\n",
      "        [288.8000, 219.0222, 322.0000, 261.6889],\n",
      "        [241.6000, 211.2000, 272.4000, 260.9778],\n",
      "        [213.6000, 256.0000, 248.8000, 301.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([151], device='cuda:0')}, {'boxes': tensor([[ 35.2294, 256.0000, 169.1009, 406.4000],\n",
      "        [343.4862, 185.6000, 489.6881, 475.7333],\n",
      "        [365.2110, 292.2667, 510.2385, 506.6667],\n",
      "        [ 39.3395, 268.8000, 126.2385, 416.0000],\n",
      "        [  0.0000, 265.6000,  75.1560, 437.3333],\n",
      "        [182.0183,  78.9333, 502.0183, 404.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7, 7, 7, 7, 6], device='cuda:0'), 'image_id': tensor([450], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[124.4000, 136.5333, 308.0000, 268.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([215], device='cuda:0')}, {'boxes': tensor([[ 62.4000, 159.2889, 444.8000, 332.0889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([155], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 48.8000, 102.4000, 390.8000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([643], device='cuda:0')}, {'boxes': tensor([[236.0000, 364.8000, 293.6000, 463.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1888], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 46.0000, 108.0889, 165.6000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1259], device='cuda:0')}, {'boxes': tensor([[270.9333, 209.0667, 464.0000, 221.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([29], device='cuda:0'), 'image_id': tensor([2102], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1106], device='cuda:0')}, {'boxes': tensor([[208.8000, 104.5333, 334.8000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1842], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[200.4000, 184.1778, 293.6000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1331], device='cuda:0')}, {'boxes': tensor([[122.4000, 167.8222, 262.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([929], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.7333, 100.9778, 309.3333, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1470], device='cuda:0')}, {'boxes': tensor([[ 26.6667, 157.1555,  72.5333, 307.9111],\n",
      "        [101.3333, 194.8445, 219.7333, 312.8889],\n",
      "        [233.6000, 214.0444, 342.4000, 315.7333],\n",
      "        [408.5333, 209.0667, 461.3333, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30, 30, 30], device='cuda:0'), 'image_id': tensor([59], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 112.3556, 412.8000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1294], device='cuda:0')}, {'boxes': tensor([[188.8000, 285.1555, 269.2000, 366.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1884], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[305.0667, 228.9778, 362.6667, 284.4445],\n",
      "        [ 25.6000, 153.6000,  83.2000, 209.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3, 3], device='cuda:0'), 'image_id': tensor([257], device='cuda:0')}, {'boxes': tensor([[  0.0000,   0.0000, 509.6000, 302.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([2082], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 50.0000,   3.5556, 419.6000, 465.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([293], device='cuda:0')}, {'boxes': tensor([[247.2000, 283.0222, 262.4000, 320.7111],\n",
      "        [216.8000, 252.4444, 234.4000, 292.9778],\n",
      "        [232.4000, 271.6444, 248.8000, 312.1778],\n",
      "        [212.4000, 208.3556, 228.8000, 248.8889],\n",
      "        [243.2000, 247.4667, 260.8000, 288.0000],\n",
      "        [240.0000, 210.4889, 256.4000, 250.3111],\n",
      "        [224.0000, 189.1555, 238.8000, 228.2667],\n",
      "        [208.0000, 174.2222, 224.4000, 216.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([137], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[270.8000,  88.1778, 365.2000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1192], device='cuda:0')}, {'boxes': tensor([[ 53.3333, 263.1111, 183.4667, 382.5778],\n",
      "        [361.6000, 250.3111, 429.8667, 332.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([701], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([955], device='cuda:0')}, {'boxes': tensor([[272.0000,  95.2889, 418.4000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1673], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 57.6000,  76.8000, 236.8000, 312.8889],\n",
      "        [224.0000,   0.0000, 508.8000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1081], device='cuda:0')}, {'boxes': tensor([[116.8000, 151.2727, 307.2000, 269.0909]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1418], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[292.0000, 248.8889, 408.8000, 419.5555],\n",
      "        [  0.0000, 164.9778,  93.6000, 507.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([898], device='cuda:0')}, {'boxes': tensor([[ 14.8000, 164.2667, 189.2000, 324.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1383], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[271.6000,  88.1778, 365.2000, 226.1333],\n",
      "        [139.2000, 105.9556, 177.6000, 187.7333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1191], device='cuda:0')}, {'boxes': tensor([[108.8000,  81.0667, 350.4000, 398.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11], device='cuda:0'), 'image_id': tensor([64], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[253.6000,   0.0000, 384.4000, 231.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([32], device='cuda:0')}, {'boxes': tensor([[ 89.6000,  72.5333, 413.8667, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1693], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.6000, 182.7556, 320.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1965], device='cuda:0')}, {'boxes': tensor([[ 13.6000,   0.0000, 299.2000, 318.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([407], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 90.8000,  73.2444, 372.4000, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1797], device='cuda:0')}, {'boxes': tensor([[ 53.2000, 467.2000, 234.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1163], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[256.0000,  62.5778, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([392], device='cuda:0')}, {'boxes': tensor([[209.6000, 296.5333, 248.8000, 403.2000],\n",
      "        [250.0000, 205.5111, 269.2000, 266.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([832], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[243.6000, 289.4222, 293.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1889], device='cuda:0')}, {'boxes': tensor([[197.6000,  61.8667, 362.8000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([842], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[108.8000, 156.4444, 275.2000, 304.3556],\n",
      "        [174.9333, 244.6222, 411.7333, 412.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5, 5], device='cuda:0'), 'image_id': tensor([2076], device='cuda:0')}, {'boxes': tensor([[216.0000,  47.6444, 458.0000, 438.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([379], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[267.2000, 123.0222, 308.8000, 204.0889],\n",
      "        [347.6000, 204.0889, 398.0000, 292.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([881], device='cuda:0')}, {'boxes': tensor([[ 81.0667,   0.0000, 277.3333, 432.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1255], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 27.6000, 161.4222,  64.0000, 244.6222],\n",
      "        [170.4000, 158.5778, 202.0000, 233.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26, 26], device='cuda:0'), 'image_id': tensor([1399], device='cuda:0')}, {'boxes': tensor([[184.8889, 183.4667, 511.0518, 442.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([174], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000, 432.3556, 181.6000, 509.1555],\n",
      "        [377.6000, 348.4445, 401.6000, 506.3111],\n",
      "        [476.0000, 403.9111, 510.4000, 509.1555],\n",
      "        [200.8000, 440.8889, 324.0000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4, 4], device='cuda:0'), 'image_id': tensor([782], device='cuda:0')}, {'boxes': tensor([[209.6000, 125.1556, 508.4000, 448.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([999], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[100.8000, 223.2889, 308.4000, 375.4667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1167], device='cuda:0')}, {'boxes': tensor([[ 53.2000,  86.7556, 440.0000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([217], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 164.9778, 276.4000, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1956], device='cuda:0')}, {'boxes': tensor([[  0.0000, 123.7333, 297.6000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1945], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([12], device='cuda:0')}, {'boxes': tensor([[128.4000,   0.0000, 510.4000, 457.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([2100], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[185.6000, 193.4222, 254.0000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1892], device='cuda:0')}, {'boxes': tensor([[  0.0000, 258.8445,  76.0000, 405.3333],\n",
      "        [128.0000, 247.4667, 184.0000, 305.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15,  7], device='cuda:0'), 'image_id': tensor([949], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.4000,   0.0000, 261.6000, 509.1555],\n",
      "        [220.8000,   0.0000, 398.8000, 510.5778],\n",
      "        [265.6000, 105.2444, 412.0000, 504.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18], device='cuda:0'), 'image_id': tensor([1661], device='cuda:0')}, {'boxes': tensor([[260.4000, 123.0222, 277.6000, 165.6889],\n",
      "        [244.8000, 176.3556, 262.0000, 216.8889],\n",
      "        [230.4000, 244.6222, 249.6000, 285.1555],\n",
      "        [215.6000, 316.4445, 233.6000, 354.1333],\n",
      "        [204.8000, 379.7333, 222.4000, 419.5555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([143], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[217.6000,   0.0000, 355.2000, 210.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([2073], device='cuda:0')}, {'boxes': tensor([[194.1333, 193.4222, 356.2667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1716], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[453.3333, 288.7111, 510.9333, 337.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1707], device='cuda:0')}, {'boxes': tensor([[ 74.8000,  91.0222, 349.2000, 437.3333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([103], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[242.3787, 161.4222, 494.7731, 307.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1969], device='cuda:0')}, {'boxes': tensor([[  9.6000, 290.1333, 294.4000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1042], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[104.0000,  55.4667, 320.0000, 381.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([1668], device='cuda:0')}, {'boxes': tensor([[ 89.2000, 221.8667, 190.4000, 297.2444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([857], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[189.6000,  28.4444, 315.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([1051], device='cuda:0')}, {'boxes': tensor([[ 75.2000, 329.9556, 189.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([20], device='cuda:0'), 'image_id': tensor([808], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[151.2000, 204.8000, 224.4000, 262.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1465], device='cuda:0')}, {'boxes': tensor([[179.6000, 280.8889, 252.8000, 378.3111],\n",
      "        [ 14.0000, 202.6667, 197.6000, 384.0000],\n",
      "        [139.6000, 278.7556, 226.4000, 385.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([513], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[224.0000,  91.0222, 480.0000, 446.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([662], device='cuda:0')}, {'boxes': tensor([[249.6000, 234.6667, 297.6000, 295.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([953], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[139.7333, 186.3111, 330.6667, 445.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30], device='cuda:0'), 'image_id': tensor([202], device='cuda:0')}, {'boxes': tensor([[150.4000,  64.0000, 449.2000, 452.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([848], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[187.6000, 187.0222, 259.2000, 366.2222],\n",
      "        [185.6000, 216.8889, 270.8000, 403.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1564], device='cuda:0')}, {'boxes': tensor([[228.8000, 123.7333, 333.6000, 182.0444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1379], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 60.8000,  54.0444, 510.9333, 416.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1025], device='cuda:0')}, {'boxes': tensor([[222.0000,   0.0000, 397.6000, 263.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1454], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[201.6000, 156.4444, 288.4000, 338.4889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1332], device='cuda:0')}, {'boxes': tensor([[ 62.9333,  58.3111, 394.6667, 436.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1696], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[291.6557, 149.3333, 493.5712, 322.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1971], device='cuda:0')}, {'boxes': tensor([[169.6000, 271.6444, 251.2000, 337.0667],\n",
      "        [120.8000, 275.9111, 207.2000, 342.0444],\n",
      "        [272.0000, 233.9556, 356.8000, 301.5111],\n",
      "        [226.8000, 184.8889, 320.0000, 254.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([136], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.1333, 174.9333, 342.4000, 287.2889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1064], device='cuda:0')}, {'boxes': tensor([[ 50.8000, 156.4444, 111.6000, 201.9556],\n",
      "        [337.6000, 206.2222, 350.4000, 221.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26,  7], device='cuda:0'), 'image_id': tensor([2080], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[320.0000, 248.8889, 507.2000, 509.1555],\n",
      "        [ 86.4000,   0.0000, 236.8000, 280.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23, 24], device='cuda:0'), 'image_id': tensor([1613], device='cuda:0')}, {'boxes': tensor([[  0.0000,  17.7778, 304.0000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([1180], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[196.8000, 266.6667, 343.2000, 344.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1923], device='cuda:0')}, {'boxes': tensor([[256.4000, 110.9333, 378.0000, 471.4667],\n",
      "        [306.4000, 190.5778, 379.6000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1533], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[286.4000, 117.3333, 403.2000, 509.8667],\n",
      "        [ 81.6000, 145.0667, 273.6000, 509.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1411], device='cuda:0')}, {'boxes': tensor([[ 44.8000,  44.0889, 282.0000, 440.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([547], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[179.6000, 216.1778, 389.6000, 505.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2169], device='cuda:0')}, {'boxes': tensor([[113.6000, 211.9111, 264.0000, 283.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([40], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 92.9185, 173.5111, 297.7185, 327.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([21], device='cuda:0'), 'image_id': tensor([756], device='cuda:0')}, {'boxes': tensor([[196.0000, 283.0222, 289.2000, 349.8667],\n",
      "        [238.8000, 271.6444, 315.6000, 336.3556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7, 7], device='cuda:0'), 'image_id': tensor([1822], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 85.2000, 182.7556, 282.8000, 356.2667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([28], device='cuda:0'), 'image_id': tensor([368], device='cuda:0')}, {'boxes': tensor([[141.2000, 244.6222, 315.6000, 477.8667],\n",
      "        [ 35.6000, 221.1555, 348.0000, 435.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([558], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[252.8000, 125.8667, 350.8000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([8], device='cuda:0')}, {'boxes': tensor([[176.0000, 104.5333, 191.2000, 155.0222],\n",
      "        [238.0000, 244.6222, 251.6000, 268.8000],\n",
      "        [244.4000, 405.3333, 314.8000, 455.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 9, 24, 24], device='cuda:0'), 'image_id': tensor([1880], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  98.1333, 425.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1295], device='cuda:0')}, {'boxes': tensor([[199.2000, 104.5333, 478.8000, 499.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([313], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 98.4000, 245.3333, 309.2000, 389.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13], device='cuda:0'), 'image_id': tensor([1160], device='cuda:0')}, {'boxes': tensor([[162.0000, 238.9333, 473.6000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4], device='cuda:0'), 'image_id': tensor([1646], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[119.2000, 114.4889, 220.4000, 247.4667],\n",
      "        [272.8000, 159.2889, 314.0000, 292.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([850], device='cuda:0')}, {'boxes': tensor([[ 88.8000, 175.6444, 241.6000, 398.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([21], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[257.2000, 276.6222, 326.8000, 330.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1883], device='cuda:0')}, {'boxes': tensor([[ 67.2000,  27.0222, 361.6000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([595], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000,  62.5778, 313.6000, 327.8222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([25], device='cuda:0'), 'image_id': tensor([1848], device='cuda:0')}, {'boxes': tensor([[219.2000, 192.0000, 396.8000, 395.6364],\n",
      "        [141.6000, 244.3636, 229.6000, 385.4546]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1321], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[131.6000,   7.1111, 502.4000, 424.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([305], device='cuda:0')}, {'boxes': tensor([[255.2000, 186.1818, 400.8000, 320.0000],\n",
      "        [203.2000, 221.0909, 276.8000, 320.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([30, 30], device='cuda:0'), 'image_id': tensor([1315], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[130.4000, 201.9556, 510.4000, 475.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([584], device='cuda:0')}, {'boxes': tensor([[178.4000,  57.6000, 306.4000, 257.4222],\n",
      "        [294.4000,  36.9778, 450.8000, 270.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([564], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[175.6000, 278.0444, 258.8000, 375.4667],\n",
      "        [ 22.4000, 200.5333, 210.0000, 381.8667],\n",
      "        [140.8000, 269.5111, 238.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22, 22, 22], device='cuda:0'), 'image_id': tensor([514], device='cuda:0')}, {'boxes': tensor([[148.4000, 125.1556, 318.4000, 395.3778],\n",
      "        [ 21.6000, 147.2000, 333.6000, 369.7778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([552], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[219.2000, 264.5333, 347.2000, 334.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1922], device='cuda:0')}, {'boxes': tensor([[167.6000,  34.8444, 243.2000, 115.9111],\n",
      "        [298.4000, 251.0222, 364.8000, 349.8667],\n",
      "        [373.2000,  91.0222, 404.4000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 24, 24], device='cuda:0'), 'image_id': tensor([1868], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 258.8445, 203.2000, 402.4889],\n",
      "        [266.4000, 261.6889, 301.6000, 391.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([765], device='cuda:0')}, {'boxes': tensor([[  4.0000, 218.3111, 467.2000, 423.1111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1211], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[480.0000, 273.0667, 509.6000, 366.9333],\n",
      "        [185.6000,  68.2667, 298.4000, 409.6000],\n",
      "        [158.4000, 331.3778, 214.4000, 409.6000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 2,  2, 20], device='cuda:0'), 'image_id': tensor([508], device='cuda:0')}, {'boxes': tensor([[128.8000, 110.9333, 305.6000, 453.6889],\n",
      "        [  0.0000,  89.6000,  64.0000, 224.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18], device='cuda:0'), 'image_id': tensor([1770], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 151.4667, 357.6000, 334.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1978], device='cuda:0')}, {'boxes': tensor([[248.8000,   0.7111, 510.8000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10], device='cuda:0'), 'image_id': tensor([274], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,   0.0000, 435.2000, 301.5111],\n",
      "        [340.8000, 284.4445, 511.2000, 510.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24, 23], device='cuda:0'), 'image_id': tensor([1622], device='cuda:0')}, {'boxes': tensor([[224.8000, 147.9111, 314.4000, 386.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1992], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[228.0000, 159.2889, 311.2000, 399.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1994], device='cuda:0')}, {'boxes': tensor([[134.0000, 193.4222, 375.2000, 414.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([1603], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[223.2000, 145.0667, 369.6000, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([83], device='cuda:0')}, {'boxes': tensor([[ 74.4000, 125.8667, 348.4000, 418.1333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([649], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[191.2000, 142.2222, 468.0000, 328.5333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([334], device='cuda:0')}, {'boxes': tensor([[118.0000, 226.1333, 442.8000, 510.5778],\n",
      "        [  0.0000, 229.6889, 135.6000, 482.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4], device='cuda:0'), 'image_id': tensor([1788], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[134.4000, 106.6667, 194.4000, 376.8889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([1138], device='cuda:0')}, {'boxes': tensor([[282.0000, 179.9111, 383.6000, 292.9778],\n",
      "        [100.0000, 135.8222, 292.8000, 462.2222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([901], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[165.6000, 182.0444, 226.4000, 294.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([630], device='cuda:0')}, {'boxes': tensor([[192.4000, 119.4667, 505.6000, 395.3778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([227], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[355.2000, 192.0000, 429.8667, 268.8000],\n",
      "        [240.0000, 275.9111, 277.3333, 352.7111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([ 5, 24], device='cuda:0'), 'image_id': tensor([1702], device='cuda:0')}, {'boxes': tensor([[108.4000, 108.0889, 273.6000, 314.3111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2047], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 73.2000,   0.0000, 510.8000, 508.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([1658], device='cuda:0')}, {'boxes': tensor([[4.0000e-01, 1.7280e+02, 4.0680e+02, 3.0933e+02]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([739], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.2667, 179.2000, 229.3333, 244.6222],\n",
      "        [224.0000, 176.3556, 289.0667, 244.6222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([365], device='cuda:0')}, {'boxes': tensor([[224.0000,  80.3556, 292.8000, 219.7333],\n",
      "        [137.6000, 105.9556, 177.6000, 190.5778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9, 9], device='cuda:0'), 'image_id': tensor([1189], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[157.8667,   0.0000, 394.6667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18], device='cuda:0'), 'image_id': tensor([2087], device='cuda:0')}, {'boxes': tensor([[180.4000,  56.8889, 329.6000, 450.8445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([9], device='cuda:0'), 'image_id': tensor([875], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[169.2000, 251.0222, 317.6000, 329.9556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([1921], device='cuda:0')}, {'boxes': tensor([[224.8000, 216.1778, 348.4000, 349.8667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([2191], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[136.5333,  46.9333, 419.2000, 344.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([716], device='cuda:0')}, {'boxes': tensor([[201.2000, 206.9333, 300.0000, 275.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([2041], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[197.6000, 123.7333, 270.0000, 310.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1333], device='cuda:0')}, {'boxes': tensor([[  0.0000, 172.8000, 292.0000, 384.0000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1216], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1273], device='cuda:0')}, {'boxes': tensor([[ 61.6000, 302.9333, 164.0000, 420.9778],\n",
      "        [ 60.4000, 237.5111,  98.0000, 309.3333],\n",
      "        [109.2000, 223.2889, 222.4000, 334.9333],\n",
      "        [ 60.8000, 166.4000, 156.8000, 270.2222],\n",
      "        [106.4000, 110.9333, 213.2000, 219.7333],\n",
      "        [208.8000, 157.8667, 317.6000, 286.5778],\n",
      "        [264.4000, 228.2667, 369.6000, 338.4889],\n",
      "        [324.8000, 227.5556, 432.0000, 332.0889],\n",
      "        [162.0000, 187.0222, 269.2000, 294.4000],\n",
      "        [400.8000, 381.1555, 448.4000, 429.5111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([122], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[172.8000, 258.8445, 511.2000, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([3], device='cuda:0'), 'image_id': tensor([1225], device='cuda:0')}, {'boxes': tensor([[151.4667, 159.2889, 222.9333, 219.0222],\n",
      "        [216.5333, 169.2444, 300.8000, 227.5556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([361], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[180.4000, 185.6000, 258.8000, 396.8000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12], device='cuda:0'), 'image_id': tensor([1338], device='cuda:0')}, {'boxes': tensor([[111.2000,  98.8444, 430.8000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([8], device='cuda:0'), 'image_id': tensor([645], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[194.8000, 118.7556, 500.8000, 390.4000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([7], device='cuda:0'), 'image_id': tensor([228], device='cuda:0')}, {'boxes': tensor([[  0.0000,  41.2444, 510.8000, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([580], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 54.4000, 247.4667, 179.2000, 375.4667],\n",
      "        [405.3333, 228.9778, 434.1333, 307.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([10, 12], device='cuda:0'), 'image_id': tensor([696], device='cuda:0')}, {'boxes': tensor([[189.6000,  66.0984, 396.8000, 481.5738]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([956], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[154.8000,  52.6222, 362.4000, 421.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([343], device='cuda:0')}, {'boxes': tensor([[288.0000,  98.1333, 372.2667, 220.4444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([1585], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[128.0000, 164.2667, 307.2000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([543], device='cuda:0')}, {'boxes': tensor([[ 28.8000, 175.6444, 201.6000, 381.1555],\n",
      "        [388.8000, 179.2000, 460.8000, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([11, 11], device='cuda:0'), 'image_id': tensor([1522], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[140.0000, 196.2667, 216.0000, 477.8667],\n",
      "        [264.8000, 170.6667, 308.0000, 335.6444],\n",
      "        [478.4000, 213.3333, 509.6000, 371.2000]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([4, 4, 4], device='cuda:0'), 'image_id': tensor([780], device='cuda:0')}, {'boxes': tensor([[333.8667,  29.8667, 510.9333, 228.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1724], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[ 20.4000,   9.9556, 509.2000, 507.0222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([22], device='cuda:0'), 'image_id': tensor([1581], device='cuda:0')}, {'boxes': tensor([[ 43.6000, 217.6000, 191.2000, 433.0667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([15], device='cuda:0'), 'image_id': tensor([1655], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  36.9778, 228.2667, 261.6889]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1476], device='cuda:0')}, {'boxes': tensor([[317.6000, 234.6667, 366.0000, 312.1778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([24], device='cuda:0'), 'image_id': tensor([1870], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[  0.0000,  15.6444, 234.6667, 465.0667],\n",
      "        [296.5333,  48.3556, 509.8667, 321.4222]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([12, 12], device='cuda:0'), 'image_id': tensor([611], device='cuda:0')}, {'boxes': tensor([[ 97.6000,  76.8000, 253.6000, 250.3111],\n",
      "        [254.4000,  51.2000, 369.6000, 238.9333]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2], device='cuda:0'), 'image_id': tensor([1736], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[340.2667, 193.4222, 410.6667, 290.1333],\n",
      "        [254.9333, 192.0000, 358.4000, 285.8667],\n",
      "        [148.2667, 157.8667, 204.8000, 236.0889],\n",
      "        [433.0667, 221.8667, 510.9333, 335.6444]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([2, 2, 2, 2], device='cuda:0'), 'image_id': tensor([355], device='cuda:0')}, {'boxes': tensor([[106.0000,  49.0667, 511.2000, 452.9778]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([26], device='cuda:0'), 'image_id': tensor([749], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[171.6000, 230.4000, 509.6000, 499.9111]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([23], device='cuda:0'), 'image_id': tensor([586], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1607], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[261.3333,  91.0222, 509.8667, 509.1555]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([14], device='cuda:0'), 'image_id': tensor([1731], device='cuda:0')}, {'boxes': tensor([[142.8000, 127.2889, 239.6000, 425.9556],\n",
      "        [236.8000, 117.3333, 354.0000, 388.9778],\n",
      "        [222.4000, 201.9556, 274.4000, 369.7778],\n",
      "        [  0.0000, 273.0667,  24.0000, 291.5555],\n",
      "        [101.6000, 252.4444, 143.6000, 270.2222],\n",
      "        [455.6000, 343.4667, 510.4000, 371.2000],\n",
      "        [444.8000, 437.3333, 511.2000, 458.6667]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([18, 18, 18, 28, 28, 28, 28], device='cuda:0'), 'image_id': tensor([2069], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([[150.0000, 179.2000, 374.0000, 444.4445]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([17], device='cuda:0'), 'image_id': tensor([2158], device='cuda:0')}, {'boxes': tensor([[282.8000, 161.4222, 393.6000, 299.3778],\n",
      "        [ 94.0000, 142.2222, 290.4000, 470.7556]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([13, 13], device='cuda:0'), 'image_id': tensor([904], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n",
      "[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([1515], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'image_id': tensor([2090], device='cuda:0')}] torch.Size([3, 512, 512])\n",
      "Caught exception with running metrics for one valid image (skipped)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot reshape tensor of 0 elements into shape [0, -1, 4] because the unspecified dimension size -1 can be any value and is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e455798daba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 50,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-b1dbdd86237c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                         \u001b[0mvalid_loss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                         \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mregression_targets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             loss_classifier, loss_box_reg = fastrcnn_loss(\n\u001b[0;32m--> 761\u001b[0;31m                 class_logits, box_regression, labels, regression_targets)\n\u001b[0m\u001b[1;32m    762\u001b[0m             losses = {\n\u001b[1;32m    763\u001b[0m                 \u001b[0;34m\"loss_classifier\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss_classifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/roi_heads.py\u001b[0m in \u001b[0;36mfastrcnn_loss\u001b[0;34m(class_logits, box_regression, labels, regression_targets)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlabels_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_pos_inds_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mbox_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     box_loss = det_utils.smooth_l1_loss(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1, 4] because the unspecified dimension size -1 can be any value and is ambiguous"
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 50,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_net_trained = train(mob_net, 3, train_loader, valid_loader, 0.0005, weight_decay = 1e-5, print_times_per_epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 50.0\n",
      "Device: cuda\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/10 | Batch Number: 50 | LR: 0.00100 | Train_loss: 904.50 | Valid_loss: 235.18 | Valid mAP: 0.00% | Valid Missed Images 100 / 100\n",
      "torch.Size([3, 512, 512]) [{'boxes': tensor([[ 75.7760, 136.8408, 510.9760, 510.4625]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([5], device='cuda:0'), 'image_id': tensor([421], device='cuda:0')}, {'boxes': tensor([[188.4160, 101.0347, 355.3280, 248.4907]], device='cuda:0',\n",
      "       dtype=torch.float64), 'labels': tensor([27], device='cuda:0'), 'image_id': tensor([665], device='cuda:0')}]\n",
      "Caught an exception in an image could not predict metric for it\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-bcdb84b15e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmob_net_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmob_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-90869e855fe9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.001, weight_decay = 1e-5, print_times_per_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Every: 6499.0\n",
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n",
      "Device: cuda\n",
      "Optimizer: SAM (\n",
      "Parameter Group 0\n",
      "    N_sma_threshhold: 5\n",
      "    alpha: 0.5\n",
      "    betas: (0.95, 0.999)\n",
      "    eps: 1e-05\n",
      "    initial_lr: 0.0001\n",
      "    k: 6\n",
      "    lr: 0.0001\n",
      "    rho: 0.05\n",
      "    step_counter: 0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Epoch 1/10 | Batch Number: 6499 | LR: 0.00010 | Train_loss: 2358.17 | Valid_loss: 504.38 | Valid mAP: 10.56% | Valid Missed Images 24 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/10 | Batch Number: 12998 | LR: 0.00010 | Train_loss: 2171.53 | Valid_loss: 506.35 | Valid mAP: 10.90% | Valid Missed Images 27 / 3082\n",
      "Epoch 1/10 | Batch Number: 19497 | LR: 0.00010 | Train_loss: 2285.98 | Valid_loss: 490.59 | Valid mAP: 9.40% | Valid Missed Images 13 / 3082\n",
      "Epoch 1/10 | Batch Number: 25996 | LR: 0.00010 | Train_loss: 2500.76 | Valid_loss: 542.19 | Valid mAP: 23.81% | Valid Missed Images 801 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 1/10 | Batch Number: 32495 | LR: 0.00010 | Train_loss: 12414371.06 | Valid_loss: 1925.38 | Valid mAP: 2.00% | Valid Missed Images 0 / 3082\n",
      "\n",
      " Epoch 1 | Epoch Time 66608.08 | Final Train mAP: 13.40% | Final Train Missed Images 5064 / 64995 \n",
      "\n",
      "Saving Model path to directory Faster_rcnn_Saved_Models ... \n",
      "Succesfully saved model data to file path. \n",
      "\n",
      "Epoch 2/10 | Batch Number: 6499 | LR: 0.00010 | Train_loss: 23351.43 | Valid_loss: 675.11 | Valid mAP: 20.61% | Valid Missed Images 1790 / 3082\n",
      "Epoch 2/10 | Batch Number: 12998 | LR: 0.00010 | Train_loss: 3715.10 | Valid_loss: 605.79 | Valid mAP: 4.40% | Valid Missed Images 2890 / 3082\n",
      "Caught error. Now trying to instill transforms using Pytorch transforms\n",
      "Epoch 2/10 | Batch Number: 19497 | LR: 0.00009 | Train_loss: 2779.39 | Valid_loss: 604.81 | Valid mAP: 0.56% | Valid Missed Images 3051 / 3082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-449305a17999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.0001, weight_decay = 1e-5, print_times_per_epoch = 5,\n\u001b[0;32m----> 2\u001b[0;31m                         saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV1\")\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-e6e43a2f926b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, train_loader, valid_loader, lr, weight_decay, print_times_per_epoch, lo_valid_dataset, lo_train_dataset, saving_directory, unique_char_for_saving)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Check for degenerate boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m                                  \"of shape [C, H, W], got {}\".format(image.shape))\n\u001b[1;32m    104\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, image, target)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36mresize_boxes\u001b[0;34m(boxes, original_size, new_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     ]\n\u001b[1;32m    273\u001b[0m     \u001b[0mratio_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torchvision/models/detection/transform.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_orig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     ]\n\u001b[1;32m    273\u001b[0m     \u001b[0mratio_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mob_net_trained = train(mob_net, 10, train_loader, valid_loader, 0.0001, weight_decay = 1e-5, print_times_per_epoch = 5,\n",
    "                        saving_directory = \"Faster_rcnn_Saved_Models\", unique_char_for_saving = \"FastRCNNResNetV1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model function. \n",
    "* Only will run if you have .pth file that configures nicely with Faster RCNN Resnet50FPN\n",
    "* If model crashes while training, then might have to load in optimizer.\n",
    "\n",
    "#### Example Code of Succesful save: \n",
    "`\n",
    "checkpoint_file = \"Faster_rcnn_Saved_Models/Epoch3FastRCNNResNetV1.pth\"\n",
    "new_mob_net = load_model_fast_rcnn(checkpoint_file) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_fast_rcnn(checkpoint_file, mished = True):\n",
    "    \n",
    "    #Get model configuration\n",
    "    model = torchvision.models.detection.faster_rcnn.fasterrcnn_resnet50_fpn(pretrained = False)\n",
    "    model.roi_heads.box_predictor.cls_score.out_features = len(get_class_info())\n",
    "    model.roi_heads.box_predictor.bbox_pred.out_features = len(get_class_info()) * 4\n",
    "    \n",
    "    if mished:\n",
    "        convert_it(mob_net, Mish(), nn.ReLU6)\n",
    "    \n",
    "    #Load in state dicts \n",
    "    if os.path.isfile(checkpoint_file):\n",
    "        checkpoint = torch.load(checkpoint_file)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])   \n",
    "    else:\n",
    "        raise ValueError(\"Checkpoint File does not exist\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Effecient Det Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1122397 train images in total\n",
      "\n",
      "\n",
      "BEFORE DET: Amount of image files in Dataset 54647\n",
      "BEFORE DET: Amount of annotation files in Dataset 54647 \n",
      "\n",
      "Amount of images in Det Set (Approx.) 21455\n",
      "Amount of image files in Dataset 76102\n",
      "Amount of annotation files in Dataset 76102\n",
      "\n",
      "\n",
      "Loading with Effecient Det Structure ... \n",
      "\n",
      "Amount of image files in Dataset 2201\n",
      "Amount of annotation files in Dataset 2201\n",
      "\n",
      "\n",
      "Loading with Effecient Det Structure ... \n",
      "\n",
      " \n",
      " ... Seperate from Data Loader \n",
      "\n",
      "Length of train_dataset 500\n",
      "Length of valid_dataset 100\n"
     ]
    }
   ],
   "source": [
    "#Util Scoring Function\n",
    "def run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, mAP, missed_images, device):\n",
    "    assert (len(scores) == len(classification) == len(transformed_anchors))\n",
    "    if len(transformed_anchors) != 0:\n",
    "        curr_mAP = calculate_metrics(targets[0][:, :4], transformed_anchors, scores, device)\n",
    "        mAP += curr_mAP\n",
    "    else:\n",
    "        missed_images += 1 \n",
    "      \n",
    "    return mAP, missed_images\n",
    "\n",
    "def detection_collate(batch):\n",
    "    imgs = [s['image'] for s in batch]\n",
    "    annots = [s['bboxes'] for s in batch]\n",
    "    labels = [s['category_id'] for s in batch]\n",
    "\n",
    "    max_num_annots = max(len(annot) for annot in annots)\n",
    "    annot_padded = np.ones((len(annots), max_num_annots, 5))*-1\n",
    "\n",
    "    if max_num_annots > 0:\n",
    "        for idx, (annot, lab) in enumerate(zip(annots, labels)):\n",
    "            if len(annot) > 0:\n",
    "                annot_padded[idx, :len(annot), :4] = annot\n",
    "                annot_padded[idx, :len(annot), 4] = lab\n",
    "    return (torch.stack(imgs, 0), torch.FloatTensor(annot_padded))\n",
    "\n",
    "eff_train_batch = 8\n",
    "eff_test_batch = 1\n",
    "det_text_file = \"/data1/group/mlgroup/train_data/ILSVRC2015/DET_train_30classes.txt\"\n",
    "\n",
    "eff_train_dataset = VideoFrameDataset(\"train\", os.path.join(\"Data/VID\", \"train\"), os.path.join(\"Annotations/VID\", \"train\"), get_transforms(mode = \"effdet_train\"), \n",
    "                                  seg_len = 20, det_text_file_paths = det_text_file, effdet_data = True, data_size = 500)\n",
    "eff_valid_dataset = VideoFrameDataset(\"validation\", os.path.join(\"Data/VID\", \"val\"), os.path.join(\"Annotations/VID\", \"val\"), get_transforms(mode = \"effdet_test\"),\n",
    "                                  make_valid_smaller_percent = 0.0125, effdet_data = True, data_size = 100)\n",
    "\n",
    "eff_train_loader = torch.utils.data.DataLoader(eff_train_dataset, batch_size = eff_train_batch, shuffle = True, collate_fn= detection_collate)\n",
    "eff_valid_loader = torch.utils.data.DataLoader(eff_valid_dataset, batch_size = eff_test_batch, shuffle = True, collate_fn = detection_collate)\n",
    "\n",
    "print(\" \\n ... Seperate from Data Loader \\n\")\n",
    "print(\"Length of train_dataset {}\".format(len(eff_train_dataset)))\n",
    "print(\"Length of valid_dataset {}\".format(len(eff_valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Run with DataParallel ....\n",
      "Mish activation loaded...\n"
     ]
    }
   ],
   "source": [
    "MODEL_MAP = {\n",
    "    'efficientdet-d0': 'efficientnet-b0',\n",
    "    'efficientdet-d1': 'efficientnet-b1',\n",
    "    'efficientdet-d2': 'efficientnet-b2',\n",
    "    'efficientdet-d3': 'efficientnet-b3',\n",
    "    'efficientdet-d4': 'efficientnet-b4',\n",
    "    'efficientdet-d5': 'efficientnet-b5',\n",
    "    'efficientdet-d6': 'efficientnet-b6',\n",
    "    'efficientdet-d7': 'efficientnet-b6',\n",
    "}\n",
    "class EfficientDet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 network='efficientdet-d0',\n",
    "                 D_bifpn=3,\n",
    "                 W_bifpn=88,\n",
    "                 D_class=3,\n",
    "                 is_training=True,\n",
    "                 threshold=0.01, #can change this value 0.01\n",
    "                 iou_threshold=0.5): # can change this value 0.5\n",
    "        super(EfficientDet, self).__init__()\n",
    "        \n",
    "        self.backbone = EfficientNet.from_pretrained(MODEL_MAP[network])\n",
    "        self.is_training = is_training\n",
    "        self.neck = BIFPN(in_channels=self.backbone.get_list_features()[-5:],\n",
    "                          out_channels=W_bifpn,\n",
    "                          stack=D_bifpn,\n",
    "                          num_outs=5)\n",
    "        self.bbox_head = RetinaHead(num_classes=num_classes,\n",
    "                                    in_channels=W_bifpn)\n",
    "\n",
    "        self.anchors = Anchors()\n",
    "        self.regressBoxes = BBoxTransform()\n",
    "        self.clipBoxes = ClipBoxes()\n",
    "        self.threshold = threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        self.freeze_bn()\n",
    "        self.criterion = FocalLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.is_training:\n",
    "            inputs, annotations = inputs\n",
    "        else:\n",
    "            inputs = inputs\n",
    "        x = self.extract_feat(inputs)\n",
    "        outs = self.bbox_head(x)\n",
    "        classification = torch.cat([out for out in outs[0]], dim=1)\n",
    "        regression = torch.cat([out for out in outs[1]], dim=1)\n",
    "        anchors = self.anchors(inputs)\n",
    "        if self.is_training:\n",
    "            return self.criterion(classification, regression, anchors, annotations)\n",
    "        else:\n",
    "            transformed_anchors = self.regressBoxes(anchors, regression)\n",
    "            transformed_anchors = self.clipBoxes(transformed_anchors, inputs)\n",
    "            scores = torch.max(classification, dim=2, keepdim=True)[0]\n",
    "            scores_over_thresh = (scores > self.threshold)[0, :, 0]\n",
    "\n",
    "            if scores_over_thresh.sum() == 0:\n",
    "                # print('No boxes to NMS')\n",
    "                # no boxes to NMS, just return\n",
    "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\n",
    "            classification = classification[:, scores_over_thresh, :]\n",
    "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\n",
    "            scores = scores[:, scores_over_thresh, :]\n",
    "            anchors_nms_idx = nms(\n",
    "                transformed_anchors[0, :, :], scores[0, :, 0], iou_threshold=self.iou_threshold)\n",
    "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(\n",
    "                dim=1)\n",
    "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\n",
    "\n",
    "    def freeze_bn(self):\n",
    "        '''Freeze BatchNorm layers.'''\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.BatchNorm2d):\n",
    "                layer.eval()\n",
    "\n",
    "    def extract_feat(self, img):\n",
    "        \"\"\"\n",
    "            Directly extract features from the backbone+neck\n",
    "        \"\"\"\n",
    "        x = self.backbone(img)\n",
    "        x = self.neck(x[-5:])\n",
    "        return x\n",
    "\n",
    "model= EfficientDet(num_classes=len(get_class_info()),is_training=True)\n",
    "model.train()\n",
    "\n",
    "model.freeze_bn()\n",
    "\n",
    "model = model.cuda()\n",
    "print('Run with DataParallel ....')\n",
    "\n",
    "## Make sure that you add this line, even though you are not using more than one \n",
    "# GPU DataParallel adds \"module\" to the start of the model structure \n",
    "# allowing for the syntax to be correct when calling \"model.module.freeze_bn()\" for example\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# I am doing this here an example, you do not have to call the lines below here\n",
    "model.module.is_training = True\n",
    "model.module.freeze_bn()\n",
    "\n",
    "convert_it(model, Mish(), nn.ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_effdet(net, epochs, train_loader, test_loader, lr, weight_decay, \n",
    "          print_times_per_epoch, lo_test_dataset = len(eff_valid_dataset), lo_train_dataset = len(eff_train_dataset)):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: {}\".format(device))\n",
    "    print(\"Note: Train Accuracies are only run through one train image per batch\")\n",
    "    \n",
    "    print_every = lo_train_dataset / eff_train_batch // print_times_per_epoch\n",
    "    print(\"Print Every: {}\".format(print_every))\n",
    "\n",
    "    if device == torch.device(\"cpu\"):\n",
    "        warnings.warn(\"Code does not support running on CPU but only GPU\")\n",
    "\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "#     scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = len(train_loader) * epochs)\n",
    "\n",
    "    start_time = time.time()\n",
    "    net.module.freeze_bn()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "        net.module.is_training = True\n",
    "        \n",
    "        train_loss = steps = train_mAP = missed_train_images = 0\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "\n",
    "            net.train()\n",
    "            net.module.is_training = True\n",
    "\n",
    "            steps += 1\n",
    "            \n",
    "            images = images.cuda().float()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            classification_loss, regression_loss = net([images, targets])\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "            loss = classification_loss + regression_loss\n",
    "            if bool(loss == 0):\n",
    "                print('loss equal zero(0)')\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            net.eval()\n",
    "            net.module.is_training = False\n",
    "            \n",
    "            #Constant CPU gather error. It was working one time when trying to infer from image\n",
    "#             print(images[0].unsqueeze(0)[0].is_cuda)\n",
    "#             print(images[0].unsqueeze(0)[0][0].is_cuda)\n",
    "            scores, classification, transformed_anchors = net(images[0].unsqueeze(0))\n",
    "            \n",
    "            try:\n",
    "                #Constant CPU gather error. It was working one time\n",
    "                \n",
    "                train_mAP, missed_train_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, train_mAP, \n",
    "                                                                          missed_train_images, device)\n",
    "            except:\n",
    "                print(images.size(), targets.size())\n",
    "                print(\"Caught an exception in an image could not predict metric for it\")\n",
    "                \n",
    "            net.train()\n",
    "            net.module.is_training = True\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if (steps % print_every) == 0:\n",
    "                with torch.no_grad():\n",
    "                    test_mAP = missed_test_images = test_loss = 0\n",
    "\n",
    "                    for images, targets in test_loader:\n",
    "                        if images.size(0) != 1:\n",
    "                            warning.warn(\"Only can validate fully with batch size of 1, \\\n",
    "                            bigger batch sizes risk Errors or Incomplete Validation\")\n",
    "                        \n",
    "                        net.eval()\n",
    "                        net.module.is_training = False\n",
    "\n",
    "                        if device == torch.device(\"cuda\"):\n",
    "                            images = images.cuda().float()\n",
    "                            targets = targets.cuda()\n",
    "\n",
    "                        scores, classification, transformed_anchors = net(images)\n",
    "                        try:\n",
    "                            test_mAP, missed_test_images = run_metrics_for_effdet_batch(scores, classification, transformed_anchors, targets, \n",
    "                                                                                        test_mAP,missed_test_images, device)\n",
    "                        except:\n",
    "                            print(images.size(), targets.size())\n",
    "                            print(\"Caught exception with running metrics for one valid image (skipped)\")\n",
    "\n",
    "                        net.train()\n",
    "                        net.module.is_training = True\n",
    "\n",
    "                        classification_loss, regression_loss = net([images, targets])\n",
    "                        classification_loss = classification_loss.mean()\n",
    "                        regression_loss = regression_loss.mean()\n",
    "                        loss = classification_loss + regression_loss\n",
    "\n",
    "                        test_loss += loss.item()\n",
    "\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        learning_rate_extract = param_group[\"lr\"]\n",
    "                    print(\"Epoch {}/{} | Batch Number: {} | LR: {:0.5f} | Train_loss: {:0.2f} | Test_loss: {:0.2f} | Test mAP: {:0.2f}% | Missed Valid Images: {} / {}\".format(\n",
    "                        epoch + 1, epochs, steps, learning_rate_extract, train_loss, test_loss,  \n",
    "                        (test_mAP / float(lo_test_dataset)) * 100.,missed_test_images, lo_test_dataset))\n",
    "                assert (steps % print_every) == 0\n",
    "                train_loss = 0\n",
    "              # scheduler.step(test_loss / float(lo_test_dataset))\n",
    "             \n",
    "        print(\"\\n Epoch {} | Epoch Time {:0.2f} | Final Train mAP: {:0.2f}% | Epoch {} Final Missed Train Images: {} out of {} images \\n\".format(\n",
    "            epoch + 1, time.time() - epoch_time, (train_mAP / float(lo_train_dataset)) * 100., \n",
    "            epoch + 1, missed_train_images, lo_train_dataset\n",
    "        ))\n",
    "    \n",
    "    print(\"Time for Total Training {:0.2f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Note: Train Accuracies are only run through one train image per batch\n",
      "Print Every: 6.0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Gather function not implemented for CPU tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-63558a85fb48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_effdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meff_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meff_valid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_times_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-a413e41d27fb>\u001b[0m in \u001b[0;36mtrain_effdet\u001b[0;34m(net, epochs, train_loader, test_loader, lr, weight_decay, print_times_per_epoch, lo_test_dataset, lo_train_dataset)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#             print(images[0].unsqueeze(0)[0].is_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#             print(images[0].unsqueeze(0)[0][0].is_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, outputs, output_device)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(outputs, target_device, dim)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Setting the function to None clears the refcycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mgather_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             return type(out)(((k, gather_map([d[k] for d in outputs]))\n\u001b[1;32m     62\u001b[0m                               for k in out))\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# Recursive function calls like this create reference cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mgather_map\u001b[0;34m(outputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mGather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-base/lib/python3.7/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_device, dim, *inputs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         assert all(map(lambda i: i.device.type != 'cpu', inputs)), (\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;34m'Gather function not implemented for CPU tensors'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m         \u001b[0mtarget_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Gather function not implemented for CPU tensors"
     ]
    }
   ],
   "source": [
    "train_effdet(model, 5, eff_train_loader, eff_valid_loader, 0.01, 1e-5, print_times_per_epoch = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aShMihw2d4tB"
   },
   "source": [
    "### Extra Snippets: Using Recurrent Neural Networks with Faster R CNNs\n",
    "\n",
    "https://arxiv.org/pdf/2010.15740.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH2vWjX4IG_U"
   },
   "source": [
    "####  Get all images file paths in a folder and all xml file paths in a folder. Then put in tuple [(image file path1, xml file path1), (image2, xml 2)]\n",
    "\n",
    "Pair the image file paths and xml file paths into a particular scene. \n",
    "So all_scenes dict(): {folder name of one scene: list[(imf_path1, xml1), (img_path2, xml2), (img_path3, xml3)], foler name of second scene}\n",
    "\n",
    "key_path: [scene 1, scene 2, scene 3, scene 4, scene 5]\n",
    "\n",
    "class will get certain_scene = key_path[index] and then all_scenes[certain_scene] -> get access to list of images and labels and then load into image file path. \n",
    "\n",
    "create a tensor called single_scene\n",
    "\n",
    "For one indexed scene\n",
    "for tuple in list we get a tupe like this (img file path, annot file path)\n",
    "open image file path of (tup[0])\n",
    "open xml file and parse to get bounding boxes and other info (tup[1])\n",
    "\n",
    "use torch.stack()\n",
    "\n",
    "Now we have image tensor and target tensor. We can append to the single_scene.\n",
    "\n",
    "return single_scene which is [(image 1 tensor, target tensor of 1), (image 2 tensor, target tensor of 2)] also known as all the images and targets of one scene\n",
    "\n",
    "return this data to dataloader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFgKvZ_k19LQ"
   },
   "outputs": [],
   "source": [
    "def get_per_scene_dict(img_root_path, annotations_root_path):\n",
    "  scene_names = glob.glob(\"{}/*\".format(img_root_path))\n",
    "  all_scenes = dict()\n",
    "  for scene in scene_names:\n",
    "  \n",
    "    image_file_paths = glob.glob(\"{}{}/*.JPEG\".format(img_root_path, scene.split(\"/\")[-1]))\n",
    "    xml_file_paths = glob.glob(\"{}{}/*.xml\".format(annotations_root_path, scene.split(\"/\")[-1]))\n",
    "    image_file_paths, xml_file_paths = sorted(image_file_paths), sorted(xml_file_paths)\n",
    "\n",
    "    assert len(image_file_paths) == len(xml_file_paths)\n",
    "\n",
    "    scene_list = [(image_file_path, xml_file_paths[ii]) for ii, image_file_path in enumerate(image_file_paths)]\n",
    "    all_scenes[scene] = scene_list\n",
    "  \n",
    "  return all_scenes\n",
    "\n",
    "class VideoFrameDataset():\n",
    "    \n",
    "    def __init__(self, all_scenes_dict, transforms, seg_len = 5):\n",
    "\n",
    "      self.all_scenes_dict = all_scenes_dict\n",
    "      self.seg_len = seg_len\n",
    "      self.transforms = transforms\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "      \n",
    "      current_scene = list(self.all_scenes_dict.keys())[idx]\n",
    "      list_of_fp_per_scene = self.all_scenes_dict[current_scene]\n",
    "\n",
    "      #Random Sampling. \n",
    "      if seg_len % 5 != 0:\n",
    "        raise ValueError(\"Not allowed value for seg_len must be divisible by 5\")\n",
    "      if seg_len >= len(list_of_fp_per_scene):\n",
    "        raise ValueError(\"Segments are bigger than the amount of frames available for a scene\")\n",
    "      \n",
    "      list_of_fp_per_scene = list_of_fp_per_scene[:-(len(list_of_fp_per_scene) % seg_len)]\n",
    "      reduced_fp_per_scene, start_index = list(), 0\n",
    "      for window in range(int(len(list_of_fp_per_scene) / self.seg_len))\n",
    "        end_index = start_index + self.seg_len\n",
    "        reduced_fp_per_scene.append(random.sample(list_of_fp_per_scene[start_index: end_index], 1)[0])\n",
    "        start_index = end_index\n",
    "      \n",
    "      scene_images, scene_bboxes = [], []\n",
    "      for data in reduced_fp_per_scene:\n",
    "        img_path, xml_path = data\n",
    "\n",
    "        img = cv2.cvtColor(cv2.imread(img_path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "        xml_doc = ElementTree.parse(xml_path)\n",
    "\n",
    "        bounding_boxes = xml_doc.findall(\"object/bndbox\")\n",
    "\n",
    "        bbox = []\n",
    "        for node in bounding_boxes:\n",
    "          xmax = node.find(\"xmax\").text\n",
    "          xmin = node.find(\"xmin\").text\n",
    "          ymax = node.find(\"ymax\").text\n",
    "          ymin = node.find(\"ymin\").text\n",
    "\n",
    "          bbox.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n",
    "        \n",
    "        bbox = torch.as_tensor(bbox, dtype = torch.float32)\n",
    "        \n",
    "        if self.transforms: \n",
    "          sample = {\n",
    "              'image': img,\n",
    "              'bboxes': bbox,\n",
    "              'labels': labels\n",
    "              }\n",
    "\n",
    "        sample = self.transforms(**sample)\n",
    "        augmented_img = sample['image']\n",
    "        augmented_bbox = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "\n",
    "        scene_bboxes.append(augmented_bbox)\n",
    "        scene_images.append(augmented_img)\n",
    "      \n",
    "      scene_images, scene_bboxes = torch.stack(scene_images), torch.stack(scene_bboxes)\n",
    "\n",
    "      scene_target = dict() \n",
    "      scene_target[\"boxes\"] = scene_bboxes\n",
    "\n",
    "      scene_target[\"image_id\"] = ###############################################\n",
    "      scene_target[\"labels\"] = #################################################\n",
    "\n",
    "      return scene_images, scene_target\n",
    "      \n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nChPPsoeUE2M"
   },
   "outputs": [],
   "source": [
    "def test(net, test_loader, ####):\n",
    "\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    test_mAP = test_loss = test_missed_images = 0\n",
    "    for images, targets in test_loader:\n",
    "\n",
    "        if device == torch.device(\"cuda\"):\n",
    "          images = [image.to(device) for image in images]\n",
    "          targets = [{key: value.to(device) for key, value in t.items()} for t in targets]\n",
    "\n",
    "        net.eval()\n",
    "        output = net(images)\n",
    "        test_mAP, test_missed_images = run_metrics_for_batch(output, targets, test_mAP, test_missed_images, device)\n",
    "\n",
    "        net.train()\n",
    "        test_loss_dict = net(images, targets)\n",
    "        test_losses = sum(loss for loss in test_loss_dict.values())\n",
    "        test_loss += test_losses\n",
    "\n",
    "    print(\"Test mAP {:0.2f}% | Test Loss {:0.2f} | Test Missed Images {} / {}\".format(test_mAP, test_loss, test_missed_images, #####))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links that I used to get notebook running with correct 3rd party packages\n",
    "\n",
    "* https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "* https://www.digitalocean.com/community/tutorials/how-to-set-up-jupyter-notebook-with-python-3-on-ubuntu-18-04\n",
    "* Make sure after running packages update on conda environment to shut down and reopen notebook for update.\n",
    "* Just git clone in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resizer(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512):\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "        height, width, _ = image.shape\n",
    "        if height > width:\n",
    "            scale = self.img_size / height\n",
    "            resized_height = self.img_size\n",
    "            resized_width = int(width * scale)\n",
    "        else:\n",
    "            scale = self.img_size / width\n",
    "            resized_height = int(height * scale)\n",
    "            resized_width = self.img_size\n",
    "\n",
    "        image = cv2.resize(image, (resized_width, resized_height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        new_image = np.zeros((self.img_size, self.img_size, 3))\n",
    "        new_image[0:resized_height, 0:resized_width] = image\n",
    "\n",
    "        annots[:, :4] *= scale\n",
    "\n",
    "        return {'img': torch.from_numpy(new_image).to(torch.float32), 'annot': torch.from_numpy(annots), 'scale': scale}\n",
    "\n",
    "\n",
    "class Augmenter(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, flip_x=0.5):\n",
    "        if np.random.rand() < flip_x:\n",
    "            image, annots = sample['img'], sample['annot']\n",
    "            image = image[:, ::-1, :]\n",
    "\n",
    "            rows, cols, channels = image.shape\n",
    "\n",
    "            x1 = annots[:, 0].copy()\n",
    "            x2 = annots[:, 2].copy()\n",
    "\n",
    "            x_tmp = x1.copy()\n",
    "\n",
    "            annots[:, 0] = cols - x2\n",
    "            annots[:, 2] = cols - x_tmp\n",
    "\n",
    "            sample = {'img': image, 'annot': annots}\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Normalizer(object):\n",
    "\n",
    "    def __init__(self, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        self.mean = np.array([[mean]])\n",
    "        self.std = np.array([[std]])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, annots = sample['img'], sample['annot']\n",
    "\n",
    "        return {'img': ((image.astype(np.float32) - self.mean) / self.std), 'annot': annots}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ILSVRCVid2015VideoDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "169081d5b0d94288a2b0ebb020b790d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1c3baca68a4e42afa680e581e92a7e82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28ba486f593a4109bd152e94c871919d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c3baca68a4e42afa680e581e92a7e82",
      "max": 14212972,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_169081d5b0d94288a2b0ebb020b790d3",
      "value": 14212972
     }
    },
    "4839a59e79b6413bab12980f433870dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc398d009abc4ff7872a46b6e7bd497e",
      "placeholder": "​",
      "style": "IPY_MODEL_cb9ef1bcc2334f7190b70c08a16090f7",
      "value": " 13.6M/13.6M [00:16&lt;00:00, 875kB/s]"
     }
    },
    "afba5dfb1b1a4811b1b0c02f03cb3c8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbfa8ade6ff548aab08c392fe4bb20f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_28ba486f593a4109bd152e94c871919d",
       "IPY_MODEL_4839a59e79b6413bab12980f433870dc"
      ],
      "layout": "IPY_MODEL_afba5dfb1b1a4811b1b0c02f03cb3c8d"
     }
    },
    "cb9ef1bcc2334f7190b70c08a16090f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc398d009abc4ff7872a46b6e7bd497e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
