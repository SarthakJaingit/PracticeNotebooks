{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom string import punctuation\nfrom collections import Counter\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\nfrom torch import optim","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let us check if the kernel is using GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu = torch.cuda.is_available()\n\nif train_on_gpu:\n    print(\"GPU is available and will be used\")\nelse:\n    print(\"CPU is available and will be used\")\n","execution_count":2,"outputs":[{"output_type":"stream","text":"GPU is available and will be used\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Read File**\n* This code open up the file and reads so it will be interpreted as a byte by bte file"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"file = open(\"../input/poetry/Kanye_West.txt\")\ndata = file.read()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stats(data):\n    data = data.split(\"\\n\")\n    line_size = len(data)\n    sum_of_lenlines = 0\n    for line in data:\n        line = line.split()\n        sum_of_lenlines += len(line)\n    \n    average_per_line = sum_of_lenlines / line_size\n    return average_per_line, line_size\n\ndef print_stats(average_per_line, line_size):\n    print(\"The average words per line is: \" + str(average_per_line))\n    print(\"The amount of lines there are: \" + str(line_size))\n    \naverage_per_line, line_size = get_stats(data)\nprint_stats(average_per_line, line_size)","execution_count":4,"outputs":[{"output_type":"stream","text":"The average words per line is: 8.298562893589537\nThe amount of lines there are: 6193\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_text(text):\n    text_no_punc = \"\".join(char for char in text if char not in punctuation)\n    text_no_punc = text_no_punc.lower()\n    \n    text_split = text_no_punc.split()\n    text_split.pop(0)\n    return text_split\n\nsplit_data = preprocess_text(data)\n\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_v_to_int(split_data):\n    #Frequency of every word in a dictionary\n    vocab_freq = Counter(split_data)\n    sorted_vocab = sorted(vocab_freq, key = vocab_freq.get, reverse = True)\n    vocab_to_int = {word: idx for idx, word in enumerate(sorted_vocab)}\n    int_to_vocab = {idx: word for idx, word in enumerate(sorted_vocab)}\n    \n    return vocab_to_int, int_to_vocab\n\nvocab_to_int, int_to_vocab = get_v_to_int(split_data)\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_int_text(data_split):\n    int_text = [vocab_to_int[word] for word in data_split]\n    return int_text\n\nint_text = get_int_text(split_data)\n        \n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's define some labels and target Tensors\n* We have to first see how much (sequence_lenght * batch_size) batches square can fit into int_text\n* We then want to develop our target tensors and then our labels.\n\n#### For Example\n* [[Hello, my, really, long, name, is], [[I, really, like, to, play]]\n* [Sarthak, Ball]\n\n* [[9, 78, 97, 32, 14, 90], [6, 7, 2, 1, 3, 6]] - That would be one sentence\n* [67, 23] - That would be the target "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_data_loader(integer_text, batch_size, sequence_length):\n    \n    #Our x must be a sentence \n    #Our y must be the next word\n    \n    #Let's make our batches fit\n    number_per_batch = batch_size * sequence_length\n    batch_number = len(integer_text) // number_per_batch\n    \n    #Determine new length of int_text\n    integer_text = list(integer_text[:batch_number * sequence_length * batch_size])\n    \n    number_of_targets = len(integer_text) - sequence_length\n    data_x = []\n    target_y = []\n    \n    for idx in range(number_of_targets):\n        #First find the context numbers\n        end_idx = idx + sequence_length\n        current_context = int_text[idx : end_idx]\n        data_x.append(current_context)\n        \n        #Now we have to find the the next word to the context\n        next_word = int_text[end_idx]\n        target_y.append(next_word)\n        \n    #Turn numpy array into a Tensor\n    data_x = torch.from_numpy(np.array(data_x))\n    data_y = torch.from_numpy(np.array(target_y))\n    \n    dataset = TensorDataset(data_x, data_y)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size)\n    \n    return dataloader        ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDataLoaderfunc = create_data_loader(int_text, batch_size = 10, sequence_length = 8)\nbatch_iter_test = iter(testDataLoaderfunc)\n\nsample_x, sample_y = batch_iter_test.next()\nprint(sample_x)\nprint(\"\\n\\n\")\nprint(sample_y)\n\n\n\n","execution_count":9,"outputs":[{"output_type":"stream","text":"tensor([[ 239, 1096,  239,   21,   22,   75,   17,   16],\n        [1096,  239,   21,   22,   75,   17,   16,  173],\n        [ 239,   21,   22,   75,   17,   16,  173,   22],\n        [  21,   22,   75,   17,   16,  173,   22,    2],\n        [  22,   75,   17,   16,  173,   22,    2,   31],\n        [  75,   17,   16,  173,   22,    2,   31, 1096],\n        [  17,   16,  173,   22,    2,   31, 1096,  239],\n        [  16,  173,   22,    2,   31, 1096,  239,    1],\n        [ 173,   22,    2,   31, 1096,  239,    1,   25],\n        [  22,    2,   31, 1096,  239,    1,   25,  240]])\n\n\n\ntensor([ 173,   22,    2,   31, 1096,  239,    1,   25,  240, 1743])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN (nn.Module):\n    \n    def __init__(self, vocab_size, embedding_dimensions, n_of_layers, hidden_dimensions, output_size, dropout = 0.25):\n        super(RNN, self).__init__()\n        \n        self.output_size = output_size\n        self.n_of_layers = n_of_layers\n        self.hidden_dim = hidden_dimensions\n        \n        self.embedding_layer = nn.Embedding(vocab_size, embedding_dimensions)\n        self.lstm = nn.LSTM(embedding_dimensions, hidden_dimensions, n_of_layers, dropout = dropout, batch_first = True)\n        \n        self.fc1 = nn.Linear(hidden_dimensions, output_size)\n        \n        \n        \n    def forward(self, context, hidden):\n        \n        batch_size = context.size(0)\n        embeddings = self.embedding_layer(context)\n        lstm_output, hidden = self.lstm(embeddings)\n        \n        lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)\n        \n        output = self.fc1(lstm_output)\n        output = output.view(batch_size, -1, self.output_size)\n        \n        output_word = output[:, -1]\n        \n        return output_word, hidden\n    \n    def init_hidden(self, batch_size):\n        \n        weight = next(self.parameters()).data\n        \n        if (train_on_gpu):\n            hidden = (weight.new(self.n_of_layers, batch_size, self.hidden_dim).zero_().cuda(),\n                  weight.new(self.n_of_layers, batch_size, self.hidden_dim).zero_().cuda())\n        else:\n            hidden = (weight.new(self.n_of_layers, batch_size, self.hidden_dim).zero_(),\n                      weight.new(self.n_of_layers, batch_size, self.hidden_dim).zero_())\n        \n        return hidden\n    ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_and_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n    \n    if train_on_gpu:\n        rnn.cuda()\n    \n    h = ([each.data for each in hidden])\n    \n    \n    optimizer.zero_grad()\n    output_word, hidden = rnn(inp, h)\n    loss = criterion(output_word, target)\n    loss.backward()\n    \n    optimizer.step()\n    \n    batch_loss = loss.item()\n    return batch_loss, hidden\n    ","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is where we will now finish the training model and Setting HyperParameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(rnn, batch_size, epochs, train_loader, optimizer, criterion):\n    \n    for count, epoch in enumerate(range(epochs)):\n        train_loss = 0\n        hidden = rnn.init_hidden(batch_size)\n        \n        for batch_i, (context, target) in enumerate(train_loader):\n            \n            if train_on_gpu:\n                context, target = context.cuda(), target.cuda()\n                \n            batch_loss, hidden = forward_and_back_prop(rnn, optimizer, criterion, context, target, hidden)\n            \n            train_loss += batch_loss\n        \n        print(\"Epoch: \", str(count), \"Train Loss: \", str(train_loss))\n            ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### vocab_size, embedding_dimensions, n_of_layers, hidden_dimensions, output_size, dropout = 0.25\n\nvocab_size = len(vocab_to_int)\nembedding_dimensions = 200\nn_of_layers = 2\nhidden_dimensions = 250\noutput_size = vocab_size\n\nlyric_rnn = RNN(vocab_size, embedding_dimensions, n_of_layers, hidden_dimensions, output_size, dropout = 0.25)\n","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### This is where we will define Training Hyperparameters "},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 15\nlr = 0.001\nrnn_optimizer = optim.Adam(lyric_rnn.parameters(), lr = lr)\ncriterion = nn.CrossEntropyLoss()\n\n# Lets us define a train_loader\nbatch_size = 20\nsequence_length = 7\n\ntrain_loader = create_data_loader(int_text, batch_size, sequence_length)\n\n","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets us train the model by putting all the hyperparamters in the train function"},{"metadata":{"trusted":true},"cell_type":"code","source":"train(lyric_rnn, batch_size, epochs, train_loader, rnn_optimizer, criterion)","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch:  0 Train Loss:  16745.937193393707\nEpoch:  1 Train Loss:  14668.418756723404\nEpoch:  2 Train Loss:  13246.659477472305\nEpoch:  3 Train Loss:  11990.370819330215\nEpoch:  4 Train Loss:  10839.431100726128\nEpoch:  5 Train Loss:  9849.846519231796\nEpoch:  6 Train Loss:  8994.414194345474\nEpoch:  7 Train Loss:  8296.985239446163\nEpoch:  8 Train Loss:  7783.301341831684\nEpoch:  9 Train Loss:  7185.863565444946\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}